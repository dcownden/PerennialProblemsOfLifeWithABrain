{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcownden/PerennialProblemsOfLifeWithABrain/blob/split-and-simple-perturb/sequences/P2C1_Optimization/P2C1_Sequence4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "K10DbaXu1WBL"
      },
      "source": [
        "The following is part of a test for an upcoming text book on computational neuroscience from an optimization and learning perspective. The book will start with evolution because ultimately, all aspects of the brain are shaped by evolution and, as we will see, evolution can also be seen as an optimization algorithm. We are sharing it now to get feedback on what works and what does not and the developments we should do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "dsQ6T5OZ1WBM"
      },
      "source": [
        "___\n",
        "# **2.1.4: Learning Behaviour as a form of High Dimensional Optimization**\n",
        "\n",
        "### Objective: Explicitly connect the kinds of simple optimization process we saw in the previous sequences to learning adaptive behaviours.\n",
        "\n",
        "In this sequence we will:\n",
        "\n",
        "* Introduce a slightly more complex version of the strike-no-strike problem where the decision depends on 64 features instead of 1, and develop a simple artificial neural network that can solve this problem\n",
        "\n",
        "* Use perturb-measure-step to train this network\n",
        "\n",
        "* Investigate different times scales of learning and function evaluation.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "rK0I5ANa1WBM"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Run the following cell to setup and install the various dependencies and helper functions for this ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {},
        "id": "g9MNYxfk1WBN",
        "cellView": "form",
        "outputId": "15409dbc-6dda-465d-fbda-639412e79339",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best feature is 21\n",
            "Random seed 2021 has been set.\n",
            "This notebook isn't using and doesn't need a GPU. Good.\n",
            "Running in colab\n"
          ]
        }
      ],
      "source": [
        "# @title Dependencies, Imports and Setup\n",
        "# @markdown You don't need to worry about how this code works – but you do need to **run the cell**\n",
        "!apt install libgraphviz-dev > /dev/null 2> /dev/null #colab\n",
        "!pip install ipympl pygraphviz vibecheck datatops jupyterquiz ucimlrepo > /dev/null 2> /dev/null #google.colab\n",
        "\n",
        "import asyncio\n",
        "import requests\n",
        "from requests.exceptions import RequestException\n",
        "import numpy as np\n",
        "import itertools\n",
        "import collections\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.lines import Line2D\n",
        "from matplotlib.colors import LogNorm\n",
        "from matplotlib.animation import FuncAnimation\n",
        "from matplotlib import gridspec\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import pygraphviz as pgv\n",
        "import ipywidgets as widgets\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import os\n",
        "import copy\n",
        "import torch\n",
        "import warnings\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from io import BytesIO\n",
        "from enum import Enum\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.stats import norm\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tabulate import tabulate\n",
        "from IPython.display import display, clear_output, Markdown, HTML, Image\n",
        "from jupyterquiz import display_quiz\n",
        "from vibecheck import DatatopsContentReviewContainer\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "from tqdm.notebook import tqdm\n",
        "from ucimlrepo import fetch_ucirepo\n",
        "\n",
        "data_set = fetch_ucirepo(id=80)\n",
        "X = data_set.data.features.values\n",
        "# Translate the data to have a minimum of 0\n",
        "X_translated = X - X.min()\n",
        "# Scale the data to have a range from 0 to 12 (which is 6 - (-6))\n",
        "scaling_factor = 12 / (X.max() - X.min())\n",
        "X_scaled = X_translated * scaling_factor\n",
        "# Finally, shift the data to be centered between -6 and 6\n",
        "X_final = X_scaled - 6\n",
        "\n",
        "y = data_set.data.targets.values\n",
        "rng = np.random.default_rng(seed=2021)\n",
        "scramble_permutation = rng.permutation(X.shape[1])\n",
        "Xs = X_final[:, scramble_permutation]\n",
        "y1 = y % 2\n",
        "y2 = np.array(y >= 5, dtype=y.dtype)\n",
        "simple_index = ((y.flatten()==1) | (y.flatten()==0))\n",
        "X_simple = Xs[simple_index]\n",
        "y1_simple = y1[simple_index]\n",
        "# if you only had one feature which would likely be best for discrimination\n",
        "epsilon = 10\n",
        "class_a_sep = np.mean(X_simple[y1_simple.flatten() == 1, :], axis=0) / (np.std(X_simple[y1_simple.flatten() == 1, :], axis=0) + epsilon)\n",
        "class_b_sep = np.mean(X_simple[y1_simple.flatten() == 0, :], axis=0) / (np.std(X_simple[y1_simple.flatten() == 0, :], axis=0) + epsilon)\n",
        "best_feature = np.argmax(class_a_sep - class_b_sep)\n",
        "print(f'Best feature is {best_feature}')\n",
        "X_simple_1_feature = X_simple[:, [best_feature]]\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
        "# random seed settings and\n",
        "# getting torch to use gpu if it's there\n",
        "\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  \"\"\"\n",
        "  Function that controls randomness. NumPy and random modules must be imported.\n",
        "\n",
        "  Args:\n",
        "    seed : Integer\n",
        "      A non-negative integer that defines the random state. Default is `None`.\n",
        "    seed_torch : Boolean\n",
        "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
        "      must be imported. Default is `True`.\n",
        "\n",
        "  Returns:\n",
        "    Nothing.\n",
        "  \"\"\"\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "  \"\"\"\n",
        "  DataLoader will reseed workers following randomness in\n",
        "  multi-process data loading algorithm.\n",
        "\n",
        "  Args:\n",
        "    worker_id: integer\n",
        "      ID of subprocess to seed. 0 means that\n",
        "      the data will be loaded in the main process\n",
        "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def set_device():\n",
        "  \"\"\"\n",
        "  Set the device. CUDA if available, CPU otherwise\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"This notebook isn't using and doesn't need a GPU. Good.\")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook but not needed.\")\n",
        "    print(\"If possible, in the menu under `Runtime` -> \")\n",
        "    print(\"`Change runtime type.`  select `CPU`\")\n",
        "\n",
        "  return device\n",
        "\n",
        "\n",
        "SEED = 2021\n",
        "set_seed(seed=SEED)\n",
        "DEVICE = set_device()\n",
        "\n",
        "\n",
        "def printmd(string):\n",
        "  display(Markdown(string))\n",
        "\n",
        "\n",
        "# the different utility .py files used in this notebook\n",
        "filenames = []\n",
        "# just run the code straight out of the response, no local copies needed!\n",
        "for filename in filenames:\n",
        "  url = f'https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/utils/{filename}'\n",
        "  response = requests.get(url)\n",
        "  # Check that we got a valid response\n",
        "  if response.status_code == 200:\n",
        "    code = response.content.decode()\n",
        "    exec(code)\n",
        "  else:\n",
        "    print(f'Failed to download {url}')\n",
        "\n",
        "# environment contingent imports\n",
        "try:\n",
        "  print('Running in colab')\n",
        "  from google.colab import output\n",
        "  output.enable_custom_widget_manager()\n",
        "  from google.colab import data_table\n",
        "  data_table.disable_dataframe_formatter()\n",
        "  #from google.colab import output as colab_output\n",
        "  #colab_output.enable_custom_widget_manager()\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "  print('Not running in colab')\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib widget\n",
        "plt.style.use(\"https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/pplb.mplstyle\")\n",
        "plt.ioff() #need to use plt.show() or display explicitly\n",
        "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)\n",
        "\n",
        "\n",
        "def remove_ip_clutter(fig):\n",
        "  fig.canvas.header_visible = False\n",
        "  fig.canvas.toolbar_visible = False\n",
        "  fig.canvas.resizable = False\n",
        "  fig.canvas.footer_visible = False\n",
        "  fig.canvas.draw()\n",
        "\n",
        "\n",
        "def content_review(notebook_section: str):\n",
        "  return DatatopsContentReviewContainer(\n",
        "    \"\",  # No text prompt\n",
        "    notebook_section,\n",
        "    {\n",
        "      \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
        "      \"name\": \"neuro_book\",\n",
        "      \"user_key\": \"xuk960xj\",\n",
        "    },\n",
        "  ).render()\n",
        "feedback_prefix = \"P2C1_S2\""
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1.4.1 Learning Strike-No-Strike with Perturb-Measure-Step.\n",
        "\n",
        "Now that we know a bit about optimization in higher-dimensions we are going to introduce a harder, higher-dimensional version of our strike-no-strike problem. Whereas previously we had only a single input, now we are going to allow for 64 different inputs. So our cartoon organism that inspires this problem can now be thought of as having 64 photo-sensitive receptors, and based on this combination of inputs it must decide whether to strike or not. As before, the organism pays a cost of one if it strikes when it shouldn't and recieves a reward of one if it strikes when it should. It receives no cost or reward when it does not strike. To get a sense of this more complex discrimination problem, try it yourself by running the code cell below."
      ],
      "metadata": {
        "id": "OR3gHzvHXExf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown **Run this cell** to try out the more complex 'strike-no-strike' discrimination task.\n",
        "\n",
        "class InteractiveMNISTPredator():\n",
        "  def __init__(self,\n",
        "               features=Xs,\n",
        "               labels=y,\n",
        "               feedback_type='on_strike_only', seed=123):\n",
        "    # Initialize dataset, settings for image scrambling and feedback\n",
        "    self.features = features\n",
        "    self.labels = labels\n",
        "    # features is num_data_points x 64 (reshape to 8x8 for display, each cell 0-16)\n",
        "    # labels is num_data_points x 1 (values 0-9 or 0/1 depending)\n",
        "    self.feedback_type = feedback_type\n",
        "    self.rng = np.random.default_rng(seed)\n",
        "    sample_order = self.rng.permutation(self.features.shape[0])\n",
        "    self.features = self.features[sample_order]\n",
        "    self.labels = self.labels[sample_order]\n",
        "    # initialize game state\n",
        "    self.current_index = 0\n",
        "    self.current_image = None\n",
        "    self.previous_image = None\n",
        "    self.score = 0\n",
        "    self.best_possible_score = 0\n",
        "    self.successful_strikes = 0\n",
        "    self.failed_strikes = 0\n",
        "    self.non_strikes = 0\n",
        "    # Initialize widgets\n",
        "    self.strike_button = widgets.Button(description='Strike')\n",
        "    self.no_strike_button = widgets.Button(description='No Strike')\n",
        "    self.score_display = widgets.Output()\n",
        "    self.feedback_display = widgets.Output()\n",
        "\n",
        "    # Initialize the figure for image display\n",
        "    self.fig, self.ax = plt.subplots(figsize=(4, 4))\n",
        "    remove_ip_clutter(self.fig)\n",
        "    self.prev_fig, self.prev_ax = plt.subplots(figsize=(4, 4))\n",
        "    remove_ip_clutter(self.prev_fig)\n",
        "    self.show_next_image()\n",
        "    # Bind event handlers\n",
        "    self.strike_button.on_click(self.on_strike_clicked)\n",
        "    self.no_strike_button.on_click(self.on_no_strike_clicked)\n",
        "\n",
        "    # Arrange widgets in a layout\n",
        "    buttons_layout = widgets.HBox([self.strike_button, self.no_strike_button])\n",
        "    current_buttons = widgets.VBox([self.fig.canvas, buttons_layout])\n",
        "    previous_feedback = widgets.VBox([self.prev_fig.canvas, self.feedback_display])\n",
        "    self.ui = widgets.HBox([previous_feedback, current_buttons, self.score_display])\n",
        "\n",
        "  def show_next_image(self):\n",
        "    # Display the next image\n",
        "    image = self.features[self.current_index]\n",
        "\n",
        "    if len(image) == 64:\n",
        "        image = image.reshape(8, 8)\n",
        "    elif len(image) == 1:\n",
        "      scalar_value = image.flatten()[0]\n",
        "      # Initialize the 8x8 array with -6 (black)\n",
        "      image = np.full((8, 8), -6.0)\n",
        "      # Set the first ring to 6 (white)\n",
        "      image[0, 0] = 6\n",
        "      # Set the second ring to 6 (white)\n",
        "      image[1:-1, 1:-1] = 6\n",
        "      # Set the third (inner ring) back to -6 (black)\n",
        "      image[2:-2, 2:-2] = -6\n",
        "      # Assuming scalar_value is already in the range -6 to 6\n",
        "      #print(scalar_value)\n",
        "      image[3:-3, 3:-3] = scalar_value\n",
        "    else:\n",
        "      raise ValueError(f'Unexpected image shape: {image.shape}')\n",
        "    if self.current_image is not None:\n",
        "      self.previous_image = self.current_image\n",
        "    self.current_image = image\n",
        "    # Display the image\n",
        "    #print(image)\n",
        "    self.fig.clf()\n",
        "    self.prev_fig.clf()\n",
        "    self.ax = self.fig.add_subplot(111)\n",
        "    self.prev_ax = self.prev_fig.add_subplot(111)\n",
        "    self.ax.set_xlim(-.5, 7.5)\n",
        "    self.ax.set_ylim(-0.5, 7.5)\n",
        "    self.prev_ax.set_xlim(-.5, 7.5)\n",
        "    self.prev_ax.set_ylim(-0.5, 7.5)\n",
        "    self.ax.set_aspect('equal')\n",
        "    self.prev_ax.set_aspect('equal')\n",
        "    self.ax.axis('off')\n",
        "    self.prev_ax.axis('off')\n",
        "    self.ax.imshow(self.current_image, cmap='gray', vmin=-6, vmax=6)\n",
        "    if self.previous_image is not None:\n",
        "      self.prev_ax.imshow(self.previous_image, cmap='gray', vmin=-6, vmax=6)\n",
        "    self.ax.set_title('Current Sensory Input')\n",
        "    self.prev_ax.set_title('Previous Sensory Input')\n",
        "    self.fig.canvas.draw()\n",
        "    self.prev_fig.canvas.draw()\n",
        "\n",
        "  def on_strike_clicked(self, button):\n",
        "    self.process_decision('Strike')\n",
        "\n",
        "  def on_no_strike_clicked(self, button):\n",
        "    self.process_decision('No Strike')\n",
        "\n",
        "  def process_decision(self, decision):\n",
        "    # freeze buttons while we process\n",
        "    self.strike_button.disabled = True\n",
        "    self.no_strike_button.disabled = True\n",
        "\n",
        "    # Process the user's decision, update score, and provide feedback\n",
        "    correct_action = 'Strike' if self.labels[self.current_index] == 1 else 'No Strike'\n",
        "    if decision == 'Strike':\n",
        "      if decision == correct_action:\n",
        "        self.score += 1\n",
        "        self.successful_strikes += 1\n",
        "      else:\n",
        "        self.score -= 1\n",
        "        self.failed_strikes += 1\n",
        "    elif decision == 'No Strike':\n",
        "      self.non_strikes += 1\n",
        "      # no strike means no gain or loss\n",
        "    else:\n",
        "      raise ValueError(f'Unknown decision: {decision}')\n",
        "\n",
        "    # Show feedback and score\n",
        "    if (self.feedback_type == 'both' or\n",
        "      (self.feedback_type == 'on_strike_only' and decision == 'Strike')):\n",
        "      # Show informative feedback\n",
        "      feedback = f'Your last choice: {decision}\\nCorrect last choice: {correct_action}'\n",
        "    else:\n",
        "      # Show uninformative feedback\n",
        "      feedback = 'Feedback only available after striking.'\n",
        "    with self.feedback_display:\n",
        "      clear_output(wait=True)\n",
        "      print(feedback)\n",
        "\n",
        "    # Show score\n",
        "    with self.score_display:\n",
        "      clear_output(wait=True)\n",
        "      average_score = self.score / (self.current_index+1)\n",
        "      print(f'Total Score: {self.score}')\n",
        "      print(f'Number of Trials: {self.current_index + 1}')\n",
        "      print(f'Successful Strikes: {self.successful_strikes}')\n",
        "      print(f'Failed Strikes: {self.failed_strikes}')\n",
        "      print(f'Non-Strikes: {self.non_strikes}')\n",
        "      print(f'Average Score Per Trial: {average_score:.2f}')\n",
        "\n",
        "    # Prepare the next image\n",
        "    self.current_index += 1\n",
        "    #print(self.current_index)\n",
        "    self.show_next_image()\n",
        "    # Re-enable buttons\n",
        "    self.strike_button.disabled = False\n",
        "    self.no_strike_button.disabled = False\n",
        "\n",
        "\n",
        "scramble_bin_hard = InteractiveMNISTPredator(features=Xs,\n",
        "                                             labels=y1,\n",
        "                                             feedback_type='both')\n",
        "display(scramble_bin_hard.fig.canvas)\n",
        "display(scramble_bin_hard.prev_fig.canvas)\n",
        "clear_output()\n",
        "display(scramble_bin_hard.ui)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "y_YjCpnZCNyn",
        "outputId": "82050e53-9cba-436e-dee7-0c8ca1b13ecf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 457,
          "referenced_widgets": [
            "2947ec06cd5545fb801bdbc651d74df2",
            "4f30e724bae74aa3b9e0d4120aa39fce",
            "999058aa8ca745e19a7655f8571a3d2b",
            "c125bc87c18e4c3ca1e58acd9c5e3ef7",
            "54f530103aca46d3a5b7266779524896",
            "f13af96f4c424c10acdf5155dadc2ffb",
            "daa2526573ac4020a054b6f11381f973",
            "9c6683dbd61548f2976a52e78dcc06f1",
            "250e7860a0ab4ddf864e02037a884e2f",
            "e0cea406af6d40678a04869b37d8d652",
            "e9214185418c44a0aa75c075413f7304",
            "c6a93a90798947ac867a5c59ce59ff44",
            "390be4278e3648f49745cb61dd340a92",
            "236178ed397b4827ac0354668142428d",
            "ef672c7c29344e0386183bc0c66d70a6",
            "5b0a3d5a470040848438cd1b6b833abb",
            "50d103a151904dc489c7d896579540c5",
            "09eec50638fe476281e68383ae6f4ee9",
            "e9cdcf4ef2fc411ba98e875710134688",
            "90635d639dfb4395a39556bdb5554ac4",
            "830d4cba359e46c893fa8fe14bc86b85",
            "eb02cab145bb462c8db65407ae5c5160",
            "92595e2f4135470594c0d980974c9512",
            "fb0af9b77b104a999adf702c39bce84a",
            "4b274d399c814e459aa45e52b2ab3857",
            "fd4ad9b28d984f6e8533c6c9329059e1"
          ]
        }
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(VBox(children=(Canvas(footer_visible=False, header_visible=False, resizable=False, toolbar=Tool…"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2947ec06cd5545fb801bdbc651d74df2"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maybe you were able to solve this with some savant like abstract pattern recognition powers. We were not able to learn to discriminate between the strike and no-strike situations over a dozen or so trials. The point here is that this is a non-trivial discrimination to learn. However, it is, as we will see in the next bit of code, a discrimination that a simple artificial neural network can learn to solve. (As before The dataset that underlies this strike-no-strike decision problem is sourced from the UCI Machine Learning Repository, Alpaydin,E. and Kaynak,C. 1998. https://doi.org/10.24432/C50P49.)"
      ],
      "metadata": {
        "id": "968qM9kkIK29"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We model this creature's sensory-behaviour system much as before. Now though, $\\mathbf{x}$ is the raw sensory input (vector) of length 64 in a given episode. Each element $x_i$ of $\\mathbf{x}$ corresponds to the activation level of a single photosensitive neuron."
      ],
      "metadata": {
        "id": "1CgwmAlsJG_w"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "execution": {},
        "id": "t4Uem5FrI5K_",
        "outputId": "561bf387-1cc1-46c4-e309-663ad4532e73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(5620, 64)\n"
          ]
        }
      ],
      "source": [
        "# the data set we're working with has 5620 example sensory inputs,\n",
        "# each consisting of 64 values\n",
        "print(Xs.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "execution": {},
        "id": "nLzHDIjCI5K_",
        "outputId": "f6e05aeb-63ae-4999-e598-cb7520536027",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[-1.5   0.   -4.5  -5.25  3.    5.25 -3.75 -6.  ]\n",
            " [-6.   -6.   -2.25 -0.75  4.5  -1.5  -6.   -6.  ]\n",
            " [-4.5  -6.   -6.   -6.   -6.   -6.   -0.75 -5.25]\n",
            " [-0.75  4.5  -3.75  0.75 -2.25 -1.5  -0.75  3.75]\n",
            " [-6.   -5.25  5.25  0.   -6.    1.5   3.   -0.75]\n",
            " [-6.   -6.   -6.   -6.   -5.25 -6.    3.75  6.  ]\n",
            " [-6.   -6.   -2.25 -6.   -6.    2.25 -6.   -1.5 ]\n",
            " [ 6.    6.   -6.   -6.   -3.   -6.    0.75 -6.  ]]\n"
          ]
        }
      ],
      "source": [
        "# this is the first example\n",
        "print(Xs[0].reshape(8,8,))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "execution": {},
        "id": "qJgsx8nSI5K_",
        "outputId": "67edae95-012f-4439-b086-5524762f081c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425,
          "referenced_widgets": [
            "ccf7ab4377c84562bb5c4e7813e79122",
            "b921a573a8cb48b39b70348eecf4a92c",
            "8a344acb04414e37993a0d7362d05052",
            "0fb7378294fc4b7f86b0c61fa1161eb1"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Canvas(footer_visible=False, header_visible=False, resizable=False, toolbar=Toolbar(toolitems=[('Home', 'Reset…"
            ],
            "image/png": "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",
            "text/html": [
              "\n",
              "            <div style=\"display: inline-block;\">\n",
              "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
              "                    Figure\n",
              "                </div>\n",
              "                <img src='data:image/png;base64,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' width=400.0/>\n",
              "            </div>\n",
              "        "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ccf7ab4377c84562bb5c4e7813e79122"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "# visualizing the example we see that lower values correspond to darker pixels\n",
        "# and higher values correspond to lighter values\n",
        "fig, ax = plt.subplots(figsize=(4,4))\n",
        "remove_ip_clutter(fig)\n",
        "ax.imshow(Xs[0].reshape(8,8), cmap='gray')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "These input neurons are then connected by synapses to a single output neuron. The activation level of this output neuron is computed as\n",
        "$$a = \\mathbf{Wx} + b$$\n",
        "Here, $b$ is the (scalar) bias, or baseline activation level of the output neuron, and $\\mathbf{W}$ is a matrix of synaptic weights between the input neurons and the single output neuron. (In this case where there is only one output neuron so $\\mathbf{W}$ has shape 1x64 so could also be thought of as a row vector.)  \n",
        "\n",
        "Often to simplify exposition and coding the input $\\mathbf{x}$ is augmented to have a feature which is always 1, and then the bias terms can be treated as the weight connecting to this constant valued feature. That is\n",
        "\n",
        "$$a = \\mathbf{Wx}$$\n",
        "\n",
        "Though now $\\mathbf{W}$ has shape 1x65. As before, the probabilistic spiking of this output neuron determines the strike-no-strike behaviour of the organism, specifically:\n",
        "$$ \\Pr \\{\\text{strike}\\} = \\sigma(a) $$\n",
        "$$ \\Pr \\{\\text{no strike}\\} = 1 - \\sigma(a)$$\n",
        "\n",
        "Recall that $\\sigma(a): \\frac{1}{1+e^{-a}} = \\frac{e^a}{1+e^a}$ is the standard logistic (sigmoid) function."
      ],
      "metadata": {
        "id": "cyjeHHWJJ_vX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The organism recieves a reward of 1 for striking at the right time and a penalty of -1 for striking at the wrong time. It also recieves a reward of zero when not striking, regardless of whether striking would have returned a reward or a penalty. Given this, complete the coding exercise below to write a function that determines the reward recieved for a given sensory input $\\mathbf{x}$, the organism's probablistic response to the stimulus, $\\Pr \\{\\text{strike}\\} = \\sigma(\\mathbf{Wx})$, and the resultant outcome of the behaviour given the presence ($y=1$) or absence ($y=0$) of prey. Note that reward depends on three inputs, two $\\mathbf{x}$ and $y$ have to do with the state of the environment, and are fully outside of the control of the organism, the other $\\mathbf{W}$ determines the organism's response to the environment, and it is this $\\mathbf{W}$, that the organism has some control over in that sense that $\\mathbf{W}$ is what changes as a result of learning."
      ],
      "metadata": {
        "id": "9fnPqbxRKPhl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO for students: Complete the lines with ... set the appropriate rewards for\n",
        "# for the evaluations function\n",
        "raise NotImplementedError(\"Exercise: Set the reward for different outcomes\")\n",
        "################################################################################\n",
        "\n",
        "# As a little trick to keep our code cleaner we 'hide' our bias term.\n",
        "# We to do this by augmenting the features to include a feature that always has the value '1'.\n",
        "# Then, the 'weight' associated with this feature, which always has a value of '1', effectively serves as the bias term.\n",
        "# After augmentation there is one extra column of features\n",
        "Xs_aug = np.hstack([Xs, np.ones((Xs.shape[0],1))])\n",
        "\n",
        "def np_sigmoid(x):\n",
        "  x = np.clip(x, -500, 500) #prevent overflow, fine because sigmoid saturates\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def eval_params_stochastic_single(W, x, y, verbose=False, rng=None):\n",
        "  \"\"\"\n",
        "  evaluates parameters of simple behaviour circuit given inputs and target\n",
        "  outputs, use numpy broadcasting to be fast and concise\n",
        "  Args:\n",
        "    W: (outputs(1) x inputs(65) np.array)\n",
        "       weights between sensory neurons and output neuron\n",
        "    x: (input(65) np.array) sensory input\n",
        "    y: (outputs(1) np.array) target behavioural output\n",
        "\n",
        "  Returns:\n",
        "    R: the reward obtained given the parameters, inputs and targets\n",
        "  \"\"\"\n",
        "  if rng is None:\n",
        "    rng = np.random.default_rng()\n",
        "  # activaation\n",
        "  a = np.dot(W,x)\n",
        "  # strike probability\n",
        "  y_hat = np_sigmoid(a)\n",
        "  # what the organism actually does\n",
        "  # rng.random is a sample from the uniform distribution on [0,1)\n",
        "  y_sample = rng.random() < y_hat\n",
        "  if y_sample == 1: #organism strikes\n",
        "    if y == 1: #prey is present\n",
        "      R = ...\n",
        "    else: # prey is not present\n",
        "      R = ...\n",
        "  else: # organism does not strike\n",
        "    R = ...\n",
        "  if verbose:\n",
        "    print(f'Probability of striking: {y_hat}')\n",
        "    action_string = 'Strike' if y_sample == 1 else 'No Strike'\n",
        "    print(f'Action taken: {action_string}')\n",
        "    target_string = 'Strike' if y == 1 else 'No Strike'\n",
        "    print(f'Correct Action: {target_string}')\n",
        "    print(f'Reward recieved: {R}')\n",
        "  else:\n",
        "    return R\n",
        "\n",
        "eval_rng = np.random.default_rng(0)\n",
        "W_test = np.zeros((1,65))\n",
        "eval_params_stochastic_single(W_test, Xs_aug[0], y1[0], verbose=True, rng=eval_rng)"
      ],
      "metadata": {
        "id": "dAB-xsyQNzFs",
        "outputId": "f315c7eb-30ac-4d54-e313-19b6f3266e75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NotImplementedError",
          "evalue": "Exercise: Set the reward for different outcomes",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-ff37001ffa4f>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;31m# TODO for students: Complete the lines with ... set the appropriate rewards for\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# for the evaluations function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Exercise: Set the reward for different outcomes\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m################################################################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNotImplementedError\u001b[0m: Exercise: Set the reward for different outcomes"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# to_remove solution\n",
        "\n",
        "# As a little trick to keep our code cleaner we 'hide' our bias term.\n",
        "# We to do this by augmenting the features to include a feature that always has the value '1'.\n",
        "# Then, the 'weight' associated with this feature, which always has a value of '1', effectively serves as the bias term.\n",
        "# After augmentation there is one extra column of features\n",
        "Xs_aug = np.hstack([Xs, np.ones((Xs.shape[0],1))])\n",
        "\n",
        "def np_sigmoid(x):\n",
        "  x = np.clip(x, -500, 500) #prevent overflow, fine because sigmoid saturates\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def eval_params_stochastic_single(W, x, y, verbose=False, rng=None):\n",
        "  \"\"\"\n",
        "  evaluates parameters of simple behaviour circuit given inputs and target\n",
        "  outputs, use numpy broadcasting to be fast and concise\n",
        "  Args:\n",
        "    W: (outputs(1) x inputs(65) np.array)\n",
        "       weights between sensory neurons and output neuron\n",
        "    x: (input(65) np.array) sensory input\n",
        "    y: (outputs(1) np.array) target behavioural output\n",
        "\n",
        "  Returns:\n",
        "    R: the reward obtained given the parameters, inputs and targets\n",
        "  \"\"\"\n",
        "  if rng is None:\n",
        "    rng = np.random.default_rng()\n",
        "  # activaation\n",
        "  a = np.dot(W,x)\n",
        "  # strike probability\n",
        "  y_hat = np_sigmoid(a)\n",
        "  # what the organism actually does\n",
        "  # rng.random is a sample from the uniform distribution on [0,1)\n",
        "  y_sample = rng.random() < y_hat\n",
        "  if y_sample == 1: #organism strikes\n",
        "    if y == 1: #prey is present\n",
        "      R = 1\n",
        "    else: # prey is not present\n",
        "      R = -1\n",
        "  else: # organism does not strike\n",
        "    R = 0\n",
        "  if verbose:\n",
        "    print(f'Probability of striking: {y_hat}')\n",
        "    action_string = 'Strike' if y_sample == 1 else 'No Strike'\n",
        "    print(f'Action taken: {action_string}')\n",
        "    target_string = 'Strike' if y == 1 else 'No Strike'\n",
        "    print(f'Correct Action: {target_string}')\n",
        "    print(f'Reward recieved: {R}')\n",
        "  else:\n",
        "    return R\n",
        "\n",
        "eval_rng = np.random.default_rng(0)\n",
        "W_test = np.zeros((1,65))\n",
        "eval_params_stochastic_single(W_test, Xs_aug[0], y1[0], verbose=True, rng=eval_rng)"
      ],
      "metadata": {
        "id": "mz00q3D8h1kx",
        "outputId": "2912fb75-f62f-435b-8597-967eda38bcc5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Probability of striking: [0.5]\n",
            "Action taken: No Strike\n",
            "Correct Action: No Strike\n",
            "Reward recieved: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So that evaluates the reward over a single experience. We can use numpy broadcasting to apply this same reward calculation efficiently to many, even all, the input-out pairs in our data set. We call this **batch** evaluation."
      ],
      "metadata": {
        "id": "gPh6sBUTnZnc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "################################################################################\n",
        "# TODO for students: Complete the lines with ... to compute the number of\n",
        "# True Positives, False Positives, True Negative and False Negatives in the batch\n",
        "raise NotImplementedError(\"Exercise: Compute the number of different Outcomes\")\n",
        "################################################################################\n",
        "\n",
        "def eval_params_stochastic_batch(W, x, y, verbose=False, rng=None):\n",
        "  \"\"\"\n",
        "  evaluates parameters of simple behaviour circuit given inputs and target\n",
        "  outputs, use numpy broadcasting to be fast and concise\n",
        "  Args:\n",
        "    W: (outputs(1) x inputs(65) np.array)\n",
        "       weights between sensory neurons and output neuron\n",
        "    x: (input(65) x batch np.array) sensory input\n",
        "    y: (outputs(1) x batch np.array) target behavioural output\n",
        "\n",
        "  Returns:\n",
        "    R: the reward obtained given the parameters, inputs and targets\n",
        "  \"\"\"\n",
        "  if rng is None:\n",
        "    rng = np.random.default_rng()\n",
        "  # activaation\n",
        "  a = np.dot(W,x) # 1 x batch\n",
        "  # strike probability\n",
        "  y_hat = np_sigmoid(a) # 1 x batch\n",
        "  # what the organism actually does\n",
        "  # rng.random is a sample from the uniform distribution on [0,1)\n",
        "  y_sample = rng.random(size=y_hat.shape) < y_hat  # 1 x batch\n",
        "  R = np.zeros(y_sample.shape)\n",
        "  did_strike = y_sample == ...\n",
        "  did_not_strike = y_sample == ...\n",
        "  should_strike = y == ...\n",
        "  should_not_strike = y == ...\n",
        "  TP = np.logical_and(did_strike, should_strike) # True Positive\n",
        "  FP = np.logical_and(did_strike, should_not_strike) # False Positive\n",
        "  FN = np.logical_and(did_not_strike, should_strike) # False Negative\n",
        "  TN = np.logical_and(did_not_strike, should_not_strike) # True Negative\n",
        "  R[TP] = 1\n",
        "  R[FP] = -1\n",
        "  R[FN] = 0\n",
        "  R[TN] = 0\n",
        "  TPs = np.sum(TP)\n",
        "  FPs = np.sum(FP)\n",
        "  FNs = np.sum(FN)\n",
        "  TNs = np.sum(TN)\n",
        "  confusion_matrix = np.array([[TPs, FNs], [FPs, TNs]])\n",
        "  if verbose:\n",
        "    table = [[\"Should Strike\", TPs, FNs],\n",
        "                 [\"Shouldn't Strike\", FPs, TNs]]\n",
        "    headers = [\"\", \"Did Strike\", \"Didn't Strike\"]\n",
        "    print(\"Confusion_matrix: \")\n",
        "    print(tabulate(table, headers=headers, tablefmt=\"grid\"))\n",
        "    print(f'Total Reward: {np.sum(R)}')\n",
        "    return None\n",
        "  else:\n",
        "    return np.sum(R), confusion_matrix\n",
        "\n",
        "eval_rng = np.random.default_rng(0)\n",
        "W_test = np.zeros((1,65))\n",
        "# Xs_aug and y1 are batch x 65 and batch x 1, function wants transpose of this shape\n",
        "# for broadcasting to work\n",
        "print('Evaluation 1')\n",
        "eval_params_stochastic_batch(W_test, Xs_aug.T, y1.T, verbose=True, rng=eval_rng)\n",
        "print('\\nEvaluation 2')\n",
        "eval_params_stochastic_batch(W_test, Xs_aug.T, y1.T, verbose=True, rng=eval_rng)"
      ],
      "metadata": {
        "id": "CI-p0If_8ucJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# to_remove solution\n",
        "\n",
        "# As a little trick to keep our code cleaner we 'hide' our bias term.\n",
        "# We to do this by augmenting the features to include a feature that always has the value '1'.\n",
        "# Then, the 'weight' associated with this feature, which always has a value of '1', effectively serves as the bias term.\n",
        "# After augmentation there is one extra column of features\n",
        "Xs_aug = np.hstack([Xs, np.ones((Xs.shape[0],1))])\n",
        "\n",
        "def np_sigmoid(x):\n",
        "  x = np.clip(x, -500, 500) #prevent overflow, fine because sigmoid saturates\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def eval_params_stochastic_batch(W, x, y, verbose=False, rng=None):\n",
        "  \"\"\"\n",
        "  evaluates parameters of simple behaviour circuit given inputs and target\n",
        "  outputs, use numpy broadcasting to be fast and concise\n",
        "  Args:\n",
        "    W: (outputs(1) x inputs(65) np.array)\n",
        "       weights between sensory neurons and output neuron\n",
        "    x: (input(65) x batch np.array) sensory input\n",
        "    y: (outputs(1) x batch np.array) target behavioural output\n",
        "\n",
        "  Returns:\n",
        "    R: the reward obtained given the parameters, inputs and targets\n",
        "  \"\"\"\n",
        "  if rng is None:\n",
        "    rng = np.random.default_rng()\n",
        "  # activaation\n",
        "  a = np.dot(W,x) # 1 x batch\n",
        "  # strike probability\n",
        "  y_hat = np_sigmoid(a) # 1 x batch\n",
        "  # what the organism actually does\n",
        "  # rng.random is a sample from the uniform distribution on [0,1)\n",
        "  y_sample = rng.random(size=y_hat.shape) < y_hat  # 1 x batch\n",
        "  R = np.zeros(y_sample.shape)\n",
        "  did_strike = y_sample == 1\n",
        "  did_not_strike = y_sample == 0\n",
        "  should_strike = y == 1\n",
        "  should_not_strike = y == 0\n",
        "  TP = np.logical_and(did_strike, should_strike) # True Positive\n",
        "  FP = np.logical_and(did_strike, should_not_strike) # False Positive\n",
        "  FN = np.logical_and(did_not_strike, should_strike) # False Negative\n",
        "  TN = np.logical_and(did_not_strike, should_not_strike) # True Negative\n",
        "  R[TP] = 1\n",
        "  R[FP] = -1\n",
        "  R[FN] = 0\n",
        "  R[TN] = 0\n",
        "  TPs = np.sum(TP)\n",
        "  FPs = np.sum(FP)\n",
        "  FNs = np.sum(FN)\n",
        "  TNs = np.sum(TN)\n",
        "  confusion_matrix = np.array([[TPs, FNs], [FPs, TNs]])\n",
        "  if verbose:\n",
        "    table = [[\"Should Strike\", TPs, FNs],\n",
        "                 [\"Shouldn't Strike\", FPs, TNs]]\n",
        "    headers = [\"\", \"Did Strike\", \"Didn't Strike\"]\n",
        "    print(\"Confusion_matrix: \")\n",
        "    print(tabulate(table, headers=headers, tablefmt=\"grid\"))\n",
        "    print(f'Total Reward: {np.sum(R)}')\n",
        "    return None\n",
        "  else:\n",
        "    return np.sum(R), confusion_matrix\n",
        "\n",
        "eval_rng = np.random.default_rng(0)\n",
        "W_test = np.zeros((1,65))\n",
        "# Xs_aug and y1 are batch x 65 and batch x 1, function wants transpose of this shape\n",
        "# for broadcasting to work\n",
        "print('Evaluation 1')\n",
        "eval_params_stochastic_batch(W_test, Xs_aug.T, y1.T, verbose=True, rng=eval_rng)\n",
        "print('\\nEvaluation 2')\n",
        "eval_params_stochastic_batch(W_test, Xs_aug.T, y1.T, verbose=True, rng=eval_rng)"
      ],
      "metadata": {
        "id": "pMYaMDiYp9TS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that the two evaluations give different total rewards, even though the exact same synaptic weights $\\mathbf{W}$ are being used, on the exact same batch of inputs $\\mathbf{x}$ and prey presence indicators $y$. This is expected given the inherent stochasticity in the organisms behaviour. This stochastic evaluation of the synaptic weights will make things difficult for the perturb-measure-step alogorithm though, because it relies upon precise function evaluations to get good estimates of the rate of improvement in a given direction in parameter space. We can overcome this stochastic evaluation issue though by using our knowledge of how the different probabilities of striking or not determine the expected, or average reward. By directly evaluating expected reward we can recover a precise, deterministic evaluation function."
      ],
      "metadata": {
        "id": "SNMQj2pq5c9I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_params_expectation_batch(W, x, y, verbose=False):\n",
        "  \"\"\"\n",
        "  evaluates parameters of simple behaviour circuit given inputs and target\n",
        "  outputs, use numpy broadcasting to be fast and concise\n",
        "  Args:\n",
        "    W: (outputs(1) x inputs(65) np.array)\n",
        "       weights between sensory neurons and output neuron\n",
        "    x: (input(65) x batch np.array) sensory input\n",
        "    y: (outputs(1) x batch np.array) target behavioural output\n",
        "\n",
        "  Returns:\n",
        "    R_exp: the expected reward obtained over the batch given the parameters, inputs and targets\n",
        "  \"\"\"\n",
        "  # activaation\n",
        "  a = np.dot(W,x) # 1 x batch\n",
        "  # strike probability\n",
        "  y_hat = np_sigmoid(a) # 1 x batch\n",
        "  # Expected true positives (TPs) and false positives (FPs)\n",
        "  TPs = np.sum(y_hat * y)  # Sum of strike probabilities where true label is 1\n",
        "  FPs = np.sum(y_hat * (1 - y))  # Sum of strike probabilities where true label is 0\n",
        "  # Expected false negatives (FN_e) and true negatives (TN_e)\n",
        "  FNs = np.sum((1 - y_hat) * y)  # Sum of no strike probabilities where true label is 1\n",
        "  TNs = np.sum((1 - y_hat) * (1 - y))  # Sum of no strike probabilities where true label is 0\n",
        "  R_exp = 1 * TPs + 0 * FNs + -1 * FPs + 0 * TNs\n",
        "  confusion_matrix = np.array([[TPs, FNs], [FPs, TNs]])\n",
        "  if verbose:\n",
        "    table = [[\"Should Strike\", TPs, FNs],\n",
        "             [\"Shouldn't Strike\", FPs, TNs]]\n",
        "    headers = [\"\", \"Did Strike\", \"Didn't Strike\"]\n",
        "    print(\"Confusion_matrix: \")\n",
        "    print(tabulate(table, headers=headers, tablefmt=\"grid\"))\n",
        "    print(f'Total Reward: {R_exp}')\n",
        "    return None\n",
        "  else:\n",
        "    return R_exp, confusion_matrix\n",
        "\n",
        "W_test = np.zeros((1,65))\n",
        "# Xs_aug and y1 are batch x 65 and batch x 1, function wants transpose of this shape\n",
        "# for broadcasting to work\n",
        "print('Evaluation 1')\n",
        "eval_params_expectation_batch(W_test, Xs_aug.T, y1.T, verbose=True)\n",
        "print('\\nEvaluation 2')\n",
        "eval_params_expectation_batch(W_test, Xs_aug.T, y1.T, verbose=True)"
      ],
      "metadata": {
        "id": "ZDlv-zwC6hkm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that as hoped, the evaluation of parameters using expected reward, is consistent, as it should be. As a sanity check we see that the distribution of stochastic evaluations is roughly symmetric, and centered around this expectation, with the average of many such stochastic evaluations becoming close to our calculated expected value."
      ],
      "metadata": {
        "id": "JACJHFAi90df"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown **Run this cell** to visualize the distribution of stochastic parameter evaluation, relative to the expectation.\n",
        "def eval_params_expectation_batch(W, x, y, verbose=False):\n",
        "  \"\"\"\n",
        "  evaluates parameters of simple behaviour circuit given inputs and target\n",
        "  outputs, use numpy broadcasting to be fast and concise\n",
        "  Args:\n",
        "    W: (outputs(1) x inputs(65) np.array)\n",
        "       weights between sensory neurons and output neuron\n",
        "    x: (input(65) x batch np.array) sensory input\n",
        "    y: (outputs(1) x batch np.array) target behavioural output\n",
        "\n",
        "  Returns:\n",
        "    R_exp: the expected reward obtained over the batch given the parameters, inputs and targets\n",
        "  \"\"\"\n",
        "  # activaation\n",
        "  a = np.dot(W,x) # 1 x batch\n",
        "  # strike probability\n",
        "  y_hat = np_sigmoid(a) # 1 x batch\n",
        "  # Expected true positives (TPs) and false positives (FPs)\n",
        "  TPs = np.sum(y_hat * y)  # Sum of strike probabilities where true label is 1\n",
        "  FPs = np.sum(y_hat * (1 - y))  # Sum of strike probabilities where true label is 0\n",
        "  # Expected false negatives (FN_e) and true negatives (TN_e)\n",
        "  FNs = np.sum((1 - y_hat) * y)  # Sum of no strike probabilities where true label is 1\n",
        "  TNs = np.sum((1 - y_hat) * (1 - y))  # Sum of no strike probabilities where true label is 0\n",
        "  R_exp = 1 * TPs + 0 * FNs + -1 * FPs + 0 * TNs\n",
        "  confusion_matrix = np.array([[TPs, FNs], [FPs, TNs]])\n",
        "  if verbose:\n",
        "    table = [[\"Should Strike\", TPs, FNs],\n",
        "             [\"Shouldn't Strike\", FPs, TNs]]\n",
        "    headers = [\"\", \"Did Strike\", \"Didn't Strike\"]\n",
        "    print(\"Confusion_matrix: \")\n",
        "    print(tabulate(table, headers=headers, tablefmt=\"grid\"))\n",
        "    print(f'Total Reward: {R_exp}')\n",
        "    return None\n",
        "  else:\n",
        "    return R_exp, confusion_matrix\n",
        "\n",
        "def eval_params_stochastic_batch(W, x, y, verbose=False, rng=None):\n",
        "  \"\"\"\n",
        "  evaluates parameters of simple behaviour circuit given inputs and target\n",
        "  outputs, use numpy broadcasting to be fast and concise\n",
        "  Args:\n",
        "    W: (outputs(1) x inputs(65) np.array)\n",
        "       weights between sensory neurons and output neuron\n",
        "    x: (input(65) x batch np.array) sensory input\n",
        "    y: (outputs(1) x batch np.array) target behavioural output\n",
        "\n",
        "  Returns:\n",
        "    R: the reward obtained given the parameters, inputs and targets\n",
        "  \"\"\"\n",
        "  if rng is None:\n",
        "    rng = np.random.default_rng()\n",
        "  # activaation\n",
        "  a = np.dot(W,x) # 1 x batch\n",
        "  # strike probability\n",
        "  y_hat = np_sigmoid(a) # 1 x batch\n",
        "  # what the organism actually does\n",
        "  # rng.random is a sample from the uniform distribution on [0,1)\n",
        "  y_sample = rng.random(size=y_hat.shape) < y_hat  # 1 x batch\n",
        "  R = np.zeros(y_sample.shape)\n",
        "  did_strike = y_sample == 1\n",
        "  did_not_strike = y_sample == 0\n",
        "  should_strike = y == 1\n",
        "  should_not_strike = y == 0\n",
        "  TP = np.logical_and(did_strike, should_strike) # True Positive\n",
        "  FP = np.logical_and(did_strike, should_not_strike) # False Positive\n",
        "  FN = np.logical_and(did_not_strike, should_strike) # False Negative\n",
        "  TN = np.logical_and(did_not_strike, should_not_strike) # True Negative\n",
        "  R[TP] = 1\n",
        "  R[FP] = -1\n",
        "  R[FN] = 0\n",
        "  R[TN] = 0\n",
        "  TPs = np.sum(TP)\n",
        "  FPs = np.sum(FP)\n",
        "  FNs = np.sum(FN)\n",
        "  TNs = np.sum(TN)\n",
        "  confusion_matrix = np.array([[TPs, FNs], [FPs, TNs]])\n",
        "  if verbose:\n",
        "    table = [[\"Should Strike\", TPs, FNs],\n",
        "                 [\"Shouldn't Strike\", FPs, TNs]]\n",
        "    headers = [\"\", \"Did Strike\", \"Didn't Strike\"]\n",
        "    print(\"Confusion_matrix: \")\n",
        "    print(tabulate(table, headers=headers, tablefmt=\"grid\"))\n",
        "    print(f'Total Reward: {np.sum(R)}')\n",
        "    return None\n",
        "  else:\n",
        "    return np.sum(R), confusion_matrix\n",
        "\n",
        "W_test = np.zeros((1,65))\n",
        "exp_reward, _ = eval_params_expectation_batch(W_test, Xs_aug.T, y1.T, verbose=False)\n",
        "\n",
        "# Generate stochastic rewards\n",
        "stochastic_rewards = []\n",
        "for _ in range(500):  # Simulate 100 times to create a distribution\n",
        "  r, _ = eval_params_stochastic_batch(W_test, Xs_aug.T, y1.T, verbose=False)\n",
        "  stochastic_rewards.append(r)\n",
        "\n",
        "# Plotting\n",
        "fig, ax = plt.subplots(figsize=(10, 6))\n",
        "remove_ip_clutter(fig)\n",
        "ax.hist(stochastic_rewards, bins=20, alpha=0.75, label='Stochastic Evaluations')\n",
        "ax.axvline(x=exp_reward, color='r', linestyle='dashed', linewidth=2, label=f'Expected Reward: {exp_reward}')\n",
        "ax.set_title('Comparison of Stochastic Evaluations and Expected Reward')\n",
        "ax.set_xlabel('Reward')\n",
        "ax.set_ylabel('Frequency')\n",
        "ax.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "cellView": "form",
        "id": "fGcMioTH9zxZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "As yet another sanity check we calculate the expected reward when striking and not striking with equal probability, in all circumstances, which is what we expect from a $\\mathbf{W}$ of all zeros."
      ],
      "metadata": {
        "id": "q_M7oYlFC9y-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# There are this many cases where striking is good\n",
        "np.sum(y1 == 1)"
      ],
      "metadata": {
        "id": "k1lP9VvCPLNq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# And this many cases where striking is bad\n",
        "np.sum(y1 == 0)"
      ],
      "metadata": {
        "id": "FjR08i1kPSoF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# W = 0 should strike half the time no matter what,\n",
        "# in which case would expect a reward of\n",
        "(2829 - 2791) / 2"
      ],
      "metadata": {
        "id": "fKcCR599Piys"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "That all checks out, so now that we have some confidence in our evaluation function let's see if perturb-measure-step is able to find a good set of values for $\\mathbf{W}$ using the batch expected value version of parameter evaluation. Run the training loop. The process will take a minute or two to complete, while its running inspect the code and see if it makes sense to you."
      ],
      "metadata": {
        "id": "EK8zI-aSDTJb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Stochastic-Perturb-Measure-Step Training Loop\n",
        "learn_rng = np.random.default_rng(0)\n",
        "num_steps = 60000\n",
        "step_scale = 0.002\n",
        "dimensional_scale_factor = np.sqrt(65)\n",
        "perturbation_scale = 0.0001 # std of gaussian test perturbations\n",
        "W_init = np.zeros((1,65))\n",
        "W = W_init\n",
        "start_time = time.time()\n",
        "for step in range(num_steps):\n",
        "  R_current, _ = eval_params_expectation_batch(W, Xs_aug.T, y1.T)\n",
        "  raw_test_perturb = learn_rng.standard_normal(size=(1,65))\n",
        "  unit_test_perturb = raw_test_perturb / np.linalg.norm(raw_test_perturb.flatten())\n",
        "  test_perturbation = unit_test_perturb * perturbation_scale\n",
        "  R_test, _ = eval_params_expectation_batch(W + test_perturbation, Xs_aug.T, y1.T)\n",
        "  directional_grad_est = (R_test - R_current) / perturbation_scale\n",
        "  W += step_scale * dimensional_scale_factor * directional_grad_est * unit_test_perturb\n",
        "\n",
        "  if step == 0 or (step + 1) % 3000 == 0:\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f'Step {step + 1}/{num_steps} completed | Expected Total Batch Reward: {R_current:.6f} | Time elapsed: {elapsed_time:.2f} seconds')\n",
        "eval_params_expectation_batch(W, Xs_aug.T, y1.T, verbose=True)"
      ],
      "metadata": {
        "id": "DPCBERK3Q0kz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best possible score is 2829, and perturb measure step is able to discover network parameters that achieve a score of roughly 2500, in 60,000 steps. This is pretty good, better than we the humans were able to do in terms of figuring out the pattern, before we got bored of the problem in a few minutes. This is all well and good as an optimization exercise, but if we want to connect this form of optimization back to our inspirational cartoon of neural behaviour as a kind of learning, there are a few issues. Three major issues stand out as ways in which the perturb-measure-step training loop above deviates from a process that is simple and local enough to serve as plausible (even if very abstract) model of a physiological syanptic plasticity processes. These key issues are:\n",
        "1. The organism's striking behaviour is stochastic but expected reward outcomes, not actual obtained reward outcomes are used to drive updates to the synaptic parameters $\\mathbf{W}$.\n",
        "2. The evaluation of a given synaptic configuration is based on performance over all of the 5620 of distcint input-outpur pairs (sensory-pattern, prey-presence) in the data set that defines the \"environment\" of this learning problem. Physiologically viable would be evaluations over a single, or at least relatively few, stimulus-response-reward episodes.\n",
        "3. Evaluations are performed in seperate perturbation and non-perturbation modes in the training loop above. A single mode of evaluation that operated fully \"online\" and in congunction with the ongoing generation of behaviour is more simple and easy to imagine physiological implementations of.\n",
        "\n",
        "There are of course many other ways in which the this cartoon learning system deviates from what might plausibly be implemented in an actual simple neural system, but these have more to do with the abstractness of the model, and can concievibly be remedied with careful choices about how to make the model more concrete so as to map nicely onto measurable phyiological features of neural plasticity. In contrast, for the critical points oulined above, it is difficult to imagine how any of these key issues can be overcome physiologically, without invoking additional complex neural circuits and processes, the orgin of which also need to be explained. So for this sequence and the next we focus on addressing these core issues, different-modes, batch versus single experience based reward, and expected versus actual recieved (stochastic) reward.\n",
        "\n",
        "In the rest of this sequence we will adapt the base perturb-measure-step update rule to address each of these three issues. But first let's just get a bit of a sense of how these issues impinge upon the fantasy of using perturb-measure-step as an algorithm that might feasibly be used by a living organism to update the connection strengths of this simple network determining behaviour in response to stimulus. In each interation in the vanilla perturb-measure-step training loop implemented above the organism first evaluates its current parameters based on the expected reward over all 5620 possible experiences. It then perturbs its synaptic parameters and evaluates its performance again on all 5620 experiences, these two evaluations are compared to determine $\\Delta R$ and this together with the pertrubations $\\Delta W_i$ determine the synaptic connections update according to\n",
        "\n",
        "$$ W_i' = W_i + s \\ \\Delta W_i \\ \\Delta R $$\n",
        "where\n",
        "$$\\Delta R = R(\\mathbf{W} + \\Delta \\mathbf{W}) - R(\\mathbf{W})$$\n",
        "and $R(\\mathbf{W})$ is our reward/evaluation function.\n",
        "Note that $s$ needs to be carefully choosen to account both for the average size of the perturbation $\\| \\mathbf{W} \\|$, the appropriately level of scaling given the expected alignment of a random perturbation with the gradient given the dimensionality of $\\mathbf{W}$, and the relative scale of the gradient. While this is can be a challenge in practical applications, the \"dialing-in\" of meta-parameters of learning algorithms is something that we expect evolution to be quite good at.\n",
        "\n",
        "This process would require the organism somehow integrate all of the reward outcomes of all 5620 experiences, remember this aggregated outcome, then integrate up the reward outcomes of another 5620 experiences accumulated while in 'perturbation' mode, and then update its parameters based on a comparison of the remembered and the recently accumlated aggregate reward outcome. This all seems a bit complicated, and difficult to implement with simple, primarily local, synaptic plasticity mechanisms. What we would like intead is a version of perturb-measure-step that updates its synaptic weights as a result of every reward experience, doesn't rely on an expected reward calculation, and that does not have a seperate perturbation mode.\n",
        "\n",
        "Removing the seperate perturbation mode is perhaps the easiest issue to address so we take this on first."
      ],
      "metadata": {
        "id": "T-Qw7kZ7T8Gp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1.4.2 Stochastic-Step-Measure-Step\n",
        "\n",
        "One simple way to avoid a seperate perturbation evaluation is to simply compress the perturbation and the update into a single step. We call such an update method step-measure-step as contrasted with perturb measure step. This new update rule looks like this.\n",
        "\n",
        "\n",
        "\n",
        "$$\\ W_{i}(t+1)= W_i(t) + s \\ (W_i(t) - W_i(t-1)) \\ \\ R(\\mathbf{W}(t)) - R(\\mathbf{W}(t-1)) + \\xi_{i}(t)$$\n",
        "\n",
        "Previously we used $\\Delta$ to denote the perturbation and did not directly reference the parameter update. Because now we are combining the perturbation and the parameter update we use $\\Delta$ to denote this combined change, that is\n",
        "$$ \\ W_{i}(t+1) - W_i(t) = \\Delta W_i(t) $$\n",
        "\n",
        "Then the above simplifies\n",
        "\n",
        "$$ \\Delta W_i(t) = s \\ \\Delta W_i(t-1) \\ \\Delta R(t) + \\xi_i(t) $$\n",
        "Here $\\Delta R(t) = R(\\mathbf{W}(t)) - R(\\mathbf{W}(t-1))$\n",
        "\n",
        "Let's see if\n"
      ],
      "metadata": {
        "id": "Rdp1m0JJV2ff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Stochastic-Step-Measure-Step Training Loop\n",
        "learn_rng = np.random.default_rng(0)\n",
        "num_steps = 100000\n",
        "init_step_scale = 0.003 * np.sqrt(65)\n",
        "init_noise_scale = 0.0005\n",
        "total_scale = 1.0\n",
        "#later_step_scale = 0.002 * np.sqrt(65)\n",
        "#later_noise_scale = 0.0001\n",
        "W_init = np.zeros((1,65))\n",
        "W = W_init\n",
        "delta_W = np.zeros((1,65))\n",
        "R, _ = eval_params_expectation_batch(W, Xs_aug.T, y1.T)\n",
        "start_time = time.time()\n",
        "step_scale = init_step_scale\n",
        "noise_scale = init_noise_scale\n",
        "for step in range(num_steps):\n",
        "  R_old = R\n",
        "  R, _ = eval_params_expectation_batch(W, Xs_aug.T, y1.T)\n",
        "  delta_R = R - R_old\n",
        "  delta_W_noise = learn_rng.normal(0, noise_scale, size=(1,65))\n",
        "  delta_W = total_scale * (step_scale * delta_W * delta_R + delta_W_noise)\n",
        "  W += delta_W\n",
        "\n",
        "  if step == 0 or (step + 1) % 10000 == 0:\n",
        "    elapsed_time = time.time() - start_time\n",
        "    #print(f'Delta R: {delta_R}')\n",
        "    #print(f'Delta W: {delta_W}')\n",
        "    print(f'Step {step + 1}/{num_steps} completed | Total Expected Reward: {R:.6f} | Time elapsed: {elapsed_time:.2f} seconds')\n",
        "    #if step > 40000:\n",
        "    #  step_scale = later_step_scale\n",
        "    #  noise_scale = later_noise_scale\n",
        "eval_params_expectation_batch(W, Xs_aug.T, y1.T, verbose=True)"
      ],
      "metadata": {
        "id": "5Q6yqqAJWCHo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So this trick of smushing the perturbation and the update into a single step seems to work okay, though not as well as doing the very careful perturbation, but it shows that much of the correct pattern response to stimulus can be discovered through this mode. This particular idea for smushing together the perturbation and the update was is known as ALOPEX (an acronym from \"ALgorithms Of Pattern EXtraction\",  first proposed by Tzanakou and Harth in 1974.) This is one way of not having a seperate perturbation and non-perturbation mode. There are other ways, such as leveraging the stochasticity of relative spike timings (ref seung), and using reward signals directly (or above some anticipated baseline) which we will discuss these later. For now, it is enough to know that this issue can be mitigated, though with some apparrent cost to overall performance (relative to perturb-measure-step). Let's move on to the next issue."
      ],
      "metadata": {
        "id": "-73AjlBda7kA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1.4.3 Full-Batch versus Mini-Batch Perturb-Measure-Step\n",
        "\n",
        "Another issue in terms of physiological viability was parameter evaluation based on performance across all possible experiences. In a simple model of learning and synaptic plasticity, we would like learning to be driven by the outcomes of a single stimulus-response-reward experience.\n",
        "\n",
        "This relates to an important idea in machine learning. The idea of the mini-batch. Even though we are ulitmately interested is the performance of the parameters over all of the input-target pairs in the data set, given how computers operate, it is typically possible to generate a sample evaluation based on a small random sample of the input-target pairs in the data set. Such a samlpe is called a mini-batch of the data. (As contrasted with the entire data-set which is called a full-batch or just batch). Evaluations on these mini-batches provides an estimate of the desired full-batch evaluation. In the extreme case a mini-batch can consist of a single input-output pair. In ML the idea of using mini-batches developed in the context of Gradient Descent optimization (which we haven't covered yet). So even though the mini-batch idea applies to all kinds of optimzation processes, for historical reasons,  learning with mini-batches of size 1 is called \"Stochastic Gradient Descent\", and learning with mini-batches of size greater than 1 but less than the full batch is called \"Mini-Batch Stochastic Gradient Descent\", and learning with the full batch is just called Gradient Descent. In practical ML settings, whenever the data-set becomes sufficiently large, mini-batches are almost always used, as they allow for the most efficient use of computational resources. Here we explicitly seperate the mini-batch idea from Gradient Descent, and so use the terms full-batch, mini-batch, and singleton based learning and evaluations. Let's see what having a mini-batch of different sizes does to our learning rates. For now we test out this mini-batch idea on perturb-measure-step."
      ],
      "metadata": {
        "id": "HIOigwyZeYwK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Mini-Batch(10) Stochastic-Perturb-Measure-Step Training Loop\n",
        "learn_rng = np.random.default_rng(0)\n",
        "step_scale = 0.002\n",
        "mini_batch_size = 10\n",
        "num_epochs = 400\n",
        "dimensional_scale_factor = np.sqrt(65)\n",
        "perturbation_scale = 0.0001 # std of gaussian test perturbations\n",
        "W_init = np.zeros((1,65))\n",
        "W = W_init\n",
        "start_time = time.time()\n",
        "indices = np.arange(Xs_aug.shape[0])\n",
        "for epoch in range(num_epochs):\n",
        "  np.random.shuffle(indices)\n",
        "  for batch_step in range(0, Xs_aug.shape[0], mini_batch_size):\n",
        "    batch_indices = indices[batch_step:batch_step+mini_batch_size]\n",
        "    batch_Xs = Xs_aug[batch_indices].T\n",
        "    batch_y1 = y1[batch_indices].T\n",
        "    R_current, _ = eval_params_expectation_batch(W, batch_Xs, batch_y1)\n",
        "    raw_test_perturb = learn_rng.standard_normal(size=(1,65))\n",
        "    unit_test_perturb = raw_test_perturb / np.linalg.norm(raw_test_perturb.flatten())\n",
        "    test_perturbation = unit_test_perturb * perturbation_scale\n",
        "    R_test, _ = eval_params_expectation_batch(W + test_perturbation, batch_Xs, batch_y1)\n",
        "    directional_grad_est = (R_test - R_current) / perturbation_scale\n",
        "    W += step_scale * dimensional_scale_factor * directional_grad_est * unit_test_perturb\n",
        "\n",
        "  if epoch == 0 or (epoch + 1) % 20 == 0:\n",
        "    total_expected_reward, _ = eval_params_expectation_batch(W, Xs_aug.T, y1.T)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs} completed | Expected Total Batch Reward: {total_expected_reward:.6f} | Time elapsed: {elapsed_time:.2f} seconds')\n",
        "eval_params_expectation_batch(W, Xs_aug.T, y1.T, verbose=True)"
      ],
      "metadata": {
        "id": "b_Q3ceuPUUkb",
        "outputId": "509a3f4b-bd09-4088-832c-b07eabbed30e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        }
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'eval_params_expectation_batch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-8-c6f36328c3ea>\u001b[0m in \u001b[0;36m<cell line: 12>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mbatch_Xs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mXs_aug\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m     \u001b[0mbatch_y1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0my1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_indices\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mT\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mR_current\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0meval_params_expectation_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mW\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_Xs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_y1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m     \u001b[0mraw_test_perturb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearn_rng\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstandard_normal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m65\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[0munit_test_perturb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mraw_test_perturb\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinalg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnorm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mraw_test_perturb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'eval_params_expectation_batch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So with a mini-batch of size 10, this works really quite well, basically just as well as evaluating the parameters on the entire experience, what about when we scale down to the extreme case of a mini-batch of size 1?"
      ],
      "metadata": {
        "id": "pjayFNS7ilBP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Singleton Stochastic-Perturb-Measure-Step Training Loop\n",
        "learn_rng = np.random.default_rng(0)\n",
        "step_scale = 0.002\n",
        "mini_batch_size = 1\n",
        "num_epochs = 80\n",
        "dimensional_scale_factor = np.sqrt(65)\n",
        "perturbation_scale = 0.0001 # std of gaussian test perturbations\n",
        "W_init = np.zeros((1,65))\n",
        "W = W_init\n",
        "start_time = time.time()\n",
        "indices = np.arange(Xs_aug.shape[0])\n",
        "for epoch in range(num_epochs):\n",
        "  np.random.shuffle(indices)\n",
        "  for batch_step in range(0, Xs_aug.shape[0], mini_batch_size):\n",
        "    batch_indices = indices[batch_step:batch_step+mini_batch_size]\n",
        "    batch_Xs = Xs_aug[batch_indices].T\n",
        "    batch_y1 = y1[batch_indices].T\n",
        "    R_current, _ = eval_params_expectation_batch(W, batch_Xs, batch_y1)\n",
        "    raw_test_perturb = learn_rng.standard_normal(size=(1,65))\n",
        "    unit_test_perturb = raw_test_perturb / np.linalg.norm(raw_test_perturb.flatten())\n",
        "    test_perturbation = unit_test_perturb * perturbation_scale\n",
        "    R_test, _ = eval_params_expectation_batch(W + test_perturbation, batch_Xs, batch_y1)\n",
        "    directional_grad_est = (R_test - R_current) / perturbation_scale\n",
        "    W += step_scale * dimensional_scale_factor * directional_grad_est * unit_test_perturb\n",
        "\n",
        "  if epoch == 0 or (epoch + 1) % 5 == 0:\n",
        "    total_expected_reward, _ = eval_params_expectation_batch(W, Xs_aug.T, y1.T)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs} completed | Expected Total Batch Reward: {total_expected_reward:.6f} | Time elapsed: {elapsed_time:.2f} seconds')\n",
        "eval_params_expectation_batch(W, Xs_aug.T, y1.T, verbose=True)"
      ],
      "metadata": {
        "id": "zChE6Ud1i0dt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So learning from a single experience using perturb-measure-step doesn't appear to be a problem at all. If anything it leads to faster (in terms of computational time) learning, since evaluations on a single (or small mini-batch of) input-output pair(s) are much quicker to compute than evaluations of the parameters based on the entirety of the avialble data-set.\n",
        "\n",
        "Now, unfortunately, the smushing together of the update step and the perturbation step, does not mix well with the mini-batch idea. The key issue here, is that in the mini-batch training loops above **the same** mini-batch was used to evaluate both the base parameters and the perturbed parameters alowing for a precise estimate of the rate of improvement in the direction of the test perturbation. If two **different** mini-batches are used to estimate the reward at two different points in the parameter space (as happens in when we try to use step-measure-step with mini-batches), the noise introduced by using different mini-batches makes the estimate the degree of improvement between the two points much noisier. For many problems this degree of noise is such that learning becomes intractably slow."
      ],
      "metadata": {
        "id": "0BZyRrdxj35_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Mini-Batch(20) Step-Measure-Step Training Loop\n",
        "learn_rng = np.random.default_rng(0)\n",
        "step_scale = 0.003 * np.sqrt(65)\n",
        "noise_scale = 0.0005\n",
        "total_scale = 0.1\n",
        "mini_batch_size = 20\n",
        "num_epochs = 200\n",
        "W_init = np.zeros((1,65))\n",
        "W = W_init\n",
        "delta_W = np.zeros((1,65))\n",
        "R, _ = eval_params_expectation_batch(W, Xs_aug.T, y1.T)\n",
        "start_time = time.time()\n",
        "indices = np.arange(Xs_aug.shape[0])\n",
        "for epoch in range(num_epochs):\n",
        "  np.random.shuffle(indices)\n",
        "  for batch_step in range(0, Xs_aug.shape[0], mini_batch_size):\n",
        "    batch_indices = indices[batch_step:batch_step+mini_batch_size]\n",
        "    batch_Xs = Xs_aug[batch_indices].T\n",
        "    batch_y1 = y1[batch_indices].T\n",
        "    R_old = R\n",
        "    R, _ = eval_params_expectation_batch(W, batch_Xs, batch_y1)\n",
        "    delta_R = R - R_old\n",
        "    delta_W_noise = learn_rng.normal(0, noise_scale, size=(1,65))\n",
        "    delta_W = total_scale * (step_scale * delta_W * delta_R + delta_W_noise)\n",
        "    W += delta_W\n",
        "\n",
        "  if epoch == 0 or (epoch + 1) % 5 == 0:\n",
        "    total_expected_reward, _ = eval_params_expectation_batch(W, Xs_aug.T, y1.T)\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f'Epoch {epoch + 1}/{num_epochs} completed | Expected Total Batch Reward: {total_expected_reward:.6f} | Time elapsed: {elapsed_time:.2f} seconds')\n",
        "eval_params_expectation_batch(W, Xs_aug.T, y1.T, verbose=True)"
      ],
      "metadata": {
        "id": "7ZhwXbknl1bd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_and_evaluate(step_scale, noise_scale):\n",
        "  step_scale = step_scale * np.sqrt(65)\n",
        "  num_steps = 50000\n",
        "  W = np.zeros((1, 65))\n",
        "  delta_W = np.zeros((1,65))\n",
        "  R, _ = eval_params_expectation_batch(W, Xs_aug.T, y1.T)\n",
        "  for step in range(num_steps):\n",
        "    R_old = R\n",
        "    R, _ = eval_params_expectation_batch(W, Xs_aug.T, y1.T)\n",
        "    delta_R = R - R_old\n",
        "    delta_W_noise = learn_rng.normal(0, noise_scale, size=(1,65))\n",
        "    delta_W = step_scale * delta_W * delta_R + delta_W_noise\n",
        "    W += delta_W\n",
        "  R, _ = eval_params_expectation_batch(W, Xs_aug.T, y1.T)\n",
        "  return R  # or another performance metric"
      ],
      "metadata": {
        "id": "JoJb_CkDSRAO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = []\n",
        "for step_scale in [0.003, 0.002, 0.001]:\n",
        "  for noise_scale in [0.002, 0.001, 0.0005,]:\n",
        "    print(f'Step Scale: {step_scale}, Noise Scale: {noise_scale}')\n",
        "    result = train_and_evaluate(step_scale, noise_scale)\n",
        "    print(result)\n",
        "    results.append((step_scale, noise_scale, result))"
      ],
      "metadata": {
        "id": "ccwgVP05U2g0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1.3.5 Perturb-Measure-Step at the Synaptic Level\n",
        "\n",
        "So our update rule for perturb-measure-step can be written in compact mathematical notation as\n",
        "\n",
        "$$ \\mathbf{W}' = \\mathbf{W} + s \\Delta\\mathbf{W}\\Delta R $$\n",
        "\n",
        "This is saying that the new parameters are equal to the old parameters, shifted in the direction of some random perturbation, proportional to the rate of improvement in that random direction. So each element of the perturbation $\\Delta \\mathbf{W}$, $\\Delta W_i$, is normally distributed with mean zero and standard deviation equal to the perturbation scale. The rate of improvement in that direction is given by\n",
        "\n",
        "$$\\Delta R = \\frac{f(\\mathbf{W}_t + \\Delta \\mathbf{W}) - f(\\mathbf{W}_t)}{\\| \\Delta \\mathbf{W}\\|}$$\n",
        "\n",
        "This is all well and good, but what does this translate to in terms of an update rule for individual synapses?\n",
        "\n",
        "$$ W_i' = W_i + s \\Delta W_i \\Delta R $$\n",
        "\n",
        "From this rule it may be clear, that sometimes this learning rule will cause individual synaptic weights to shift in bad direction, since $\\Delta R$ is based on an evaluation of a shift in all the weights in our stochastic-perturb-measure-step. Note though, that in our original perturb-measure-step we only to perturbed one weight at a time, and systematically iterated through all the weights. From a physiological point of view this kind of systematic, iterative perturbation of weights seems basically impossible to coordinate, whereas small random perturbations to the effective synaptic weights is highly plausible through a number of different physiological mechanisms, several of which already have clear empirical support. Similarly, the presence of globally acting \"Reward Signals\" also has clear empirical evidence for some networks in the brain. From the perspective physiological mechanisms alone, this kind of synaptic update rule is highly plausible.  "
      ],
      "metadata": {
        "id": "r2A7RlNB2GVn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now whenever we look at the performance of a model, we have to ask ourselves, is it not getting better because our training algorithm can't make the model any better, or is the *expressivity* of the model maxed out, and given the structural limitations (basically the number of parameters in our model and how they combine to produce outputs that are contingent on inputs). Could such a model ever do any better? It turns out that this is roughly about as good as can be expected with a network as simple as this. The next question then is, can we do better with a more complex network? Let's see"
      ],
      "metadata": {
        "id": "-077uao8afjM"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2.1.3.4 Is Solving High Dimensional Optimization Problem Necissary for Adaptive Behaviour? Hard Yes.\n",
        "\n",
        "One reason for having a large, flexible brain is to produce complex behaviour that is contingent on the state of the world in complex ways. Our simple strike-no-strike network, consisted of a single layer of synaptic connections between the sensory inputs and the motor outputs. In a shallow network structure like this a sensory input either directly inhibits or promotes the striking behaviour, there is no possibility for the a sensory input to promote striking in some sensory contexts, but inhibit it in others. This is a deficincy. Context is important, loud thumping and roaring noises at a concert means the band is good, similar noises when camping in the wilderness means a large animal is nearby. A shallow network does not allow for such context dependence. However, by simply adding an additional layer to the network, consisting of some intermediate (hidden) neurons between the inputs and the output, limited forms of context dependent inhibition and promotion of striking are possible.\n",
        "\n",
        "One thing that could be holding back performance on this discrimination problem is that our algorithms are not capable of finding the optimal parameters for the given model, but... we don't really think that is the case here. Another possibility is that our simple sensory-behaviour circuit is not flexible or complex enough to fully discriminate between the two types of input. There is good reason to think that this might be the case. Our current sensory-behavioural circuit is effectively equivalent to logistic regression, i.e. each feature can either inhibit or potentiate striking behaviour to varying degrees, but there is no possibility for conditional interaction between features. By 'conditional interaction,' we mean a scenario where, for instance, feature 1 typically inhibits the behavior, except when feature 2 is positive, under which condition feature 1 becomes potentiating. These kinds of feature interactions are impossible in the current model. One way to allow for such interactions is to augment the base set of features with composite features, e.g. incorporate all the pairwise products of the existing feature set, so that instead of 65 features (bias included) we have $(65^2 - 1) = 4224$ features to work with. This could work, but what if we want something that depends on the interaction of more than 2 features, adding higher order polynomial terms will quickly make the problem intractable (Reference appendix section on why hidden layers not polynomials if we do that). If we had some mechanistically grounded understanding or hypothesis about the relationship between the features and label could might be able to cherry pick some small subset of higher order interaction terms, but the ML/supervised learning framework is in large part about automating the feature selection processes based on the data alone. In turns out that instead of resorting the regression on polynomial terms to capture feature interactions, there is a much more compact and expressive way of allowing for feature interactions. The idea is to allow for feature interactions to emerge as needed in a 'hidden' computational layer of our highly abstracted neurons.\n",
        "\n",
        "Our new strike-no-strike network with 1 hidden layer is structured as follows"
      ],
      "metadata": {
        "id": "u1lGLbkNVUj8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "As before $\\mathbf{x}$ is the raw sensory input (vector) in a given episode and each element of $\\mathbf{x}$ corresponds to the activation level and firing rate of a single photosensitive neuron.\n",
        "These input neurons are then connected by synapses to a 'hidden layer' of intermediate computational neurons, say 10 of them. The activation level of these hidden layer neurons is computed as\n",
        "$$\\mathbf{h} = \\sigma(\\mathbf{W}_{in} \\cdot \\mathbf{x})$$\n",
        "Now $\\mathbf{W}_{in}$ is a matrix of synaptic weights between the input neurons and the hidden layer neurons, and $\\cdot$ denotes standard matrix vector multiplication. (In this case $\\mathbf{W}$ has shape $10 \\times 65$. Each the values in the $i^{th}$ row of $\\mathbf{W}_{in}$ given the sign and strength of the connections coming into the $i^{th}$ element of $h$ and similarly each value in the $j^{th}$ column of $\\mathbf{W}_{in}$ corresponds to connection strengths coming out of the $j^{th}$ sensory input neuron.)  We still us $\\sigma$ to represent the standard logistic sigmoid function, but in these case applied elementwise the vector output of the product $\\mathbf{W}_{in} \\cdot \\mathbf{x}$. Then much as before our striking probability is computed as\n",
        "$$y = \\mathbf{W}_{out} \\cdot \\mathbf{h}$$\n",
        "and\n",
        "$$ \\Pr \\{\\text{strike}\\} = \\sigma(y) $$\n",
        "$$ \\Pr \\{\\text{no strike}\\} = 1 - \\sigma(y)$$\n",
        "Here $\\mathbf{W}_{out}$ has shape $1  \\times 10$.\n"
      ],
      "metadata": {
        "id": "CvsVIoAvVNh0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will need to write a new eval params function for this new model, let's do it."
      ],
      "metadata": {
        "id": "j9tt8sJofITF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def eval_params_hidden(W_in, W_out, x, y, verbose=False):\n",
        "  \"\"\"\n",
        "  evaluates parameters of simple behaviour circuit given inputs and target\n",
        "  outputs, use numpy broadcasting to be fast and concise\n",
        "  Args:\n",
        "    W_in: (hidden-neurons(20) x inputs(65) np.array)\n",
        "           weights between sensory neurons and hidden layer neurons\n",
        "    W_out: (output(1) x hidden-neurons(20) np.array)\n",
        "           weights between hidden layer neurons and output\n",
        "    x: (input(64) x batch np.array) sensory input\n",
        "       (can be single input, mini-batch of inputs or the whole batch of inputs)\n",
        "    y: (outputs(1) x batch np.array) target behavioural output\n",
        "       (can be a single target, mini-batch of targets, or whole batch),\n",
        "       needs to correspond to input\n",
        "\n",
        "  Returns:\n",
        "    R_bar: the average/expected reward obtained given the parameters, over the\n",
        "           (mini-)batch of inputs and targets. (mini-batch could be size 1)\n",
        "  \"\"\"\n",
        "  h = np_sigmoid(np.dot(W_in,x)) # hidden x batch\n",
        "  y_hat = np_sigmoid(np.dot(W_out,h)) # 1 x batch\n",
        "  y_score = np.copy(y)\n",
        "  y_score[y_score == 0] = -1\n",
        "  batch_expected_reward = y_score * y_hat\n",
        "  R_bar = np.sum(batch_expected_reward)\n",
        "  if verbose:\n",
        "    # Expected true positives (TP_e) and false positives (FP_e)\n",
        "    TP_e = np.sum(y_hat * y)  # Probabilities where true label is 1\n",
        "    FP_e = np.sum(y_hat * (1 - y))  # Probabilities where true label is 0\n",
        "    # Expected false negatives (FN_e) and true negatives (TN_e)\n",
        "    FN_e = np.sum((1 - y_hat) * y)  # (1 - probabilities) where true label is 1\n",
        "    TN_e = np.sum((1 - y_hat) * (1 - y))  # (1 - probabilities) where true label is 0\n",
        "    confusion_matrix = np.array([[TP_e, FN_e], [FP_e, TN_e]])\n",
        "    table = [[\"Should Strike\", TP_e, FN_e],\n",
        "                 [\"Shouldn't Strike\", FP_e, TN_e]]\n",
        "    headers = [\"\", \"Did Strike\", \"Didn't Strike\"]\n",
        "    print(\"Expected Confusion_matrix: \")\n",
        "    print(tabulate(table, headers=headers, tablefmt=\"grid\"))\n",
        "    print(f'Expected reward: {R_bar}')\n",
        "    return None\n",
        "  else:\n",
        "    return R_bar\n"
      ],
      "metadata": {
        "id": "wequmEMQfJMp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We've got a more complicated circuit with more parameters, how much longer does it take us to evaluate this circuit compared to our previous one?"
      ],
      "metadata": {
        "id": "Eiem7eE-fw8D"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "W = np.zeros((1,65))\n",
        "%timeit eval_params_aug(W, Xs_aug.T, y1.T)"
      ],
      "metadata": {
        "id": "vyebIZ8Vf3bx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "W_in = np.zeros((10,65))\n",
        "W_out = np.zeros((1,10))\n",
        "%timeit eval_params_hidden(W_in, W_out, Xs_aug.T, y1.T)"
      ],
      "metadata": {
        "id": "htd8pC1uf55M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Roughly 5x longer per function evaluation, which means not only will we likely need more iterations of our algorithm because it is harder to find good parameters in high dimensions (we have 660 parameters now, which is a lot more than 65), but also each of those steps will take longer to process because function evaluations are also more costly. It will all be worth it if we can get better final performance though."
      ],
      "metadata": {
        "id": "Px0KZWgFgK1P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 10 Hidden Units - Perturb-Measure-Step Training Loop\n",
        "learn_rng = np.random.default_rng(0)\n",
        "num_steps = 30000\n",
        "step_scale = 0.025\n",
        "perturbation_scale = 0.0001 # std of gaussian test perturbations\n",
        "num_hidden_units = 10\n",
        "# initializing both layers as zero leads to some issues, so we\n",
        "# use a Xavier/Glorot random initialization scheme\n",
        "in_init = np.sqrt(6 / (65 + num_hidden_units))\n",
        "W_in_init = learn_rng.uniform(-in_init, in_init, size=(num_hidden_units, 65))\n",
        "out_init = np.sqrt(6 / (10 + 1))\n",
        "W_out_init = learn_rng.uniform(-out_init, out_init, size=(1, num_hidden_units))\n",
        "flat_params = np.concatenate((W_in_init.flatten(), W_out_init.flatten()))\n",
        "dimensional_scale_factor = np.sqrt(len(flat_params))\n",
        "start_time = time.time()\n",
        "indices = np.arange(Xs_aug.shape[0])\n",
        "for step in range(num_steps):\n",
        "  W_in, W_out = np.split(flat_params, [650])\n",
        "  W_in = W_in.reshape((10,65))\n",
        "  W_out = W_out.reshape((1,10))\n",
        "  R_current = eval_params_hidden(W_in, W_out, Xs_aug.T, y1.T)\n",
        "  raw_param_perturb = learn_rng.standard_normal(size=len(flat_params))\n",
        "  unit_param_perturb = raw_param_perturb / np.linalg.norm(raw_param_perturb.flatten())\n",
        "  test_perturbation = unit_param_perturb * perturbation_scale\n",
        "  perturbed_flat_params = flat_params + test_perturbation\n",
        "  W_in_test, W_out_test = np.split(perturbed_flat_params, [650])\n",
        "  W_in_test = W_in_test.reshape((10,65))\n",
        "  W_out_test = W_out_test.reshape((1,10))\n",
        "  R_test = eval_params_hidden(W_in_test, W_out_test, Xs_aug.T, y1.T)\n",
        "  directional_grad_est = (R_test - R_current) / perturbation_scale\n",
        "  flat_params += step_scale * dimensional_scale_factor * directional_grad_est * unit_param_perturb\n",
        "\n",
        "  if step == 0 or (step + 1) % 1000 == 0:\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f'Step {step + 1}/{num_steps} completed | Current Total Reward: {R_current:.6f} | Time elapsed: {elapsed_time:.2f} seconds')\n",
        "W_in, W_out = np.split(flat_params, [650])\n",
        "W_in = W_in.reshape((10,65))\n",
        "W_out = W_out.reshape((1,10))\n",
        "eval_params_hidden(W_in, W_out, Xs_aug.T, y1.T, verbose=True)\n"
      ],
      "metadata": {
        "id": "MDoAqfWghM--"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "So this new, more complex circuit is great. We're much closer to the theoretical maximum performance of 2829, maybe with a few more hidden units, and a little longer training time we could have perfect discrimination. Let's see what happens when we go up to 20 hidden units. As a heads up this is going to take awhile (about 3 minutes) so you should read ahead while waiting for this training loop to complete"
      ],
      "metadata": {
        "id": "m4hKKsmKnjrD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title 20 Hidden Units - Perturb-Measure-Step Training Loop\n",
        "learn_rng = np.random.default_rng(0)\n",
        "num_steps = 10000\n",
        "step_scale = 0.025\n",
        "perturbation_scale = 0.0001 # std of gaussian test perturbations\n",
        "num_hidden_units = 20\n",
        "# initializing both layers as zero leads to some issues, so we\n",
        "# use a Xavier/Glorot random initialization scheme\n",
        "in_init = np.sqrt(6 / (65 + num_hidden_units))\n",
        "W_in_init = learn_rng.uniform(-in_init, in_init, size=(num_hidden_units, 65))\n",
        "out_init = np.sqrt(6 / (num_hidden_units + 1))\n",
        "W_out_init = learn_rng.uniform(-out_init, out_init, size=(1, num_hidden_units))\n",
        "flat_params = np.concatenate((W_in_init.flatten(), W_out_init.flatten()))\n",
        "dimensional_scale_factor = np.sqrt(len(flat_params))\n",
        "start_time = time.time()\n",
        "indices = np.arange(Xs_aug.shape[0])\n",
        "for step in range(num_steps):\n",
        "  W_in, W_out = np.split(flat_params, [num_hidden_units*65])\n",
        "  W_in = W_in.reshape((num_hidden_units,65))\n",
        "  W_out = W_out.reshape((1,num_hidden_units))\n",
        "  R_current = eval_params_hidden(W_in, W_out, Xs_aug.T, y1.T)\n",
        "  raw_param_perturb = learn_rng.standard_normal(size=len(flat_params))\n",
        "  unit_param_perturb = raw_param_perturb / np.linalg.norm(raw_param_perturb.flatten())\n",
        "  test_perturbation = unit_param_perturb * perturbation_scale\n",
        "  perturbed_flat_params = flat_params + test_perturbation\n",
        "  W_in_test, W_out_test = np.split(perturbed_flat_params, [num_hidden_units*65])\n",
        "  W_in_test = W_in_test.reshape((num_hidden_units,65))\n",
        "  W_out_test = W_out_test.reshape((1,num_hidden_units))\n",
        "  R_test = eval_params_hidden(W_in_test, W_out_test, Xs_aug.T, y1.T)\n",
        "  directional_grad_est = (R_test - R_current) / perturbation_scale\n",
        "  flat_params += step_scale * dimensional_scale_factor * directional_grad_est * unit_param_perturb\n",
        "\n",
        "  if step == 0 or (step + 1) % 500 == 0:\n",
        "    elapsed_time = time.time() - start_time\n",
        "    print(f'Step {step + 1}/{num_steps} completed | Current Total Reward: {R_current:.6f} | Time elapsed: {elapsed_time:.2f} seconds')\n",
        "W_in, W_out = np.split(flat_params, [num_hidden_units*65])\n",
        "W_in = W_in.reshape((num_hidden_units,65))\n",
        "W_out = W_out.reshape((1,num_hidden_units))\n",
        "eval_params_hidden(W_in, W_out, Xs_aug.T, y1.T, verbose=True)\n"
      ],
      "metadata": {
        "id": "LV67Oyy1nxSi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This more complex circuit gets us even closer to the theoretical maximum performance of 2829, but it's taking longer to get there. This is a consequence of both, the function evaluations required at each step being slower (for the more complex function) and because more iterations are needed to effectively search the higher dimensional space for a good configuration of $\\mathbf{W}_{in}$ and $\\mathbf{W}_{out}$. With even more hidden units and more time we can likely learn perfect discrimination, but it will take even longer (more than 3 minutes!)."
      ],
      "metadata": {
        "id": "DoYe61pfdTzu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Although the toy neural circuit models in this sequence are a far cry from actual neural circuits, they still provide insight into possible mechanisms of synaptic plasticity the brain. We can imagine a scenario where synaptic strengths between neurons in a circuit undergo small, transient perturbations. The brain might integrate and compare the performance of these perturbations over a learning episode (for example, a day) to previous performance levels. (Ee leave aside the specifics of how this integration and comparison occur for now.)\n",
        "\n",
        "If performance improves with a perturbation, synaptic changes could be consolidated in the direction of the perturbation, proportionate to the degree of improvement. Conversely, if performance worsens, changes might be consolidated in the opposite direction, also proportional to the performance decrease. This concept, while still vague, suggests a mechanism of synaptic adjustment based on performance feedback.\n",
        "\n",
        "One critical point to consider is the scalability of such a learning process. The number of learning episodes required for effective optimization grows with the number of parameters in a neural circuit. This implies that 'perturb-measure-step' plasticity cannot be the primary mechanism driving neural plasticity in large, complex neural circuits that learn rapidly. This limitation is critical, the lifetimes of most animals simply aren't long enough to accommodate the number of learning iterations needed for extensive optimization.\n",
        "\n",
        "However, as demonstrated above, a more complex circuit achieved significantly better performance in the discrimination task, so large complex circuits can be useful. This suggests that even if empirical evidence of perturbation-based learning in the brain exists and its physiological implementation is understood, such processes are unlikely to be the primary drivers of neural plasticity for complex and challenging behaviors.\n",
        "\n",
        "(One counterargument in favor of simple learning rules is that extensive learning might not be necessary if genetic predisposition starts the circuit off close to an optimal parameter configuration. Then subsequently, relatively slow learning processes could 'fine-tune' the neural circuit's configuration. However, as noted in our earlier discussions on evolution, changing environments necessitate that a significant portion of behavior must emerge from learning, thereby limiting the extent to which genetic predispositions can facilitate efficient and adaptive learning.)"
      ],
      "metadata": {
        "id": "4s0X34-jgHZ2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "In the next sequence we will explore the relationship between perturb-measure-step updates and the gradient in even more detail, show how this together with stochastic function evaluation enable introduce the idea of stochastic function e"
      ],
      "metadata": {
        "id": "B-UDcsvvhF9V"
      }
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "P2C1_Sequence4",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "2947ec06cd5545fb801bdbc651d74df2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4f30e724bae74aa3b9e0d4120aa39fce",
              "IPY_MODEL_999058aa8ca745e19a7655f8571a3d2b",
              "IPY_MODEL_c125bc87c18e4c3ca1e58acd9c5e3ef7"
            ],
            "layout": "IPY_MODEL_54f530103aca46d3a5b7266779524896"
          }
        },
        "4f30e724bae74aa3b9e0d4120aa39fce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f13af96f4c424c10acdf5155dadc2ffb",
              "IPY_MODEL_daa2526573ac4020a054b6f11381f973"
            ],
            "layout": "IPY_MODEL_9c6683dbd61548f2976a52e78dcc06f1"
          }
        },
        "999058aa8ca745e19a7655f8571a3d2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_250e7860a0ab4ddf864e02037a884e2f",
              "IPY_MODEL_e0cea406af6d40678a04869b37d8d652"
            ],
            "layout": "IPY_MODEL_e9214185418c44a0aa75c075413f7304"
          }
        },
        "c125bc87c18e4c3ca1e58acd9c5e3ef7": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_c6a93a90798947ac867a5c59ce59ff44",
            "msg_id": "",
            "outputs": []
          }
        },
        "54f530103aca46d3a5b7266779524896": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f13af96f4c424c10acdf5155dadc2ffb": {
          "model_module": "jupyter-matplotlib",
          "model_name": "MPLCanvasModel",
          "model_module_version": "^0.11",
          "state": {
            "_cursor": "default",
            "_data_url": "data:image/png;base64,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",
            "_dom_classes": [],
            "_figure_label": "Figure 2",
            "_image_mode": "full",
            "_message": "",
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "MPLCanvasModel",
            "_rubberband_height": 0,
            "_rubberband_width": 0,
            "_rubberband_x": 0,
            "_rubberband_y": 0,
            "_size": [
              400,
              400
            ],
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "MPLCanvasView",
            "capture_scroll": false,
            "footer_visible": false,
            "header_visible": false,
            "layout": "IPY_MODEL_830d4cba359e46c893fa8fe14bc86b85",
            "pan_zoom_throttle": 33,
            "resizable": false,
            "toolbar": "IPY_MODEL_eb02cab145bb462c8db65407ae5c5160",
            "toolbar_position": "left",
            "toolbar_visible": false
          }
        },
        "daa2526573ac4020a054b6f11381f973": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_390be4278e3648f49745cb61dd340a92",
            "msg_id": "",
            "outputs": []
          }
        },
        "9c6683dbd61548f2976a52e78dcc06f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "250e7860a0ab4ddf864e02037a884e2f": {
          "model_module": "jupyter-matplotlib",
          "model_name": "MPLCanvasModel",
          "model_module_version": "^0.11",
          "state": {
            "_cursor": "default",
            "_data_url": "data:image/png;base64,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",
            "_dom_classes": [],
            "_figure_label": "Figure 1",
            "_image_mode": "full",
            "_message": "",
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "MPLCanvasModel",
            "_rubberband_height": 0,
            "_rubberband_width": 0,
            "_rubberband_x": 0,
            "_rubberband_y": 0,
            "_size": [
              400,
              400
            ],
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "MPLCanvasView",
            "capture_scroll": false,
            "footer_visible": false,
            "header_visible": false,
            "layout": "IPY_MODEL_92595e2f4135470594c0d980974c9512",
            "pan_zoom_throttle": 33,
            "resizable": false,
            "toolbar": "IPY_MODEL_fb0af9b77b104a999adf702c39bce84a",
            "toolbar_position": "left",
            "toolbar_visible": false
          }
        },
        "e0cea406af6d40678a04869b37d8d652": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_236178ed397b4827ac0354668142428d",
              "IPY_MODEL_ef672c7c29344e0386183bc0c66d70a6"
            ],
            "layout": "IPY_MODEL_5b0a3d5a470040848438cd1b6b833abb"
          }
        },
        "e9214185418c44a0aa75c075413f7304": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c6a93a90798947ac867a5c59ce59ff44": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "390be4278e3648f49745cb61dd340a92": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "236178ed397b4827ac0354668142428d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Strike",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_50d103a151904dc489c7d896579540c5",
            "style": "IPY_MODEL_09eec50638fe476281e68383ae6f4ee9",
            "tooltip": ""
          }
        },
        "ef672c7c29344e0386183bc0c66d70a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "No Strike",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_e9cdcf4ef2fc411ba98e875710134688",
            "style": "IPY_MODEL_90635d639dfb4395a39556bdb5554ac4",
            "tooltip": ""
          }
        },
        "5b0a3d5a470040848438cd1b6b833abb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "50d103a151904dc489c7d896579540c5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "09eec50638fe476281e68383ae6f4ee9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "e9cdcf4ef2fc411ba98e875710134688": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "90635d639dfb4395a39556bdb5554ac4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "830d4cba359e46c893fa8fe14bc86b85": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "eb02cab145bb462c8db65407ae5c5160": {
          "model_module": "jupyter-matplotlib",
          "model_name": "ToolbarModel",
          "model_module_version": "^0.11",
          "state": {
            "_current_action": "",
            "_dom_classes": [],
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "ToolbarModel",
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "ToolbarView",
            "button_style": "",
            "collapsed": true,
            "layout": "IPY_MODEL_4b274d399c814e459aa45e52b2ab3857",
            "orientation": "vertical",
            "toolitems": [
              [
                "Home",
                "Reset original view",
                "home",
                "home"
              ],
              [
                "Back",
                "Back to previous view",
                "arrow-left",
                "back"
              ],
              [
                "Forward",
                "Forward to next view",
                "arrow-right",
                "forward"
              ],
              [
                "Pan",
                "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
                "arrows",
                "pan"
              ],
              [
                "Zoom",
                "Zoom to rectangle\nx/y fixes axis",
                "square-o",
                "zoom"
              ],
              [
                "Download",
                "Download plot",
                "floppy-o",
                "save_figure"
              ]
            ]
          }
        },
        "92595e2f4135470594c0d980974c9512": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fb0af9b77b104a999adf702c39bce84a": {
          "model_module": "jupyter-matplotlib",
          "model_name": "ToolbarModel",
          "model_module_version": "^0.11",
          "state": {
            "_current_action": "",
            "_dom_classes": [],
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "ToolbarModel",
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "ToolbarView",
            "button_style": "",
            "collapsed": true,
            "layout": "IPY_MODEL_fd4ad9b28d984f6e8533c6c9329059e1",
            "orientation": "vertical",
            "toolitems": [
              [
                "Home",
                "Reset original view",
                "home",
                "home"
              ],
              [
                "Back",
                "Back to previous view",
                "arrow-left",
                "back"
              ],
              [
                "Forward",
                "Forward to next view",
                "arrow-right",
                "forward"
              ],
              [
                "Pan",
                "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
                "arrows",
                "pan"
              ],
              [
                "Zoom",
                "Zoom to rectangle\nx/y fixes axis",
                "square-o",
                "zoom"
              ],
              [
                "Download",
                "Download plot",
                "floppy-o",
                "save_figure"
              ]
            ]
          }
        },
        "4b274d399c814e459aa45e52b2ab3857": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd4ad9b28d984f6e8533c6c9329059e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccf7ab4377c84562bb5c4e7813e79122": {
          "model_module": "jupyter-matplotlib",
          "model_name": "MPLCanvasModel",
          "model_module_version": "^0.11",
          "state": {
            "_cursor": "default",
            "_data_url": "data:image/png;base64,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",
            "_dom_classes": [],
            "_figure_label": "Figure 3",
            "_image_mode": "full",
            "_message": "",
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "MPLCanvasModel",
            "_rubberband_height": 0,
            "_rubberband_width": 0,
            "_rubberband_x": 0,
            "_rubberband_y": 0,
            "_size": [
              400,
              400
            ],
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "MPLCanvasView",
            "capture_scroll": false,
            "footer_visible": false,
            "header_visible": false,
            "layout": "IPY_MODEL_b921a573a8cb48b39b70348eecf4a92c",
            "pan_zoom_throttle": 33,
            "resizable": false,
            "toolbar": "IPY_MODEL_8a344acb04414e37993a0d7362d05052",
            "toolbar_position": "left",
            "toolbar_visible": false
          }
        },
        "b921a573a8cb48b39b70348eecf4a92c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8a344acb04414e37993a0d7362d05052": {
          "model_module": "jupyter-matplotlib",
          "model_name": "ToolbarModel",
          "model_module_version": "^0.11",
          "state": {
            "_current_action": "",
            "_dom_classes": [],
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "ToolbarModel",
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "ToolbarView",
            "button_style": "",
            "collapsed": true,
            "layout": "IPY_MODEL_0fb7378294fc4b7f86b0c61fa1161eb1",
            "orientation": "vertical",
            "toolitems": [
              [
                "Home",
                "Reset original view",
                "home",
                "home"
              ],
              [
                "Back",
                "Back to previous view",
                "arrow-left",
                "back"
              ],
              [
                "Forward",
                "Forward to next view",
                "arrow-right",
                "forward"
              ],
              [
                "Pan",
                "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
                "arrows",
                "pan"
              ],
              [
                "Zoom",
                "Zoom to rectangle\nx/y fixes axis",
                "square-o",
                "zoom"
              ],
              [
                "Download",
                "Download plot",
                "floppy-o",
                "save_figure"
              ]
            ]
          }
        },
        "0fb7378294fc4b7f86b0c61fa1161eb1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}