{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dcownden/PerennialProblemsOfLifeWithABrain/blob/main/sequences/P2C1_Optimization/student/P2C1_Sequence1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/sequences/P2C1_Optimization/student/P2C1_Sequence1.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The following is part of a test for an upcoming text book on computational neuroscience from an optimization and learning perspective. The book will start with evolution because ultimately, all aspects of the brain are shaped by evolution and, as we will see, evolution can also be seen as an optimization algorithm. We are sharing it now to get feedback on what works and what does not and the developments we should do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "# **2.1.1: Optimization in One Dimension: Developing Intuition**\n",
    "In the first part of the book we gained insight into what the brain is for: the primary function of the brain is the rapid acquisition of adaptive behaviours. Now that we know what a brain is for, we are going to start thinking about how it does what it needs to do. Instead of taking a bottom up approach grounded in observed physiological mechanisms, we are going to use a problem oriented, top down approach. That is, we will think about what problems the brain is solving and then survey the various physiological mechanisms that could feasibly implement algorithms that solve those problems. We will start with problems that are simple to understand from a statistical and mathematical perspective; basic optimization and then a broad sub-field of machine learning known as supervised learning. To develop and ground our intuitions, in particular around problem scale, we start with some very simple problems.\n",
    "\n",
    "In our last chapter, 1.4 Life is Reinforcement Learning, we introduced the idea that within life time learning of an organism can be understood as solving a particular set of reinforcement learning problems selected for by the evolutionary process. In particular we view the evolutionary process as selecting both the intrinsic reward signals (i.e. which kinds of base sensory inputs are intrinsically rewarding) and the neural plasticity rules by which the sensory to behaviour function is updated using these reward signals. That is evolution selects for both the goals and the method of learning, choosing sensory grounded goals that guide behaviour towards being adaptive in the evolutionary sense (survival and reproduction) and learning methods that *quickly* develop these adaptive behaviours. We will come back to RL in the 4th part of this book but before we do we want to ground ourselves in a general optimization perspective.\n",
    "\n",
    "### Objective: Solve simple optimization problems using perturbation methods, and connect these methods with physiological neural plasticity mechanisms.\n",
    "\n",
    "In this sequence we will:\n",
    "\n",
    "* Introduce and review the fundamental ideas of optimization.\n",
    "\n",
    "* Introduce the perturb -> measure -> update learning rule\n",
    "\n",
    "* Introduce a simple visual (binary) discrimination tasks\n",
    "\n",
    "* Show how perturb -> measure -> update can be used to train a simple threshold striking rule that solves this binary discrimination problem.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Setup\n",
    "\n",
    "Run the following cell to setup and install the various dependencies and helper functions for this ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Dependencies, Imports and Setup\n",
    "# @markdown You don't need to worry about how this code works â€“ but you do need to **run the cell**\n",
    "!apt install libgraphviz-dev > /dev/null 2> /dev/null #colab\n",
    "!pip install ipympl pygraphviz vibecheck datatops jupyterquiz ucimlrepo > /dev/null 2> /dev/null #google.colab\n",
    "\n",
    "import asyncio\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "import numpy as np\n",
    "import itertools\n",
    "import collections\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pygraphviz as pgv\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from io import BytesIO\n",
    "from enum import Enum\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, clear_output, Markdown, HTML, Image\n",
    "from jupyterquiz import display_quiz\n",
    "from vibecheck import DatatopsContentReviewContainer\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from tqdm.notebook import tqdm\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "data_set = fetch_ucirepo(id=80)\n",
    "X = data_set.data.features.values\n",
    "# Translate the data to have a minimum of 0\n",
    "X_translated = X - X.min()\n",
    "# Scale the data to have a range from 0 to 12 (which is 6 - (-6))\n",
    "scaling_factor = 12 / (X.max() - X.min())\n",
    "X_scaled = X_translated * scaling_factor\n",
    "# Finally, shift the data to be centered between -6 and 6\n",
    "X_final = X_scaled - 6\n",
    "\n",
    "y = data_set.data.targets.values\n",
    "rng = np.random.default_rng(seed=2021)\n",
    "scramble_permutation = rng.permutation(X.shape[1])\n",
    "Xs = X_final[:, scramble_permutation]\n",
    "y1 = y % 2\n",
    "y2 = np.array(y >= 5, dtype=y.dtype)\n",
    "simple_index = ((y.flatten()==1) | (y.flatten()==0))\n",
    "X_simple = Xs[simple_index]\n",
    "y1_simple = y1[simple_index]\n",
    "# if you only had one feature which would likely be best for discrimination\n",
    "epsilon = 10\n",
    "class_a_sep = np.mean(X_simple[y1_simple.flatten() == 1, :], axis=0) / (np.std(X_simple[y1_simple.flatten() == 1, :], axis=0) + epsilon)\n",
    "class_b_sep = np.mean(X_simple[y1_simple.flatten() == 0, :], axis=0) / (np.std(X_simple[y1_simple.flatten() == 0, :], axis=0) + epsilon)\n",
    "best_feature = np.argmax(class_a_sep - class_b_sep)\n",
    "print(f'Best feature is {best_feature}')\n",
    "X_simple_1_feature = X_simple[:, [best_feature]]\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "# random seed settings and\n",
    "# getting torch to use gpu if it's there\n",
    "\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  \"\"\"\n",
    "  Function that controls randomness. NumPy and random modules must be imported.\n",
    "\n",
    "  Args:\n",
    "    seed : Integer\n",
    "      A non-negative integer that defines the random state. Default is `None`.\n",
    "    seed_torch : Boolean\n",
    "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
    "      must be imported. Default is `True`.\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "  \"\"\"\n",
    "  DataLoader will reseed workers following randomness in\n",
    "  multi-process data loading algorithm.\n",
    "\n",
    "  Args:\n",
    "    worker_id: integer\n",
    "      ID of subprocess to seed. 0 means that\n",
    "      the data will be loaded in the main process\n",
    "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def set_device():\n",
    "  \"\"\"\n",
    "  Set the device. CUDA if available, CPU otherwise\n",
    "\n",
    "  Args:\n",
    "    None\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "    print(\"This notebook isn't using and doesn't need a GPU. Good.\")\n",
    "  else:\n",
    "    print(\"GPU is enabled in this notebook but not needed.\")\n",
    "    print(\"If possible, in the menu under `Runtime` -> \")\n",
    "    print(\"`Change runtime type.`  select `CPU`\")\n",
    "\n",
    "  return device\n",
    "\n",
    "\n",
    "SEED = 2021\n",
    "set_seed(seed=SEED)\n",
    "DEVICE = set_device()\n",
    "\n",
    "\n",
    "def printmd(string):\n",
    "  display(Markdown(string))\n",
    "\n",
    "\n",
    "# the different utility .py files used in this notebook\n",
    "filenames = []\n",
    "# just run the code straight out of the response, no local copies needed!\n",
    "for filename in filenames:\n",
    "  url = f'https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/utils/{filename}'\n",
    "  response = requests.get(url)\n",
    "  # Check that we got a valid response\n",
    "  if response.status_code == 200:\n",
    "    code = response.content.decode()\n",
    "    exec(code)\n",
    "  else:\n",
    "    print(f'Failed to download {url}')\n",
    "\n",
    "# environment contingent imports\n",
    "try:\n",
    "  print('Running in colab')\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "  from google.colab import data_table\n",
    "  data_table.disable_dataframe_formatter()\n",
    "  #from google.colab import output as colab_output\n",
    "  #colab_output.enable_custom_widget_manager()\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "  print('Not running in colab')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib widget\n",
    "plt.style.use(\"https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/pplb.mplstyle\")\n",
    "plt.ioff() #need to use plt.show() or display explicitly\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "def remove_ip_clutter(fig):\n",
    "  fig.canvas.header_visible = False\n",
    "  fig.canvas.toolbar_visible = False\n",
    "  fig.canvas.resizable = False\n",
    "  fig.canvas.footer_visible = False\n",
    "  fig.canvas.draw()\n",
    "\n",
    "\n",
    "def content_review(notebook_section: str):\n",
    "  return DatatopsContentReviewContainer(\n",
    "    \"\",  # No text prompt\n",
    "    notebook_section,\n",
    "    {\n",
    "      \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "      \"name\": \"neuro_book\",\n",
    "      \"user_key\": \"xuk960xj\",\n",
    "    },\n",
    "  ).render()\n",
    "feedback_prefix = \"P2C1_S1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# 2.1.1.1: Optimizing a Polynomial Analytically\n",
    "\n",
    "\n",
    "\n",
    "In general, optimization problems are of the form: \"Find some set of parameters or values, say $x$, such that some other scalar valued quantity which depends in some way on those values, i.e. a function of $x$, calli it $f(x)$, is as large (or small) as possible, subject to some constraints on the possible values of $x$.\" In other words, we're looking for the best setting on a dial (the value of $x$) that maximizes or minimizes our outcome (the value of $f(x)$), within certain limits (constraints on $x$).\n",
    "\n",
    "Here's an example. Find a value of $x$ on the interval $[-2, 2]$ such that $f(x) = -x^2 + 2x + 3$ is as large as possible. This might be written more tersely with symbols as:\n",
    "\n",
    "$$\\underset{x\\in[-2,2]}{\\arg \\max}(-x^2 + 2x + 3)  $$\n",
    "\n",
    "If you have taken (and remember!) a calculus course you might think to yourself, \"Oh, I know how to do that\". First we take the derivative,\n",
    "\n",
    "$$\n",
    "\\frac{\\text{d}}{\\text{d}x} -x^2 + 2x + 3 = -2x + 2\n",
    "$$\n",
    "\n",
    "then we set that equal to zero and solve for the extrema. Since the derivative is the instantaneous rate of change of $f(x)$ with respect to $x$, setting the derivative to zero helps us find the peaks or valleys of the equation, indicating where $f(x)$ is at its largest or smallest values within our constraints.\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "-2x + 2 &= 0 \\\\\n",
    "x &= 1\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "If you really dig into your calculus memories (if you have them) you might recall that you also need to check the concavity (whether the curve bends upwards or downwards) to see if this zero-derivative point is a maximum or a minimum. In the same way that the first derivative gives the slope of $f(x)$ the second derivative gives the curvature.\n",
    "$$\n",
    "\\left. \\frac{\\text{d}^2}{\\text{d}x^2} -x^2 + 2x + 3 \\right|_{x=1}= -2\n",
    "$$\n",
    "\n",
    "The negative curvature at $x=1$ tells us that the curve bends downwards there, so the zero-derivative point, $x=1$, is a maximum. Looking at the picture below, this all seems to be correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown **Run this cell** to plot the function we are optimizing\n",
    "\n",
    "def f(x):\n",
    "  return -(x-1)**2 + 4\n",
    "\n",
    "x = np.linspace(-2, 2, 400)\n",
    "y = f(x)\n",
    "\n",
    "ymax = np.max(y)\n",
    "xmax = x[np.argmax(y)]\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "# Plot the function\n",
    "ax.plot(x, y, label='f(x)')\n",
    "ax.scatter(xmax, ymax, color='red', label=f'Max at {xmax:.2f}', zorder=5)\n",
    "ax.set_title('Plot of f(x) = -x^2 + 2x + 3 with max highlighted')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('f(x)')\n",
    "ax.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "If the parabola were opening up instead of down the maximum would have been on the edges, so we should have checked those as well.\n",
    "\n",
    "Although this particular problem was framed in the abstract language of polynomials and math symbols, we can view the brain's plasticity as a form of optimization on the 'parameters' of the brain. In such cases constraints like $x\\in[-2,2]$ are critical as they correspond to physiologically informed constraints. Just as we look for the optimal value of $x$ within constraints, the brain adjusts its neural 'parameters' within the limits of physiological constraints to optimize behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "**Math Exercise**\n",
    "1. Use the calculus principles we've discussed and apply them to derive a general formula for finding the maxima or minima of any parabola, parameterized by coefficients $a$, $b$, and $c$ as\n",
    "\n",
    "$$f(x) = a(x-b)^2 + c$$\n",
    "\n",
    "(Answer: The vertex of the parabola, occurring at $x=b$, is either the global maximum or minimum value. Whether it is a maximum or minimum is determined by the curvature of the parabola, which is given by coefficient $a$. Specifically, the vertex represents a minimum when $a$ is positive and the parabola opens upwards, and a maximum when $a$ is negative and the parabola opens downwards. The value at this vertex, $f(b) = c$, is thus either the maximum or minimum value depending on $a$'s sign. Virtually all practical optimizations problems involve constraints. With $x$ constrained to an interval, two possible cases arise. First, if the vertex falls outside this interval, both the maximum and minimum values within the constraints will occur at the boundary points. Second, if the vertex falls within the constrained interval, then either the vertex is a minimum (with $a$ positive) and the maximum value of the function will be found at a boundary point, or the vertex is a maximum (with $a$ negative) and the minimum value will similarly be located at the boundary.)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_M1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# 2.1.1.2: Optimizing a Polynomial with Propose and Reject\n",
    "Now, the analytic method above of taking derivatives, finding zeros, and checking concavity offers a clear solution to optimization problems. However, these sorts of computations are unlikely to serve as model of low level neural plasciticty, for several interelated reasons having to do with scalability, complexity, and information requirements, each of which we will unpack in more detail later. For now we take as given that something like analytic optimization is likely not what is happening in the brain. This raises the question of whether there are other more simple methods for solving this kind of problem, methods that are more likely to have clearer correspondence witht the physilology of th brain.\n",
    "\n",
    "One of the simplest optimization strategies that exists, and one that proved quite effective earlier in this book, is propose and reject. Indeed, evolution through natural selection is roughly running a kind of propose (new variants through mutation and recombination) and accept or reject (through selective survival and reproduction) algorithm on the living world. To further develop our intuitions, let's apply this approach to our familiar optimization challenge of finding the value of $x$ that maximizes a quadratic function $f(x)$.\n",
    "\n",
    "Propose and reject algorithms offer a conceptual simplicity that makes them easier to envision as mechanisms within the brain. Imagine synaptic weights between neurons undergoing slight, temporary adjustments. If these adjustments yield a positive outcome, they are reinforced and made more permanent, laying the groundwork for future experimentation. This is, admittedly, an oversimplification, but it outlines a process that aligns more closely with what is known of the underlying physiology of neural plasticity at the micro level and behavioural plasticity at the macro level: iterative, trial and error learning.\n",
    "\n",
    "Below, is an interactive implementation of the propose-and-reject method applied to finding the maximum of a quadratic function. Stepping through the process will give a feel for the iterative nature of decision-making. Start by clicking 'Propose' to sample a new proposed $x$ value. Then, decide whether to 'Accept' or 'Reject' the proposed point based on a comparison with the previous point. Your goal is to find the peak of the curve. 'Show History' is turned on to start so you can see all of the previous steps in the process. You can toggle the 'Show Function' button to plot the polynomial we are optimizing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Stepping Through Optimization with Propose and Reject\n",
    "# @markdown **Run this cell** to try your hand at manually finding the maximum of a quadratic function using propose and reject.\n",
    "class InteractivePolynomialProposeReject:\n",
    "  def __init__(self,\n",
    "               polynomial_max = 1,\n",
    "               bounds=(-4, 4),\n",
    "               step_size=0.5, seed=None):\n",
    "    self.polynomial_max = polynomial_max\n",
    "    self.polynomial = lambda x: -(x - polynomial_max)**2 + 4\n",
    "    self.bounds = bounds\n",
    "    self.step_size = step_size\n",
    "    self.rng = np.random.default_rng(seed)\n",
    "    self.current_x = self.rng.uniform(self.bounds[0], self.bounds[1])\n",
    "    self.current_y = self.polynomial(self.current_x)\n",
    "    self.proposed_x = None\n",
    "    self.proposed_y = None\n",
    "    self.x_history = []\n",
    "    self.y_history = []\n",
    "    self.proposals_evaluated = 0\n",
    "    self.fig, self.ax = plt.subplots(figsize=(6, 4))\n",
    "    self.propose = widgets.Button(description='Propose')\n",
    "    self.accept = widgets.Button(description='Accept', disabled=True)\n",
    "    self.reject = widgets.Button(description='Reject', disabled=True)\n",
    "    self.full_step = widgets.Button(description='Do It For Me', disabled=True)\n",
    "    self.reset = widgets.Button(description='Reset')\n",
    "    self.show_history = widgets.ToggleButton(value=True, description='Show History')\n",
    "    self.show_curve = widgets.ToggleButton(value=False, description='Show Function')\n",
    "    self.init_plot()\n",
    "    self.narration_display = widgets.Output()\n",
    "    remove_ip_clutter(self.fig)\n",
    "    # Arrange widgets in a layout\n",
    "    buttons_layout = widgets.VBox([\n",
    "        widgets.HBox([self.propose, self.accept, self.reject]),\n",
    "        self.full_step,\n",
    "        widgets.HBox([self.reset, self.show_history, self.show_curve])])\n",
    "    buttons_and_narration = widgets.HBox([buttons_layout, self.narration_display])\n",
    "    self.ui = widgets.VBox([self.fig.canvas, buttons_and_narration])\n",
    "    #bind actions to handlers\n",
    "    self.propose.on_click(self.on_propose_clicked)\n",
    "    self.accept.on_click(self.on_accept_clicked)\n",
    "    self.reject.on_click(self.on_reject_clicked)\n",
    "    self.full_step.on_click(lambda btn: asyncio.create_task(self.on_full_step_clicked(btn)))\n",
    "    self.reset.on_click(self.on_reset_clicked)\n",
    "    self.show_curve.observe(self.on_show_curve_toggled, 'value')\n",
    "    self.show_history.observe(self.on_show_history_toggled, 'value')\n",
    "\n",
    "  def init_plot(self):\n",
    "    \"\"\"Initialize the plot with placeholder data.\"\"\"\n",
    "    x_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "    y_vals = self.polynomial(x_vals)\n",
    "    # Initial plot commands return line objects, keep references to them\n",
    "    self.line_polynomial, = self.ax.plot(x_vals, y_vals, alpha=1.0, label='Polynomial Curve')\n",
    "    self.point_current, = self.ax.plot([self.current_x], [self.current_y], 'bo', label='Current')\n",
    "    self.point_proposed, = self.ax.plot([], [], 'rx', label='Proposed')  # Empty data to start\n",
    "    self.points_history, = self.ax.plot([], [], 'ks', alpha=0.5, label='History')  # Empty data to start\n",
    "    self.ax.legend()\n",
    "    alpha = 1 if self.show_curve.value else 0\n",
    "    self.line_polynomial.set_alpha(alpha)\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "    self.ax.set_xlabel('x')\n",
    "    self.ax.set_ylabel('f(x)')\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_propose_clicked(self, button):\n",
    "    self.proposals_evaluated += 1\n",
    "    perturbation = self.rng.standard_normal() * self.step_size\n",
    "    self.proposed_x = self.current_x + perturbation\n",
    "    self.proposed_y = self.polynomial(self.proposed_x)\n",
    "    self.point_proposed.set_data([self.proposed_x], [self.proposed_y])\n",
    "    self.fig.canvas.draw_idle()\n",
    "    #self.update_plot()\n",
    "    with self.narration_display:\n",
    "      clear_output()\n",
    "      print(f'Proposed x: {self.proposed_x:.3f}, y: {self.proposed_y:.3f}.')\n",
    "      print(f' Current x: {self.current_x:.3f}, y: {self.current_y:.3f}.')\n",
    "      print(\"Click 'Accept' or 'Reject' to accept or reject this proposed x?\")\n",
    "      print(f'Proposals evaluated so far: {self.proposals_evaluated}')\n",
    "    self.accept.disabled = False\n",
    "    self.reject.disabled = False\n",
    "    self.propose.disabled = True\n",
    "    self.full_step.disabled = True\n",
    "\n",
    "  def on_accept_clicked(self, button):\n",
    "    with self.narration_display:\n",
    "      clear_output()\n",
    "      print(f'Accepted x: {self.proposed_x:.3f}, y: {self.proposed_y:.3f}.')\n",
    "      print(f\"Click 'Propose' or 'Do It For Me' to try a new value.\")\n",
    "      print(f'Proposals evaluated so far: {self.proposals_evaluated}')\n",
    "    self.x_history.append(self.current_x)\n",
    "    self.y_history.append(self.current_y)\n",
    "    self.current_x = self.proposed_x\n",
    "    self.current_y = self.proposed_y\n",
    "    self.proposed_x = None\n",
    "    self.proposed_y = None\n",
    "    self.point_current.set_data([self.current_x], [self.current_y])\n",
    "    self.points_history.set_data(self.x_history, self.y_history)\n",
    "    self.point_proposed.set_data([], [])\n",
    "    self.fig.canvas.draw_idle()\n",
    "    self.accept.disabled = True\n",
    "    self.reject.disabled = True\n",
    "    self.propose.disabled = False\n",
    "    self.full_step.disabled = False\n",
    "\n",
    "  def on_reject_clicked(self, button):\n",
    "    with self.narration_display:\n",
    "      clear_output()\n",
    "      print(f'Rejected x: {self.proposed_x:.3f}, y: {self.proposed_y:.3f}.')\n",
    "      print(f' Keeping x: {self.current_x:.3f}, y: {self.current_y:.3f}.')\n",
    "      print(f\"Click 'Propose' or 'Do It For Me' to try a new value.\")\n",
    "      print(f'Proposals evaluated so far: {self.proposals_evaluated}')\n",
    "    self.proposed_x = None\n",
    "    self.proposed_y = None\n",
    "    self.point_proposed.set_data([], [])\n",
    "    self.fig.canvas.draw_idle()\n",
    "    self.accept.disabled = True\n",
    "    self.reject.disabled = True\n",
    "    self.propose.disabled = False\n",
    "    self.full_step.disabled = False\n",
    "\n",
    "  async def on_full_step_clicked(self, button):\n",
    "    # Automatically propose, accept if better, or reject\n",
    "    self.on_propose_clicked(button)  # Simulate a proposal\n",
    "    self.accept.disabled = True\n",
    "    self.reject.disabled = True\n",
    "    #await asyncio.sleep(2)  # Non-blocking wait for 1 second to allow UI to update\n",
    "    if self.proposed_y > self.current_y:\n",
    "        self.on_accept_clicked(button)\n",
    "    else:\n",
    "        self.on_reject_clicked(button)\n",
    "\n",
    "  def on_reset_clicked(self, button):\n",
    "    self.proposals_evaluated = 0\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Reset. Clearing history')\n",
    "      print(f'Generating a new curve for you to find the max of.')\n",
    "    self.polynomial_max = self.rng.uniform(self.bounds[0], self.bounds[1])\n",
    "    self.polynomial = lambda x: -(x - self.polynomial_max)**2 + 5\n",
    "    x_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "    y_vals = self.polynomial(x_vals)\n",
    "    self.line_polynomial.set_data(x_vals, y_vals)\n",
    "    min_y, max_y = min(y_vals), max(y_vals)\n",
    "    padding = (max_y - min_y) * 0.1  # Add some padding to the limits\n",
    "    self.ax.set_ylim(min_y - padding, max_y + padding)\n",
    "    self.current_x = self.rng.uniform(self.bounds[0], self.bounds[1])\n",
    "    self.current_y = self.polynomial(self.current_x)\n",
    "    self.proposed_x = None\n",
    "    self.proposed_y = None\n",
    "    self.x_history = []\n",
    "    self.y_history = []\n",
    "    self.accept.disabled = True\n",
    "    self.reject.disabled = True\n",
    "    self.propose.disabled = False\n",
    "    self.point_current.set_data([self.current_x], [self.current_y])\n",
    "    self.points_history.set_data(self.x_history, self.y_history)\n",
    "    self.point_proposed.set_data([], [])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_curve_toggled(self, change):\n",
    "    alpha = 1 if self.show_curve.value else 0\n",
    "    self.line_polynomial.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_history_toggled(self, change):\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "ippr = InteractivePolynomialProposeReject()\n",
    "display(ippr.fig.canvas)\n",
    "clear_output()\n",
    "display(ippr.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "So propose and reject works pretty well, but there is a notable limitation. Whenever the proposed step is in the 'wrong' direction, we don't make any progress towards a better $x$ value. Although propose and reject has a nice ratcheting featureâ€”that is, we never pick an $x$ value that is worse than the one we currently haveâ€”we can potentially waste a lot of evaluations on test steps in the wrong direction. To overcome this limitation, we can introduce a tweak: making updates in the opposite direction of a 'wrong' step. This tweak shifts our evaluative question from 'Is this a good new point to jump to?' to 'In which direction should I change the parameter?'. This shift helps us avoid 'wasting' unfavorable proposals. Specifically, by using every proposalâ€”favorable or notâ€”for guidance, this method ensures that each test step, regardless of its initial direction, contributes valuable information for parameter adjustment. However, this leaves open the question of how far to step in that opposite direction. For now, let's just try stepping as far as the initially proposed step but in the opposite direction. You can try out this modified version of the algorithm in the interactive widget below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Manual Optimization with Modified Propose and Reject (always step)\n",
    "# @markdown **Run this cell** to try your hand at manually finding the maximum of a quadratic function with this modified Propose and Reject method.\n",
    "class InteractivePolynomialTestStep:\n",
    "  def __init__(self,\n",
    "               polynomial_max = 1,\n",
    "               bounds=(-4, 4),\n",
    "               step_size=0.5, seed=None):\n",
    "    self.polynomial_max = polynomial_max\n",
    "    self.polynomial = lambda x: -(x - polynomial_max)**2 + 4\n",
    "    self.bounds = bounds\n",
    "    self.step_size = step_size\n",
    "    self.rng = np.random.default_rng(seed)\n",
    "    self.current_x = self.rng.uniform(self.bounds[0], self.bounds[1])\n",
    "    self.current_y = self.polynomial(self.current_x)\n",
    "    self.proposed_x = None\n",
    "    self.proposed_y = None\n",
    "    self.x_history = []\n",
    "    self.y_history = []\n",
    "    self.proposals_evaluated = 0\n",
    "    self.fig, self.ax = plt.subplots(figsize=(6, 4))\n",
    "    self.propose = widgets.Button(description='Propose')\n",
    "    self.take_step = widgets.Button(description='Take Step')\n",
    "    self.full_step = widgets.Button(description='Do It For Me', disabled=True)\n",
    "    self.reset = widgets.Button(description='Reset')\n",
    "    self.take_step.disabled = True  # Disable since there's no proposal initially\n",
    "    self.show_history = widgets.ToggleButton(value=True, description='Show History')\n",
    "    self.show_curve = widgets.ToggleButton(value=False, description='Show Function')\n",
    "    self.init_plot()\n",
    "    self.narration_display = widgets.Output()\n",
    "    remove_ip_clutter(self.fig)\n",
    "    # Arrange widgets in a layout\n",
    "    buttons_layout = widgets.VBox([\n",
    "        widgets.HBox([self.propose, self.take_step]),\n",
    "        self.full_step,\n",
    "        widgets.HBox([self.reset, self.show_history, self.show_curve])])\n",
    "    buttons_and_narration = widgets.HBox([buttons_layout, self.narration_display])\n",
    "    self.ui = widgets.VBox([self.fig.canvas, buttons_and_narration])\n",
    "    #bind actions to handlers\n",
    "    self.propose.on_click(self.on_propose_clicked)\n",
    "    self.take_step.on_click(self.on_take_step_clicked)\n",
    "    self.full_step.on_click(lambda btn: asyncio.create_task(self.on_full_step_clicked(btn)))\n",
    "    self.reset.on_click(self.on_reset_clicked)\n",
    "    self.show_curve.observe(self.on_show_curve_toggled, 'value')\n",
    "    self.show_history.observe(self.on_show_history_toggled, 'value')\n",
    "\n",
    "  def init_plot(self):\n",
    "    \"\"\"Initialize the plot with placeholder data.\"\"\"\n",
    "    x_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "    y_vals = self.polynomial(x_vals)\n",
    "    # Initial plot commands return line objects, keep references to them\n",
    "    self.line_polynomial, = self.ax.plot(x_vals, y_vals, alpha=1.0, label='Polynomial Curve')\n",
    "    self.point_current, = self.ax.plot([self.current_x], [self.current_y], 'bo', label='Current')\n",
    "    self.point_proposed, = self.ax.plot([], [], 'rx', label='Proposed')  # Empty data to start\n",
    "    self.points_history, = self.ax.plot([], [], 'ks', alpha=0.5, label='History')  # Empty data to start\n",
    "    self.ax.legend()\n",
    "    alpha = 1 if self.show_curve.value else 0\n",
    "    self.line_polynomial.set_alpha(alpha)\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "    self.ax.set_xlabel('x')\n",
    "    self.ax.set_ylabel('f(x)')\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_propose_clicked(self, button):\n",
    "    self.proposals_evaluated += 1\n",
    "    perturbation = self.rng.standard_normal() * self.step_size\n",
    "    self.proposed_x = self.current_x + perturbation\n",
    "    self.proposed_y = self.polynomial(self.proposed_x)\n",
    "    self.point_proposed.set_data([self.proposed_x], [self.proposed_y])\n",
    "    self.fig.canvas.draw_idle()\n",
    "    #self.update_plot()\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Proposed x: {self.proposed_x:.3f}, y: {self.proposed_y:.3f}.')\n",
    "      print(f' Current x: {self.current_x:.3f}, y: {self.current_y:.3f}.')\n",
    "      print(\"Click 'Take Step' to update x?\")\n",
    "      print(f'Proposals evaluated so far: {self.proposals_evaluated}')\n",
    "    self.take_step.disabled = False\n",
    "    self.propose.disabled = True\n",
    "    self.full_step.disabled = True\n",
    "\n",
    "  def on_take_step_clicked(self, button):\n",
    "    if self.proposed_y > self.current_y:\n",
    "      with self.narration_display:\n",
    "        clear_output(wait=True)\n",
    "        print('Proposed is better stepping to proposed')\n",
    "        print(f'Step to x: {self.proposed_x:.3f}, y: {self.proposed_y:.3f}.')\n",
    "        print(f\"Click 'Propose' or 'Do It For Me' to try a new value.\")\n",
    "        print(f'Points evaluated so far: {self.proposals_evaluated}')\n",
    "      self.x_history.append(self.current_x)\n",
    "      self.y_history.append(self.current_y)\n",
    "      self.current_x = self.proposed_x\n",
    "      self.current_y = self.proposed_y\n",
    "      self.proposed_x = None\n",
    "      self.proposed_y = None\n",
    "      self.point_current.set_data([self.current_x], [self.current_y])\n",
    "      self.points_history.set_data(self.x_history, self.y_history)\n",
    "      self.point_proposed.set_data([], [])\n",
    "    elif self.proposed_y < self.current_y:\n",
    "      mirror_x = self.current_x - (self.proposed_x - self.current_x)\n",
    "      mirror_y = self.polynomial(mirror_x)\n",
    "      self.proposals_evaluated += 1\n",
    "      with self.narration_display:\n",
    "        clear_output(wait=True)\n",
    "        print('Proposed is not as good as current, going in the opposite direction.')\n",
    "        print(f'Step to x: {mirror_x:.3f}, y: {mirror_y:.3f}.')\n",
    "        print(f'Points evaluated so far: {self.proposals_evaluated}')\n",
    "        print(f\"Click 'Propose' or 'Do It For Me' to try a new value.\")\n",
    "      self.x_history.append(self.current_x)\n",
    "      self.y_history.append(self.current_y)\n",
    "      self.current_x = mirror_x\n",
    "      self.current_y = mirror_y\n",
    "      self.proposed_x = None\n",
    "      self.proposed_y = None\n",
    "      self.point_current.set_data([self.current_x], [self.current_y])\n",
    "      self.points_history.set_data(self.x_history, self.y_history)\n",
    "      self.point_proposed.set_data([], [])\n",
    "    self.fig.canvas.draw_idle()\n",
    "    self.take_step.disabled = True\n",
    "    self.propose.disabled = False\n",
    "    self.full_step.disabled = False\n",
    "\n",
    "  async def on_full_step_clicked(self, button):\n",
    "    # Automatically propose, accept if better, or reject\n",
    "    self.on_propose_clicked(button)  # Simulate a proposal\n",
    "    #await asyncio.sleep(1)  # Non-blocking wait for 1 second to allow UI to update\n",
    "    self.on_take_step_clicked(button)  # Simulate a step\n",
    "\n",
    "  def on_reset_clicked(self, button):\n",
    "    self.proposals_evaluated = 0\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Reset. Clearing history')\n",
    "      print(f'Generating a new curve for you to find the max of.')\n",
    "    self.polynomial_max = self.rng.uniform(self.bounds[0], self.bounds[1])\n",
    "    self.polynomial = lambda x: -(x - self.polynomial_max)**2 + 5\n",
    "    x_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "    y_vals = self.polynomial(x_vals)\n",
    "    self.line_polynomial.set_data(x_vals, y_vals)\n",
    "    min_y, max_y = min(y_vals), max(y_vals)\n",
    "    padding = (max_y - min_y) * 0.1  # Add some padding to the limits\n",
    "    self.ax.set_ylim(min_y - padding, max_y + padding)\n",
    "    self.current_x = self.rng.uniform(self.bounds[0], self.bounds[1])\n",
    "    self.current_y = self.polynomial(self.current_x)\n",
    "    self.proposed_x = None\n",
    "    self.proposed_y = None\n",
    "    self.x_history = []\n",
    "    self.y_history = []\n",
    "    self.take_step.disabled = True\n",
    "    self.propose.disabled = False\n",
    "    self.point_current.set_data([self.current_x], [self.current_y])\n",
    "    self.points_history.set_data(self.x_history, self.y_history)\n",
    "    self.point_proposed.set_data([], [])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_curve_toggled(self, change):\n",
    "    alpha = 1 if self.show_curve.value else 0\n",
    "    self.line_polynomial.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_history_toggled(self, change):\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "ipts = InteractivePolynomialTestStep()\n",
    "display(ipts.fig.canvas)\n",
    "clear_output()\n",
    "display(ipts.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This modified propose and reject is likely more efficient at first, especially in moving quickly towards the general area of the maximum. However, an issue arises near the maximum value: the risk of \"over-shooting\" increases, and unlike the original version of propose and reject, this always steo method can sometimes step to worse $x$ values because it lacks a strict ratcheting mechanism. One way to mitigate this issue is to fiddle with step size, but in doing so we will always face a tradeoff. Large step sizes are helpful in the beginning to quickly get into the rough neighbourhood of the maximum and smaller step sizes are better once we are close to the maximum to dial in the maximum precisely. However, without a sense of how close or far away the maximum is, it is difficult to choose an appropriate step size.\n",
    "\n",
    "Also note that when we step in the opposite direction of the initial proposal, an additional function evaluation is required since this new point is not the same as the proposed point. So even though we take a step as result of every proposal, an additional function evaluation is required whenever we step in the opposite direction of the proposal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_M2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# 2.1.1.3 Optimizing a Polynomial with Perturb-Measure-Step\n",
    "\n",
    "One way to get around the limitations we've encountered in propose and reject (and modified propose and reject) is to dive a little deeper into the insights possible from evaluating proposed values. Previously, with propose and reject, we only ask, \"Is this better?\" in modified propose and reject, this becomes \"Is this the correct direction for our step?\" However, we can pose and answer a much more sophisticated question using the same information: \"Given the comparison of this proposed $x$ to the current value, how does $f(x)$ change with $x$ near our current position, and based on this, ***in which direction and how far*** should we step?\" Essentially, this boils down to assessing the slope of the line connecting our current and proposed points and then updating $x$ in a direction proportional to this slope. In this way, the slope informs us not only about the direction but also about the appropriate distance of our update. We call this the perturb-measure-step approach.\n",
    "\n",
    "In this approach we ***measure*** the relationship between the change in the performance and the change in the parameter using a small perturbation as a test point. The update applied is then ***proportional*** to the ***measured performance changes*** over the ***measured parameter changes***, i.e. an estimate of the rate of change in performance for changes in the parameters or the slope. As a word equation\n",
    "\n",
    "$$ \\text{Parameter Update} = \\alpha \\cdot \\frac{\\text{Measured Perturbation in Performance}}{\\text{Measured Perturbation in Parameters}}$$\n",
    "\n",
    "where $\\alpha$ is some constant of proportionality in this case usually called the learning rate or step-size meta-parameter of the learning algorithm. In the case of optimizing a function $f(x)$ this gives us\n",
    "\n",
    "\n",
    "$$x_{t+1} = x_t + \\alpha \\cdot \\frac{f(x_t + \\Delta) - f(x)}{\\Delta}$$\n",
    "\n",
    "Where $\\Delta$ is the small test pertubation applied to $x$ to measure the slope.\n",
    "\n",
    "On the one hand we might expect a 'measure and update' method to be more efficient than a 'propose and reject' method, because with a 'propose and reject' algorithm we don't make any parameter updates unless 'better' parameters are proposed. This means that most of the information from evaluation is thrown away every time parameters are rejected. In contrast, a 'measure and update' method will always updated the parameters using the information gleaned from the tested parameters. Note that because of this, in the propose and reject method, the test point step size and the parameter update step size are one and the same. In contrast in the perturb-measure-step approach the test step $\\Delta$ and the scaling factor of the step size $\\alpha$ are different quantities.\n",
    "\n",
    "Use the interactive widget below to step through the perturb-measure-step process we've outlined to see how the slope between the current point and a test point can efficiently guide parameter updates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Optimization with Perturb-Measure-Step\n",
    "# @markdown **Run this cell** to step through finding the maximum of a quadratic function using a perturb-measure-step approach.\n",
    "class InteractivePolynomialSlopeStepper:\n",
    "  def __init__(self,\n",
    "               polynomial_max = 1,\n",
    "               bounds=(-2, 2),\n",
    "               test_step_size=0.1,\n",
    "               x_step_size=0.2,\n",
    "               adjustable_step_size=False,\n",
    "               seed=None):\n",
    "    self.polynomial_max = polynomial_max\n",
    "    self.polynomial = lambda x: -(x - polynomial_max)**2 + 5\n",
    "    self.bounds = bounds\n",
    "    self.test_step_slider = widgets.FloatSlider(value=test_step_size, min=-0.5, max=0.5, step=0.01,\n",
    "                                                    description='Test Step:', readout=True, readout_format='.2f')\n",
    "    self.x_step_slider = widgets.FloatSlider(value=x_step_size, min=0.01, max=1.5, step=0.01,\n",
    "                                                    description='x Step:', readout=True, readout_format='.2f')\n",
    "    self.adjustable_step_size = adjustable_step_size\n",
    "    self.rng = np.random.default_rng(seed)\n",
    "    self.current_x = self.rng.uniform(self.bounds[0], self.bounds[1])\n",
    "    self.current_y = self.polynomial(self.current_x)\n",
    "    self.test_x = None\n",
    "    self.test_y = None\n",
    "    self.step_x = None\n",
    "    self.step_y = None\n",
    "    self.x_history = []\n",
    "    self.y_history = []\n",
    "    self.points_tested = 0\n",
    "    self.fig, self.ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    self.perturb = widgets.Button(description='Perturb')\n",
    "    self.measure = widgets.Button(description='Measure', disabled=True)\n",
    "    self.step = widgets.Button(description='Step', disabled=True)\n",
    "    self.full_step = widgets.Button(description='Do It For Me', disabled=True)\n",
    "\n",
    "    self.reset = widgets.Button(description='Reset')\n",
    "    self.show_history = widgets.ToggleButton(value=True, description='Show History')\n",
    "    self.show_curve = widgets.ToggleButton(value=False, description='Show Function')\n",
    "    self.init_plot()\n",
    "    self.narration_display = widgets.Output()\n",
    "    remove_ip_clutter(self.fig)\n",
    "\n",
    "    # Arrange widgets in a layout\n",
    "    if self.adjustable_step_size:\n",
    "      buttons_layout = widgets.VBox([\n",
    "        widgets.HBox([self.perturb, self.measure, self.step]),\n",
    "        self.full_step,\n",
    "        self.test_step_slider,\n",
    "        self.x_step_slider,\n",
    "        widgets.HBox([self.reset, self.show_history, self.show_curve])])\n",
    "    else:\n",
    "      buttons_layout = widgets.VBox([\n",
    "        widgets.HBox([self.perturb, self.measure, self.step]),\n",
    "        self.full_step,\n",
    "        widgets.HBox([self.reset, self.show_history, self.show_curve])])\n",
    "    buttons_and_narration = widgets.HBox([buttons_layout, self.narration_display])\n",
    "    self.ui = widgets.VBox([self.fig.canvas, buttons_and_narration])\n",
    "\n",
    "    #bind actions to handlers\n",
    "    self.perturb.on_click(self.on_perturb_clicked)\n",
    "    self.measure.on_click(self.on_measure_clicked)\n",
    "    self.step.on_click(self.on_step_clicked)\n",
    "    self.full_step.on_click(self.on_full_step_clicked)\n",
    "    self.reset.on_click(self.on_reset_clicked)\n",
    "    self.show_curve.observe(self.on_show_curve_toggled, 'value')\n",
    "    self.show_history.observe(self.on_show_history_toggled, 'value')\n",
    "    self.x_step_slider.observe(self.on_x_step_slider_changed, 'value')\n",
    "    self.test_step_slider.observe(self.on_test_step_slider_changed, 'value')\n",
    "\n",
    "  def on_x_step_slider_changed(self, change):\n",
    "    self.step_x = self.current_x + self.x_step_slider.value * self.slope\n",
    "    self.step_y = self.slope * self.step_x + self.y_intercept\n",
    "    self.step_point.set_data([self.step_x], [self.step_y])\n",
    "    y_min, y_max = self.ax.get_ylim()\n",
    "    self.step_vline.set_data([self.step_x, self.step_x], [y_min, self.step_y])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_test_step_slider_changed(self, change):\n",
    "    if self.test_step_slider.value == 0:\n",
    "      # Set to a default non-zero value\n",
    "      self.test_step_slider.value = 0.01\n",
    "      with self.narration_display:\n",
    "        print(f\"Test step size of 0 cannot be used to calculate slope. Using 0.01 to avoid division by zero in slope calculation.\")\n",
    "    self.test_x = self.current_x + self.test_step_slider.value\n",
    "    self.test_y = self.polynomial(self.test_x)\n",
    "    self.test_point.set_data([self.test_x], [self.test_y])\n",
    "    if self.step_x is not None:\n",
    "      rise = self.test_y - self.current_y\n",
    "      run = self.test_x - self.current_x\n",
    "      self.slope = rise / run\n",
    "      self.y_intercept = self.current_y - self.slope * self.current_x\n",
    "      x_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "      y_vals = self.slope * x_vals + self.y_intercept\n",
    "      self.step_line.set_data(x_vals, y_vals)\n",
    "      self.step_x = self.current_x + self.x_step_slider.value * self.slope\n",
    "      self.step_y = self.slope * self.step_x + self.y_intercept\n",
    "      self.step_point.set_data([self.step_x], [self.step_y])\n",
    "      y_min, y_max = self.ax.get_ylim()\n",
    "      self.step_vline.set_data([self.step_x, self.step_x], [y_min, self.step_y])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def init_plot(self):\n",
    "    \"\"\"Initialize the plot with placeholder data.\"\"\"\n",
    "    x_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "    y_vals = self.polynomial(x_vals)\n",
    "    # Initial plot commands return line objects, keep references to them\n",
    "    self.point_current, = self.ax.plot([self.current_x], [self.current_y], 'bo', label='Current')\n",
    "    self.test_point, = self.ax.plot([], [], 'rx', label='Test Point')  # Empty data to start\n",
    "    self.step_point, = self.ax.plot([], [], 'go', label='Step Point')  # Empty data to start\n",
    "    self.points_history, = self.ax.plot([], [], 'ks', alpha=0.5, label='History')  # Empty data to start\n",
    "    self.line_polynomial, = self.ax.plot(x_vals, y_vals, alpha=1.0, label='Polynomial Curve')\n",
    "    self.slope = 0\n",
    "    self.y_intercept = self.current_y - self.slope * self.current_x\n",
    "    self.step_line, = self.ax.plot([], [], 'r', label='Measure')\n",
    "    self.step_vline, = self.ax.plot([], [], 'g', linestyle='--')\n",
    "    self.ax.legend()\n",
    "    alpha = 1 if self.show_curve.value else 0\n",
    "    self.line_polynomial.set_alpha(alpha)\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_perturb_clicked(self, button):\n",
    "    self.points_tested += 1\n",
    "    self.test_x = self.current_x + self.test_step_slider.value\n",
    "    self.test_y = self.polynomial(self.test_x)\n",
    "    self.test_point.set_data([self.test_x], [self.test_y])\n",
    "    self.fig.canvas.draw_idle()\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Test x: {self.test_x:.3f}, y: {self.test_y:.3f}.')\n",
    "      print(f'Current x: {self.current_x:.3f}, y: {self.current_y:.3f}.')\n",
    "      print(f'Points evaluated so far: {self.points_tested}')\n",
    "      print(\"Click 'Measure' to evaluate the slope based on this test point\")\n",
    "    self.measure.disabled = False\n",
    "    self.perturb.disabled = True\n",
    "\n",
    "  def on_measure_clicked(self, button):\n",
    "    rise = self.test_y - self.current_y\n",
    "    run = self.test_x - self.current_x\n",
    "    self.slope = rise / run\n",
    "    self.y_intercept = self.current_y - self.slope * self.current_x\n",
    "    x_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "    y_vals = self.slope * x_vals + self.y_intercept\n",
    "    self.step_line.set_data(x_vals, y_vals)\n",
    "    self.step_x = self.current_x + self.x_step_slider.value * self.slope\n",
    "    self.step_y = self.slope * self.step_x + self.y_intercept\n",
    "    self.step_point.set_data([self.step_x], [self.step_y])\n",
    "    y_min, y_max = self.ax.get_ylim()\n",
    "    self.step_vline.set_data([self.step_x, self.step_x], [y_min, self.step_y])\n",
    "    self.fig.canvas.draw_idle()\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Based on slope measurement proposed step from {self.current_x:.3f} to {self.step_x:.3f}')\n",
    "      print(\"Click 'Step', to make the step.\")\n",
    "\n",
    "    self.step.disabled = False\n",
    "    self.measure.disabled = True\n",
    "\n",
    "  def on_step_clicked(self, button):\n",
    "    self.points_tested += 1\n",
    "    new_y = self.polynomial(self.step_x)\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Stepped to x: {self.step_x:.3f}')\n",
    "      print(f'Actual y value there is {new_y:.3f}')\n",
    "      print(f'Points evaluated so far: {self.points_tested}')\n",
    "      print(f\"Click 'Perturb' to test a new value.\")\n",
    "    self.x_history.append(self.current_x)\n",
    "    self.y_history.append(self.current_y)\n",
    "    self.points_history.set_data(self.x_history, self.y_history)\n",
    "    self.current_x = self.step_x\n",
    "    self.current_y = new_y\n",
    "    self.point_current.set_data([self.current_x], [self.current_y])\n",
    "    self.test_x = None\n",
    "    self.test_y = None\n",
    "    self.test_point.set_data([], [])\n",
    "    self.step_x = None\n",
    "    self.step_y = None\n",
    "    self.step_point.set_data([], [])\n",
    "    self.step_line.set_data([], [])\n",
    "    self.step_vline.set_data([], [])\n",
    "    self.fig.canvas.draw_idle()\n",
    "    self.step.disabled = True\n",
    "    self.perturb.disabled = False\n",
    "    self.full_step.disabled = False\n",
    "\n",
    "  def on_full_step_clicked(self, button):\n",
    "    self.on_perturb_clicked(button)\n",
    "    self.on_measure_clicked(button)\n",
    "    self.on_step_clicked(button)\n",
    "\n",
    "  def on_reset_clicked(self, button):\n",
    "    self.proposals_evaluated = 0\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Reset. Clearing history')\n",
    "      print(f'Generating a new curve for you to find the max of.')\n",
    "    self.polynomial_max = self.rng.uniform(self.bounds[0], self.bounds[1])\n",
    "    self.polynomial = lambda x: -(x - self.polynomial_max)**2 + 5\n",
    "    x_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "    y_vals = self.polynomial(x_vals)\n",
    "    self.line_polynomial.set_data(x_vals, y_vals)\n",
    "    min_y, max_y = min(y_vals), max(y_vals)\n",
    "    padding = (max_y - min_y) * 0.1  # Add some padding to the limits\n",
    "    self.ax.set_ylim(min_y - padding, max_y + padding)\n",
    "    self.current_x = self.rng.uniform(self.bounds[0], self.bounds[1])\n",
    "    self.current_y = self.polynomial(self.current_x)\n",
    "    self.test_x = None\n",
    "    self.test_y = None\n",
    "    self.step_x = None\n",
    "    self.step_y = None\n",
    "    self.x_history = []\n",
    "    self.y_history = []\n",
    "    self.step.disabled = True\n",
    "    self.perturb.disabled = False\n",
    "    self.point_current.set_data([self.current_x], [self.current_y])\n",
    "    self.points_history.set_data(self.x_history, self.y_history)\n",
    "    self.test_point.set_data([], [])\n",
    "    self.step_point.set_data([], [])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_curve_toggled(self, change):\n",
    "    alpha = 1 if self.show_curve.value else 0\n",
    "    self.line_polynomial.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_history_toggled(self, change):\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "\n",
    "ipss = InteractivePolynomialSlopeStepper()\n",
    "display(ipss.fig.canvas)\n",
    "clear_output()\n",
    "display(ipss.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Wow, that works great. We consistently move in the correct direction: taking larger steps when we're further from the maximum and gradually reducing our step size as we approach it. This ensures that even if we overshoot, we're never too far from the maximum, minimizing any potential backtracking. Note though that because we are never stepping to exactly our test point, each iteration requires two function evaluations, one to evaluate the new current location and another to evaluate the test point, that will inform the next step.\n",
    "\n",
    "For those with a background in calculus, the success of this method might not come as a surprise. The slope between two closely spaced test points serves as an approximation of the derivative. By aligning our step sizes with this slopeâ€”both in magnitude and directionâ€”we effectively harness the principle of gradient ascent, which naturally leads to smaller steps as we near the peak. This gradient-based approach ensures continuous progress towards a maximum, with the rare exceptions of slight overshoots when we're very close to the maximum goal. Fortunately, even these overshots are corrected in subsequent steps, given sufficiently small test and parameter step sizes.\n",
    "\n",
    "To get a sense of how both test step size and parameter step size impact the rate of convergence on the maximum, use the sliders to play with these two different meta-parameters of the optimization process in the widget below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Playing with step sizes in Perturb-Measure-Step\n",
    "# @markdown **Run this cell** to play with the effect of step-size on the perturb-measure-step approach.\n",
    "ipss2 = InteractivePolynomialSlopeStepper(adjustable_step_size=True)\n",
    "display(ipss2.fig.canvas)\n",
    "clear_output()\n",
    "display(ipss2.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "**Exploration Exercise:**\n",
    "\n",
    "In the widget above, adjust the `x Step` and `Test Step` size sliders to explore the following scenarios:\n",
    "1. **Gradual Approach without Overshooting:** Adjust the step sizes so that the current value of $x$ slowly approaches the maximum without overshooting. Aim for a scenario where $x$ gets increasingly closer to the maximizing value but never quite reaches or surpasses it.\n",
    "2. **Controlled Chattering:** Set the step sizes to allow the current value of $x$ to slowly approach the maximum but with overshoots in each iteration (after possibly a few initial iterations). This behavior, known as chattering, can still be acceptable as long as the process is overall converging on the optimal value.\n",
    "3. **Unstable Chattering:** Adjust the steps to cause the value of $x$ to consistently overshoot and end up further away from the optimal value with each iteration. This scenario represents unstable chattering, which prevents the optimization process from maintaining $x$ close to the optimal value.\n",
    "\n",
    "**Hint:** Click the \"Show Function\" button to see the curve you're optimizing against. Visualizing the function can provide valuable insights into how different step sizes affect the optimization journey towards the maximum.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now that we've covered some foundational optimization ideas, we can start to consider how these ideas might be applied to the learning challenges faced by organismsâ€”and, more specifically, their brainsâ€”in the natural world. We'll start with applying these ideas in simple, illustrative scenarios that roughly abstract the types of challenges living organisms navigate in their quest to survive and thrive. We will still be a long way off from anything a brain is likely to be doing, but this is good step towards bridging the gap between abstract optimization and tangible, adaptive neural plasticity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_M3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "#2.1.1.4: Optimizing Behaviour with Perturb-Measure-Step: The Optimal Striking Threshold\n",
    "\n",
    "In previous chapters we motivated much of our modeling using a binary classification problem in which a lurking predator must choose between striking and not striking based on sensory input. Initially, we viewed the behavioral map from sensory input to action as genetically determined. However, we concluded the chapter on evolution by highlighting the evolutionary advantage of at least partially learning these sensory-behaviour maps within an organism's lifetime. These advantages emerge in part due to variable environments and complex behaviors with non-linear fitness impacts.\n",
    "\n",
    "Here we shift our focus and work with the case where the behavioural map from sensory input to action is to be entirely 'learned' by the organism, using feedback signals from the environment. We will use and extend the fundamental optimization concepts just introduced. But, before we build a highly abstracted model of a neural circuit together with a learning/optimization rule to solve this problem, let's see if your neural network is up to the task. In the simulation below, given a sensory input pattern, decide whether to strike or not. Try to maximize your average score and see how well you can perform. We will start with a very simple 'sensory' pattern.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown **Run this cell** to try out the 'strike-no-strike' discrimination task.\n",
    "\n",
    "class InteractiveMNISTPredator():\n",
    "  def __init__(self,\n",
    "               features=Xs,\n",
    "               labels=y,\n",
    "               feedback_type='on_strike_only', seed=123):\n",
    "    # Initialize dataset, settings for image scrambling and feedback\n",
    "    self.features = features\n",
    "    self.labels = labels\n",
    "    # features is num_data_points x 64 (reshape to 8x8 for display, each cell 0-16)\n",
    "    # labels is num_data_points x 1 (values 0-9 or 0/1 depending)\n",
    "    self.feedback_type = feedback_type\n",
    "    self.rng = np.random.default_rng(seed)\n",
    "    sample_order = self.rng.permutation(self.features.shape[0])\n",
    "    self.features = self.features[sample_order]\n",
    "    self.labels = self.labels[sample_order]\n",
    "    # initialize game state\n",
    "    self.current_index = 0\n",
    "    self.score = 0\n",
    "    self.best_possible_score = 0\n",
    "    self.successful_strikes = 0\n",
    "    self.failed_strikes = 0\n",
    "    self.non_strikes = 0\n",
    "    # Initialize widgets\n",
    "    self.strike_button = widgets.Button(description='Strike')\n",
    "    self.no_strike_button = widgets.Button(description='No Strike')\n",
    "    self.score_display = widgets.Output()\n",
    "    self.feedback_display = widgets.Output()\n",
    "\n",
    "    # Initialize the figure for image display\n",
    "    self.fig, self.ax = plt.subplots(figsize=(4, 4))\n",
    "    remove_ip_clutter(self.fig)\n",
    "    self.show_next_image()\n",
    "    # Bind event handlers\n",
    "    self.strike_button.on_click(self.on_strike_clicked)\n",
    "    self.no_strike_button.on_click(self.on_no_strike_clicked)\n",
    "\n",
    "    # Arrange widgets in a layout\n",
    "    buttons_layout = widgets.HBox([self.strike_button, self.no_strike_button])\n",
    "    board_buttons = widgets.VBox([self.fig.canvas, buttons_layout])\n",
    "    self.ui = widgets.HBox([board_buttons, widgets.VBox([self.score_display,\n",
    "                                                         self.feedback_display])])\n",
    "\n",
    "  def show_next_image(self):\n",
    "    # Display the next image\n",
    "    image = self.features[self.current_index]\n",
    "    if len(image) == 64:\n",
    "        image = image.reshape(8, 8)\n",
    "    elif len(image) == 1:\n",
    "      scalar_value = image.flatten()[0]\n",
    "      # Initialize the 8x8 array with -6 (black)\n",
    "      image = np.full((8, 8), -6.0)\n",
    "      # Set the second ring to 6 (white)\n",
    "      image[1:-1, 1:-1] = 6\n",
    "      # Set the third (inner ring) back to -6 (black)\n",
    "      image[2:-2, 2:-2] = -6\n",
    "      # Assuming scalar_value is already in the range -6 to 6\n",
    "      #print(scalar_value)\n",
    "      image[3:-3, 3:-3] = scalar_value\n",
    "    else:\n",
    "      raise ValueError(f'Unexpected image shape: {image.shape}')\n",
    "    # Display the image\n",
    "    #print(image)\n",
    "    self.fig.clf()\n",
    "    self.ax = self.fig.add_subplot(111)\n",
    "    self.ax.set_xlim(-.5, 7.5)\n",
    "    self.ax.set_ylim(-0.5, 7.5)\n",
    "    self.ax.set_aspect('equal')\n",
    "    self.ax.axis('off')\n",
    "    self.ax.imshow(image, cmap='gray', vmin=-6, vmax=6)\n",
    "    self.fig.canvas.draw_idle()  # Force redraw\n",
    "\n",
    "  def on_strike_clicked(self, button):\n",
    "    self.process_decision('Strike')\n",
    "\n",
    "  def on_no_strike_clicked(self, button):\n",
    "    self.process_decision('No Strike')\n",
    "\n",
    "  def process_decision(self, decision):\n",
    "    # freeze buttons while we process\n",
    "    self.strike_button.disabled = True\n",
    "    self.no_strike_button.disabled = True\n",
    "\n",
    "    # Process the user's decision, update score, and provide feedback\n",
    "    correct_action = 'Strike' if self.labels[self.current_index] == 1 else 'No Strike'\n",
    "    if decision == 'Strike':\n",
    "      if decision == correct_action:\n",
    "        self.score += 1\n",
    "        self.successful_strikes += 1\n",
    "      else:\n",
    "        self.score -= 1\n",
    "        self.failed_strikes += 1\n",
    "    elif decision == 'No Strike':\n",
    "      self.non_strikes += 1\n",
    "      # no strike means no gain or loss\n",
    "    else:\n",
    "      raise ValueError(f'Unknown decision: {decision}')\n",
    "\n",
    "    # Show feedback and score\n",
    "    if (self.feedback_type == 'both' or\n",
    "      (self.feedback_type == 'on_strike_only' and decision == 'Strike')):\n",
    "      # Show informative feedback\n",
    "      feedback = f'Your last choice: {decision}\\nCorrect last choice: {correct_action}'\n",
    "    else:\n",
    "      # Show uninformative feedback\n",
    "      feedback = 'Feedback only available after striking.'\n",
    "    with self.feedback_display:\n",
    "      clear_output(wait=True)\n",
    "      print(feedback)\n",
    "\n",
    "    # Show score\n",
    "    with self.score_display:\n",
    "      clear_output(wait=True)\n",
    "      average_score = self.score / (self.current_index+1)\n",
    "      print(f'Total Score: {self.score}')\n",
    "      print(f'Number of Trials: {self.current_index + 1}')\n",
    "      print(f'Successful Strikes: {self.successful_strikes}')\n",
    "      print(f'Failed Strikes: {self.failed_strikes}')\n",
    "      print(f'Non-Strikes: {self.non_strikes}')\n",
    "      print(f'Average Score Per Trial: {average_score:.2f}')\n",
    "\n",
    "    # Prepare the next image\n",
    "    self.current_index += 1\n",
    "    #print(self.current_index)\n",
    "    self.show_next_image()\n",
    "    # Re-enable buttons\n",
    "    self.strike_button.disabled = False\n",
    "    self.no_strike_button.disabled = False\n",
    "\n",
    "\n",
    "scramble_01_imp = InteractiveMNISTPredator(features=X_simple_1_feature,\n",
    "                                           labels=y1_simple, feedback_type='both')\n",
    "display(scramble_01_imp.fig.canvas)\n",
    "clear_output()\n",
    "display(scramble_01_imp.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "For us at least, this task wasn't too hard. The simple association - strike when the center pixel is relatively light, don't strike when the center pixel is dark - works well. We can learn this association with our eyes and brains. Now, let's see if we can take our perturb-measure-step idea from above and adapt it into a model that learns to appropriately strike and not strike. The dataset that underlies this strike-no-strike decision problem is sourced from the UCI Machine Learning Repository, (Alpaydin,E. and Kaynak,C. 1998. https://doi.org/10.24432/C50P49). Let's take a quick look at the data before we start coming up with a way to correctly distinguish between the strike and no-strike cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# What is the shape and type of the data we have to work with\n",
    "print(f'Input data type: {type(X_simple_1_feature)}')\n",
    "print(f'Input data shape: {X_simple_1_feature.shape}')\n",
    "print(f'Output target data type: {type(y1_simple.dtype)}')\n",
    "print(f'Output target shape: {y1_simple.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This data set consist of 1125 distinct $(\\text{input}, \\text{output})$ pairs. The goal of the organism is to learn as quickly as possible to correctly distinguish between these two different kinds of situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# what do the ouptus look like, what is their range\n",
    "print(y1_simple[:10])\n",
    "print(f'max output value: {np.max(y1_simple)}')\n",
    "print(f'min output value: {np.min(y1_simple)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In the interactive strike-no-strik setup above we used the label '1' to correspond to situations when 'strike' is the correct action and the label '0' to correspond to situations where 'no-strike' is the correct action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# what do the inputs look like, what is there range\n",
    "print(X_simple_1_feature[:10])\n",
    "print(f'Max input value: {np.max(X_simple_1_feature)}')\n",
    "print(f'Min input value: {np.min(X_simple_1_feature)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In the visualization above a high 'feature value' corresponded to lighter colors in the center pixels and a lower feature value corresponded to darker center pixels. Now that we have a sense of the type and range of the input and output pairs let's visualize the whole dataset. For a simple dataset like this we can visualize the distribution of the input values conditional on the two different \"correct\" outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# and for scalar data always good to look at a histogram\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "remove_ip_clutter(fig)\n",
    "ax1.hist(X_simple_1_feature[y1_simple.flatten() == 1])\n",
    "ax1.set_title('Feature Distribution When Strike is Correct')\n",
    "ax2.hist(X_simple_1_feature[y1_simple.flatten() == 0])\n",
    "ax2.set_title('Feature Distribution When No-Strike is Correct')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Looking at the distribution of the input values across these two classes (strike vs. no-strike situations), we see that we should be able to correctly discriminate between these two cases most of the time. Perhaps the simplest decision rule that could be used in a situation like this is a 'threshold' decision rule. Looking at the histograms above, a good threshold would be one where the organism strikes if the input value is above the threshold and does not strike if the input value is below the threshold. For now we leave aside how an organism might actually learn such a threshold from experience, and simply ask, what is the optimal such threshold value, given this particular set of $\\text{input}, \\text{output}$ pairs. Use the widget below to dial in the optimal threshold given this particular data-set and payoff function.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Dialing in The Optimal Threshold\n",
    "# @markdown **Run this cell** to manually dial in the optimal threshold\n",
    "class InteractiveThresholdDialer:\n",
    "  def __init__(self,\n",
    "               features=X_simple_1_feature,\n",
    "               labels=y1_simple):\n",
    "    self.features = features\n",
    "    self.labels = labels\n",
    "    # maybe rewards have a slider ?\n",
    "    self.correct_strike_r_slider = widgets.FloatSlider(\n",
    "        value=1, min=0.5, max=2, step=0.25,\n",
    "        description='Strike:', readout=True, readout_format='.2f')\n",
    "    self.false_strike_r_slider = widgets.FloatSlider(\n",
    "        value=-1, min=-2, max=-0.5, step=0.25,\n",
    "        description='Miss:', readout=True, readout_format='.2f')\n",
    "    self.non_strike_r_slider = widgets.FloatSlider(\n",
    "        value=0, min=-1, max=1, step=0.25,\n",
    "        description='Lurk:', readout=True, readout_format='.2f')\n",
    "    self.bounds = [min(features)-0.5, max(features)+0.5]\n",
    "    self.threshold_slider = widgets.FloatSlider(\n",
    "        value=0, min=self.bounds[0], max=self.bounds[1], step=0.1,\n",
    "        description='Threshold:', readout=True, readout_format='.2f')\n",
    "    self.fig, (self.hist_ax, self.r_ax) = plt.subplots(2, 1, figsize=(8, 6),\n",
    "                                                       sharex=True)\n",
    "    self.narration_display = widgets.Output()\n",
    "    self.init_plot()\n",
    "    remove_ip_clutter(self.fig)\n",
    "\n",
    "    # Arrange widgets in a layout\n",
    "    self.ui = widgets.VBox([\n",
    "        widgets.HBox([self.fig.canvas,]),\n",
    "        widgets.HBox([widgets.VBox([self.threshold_slider,\n",
    "                                    self.correct_strike_r_slider,\n",
    "                                    self.false_strike_r_slider,\n",
    "                                    self.non_strike_r_slider]),\n",
    "                      self.narration_display])\n",
    "    ])\n",
    "    self.threshold_slider.observe(self.on_slider_changed, 'value')\n",
    "    self.correct_strike_r_slider.observe(self.on_slider_changed, 'value')\n",
    "    self.false_strike_r_slider.observe(self.on_slider_changed, 'value')\n",
    "    self.non_strike_r_slider.observe(self.on_slider_changed, 'value')\n",
    "    print(\"We have narration display\", hasattr(self, 'narration_display'))\n",
    "\n",
    "\n",
    "  def eval_threshold(self, t):\n",
    "    t = np.asarray(t).reshape(1, -1)  # 1 x len(t)\n",
    "    features = self.features.reshape(-1, 1)  # len(features) x 1\n",
    "    labels = self.labels.reshape(-1, 1)  # len(labels) x 1\n",
    "    strikes = features > t # len(features) x len(t)\n",
    "    non_strikes = features <= t # len(feature) x len(t)\n",
    "    should_strike = labels == 1 # len(labels) x 1\n",
    "    should_not_strike = labels == 0 #len(labels) x 1\n",
    "\n",
    "    correct_strikes = strikes & should_strike #len(labels/features) x len(t)\n",
    "    false_strikes = strikes & should_not_strike #len(labels/features) x len(t)\n",
    "    correct_non_strikes = non_strikes & should_not_strike #len(labels/features) x len(t)\n",
    "    false_non_strikes = non_strikes & should_strike #len(labels/features) x len(t)\n",
    "\n",
    "    r = (self.correct_strike_r_slider.value * np.sum(correct_strikes, axis=0) +\n",
    "         self.false_strike_r_slider.value * np.sum(false_strikes, axis=0) +\n",
    "         self.non_strike_r_slider.value * np.sum(correct_non_strikes, axis=0) +\n",
    "         self.non_strike_r_slider.value * np.sum(false_non_strikes, axis=0))\n",
    "    r = r.flatten()\n",
    "    if len(r) == 1:\n",
    "      r = r[0]\n",
    "      # for single threshold evaluations\n",
    "      num_correct_strikes = np.sum(correct_strikes)\n",
    "      num_false_strikes = np.sum(false_strikes)\n",
    "      num_correct_non_strikes = np.sum(correct_non_strikes)\n",
    "      num_false_non_strikes = np.sum(false_non_strikes)\n",
    "      # Prepare a text-based confusion matrix\n",
    "      confusion_matrix_data = [\n",
    "          [\"Should Strike\", num_correct_strikes, num_false_non_strikes],\n",
    "          [\"Should Not Strike\", num_false_strikes, num_correct_non_strikes]]\n",
    "      headers = [\"\", \"Will Strike\", \"Will Not Strike\"]\n",
    "      confusion_matrix_table = tabulate(confusion_matrix_data, headers, tablefmt=\"grid\")\n",
    "      message = f\"Confusion Matrix for threshold {t[0][0]:.2f}:\\n{confusion_matrix_table}\\n\\nTotal Reward: {r}\"\n",
    "      self.narration_display.clear_output(wait=True)\n",
    "      with self.narration_display:\n",
    "        clear_output()\n",
    "        print(message)\n",
    "    return r\n",
    "\n",
    "  def on_slider_changed(self, change):\n",
    "    self.plot_threshold(self.threshold_slider.value)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def plot_threshold(self, t):\n",
    "    r = self.eval_threshold(t)\n",
    "    self.threshold_vline.set_data([t, t], [0, r])\n",
    "    y_min, y_max = self.hist_ax.get_ylim()\n",
    "    self.hist_vline.set_data([t, t], [y_min, y_max])\n",
    "    t_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "    r_vals = self.eval_threshold(t_vals)\n",
    "    reward_min, reward_max = min(r_vals), max(r_vals)\n",
    "    padding = (reward_max - reward_min) * 0.1  # Adjust padding as needed\n",
    "    self.r_ax.set_ylim(reward_min - padding, reward_max + padding)  # Update y-axis limits\n",
    "    self.reward_curve.set_data(t_vals, r_vals)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def init_plot(self):\n",
    "    \"\"\"Initialize the plot with placeholder data.\"\"\"\n",
    "    t_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "    r_vals = self.eval_threshold(t_vals)\n",
    "    # Initial plot commands return line objects, keep references to them\n",
    "    self.threshold_vline, = self.r_ax.plot([],[] ,color='r', linestyle='--', label='Threshold')\n",
    "    self.hist_vline, = self.hist_ax.plot([], [], color='r', linestyle='--', label='Threshold')\n",
    "    self.reward_curve, = self.r_ax.plot(t_vals, r_vals, alpha=1.0, label='Expected Reward')\n",
    "    self.hist_ax.hist(self.features[self.labels.flatten() == 1], alpha=0.5, label='Strike')\n",
    "    self.hist_ax.hist(self.features[self.labels.flatten() == 0], alpha=0.5, label='No Strike')\n",
    "    self.hist_ax.set_xlabel('Feature Value')\n",
    "    self.hist_ax.set_ylabel('Counts')\n",
    "\n",
    "    self.fig.suptitle('Threshold Evaluation')\n",
    "    y_min, y_max = self.r_ax.get_ylim()\n",
    "    self.r_ax.set_ylim(y_min, 1700)\n",
    "    self.r_ax.set_xlabel('Threshold')\n",
    "    self.r_ax.set_ylabel('Total Reward\\n(Over 1125 trials)')\n",
    "    self.plot_threshold(self.threshold_slider.value)\n",
    "    self.hist_ax.legend()\n",
    "    self.r_ax.legend()\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "\n",
    "itd = InteractiveThresholdDialer()\n",
    "display(itd.fig.canvas)\n",
    "clear_output()\n",
    "display(itd.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "By playing with the threshold slider in the widget above you can see how there is a fundamental trade-off between missing opportunities to strike at prey and avoiding false strikes. This balance is crucial in binary discrimination tasks like the one we're exploringâ€”and, indeed, in any categorization task. A key piece of feedback that can help us navigate this balance is the *confusion matrix*. The confusion matrix offers a comprehensive view of the decision rule's performance, going far beyond merely tallying correct and incorrect categorizations. Instead it shows exactly which categories are being confused with which. The confusion matrix, together with the relative rewards(costs) for the different types of correct and incorrect classifications determine what the optimal trade-off between missed opportunities and failed strikes will be.  \n",
    "\n",
    "Now, let's now see if our Perturb-Measure-Step approach can find this optimal trade-off.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Optimal Stike-No-Stike Threshold with Perturb-Measure-Step\n",
    "# @markdown **Run this cell** to step through finding the optimal strike-no-stike threshold our perturb-measure-step approach.\n",
    "class InteractiveThresholdSlopeStepper:\n",
    "  def __init__(self,\n",
    "               features=X_simple_1_feature,\n",
    "               labels=y1_simple,\n",
    "               test_size=0.1,\n",
    "               step_size=0.2,\n",
    "               adjustable_step_size=False,\n",
    "               seed=None):\n",
    "    self.features = features\n",
    "    self.labels = labels\n",
    "    # maybe rewards have a slider ?\n",
    "    self.correct_strike_r = 1\n",
    "    self.false_strike_r = -1\n",
    "    self.correct_non_strike_r = 0\n",
    "    self.false_non_strike_r = 0\n",
    "    self.bounds = [min(features)-0.5, max(features)+0.5]\n",
    "    self.test_step_slider = widgets.FloatSlider(\n",
    "        value=test_size, min=-1.5, max=1.5, step=0.1,\n",
    "        description='Test Step:', readout=True, readout_format='.2f')\n",
    "    self.t_step_slider = widgets.FloatSlider(\n",
    "        value=step_size, min=0.005, max=0.5, step=0.005,\n",
    "        description='t Step:', readout=True, readout_format='.2f')\n",
    "    self.adjustable_step_size = adjustable_step_size\n",
    "    self.rng = np.random.default_rng(seed)\n",
    "    self.current_t = self.rng.uniform(self.bounds[0], self.bounds[1])[0]\n",
    "    self.current_r = self.eval_threshold(self.current_t)\n",
    "    self.test_t = None\n",
    "    self.test_r = None\n",
    "    self.step_t = None\n",
    "    self.step_r = None\n",
    "    self.t_history = []\n",
    "    self.r_history = []\n",
    "    self.points_tested = 0\n",
    "    self.fig, self.ax = plt.subplots(figsize=(6, 4))\n",
    "\n",
    "    self.perturb = widgets.Button(description='Perturb')\n",
    "    self.measure = widgets.Button(description='Measure')\n",
    "    self.measure.disabled = True\n",
    "    self.step = widgets.Button(description='Step')\n",
    "    self.step.disabled = True\n",
    "\n",
    "    self.reset = widgets.Button(description='Reset')\n",
    "    self.show_history = widgets.ToggleButton(value=True, description='Show History')\n",
    "    self.show_curve = widgets.ToggleButton(value=True, description='Show Curve')\n",
    "    self.init_plot()\n",
    "    self.narration_display = widgets.Output()\n",
    "    remove_ip_clutter(self.fig)\n",
    "\n",
    "    # Arrange widgets in a layout\n",
    "    if self.adjustable_step_size:\n",
    "      buttons_layout = widgets.VBox([\n",
    "        widgets.HBox([self.perturb, self.measure, self.step]),\n",
    "        self.test_step_slider,\n",
    "        self.t_step_slider,\n",
    "        widgets.HBox([self.reset, self.show_history])])\n",
    "    else:\n",
    "      buttons_layout = widgets.VBox([\n",
    "        widgets.HBox([self.perturb, self.measure, self.step]),\n",
    "        widgets.HBox([self.reset, self.show_history, self.show_curve])])\n",
    "    buttons_and_narration = widgets.HBox([buttons_layout, self.narration_display])\n",
    "    self.ui = widgets.VBox([self.fig.canvas, buttons_and_narration])\n",
    "\n",
    "    #bind actions to handlers\n",
    "    self.perturb.on_click(self.on_perturb_clicked)\n",
    "    self.measure.on_click(self.on_measure_clicked)\n",
    "    self.step.on_click(self.on_step_clicked)\n",
    "    self.reset.on_click(self.on_reset_clicked)\n",
    "    self.show_curve.observe(self.on_show_curve_toggled, 'value')\n",
    "    self.show_history.observe(self.on_show_history_toggled, 'value')\n",
    "    self.t_step_slider.observe(self.on_t_step_slider_changed, 'value')\n",
    "    self.test_step_slider.observe(self.on_test_step_slider_changed, 'value')\n",
    "\n",
    "  def eval_threshold(self, t):\n",
    "    t = np.asarray(t).reshape(1, -1)  # 1 x len(t)\n",
    "    features = self.features.reshape(-1, 1)  # len(features) x 1\n",
    "    labels = self.labels.reshape(-1, 1)  # len(labels) x 1\n",
    "    strikes = features > t # len(features) x len(t)\n",
    "    non_strikes = features <= t # len(feature) x len(t)\n",
    "    should_strike = labels == 1 # len(labels) x 1\n",
    "    should_not_strike = labels == 0 #len(labels) x 1\n",
    "\n",
    "    correct_strikes = strikes & should_strike #len(labels/features) x len(t)\n",
    "    false_strikes = strikes & should_not_strike #len(labels/features) x len(t)\n",
    "    correct_non_strikes = non_strikes & should_not_strike #len(labels/features) x len(t)\n",
    "    false_non_strikes = non_strikes & should_strike #len(labels/features) x len(t)\n",
    "\n",
    "    r = (self.correct_strike_r * np.sum(correct_strikes, axis=0) +\n",
    "         self.false_strike_r * np.sum(false_strikes, axis=0) +\n",
    "         self.correct_non_strike_r * np.sum(correct_non_strikes, axis=0) +\n",
    "         self.false_non_strike_r * np.sum(false_non_strikes, axis=0))\n",
    "    r = r.flatten()\n",
    "    if len(r) == 1:\n",
    "      r = r[0]\n",
    "    return r\n",
    "\n",
    "  def on_t_step_slider_changed(self, change):\n",
    "    self.step_t = self.current_t + self.t_step_slider.value * self.slope\n",
    "    self.step_r = self.slope * self.step_t + self.y_intercept\n",
    "    self.step_point.set_data([self.step_t], [self.step_r])\n",
    "    y_min, y_max = self.ax.get_ylim()\n",
    "    self.step_vline.set_data([self.step_t, self.step_t], [y_min, self.step_r])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_test_step_slider_changed(self, change):\n",
    "    if self.test_step_slider.value == 0:\n",
    "      # Set to a default non-zero value\n",
    "      self.test_step_slider.value = 0.01\n",
    "      with self.narration_display:\n",
    "        print(f\"Test step size of 0 cannot be used to calculate slope. Using 0.01 to avoid division by zero in slope calculation.\")\n",
    "    self.test_t = self.current_t + self.test_step_slider.value\n",
    "    self.test_r = self.eval_threshold(self.test_t)\n",
    "    self.test_point.set_data([self.test_t], [self.test_r])\n",
    "    if self.step_t is not None:\n",
    "      rise = self.test_r - self.current_r\n",
    "      run = self.test_t - self.current_t\n",
    "      self.slope = rise / run\n",
    "      self.y_intercept = self.current_r - self.slope * self.current_t\n",
    "      t_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "      r_vals = self.slope * t_vals + self.y_intercept\n",
    "      self.step_line.set_data(t_vals, r_vals)\n",
    "      self.step_t = self.current_t + self.t_step_slider.value * self.slope\n",
    "      self.step_r = self.slope * self.step_t + self.y_intercept\n",
    "      self.step_point.set_data([self.step_t], [self.step_r])\n",
    "      y_min, y_max = self.ax.get_ylim()\n",
    "      self.step_vline.set_data([self.step_t, self.step_r], [y_min, self.step_r])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def init_plot(self):\n",
    "    \"\"\"Initialize the plot with placeholder data.\"\"\"\n",
    "    t_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "    r_vals = self.eval_threshold(t_vals)\n",
    "    # Initial plot commands return line objects, keep references to them\n",
    "    self.point_current, = self.ax.plot([self.current_t], [self.current_r], 'bo', label='Current')\n",
    "    self.test_point, = self.ax.plot([], [], 'rx', label='Test Point')  # Empty data to start\n",
    "    self.step_point, = self.ax.plot([], [], 'go', label='Step Point')  # Empty data to start\n",
    "    self.points_history, = self.ax.plot([], [], 'ks', alpha=0.5, label='History')  # Empty data to start\n",
    "    self.line_polynomial, = self.ax.plot(t_vals, r_vals, alpha=1.0, label='Polynomial Curve')\n",
    "    self.slope = 0\n",
    "    self.y_intercept = self.current_r - self.slope * self.current_t\n",
    "    self.step_line, = self.ax.plot([], [], 'r', label='Measure')\n",
    "    self.step_vline, = self.ax.plot([], [], 'g', linestyle='--')\n",
    "    self.ax.set_title('Threshold Evaluation')\n",
    "    self.ax.set_xlabel('Threshold')\n",
    "    self.ax.set_ylabel('Total Reward\\n(Over 1125 trials)')\n",
    "    self.ax.legend()\n",
    "    alpha = 1 if self.show_curve.value else 0\n",
    "    self.line_polynomial.set_alpha(alpha)\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_perturb_clicked(self, button):\n",
    "    self.points_tested += 1\n",
    "    self.test_t = self.current_t + self.test_step_slider.value\n",
    "    self.test_r = self.eval_threshold(self.test_t)\n",
    "    self.test_point.set_data([self.test_t], [self.test_r])\n",
    "    self.fig.canvas.draw_idle()\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Test t: {self.test_t:.3f}, y: {self.test_r:.3f}.')\n",
    "      print(f'Current t: {self.current_t:.3f}, r: {self.current_r:.3f}.')\n",
    "      print(\"Click measure to evaluate the slope based on this test point\")\n",
    "    self.measure.disabled = False\n",
    "    self.perturb.disabled = True\n",
    "\n",
    "  def on_measure_clicked(self, button):\n",
    "    rise = self.test_r - self.current_r\n",
    "    run = self.test_t - self.current_t\n",
    "    self.slope = rise / run\n",
    "    self.y_intercept = self.current_r - self.slope * self.current_t\n",
    "    t_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "    r_vals = self.slope * t_vals + self.y_intercept\n",
    "    self.step_line.set_data(t_vals, r_vals)\n",
    "    self.step_t = self.current_t + self.t_step_slider.value * self.slope\n",
    "    self.step_r = self.slope * self.step_t + self.y_intercept\n",
    "    self.step_point.set_data([self.step_t], [self.step_r])\n",
    "    y_min, y_max = self.ax.get_ylim()\n",
    "    self.step_vline.set_data([self.step_t, self.step_t], [y_min, self.step_r])\n",
    "    self.fig.canvas.draw_idle()\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Based on slope measurement proposed step from {self.current_t:.3f} to {self.step_t:.3f}')\n",
    "      print(\"Click step, to make the step.\")\n",
    "\n",
    "    self.step.disabled = False\n",
    "    self.measure.disabled = True\n",
    "\n",
    "  def on_step_clicked(self, button):\n",
    "    new_r = self.eval_threshold(self.step_t)\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Stepped to t: {self.step_t:.3f}')\n",
    "      print(f'Actual reward for this threshold is {new_r:.3f}')\n",
    "      print(f'Click perturb to test a new threshold.')\n",
    "    self.t_history.append(self.current_t)\n",
    "    self.r_history.append(self.current_r)\n",
    "    self.points_history.set_data(self.t_history, self.r_history)\n",
    "    self.current_t = self.step_t\n",
    "    self.current_r = new_r\n",
    "    self.point_current.set_data([self.current_t], [self.current_r])\n",
    "    self.test_t = None\n",
    "    self.test_r = None\n",
    "    self.test_point.set_data([], [])\n",
    "    self.step_t = None\n",
    "    self.step_r = None\n",
    "    self.step_point.set_data([], [])\n",
    "    self.step_line.set_data([], [])\n",
    "    self.step_vline.set_data([], [])\n",
    "    self.fig.canvas.draw_idle()\n",
    "    self.step.disabled = True\n",
    "    self.perturb.disabled = False\n",
    "\n",
    "  def on_reset_clicked(self, button):\n",
    "    self.proposals_evaluated = 0\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Reset. Clearing history')\n",
    "      print(f'Still using the same features and labels though')\n",
    "    self.current_t = self.rng.uniform(self.bounds[0], self.bounds[1])\n",
    "    self.current_r = self.eval_threshold(self.current_x)\n",
    "    self.test_t = None\n",
    "    self.test_r = None\n",
    "    self.step_t = None\n",
    "    self.step_r = None\n",
    "    self.t_history = []\n",
    "    self.r_history = []\n",
    "    self.step.disabled = True\n",
    "    self.perturb.disabled = False\n",
    "    self.point_current.set_data([self.current_t], [self.current_r])\n",
    "    self.points_history.set_data(self.t_history, self.r_history)\n",
    "    self.test_point.set_data([], [])\n",
    "    self.step_point.set_data([], [])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_curve_toggled(self, change):\n",
    "    alpha = 1 if self.show_curve.value else 0\n",
    "    self.line_polynomial.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_history_toggled(self, change):\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "\n",
    "itss = InteractiveThresholdSlopeStepper()\n",
    "display(itss.fig.canvas)\n",
    "clear_output()\n",
    "display(itss.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This likely isn't working very well for you. The reason for this is that unlike the polynomial we first worked with, the reward does not change smoothly with the threshold used by the striking policy. Rather, the reward is a step function of the threshold. This means that whole ranges of threshold values result in exactly the same reward, and comparing points in these regions gives no guidance about which direction to step and how far (the slope is zero!). There are ways of smoothing out such functions, but for now let's see if we can salvage our perturb-measure-step approach by taking perturbations (test steps) that are large enough to ensure that our test point is never on the same step (flat bit) as our current point. Use the step size sliders in the widget below to see if we can make perturb-measure-step work for this problem."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown **Run this cell** to try Perturb-Measure-Step again with adjustable step sizes.\n",
    "itssv = InteractiveThresholdSlopeStepper(adjustable_step_size=True)\n",
    "display(itssv.fig.canvas)\n",
    "clear_output()\n",
    "display(itssv.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "So here we have a bit of an issue. To overcome the staircase like shape of the reward function and make any progress we have to take big test steps, but big test steps ultimately limit how precisely we can dial in the actual optimal threshold value. This sort of fragility and fiddlyness is something that can be overcome, either by having test and parameter step sizes vary to match the scale of the reward function, in particular its step widths. In the next sequence we explore a powerful and widespread method of overcoming this kind of issue. For now though we conclude with the following thoughts."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We touched briefly on three different approaches to optimization in this sequence.\n",
    "\n",
    "The first was an analytic approach, in which we used total knowledge of the problem together with mathematical super-powers like taking derivatives and solving systems of linear equations to determine an optimal point.\n",
    "\n",
    "The second was almost the opposite, a very simple try and see approach which we've been calling propose and reject. We don't need to know anything about derivatives or algebra to implement this, we just need to be able to evaluate differences in performance between two different points, and then switch when a new point is better than the previous best. This seems to be the minimum viable optimization process, and is roughly the kind of \"optimization\" that evolution by natural selection is performing, i.e. try new things that are slightly different from the previous things, select the things that performed better to continue the process with.\n",
    "\n",
    "The third approach was somewhere in between these two. We noted that the propose and reject approach can be very inefficient from a computational perspective; in our simple one dimensional problem on average half of all proposals were rejected. We came up with a middle ground approach that slightly extended the computational complexity of the propose and reject mechanism. The new approach which we called perturb-measure-step, used the comparison between the new and old point to estimate the slope of the reward at the current point, and then step to a new point based on this slope estimate. We think of this as intermediate between the analytic approach and propose and reject, because like the analytic approach it uses the gradient, but instead of requiring full knowledge of the reward function being optimized and math super-powers, this approach only required slightly more computational complexity than propose and reject to create local knowledge of the reward function in the form of a comparison between the current point and a nearby test point in parameter space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_M4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown **Run this cell** to take the quiz\n",
    "comprehension_quiz = [\n",
    "  {\n",
    "    \"question\": \"What is the primary distinction between the analytic approach and the propose-and-reject method in optimization?\",\n",
    "    \"type\": \"multiple_choice\",\n",
    "    \"answers\": [\n",
    "      {\n",
    "        \"answer\": \"The analytic approach requires less computational power.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Depending on the circumstances, the analytic approach often requires more computational power due to its reliance on mathematical techniques.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"The propose-and-reject method relies on full knowledge of the problem.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Contrary to this, the propose-and-reject method does not require full problem knowledge and instead relies on trial-and-error.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"The analytic approach utilizes mathematical techniques like derivatives, while propose-and-reject relies on trial-and-error.\",\n",
    "        \"correct\": True,\n",
    "        \"feedback\": \"Correct! The analytic method leverages mathematical analysis, whereas propose-and-reject uses a more experimental approach.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"The propose-and-reject method is more precise in finding the optimal point.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Actually, the analytic approach tends to be more precise due to its use of mathematical optimization techniques.\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Why does the propose-and-reject method resemble natural selection in evolutionary processes?\",\n",
    "    \"type\": \"multiple_choice\",\n",
    "    \"answers\": [\n",
    "      {\n",
    "        \"answer\": \"It selects the best solutions after a series of random mutations.\",\n",
    "        \"correct\": True,\n",
    "        \"feedback\": \"Exactly! The propose-and-reject method's selection of better points mirrors natural selection's favoring of beneficial mutations.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It relies on derivatives to improve performance.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"This is not accurate; propose-and-reject does not use derivatives but rather a simple comparison of performance between points.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It uses mathematical super-powers to determine optimal points.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"The method is actually quite straightforward and does not involve complex mathematical operations.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It evaluates differences in performance between two points and prefers the better one.\",\n",
    "        \"correct\": True,\n",
    "        \"feedback\": \"Correct! This basic evaluative process is similar to how evolutionary processes favor traits that offer a survival advantage.\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What is a significant limitation of the propose-and-reject method when applied to a step function in optimization tasks?\",\n",
    "    \"type\": \"multiple_choice\",\n",
    "    \"answers\": [\n",
    "      {\n",
    "        \"answer\": \"It cannot determine the direction of optimization.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"The method can determine direction by preferring better-performing points, but its efficiency is the issue here.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It always requires knowledge of derivatives.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"No, one of propose-and-reject's advantages is that it does not require knowledge of derivatives.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It can be computationally inefficient due to the potential for a high rate of proposal rejection.\",\n",
    "        \"correct\": True,\n",
    "        \"feedback\": \"Correct! Many proposed changes may not result in performance improvements, leading to inefficiency.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It cannot work with binary classification problems.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"This method can be applied to binary classification; the challenge lies in its efficiency and precision in certain functions.\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"How does the perturb-measure-step approach improve upon the propose-and-reject method?\",\n",
    "    \"type\": \"multiple_choice\",\n",
    "    \"answers\": [\n",
    "      {\n",
    "        \"answer\": \"By automatically increasing test-step size in response to zero slope measurements.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"While this might be a good improvement to the perturb-measure-step approach, this is not what sets it apart from propose-and-reject.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"By estimating the slope (gradient) of the reward function at the current point to inform the next step.\",\n",
    "        \"correct\": True,\n",
    "        \"feedback\": \"Correct! This use of local gradient estimation makes perturb-measure-step more efficient in navigating towards optimal solutions.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"By eliminating the need for any computational processing.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"The method still requires computational effort, particularly in estimating the reward function's slope.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"By using global knowledge of the reward function to make decisions.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Perturb-measure-step primarily relies on local rather than global knowledge of the reward function.\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\n",
    "display_quiz(comprehension_quiz)\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "P2C1_Sequence1",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
