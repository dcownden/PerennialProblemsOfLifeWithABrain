{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dcownden/PerennialProblemsOfLifeWithABrain/blob/main/sequences/P2C1_Optimization/student/P2C1_Sequence2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/sequences/P2C1_Optimization/student/P2C1_Sequence2.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The following is part of a test for an upcoming text book on computational neuroscience from an optimization and learning perspective. The book will start with evolution because ultimately, all aspects of the brain are shaped by evolution and, as we will see, evolution can also be seen as an optimization algorithm. We are sharing it now to get feedback on what works and what does not and the developments we should do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "# **2.1.2: Optimization in Two Dimensions: Estimating Gradients**\n",
    "\n",
    "### Objective: Solve simple 2 dimensional optimization problems using perturbation methods, and connect these methods with physiological neural plasticity mechanisms.\n",
    "\n",
    "In this sequence we will:\n",
    "\n",
    "* Extend the perturbation based methods used in the previous sequence to the 2-dimesional case.\n",
    "\n",
    "* Introduce a simple artificial nerual network model of behaviour for binary discrimination.\n",
    "\n",
    "* Use the perturb -> measure -> step learning rule to optimize a stochastic strike-no-strike policy for a lurk and strike predator.\n",
    "\n",
    "* Show how perturb -> measure -> update can be used to estimate gradients in 2 dimensions and how important gradients are when the updates to multiple parameters need to act in a coordinated fashion.\n",
    "\n",
    "* Using the intuitions gained from going from 1-d to 2-d reflect on how well (or not) our current methods will scale to higher dimensional problems.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Setup\n",
    "\n",
    "Run the following cell to setup and install the various dependencies and helper functions for this ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Dependencies, Imports and Setup\n",
    "# @markdown You don't need to worry about how this code works â€“ but you do need to **run the cell**\n",
    "!apt install libgraphviz-dev > /dev/null 2> /dev/null #colab\n",
    "!pip install ipympl pygraphviz vibecheck datatops jupyterquiz ucimlrepo > /dev/null 2> /dev/null #google.colab\n",
    "\n",
    "import asyncio\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "import numpy as np\n",
    "import itertools\n",
    "import collections\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.lines import Line2D\n",
    "from matplotlib.colors import LogNorm\n",
    "from matplotlib.animation import FuncAnimation\n",
    "from matplotlib import gridspec\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pygraphviz as pgv\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from io import BytesIO\n",
    "from enum import Enum\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, clear_output, Markdown, HTML, Image\n",
    "from jupyterquiz import display_quiz\n",
    "from vibecheck import DatatopsContentReviewContainer\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from tqdm.notebook import tqdm\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "data_set = fetch_ucirepo(id=80)\n",
    "X = data_set.data.features.values\n",
    "# Translate the data to have a minimum of 0\n",
    "X_translated = X - X.min()\n",
    "# Scale the data to have a range from 0 to 12 (which is 6 - (-6))\n",
    "scaling_factor = 12 / (X.max() - X.min())\n",
    "X_scaled = X_translated * scaling_factor\n",
    "# Finally, shift the data to be centered between -6 and 6\n",
    "X_final = X_scaled - 6\n",
    "\n",
    "y = data_set.data.targets.values\n",
    "rng = np.random.default_rng(seed=2021)\n",
    "scramble_permutation = rng.permutation(X.shape[1])\n",
    "Xs = X_final[:, scramble_permutation]\n",
    "y1 = y % 2\n",
    "y2 = np.array(y >= 5, dtype=y.dtype)\n",
    "simple_index = ((y.flatten()==1) | (y.flatten()==0))\n",
    "X_simple = Xs[simple_index]\n",
    "y1_simple = y1[simple_index]\n",
    "# if you only had one feature which would likely be best for discrimination\n",
    "epsilon = 10\n",
    "class_a_sep = np.mean(X_simple[y1_simple.flatten() == 1, :], axis=0) / (np.std(X_simple[y1_simple.flatten() == 1, :], axis=0) + epsilon)\n",
    "class_b_sep = np.mean(X_simple[y1_simple.flatten() == 0, :], axis=0) / (np.std(X_simple[y1_simple.flatten() == 0, :], axis=0) + epsilon)\n",
    "best_feature = np.argmax(class_a_sep - class_b_sep)\n",
    "print(f'Best feature is {best_feature}')\n",
    "X_simple_1_feature = X_simple[:, [best_feature]]\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "# random seed settings and\n",
    "# getting torch to use gpu if it's there\n",
    "\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  \"\"\"\n",
    "  Function that controls randomness. NumPy and random modules must be imported.\n",
    "\n",
    "  Args:\n",
    "    seed : Integer\n",
    "      A non-negative integer that defines the random state. Default is `None`.\n",
    "    seed_torch : Boolean\n",
    "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
    "      must be imported. Default is `True`.\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "  \"\"\"\n",
    "  DataLoader will reseed workers following randomness in\n",
    "  multi-process data loading algorithm.\n",
    "\n",
    "  Args:\n",
    "    worker_id: integer\n",
    "      ID of subprocess to seed. 0 means that\n",
    "      the data will be loaded in the main process\n",
    "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def set_device():\n",
    "  \"\"\"\n",
    "  Set the device. CUDA if available, CPU otherwise\n",
    "\n",
    "  Args:\n",
    "    None\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "    print(\"This notebook isn't using and doesn't need a GPU. Good.\")\n",
    "  else:\n",
    "    print(\"GPU is enabled in this notebook but not needed.\")\n",
    "    print(\"If possible, in the menu under `Runtime` -> \")\n",
    "    print(\"`Change runtime type.`  select `CPU`\")\n",
    "\n",
    "  return device\n",
    "\n",
    "\n",
    "SEED = 2021\n",
    "set_seed(seed=SEED)\n",
    "DEVICE = set_device()\n",
    "\n",
    "\n",
    "def printmd(string):\n",
    "  display(Markdown(string))\n",
    "\n",
    "\n",
    "# the different utility .py files used in this notebook\n",
    "filenames = []\n",
    "# just run the code straight out of the response, no local copies needed!\n",
    "for filename in filenames:\n",
    "  url = f'https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/utils/{filename}'\n",
    "  response = requests.get(url)\n",
    "  # Check that we got a valid response\n",
    "  if response.status_code == 200:\n",
    "    code = response.content.decode()\n",
    "    exec(code)\n",
    "  else:\n",
    "    print(f'Failed to download {url}')\n",
    "\n",
    "# environment contingent imports\n",
    "try:\n",
    "  print('Running in colab')\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "  from google.colab import data_table\n",
    "  data_table.disable_dataframe_formatter()\n",
    "  #from google.colab import output as colab_output\n",
    "  #colab_output.enable_custom_widget_manager()\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "  print('Not running in colab')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib widget\n",
    "plt.style.use(\"https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/pplb.mplstyle\")\n",
    "plt.ioff() #need to use plt.show() or display explicitly\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "def remove_ip_clutter(fig):\n",
    "  fig.canvas.header_visible = False\n",
    "  fig.canvas.toolbar_visible = False\n",
    "  fig.canvas.resizable = False\n",
    "  fig.canvas.footer_visible = False\n",
    "  fig.canvas.draw()\n",
    "\n",
    "\n",
    "def content_review(notebook_section: str):\n",
    "  return DatatopsContentReviewContainer(\n",
    "    \"\",  # No text prompt\n",
    "    notebook_section,\n",
    "    {\n",
    "      \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "      \"name\": \"neuro_book\",\n",
    "      \"user_key\": \"xuk960xj\",\n",
    "    },\n",
    "  ).render()\n",
    "feedback_prefix = \"P2C1_S1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# 2.1.2.1: Optimizing a Polynomial of Two Variables Analytically\n",
    "\n",
    "Last sequence we reviewed the general optimization problem as anything of the form: \"Find some set of parameters or values, say $x$, such that some other scalar valued quantity which depends in some way on those values, i.e. a function of $x$, call it $f(x)$, is as large (or small) as possible, subject to some constraints on the possible values of $x$.\" In other words, we're looking for the best setting on a dial (the value of $x$) that maximizes or minimizes our outcome (the value of $f(x)$), within certain limits (constraints on $x$).\n",
    "\n",
    "Now we want to think about how we should do this when we have more than one dial to work with. Here's an example. Find a pair of values of $(x,y)$ on in the region $[-2, 2] \\times [-2, 2]$ such that $f(x,y) = 6(x-3)^2 + 6(y-3)^2 - 3xy$ is as small as possible. This can be written more tersely with symbols as:\n",
    "\n",
    "$$\\underset{x,y\\in[-2,2]}{\\arg \\min}\\ 6(x-3)^2 + 6(y-3)^2 - 3xy$$\n",
    "\n",
    "If you have taken (and remember!) a multivariate calculus course you might recall how this sort of problem can be solved using calculus and algebra. First we take the partial derivatives,\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\frac{\\partial f}{\\partial x} &= 12 (x-3) - 3y  \\\\\n",
    "\\frac{\\partial f}{\\partial y} &= 12 (y-3) - 3x\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "then we set that equal to zero and use our algebra skills to find the pairs of $(x,y)$ values where the derivative is zero. There is precisely one such pair at $(x,y) = (4,4)$.\n",
    "\n",
    "We also need to check the concavity (whether the curve bends upwards or downwards) to see if this zero-derivative point is a maximum or a minimum (we are looking for a minimum in this case). In the same way that the first partial derivatives give the slope of $f(x,y)$ in the direction of the two parameters, i.e. the slope of the tangent plane, the second derivative gives the curvature.\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "\\frac{\\partial^2 f}{\\partial x^2} & \\frac{\\partial^2 f}{\\partial x \\partial y} \\\\\n",
    "\\frac{\\partial^2 f}{\\partial y \\partial x} & \\frac{\\partial^2 f}{\\partial y^2} \\\\\n",
    "\\end{bmatrix} = \\begin{bmatrix}\n",
    "12 & -3 \\\\\n",
    "-3 & 12 \\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "In one dimension the second derivative is just a single number, and the sign of that number tells us whether the curve opens up or down. In two dimensions though the curvature is not just a single number, nor is it even just two numbers (one for $x$ one for $y$) but rather a whole grid of numbers that captures not just the curvature along the $x$ or $y$ dimension, but also capturing the effect of the interaction between $x$ and $y$ on the function value. This grid of second partial derivatives of a function is called the Hessian, and is often denoted as $H(f)$. Whether or not a critical point (where all the first partial derivatives are equal to zero) is a maximum, a minimum or neither, is determined by an aptly named scalar quantitity called the determinant. This quantity can be computed from the Hessian of our function $H(f)$ as:\n",
    "\n",
    "$$\n",
    "\\begin{align}\n",
    "\\det(H(f)) &= \\left( \\frac{\\partial^2 f}{\\partial x^2} \\right)\\left( \\frac{\\partial^2 f}{\\partial y^2} \\right) - \\left( \\frac{\\partial^2 f}{\\partial x \\partial y} \\right)^2 \\\\\n",
    "&= 12 \\cdot 12 - (-3)^2\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "In particular the sign of the determenant, evaluated at a critical point, determines the nature of the critical point:\n",
    "\n",
    "- If $\\Delta > 0$ the point is either a local minimum or maximum.\n",
    "- If $\\Delta < 0$, the critical point is a saddle point, which is neither a maximum nor a minimum.\n",
    "- If $\\Delta = 0$, the test is inconclusive, and the point's nature cannot be determined from the determinant alone\n",
    "\n",
    "Further, if $\\Delta > 0$ then $\\frac{\\partial^2 f}{\\partial x^2}$ and $\\frac{\\partial^2 f}{\\partial y^2}$ will have the same sign at this critical point, and $\\frac{\\partial^2 f}{\\partial x^2} > 0$ indicates a local minimum and $\\frac{\\partial^2 f}{\\partial x^2} > 0$ indicates a local maximum.\n",
    "\n",
    "For this function, the Hessian and hence the determinant are constant, so the value of the determinant at the critical point $(4,4)$, is $12^2 - 3^2 = 135$.\n",
    "\n",
    "The determinant is positive so we know we have a maximum or a minimum and $\\left. \\frac{\\partial^2 f}{\\partial x^2} \\right|_{(4,4)}=12>0$ so we know that this is a minimum (which is what we were looking for). With some reasoning we might also convince ourselves that the function is always increases with distance from this critical point, so this local minimum is also the global minimum.\n",
    "\n",
    "That's how we do things in two dimensions the calculus way. It was a little more involved than in one dimension but still fairly tractable. In general when optimizing a function of $n$ values $x_1$, $x_2$, ... $x_n$, we will have system of $n$ equations to solve to try and find critical points (where all partial derivatives are equal to zero), and then an $n \\times n$ Hessian matrix, that needs to have its determinant evaluated at each of the critical points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown **Run this cell** to plot the function we are optimizing\n",
    "\n",
    "# Define the function\n",
    "def quad_poly(x, y, a=6, b=3, c=3):\n",
    "    return a * (x - b)**2 + a * (y - b)**2 - c * x * y\n",
    "\n",
    "# Generate the grid of x and y values\n",
    "x = np.linspace(0, 8, 400)\n",
    "y = np.linspace(0, 8, 400)\n",
    "X, Y = np.meshgrid(x, y)\n",
    "Z = quad_poly(X, Y)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "c = ax.contourf(X, Y, Z, cmap='viridis')\n",
    "#c = ax.imshow(Z_positive, extent=[x.min(), x.max(), y.min(), y.max()], origin='lower', cmap='viridis', aspect='auto', norm=LogNorm())\n",
    "ax.plot(4, 4, 'rx')  # Using 'rx' to mark the point (1,1) with a red \"x\"\n",
    "\n",
    "# Add a color bar to interpret the colors\n",
    "fig.colorbar(c, ax=ax)\n",
    "\n",
    "ax.set_title('Plot of $f(x,y) = 6(x-3)^2 + 6(y-3)^2 - 3xy$')\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In this countour plot dark blue indicates lower values, and brighter green/yellow colors indicate higher values. Looking at the plot confirms that our analytic approach did indeed find a minimum at $(x,y) = (4,4)$. Now that we've seen how the analytic approach extends to 2-dimensions let's take a look at how our perturbation methods, propose and reject and perturb-measure-step work in 2-dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# 2.1.2.2: Optimizing a Two Dimensional Function with Propose and Reject\n",
    "\n",
    "Below, is an interactive implementation of the propose-and-reject method applied to finding the maximum of our 2-d polynomial. Start by clicking 'Propose' to sample a new proposed $x,y$ value. Then, decide whether to 'Accept' or 'Reject' the proposed point based on a comparison with the previous point. Your goal is to find the lowest point in of this curve. 'Show History' is turned on to start so you can see all of the previous steps in the process. Similarly the 'Show Rejected' button is turned on so you can see all the tested points that have been rejected since the last accept."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Stepping Through Optimization with Propose and Reject\n",
    "# @markdown **Run this cell** to step through finding the minimum of a 2-d quadratic function using propose and reject.\n",
    "class InteractivePolynomialProposeReject:\n",
    "  def __init__(self,\n",
    "               a = 6,\n",
    "               b = 3,\n",
    "               c = 3,\n",
    "               x_bounds=(0, 8),\n",
    "               y_bounds=(0, 8),\n",
    "               step_size=0.2, seed=None):\n",
    "    self.a = a\n",
    "    self.b = b\n",
    "    self.c = c\n",
    "    self.x_bounds = x_bounds\n",
    "    self.y_bounds = y_bounds\n",
    "    self.step_size = step_size\n",
    "    self.rng = np.random.default_rng(seed)\n",
    "    self.current_x = 2.0\n",
    "    self.current_y = 1.0\n",
    "    self.current_z = self.eval_function(self.current_x, self.current_y)\n",
    "    self.proposed_x = None\n",
    "    self.proposed_y = None\n",
    "    self.proposed_z = None\n",
    "    self.x_history = []\n",
    "    self.y_history = []\n",
    "    self.z_history = []\n",
    "    self.rejected_x = []\n",
    "    self.rejected_y = []\n",
    "    self.total_proposals = 0\n",
    "    self.acceptance_count = 0\n",
    "    self.current_proposals = 0\n",
    "    self.fig, self.ax = plt.subplots(figsize=(6, 4))\n",
    "    self.propose = widgets.Button(description='Propose')\n",
    "    self.accept = widgets.Button(description='Accept', disabled=True)\n",
    "    self.reject = widgets.Button(description='Reject', disabled=True)\n",
    "    self.full_step = widgets.Button(description='Do It For Me', disabled=True)\n",
    "    self.take_10_steps = widgets.Button(description='Do 10 For Me', disabled=True)\n",
    "    self.reset = widgets.Button(description='Reset')\n",
    "    self.show_history = widgets.Checkbox(value=True, description='Show History')\n",
    "    self.show_rejected = widgets.Checkbox(value=True, description='Show Rejected')\n",
    "    self.in_loop = False\n",
    "    self.init_plot()\n",
    "    self.narration_display = widgets.Output()\n",
    "    remove_ip_clutter(self.fig)\n",
    "    # Arrange widgets in a layout\n",
    "    buttons_layout = widgets.VBox([\n",
    "        widgets.HBox([self.propose, self.accept, self.reject]),\n",
    "        widgets.HBox([self.full_step, self.take_10_steps]),\n",
    "        widgets.HBox([self.reset, self.show_history, self.show_rejected])])\n",
    "    buttons_and_narration = widgets.HBox([buttons_layout, self.narration_display])\n",
    "    self.ui = widgets.VBox([self.fig.canvas, buttons_and_narration])\n",
    "    #bind actions to handlers\n",
    "    self.propose.on_click(self.on_propose_clicked)\n",
    "    self.accept.on_click(self.on_accept_clicked)\n",
    "    self.reject.on_click(self.on_reject_clicked)\n",
    "    self.full_step.on_click(self.on_full_step_clicked)\n",
    "    self.take_10_steps.on_click(self.on_take_10_steps_clicked)\n",
    "    self.reset.on_click(self.on_reset_clicked)\n",
    "    self.show_rejected.observe(self.on_show_rejected_toggled, 'value')\n",
    "    self.show_history.observe(self.on_show_history_toggled, 'value')\n",
    "\n",
    "  def init_plot(self):\n",
    "    \"\"\"Initialize the plot with placeholder data.\"\"\"\n",
    "    x_vals = np.linspace(self.x_bounds[0], self.x_bounds[1], 400)\n",
    "    y_vals = np.linspace(self.y_bounds[0], self.y_bounds[1], 400)\n",
    "    X, Y = np.meshgrid(x_vals, y_vals)\n",
    "    Z = self.eval_function(X, Y)\n",
    "    # Initial plot commands return line objects, keep references to them\n",
    "    self.contours = self.ax.contour(X, Y, Z, cmap='viridis')\n",
    "    self.point_current, = self.ax.plot([self.current_x], [self.current_y], 'bo', label='Current')\n",
    "    self.point_proposed, = self.ax.plot([], [], 'go', label='Proposed')  # Empty data to start\n",
    "    self.points_history, = self.ax.plot([], [], 'ks', alpha=0.5, label='History')  # Empty data to start\n",
    "    self.points_rejected, = self.ax.plot([], [], 'kx', label='Rejected')  # Empty data to start\n",
    "    self.ax.legend()\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "    alpha = 0.5 if self.show_rejected.value else 0\n",
    "    self.points_rejected.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def eval_function (self, x, y, a=None, b=None, c=None):\n",
    "    if a is None:\n",
    "      a = self.a\n",
    "    if b is None:\n",
    "      b = self.b\n",
    "    if c is None:\n",
    "      c = self.c\n",
    "    return a*(x-b)**2 + a*(y-b)**2 - c*x*y\n",
    "\n",
    "  def on_propose_clicked(self, button):\n",
    "    self.total_proposals += 1\n",
    "    self.current_proposals += 1\n",
    "    self.averaverage_proposals = self.acceptance_count / self.total_proposals\n",
    "    perturbation_x, perturbation_y = self.rng.standard_normal(size=2) * self.step_size\n",
    "    self.proposed_x = self.current_x + perturbation_x\n",
    "    self.proposed_y = self.current_y + perturbation_y\n",
    "    self.proposed_z = self.eval_function(self.proposed_x, self.proposed_y)\n",
    "    self.point_proposed.set_data([self.proposed_x], [self.proposed_y])\n",
    "    with self.narration_display:\n",
    "      clear_output()\n",
    "      print(f'Proposed x: {self.proposed_x:.3f}, y: {self.proposed_y:.3f}, z: {self.proposed_z:.3f}.')\n",
    "      print(f' Current x: {self.current_x:.3f}, y: {self.current_y:.3f}, z: {self.current_z}')\n",
    "      print(\"Click 'Accept' or 'Reject' to accept or reject this proposed x,y?\")\n",
    "      print(f'Proposals evaluated since last step: {self.current_proposals}')\n",
    "      print(f'Total number of proposals evaluated: {self.total_proposals}')\n",
    "    if not self.in_loop:\n",
    "      self.fig.canvas.draw()\n",
    "      self.accept.disabled = False\n",
    "      self.reject.disabled = False\n",
    "      self.propose.disabled = True\n",
    "      self.full_step.disabled = True\n",
    "\n",
    "  def on_accept_clicked(self, button):\n",
    "    self.acceptance_count += 1\n",
    "    self.current_proposals = 0\n",
    "    with self.narration_display:\n",
    "      clear_output()\n",
    "      print(f'Accepted x: {self.proposed_x:.3f}, y: {self.proposed_y:.3f}, z: {self.proposed_z:.3f}.')\n",
    "      print(f\"Click 'Propose' or 'Do It For Me' to try a new value.\")\n",
    "      print(f'Proposals evaluated since last step: {self.current_proposals}')\n",
    "      print(f'Total number of proposals evaluated: {self.total_proposals}')\n",
    "      print(f'Average proposals per step: {self.total_proposals / self.acceptance_count:.3f}')\n",
    "    self.x_history.append(self.current_x)\n",
    "    self.y_history.append(self.current_y)\n",
    "    self.z_history.append(self.current_z)\n",
    "    self.current_x = self.proposed_x\n",
    "    self.current_y = self.proposed_y\n",
    "    self.current_z = self.proposed_z\n",
    "    self.proposed_x = None\n",
    "    self.proposed_y = None\n",
    "    self.proposed_z = None\n",
    "    self.rejected_x = []\n",
    "    self.rejected_y = []\n",
    "    self.point_current.set_data([self.current_x], [self.current_y])\n",
    "    self.points_history.set_data(self.x_history, self.y_history)\n",
    "    self.point_proposed.set_data([], [])\n",
    "    self.points_rejected.set_data([], [])\n",
    "    if not self.in_loop:\n",
    "      self.fig.canvas.draw()\n",
    "      self.accept.disabled = True\n",
    "      self.reject.disabled = True\n",
    "      self.propose.disabled = False\n",
    "      self.full_step.disabled = False\n",
    "      self.take_10_steps.disabled = False\n",
    "\n",
    "  def on_reject_clicked(self, button):\n",
    "    self.rejected_x.append(self.proposed_x)\n",
    "    self.rejected_y.append(self.proposed_y)\n",
    "    with self.narration_display:\n",
    "      clear_output()\n",
    "      print(f'Rejected x: {self.proposed_x:.3f}, y: {self.proposed_y:.3f}, z: {self.proposed_z:.3f}.')\n",
    "      print(f' Keeping x: {self.current_x:.3f}, y: {self.current_y:.3f}, z: {self.current_z:.3f}.')\n",
    "      print(f\"Click 'Propose' or 'Do It For Me' to try a new value.\")\n",
    "      print(f'Proposals evaluated since last step: {self.current_proposals}')\n",
    "      print(f'Total number of proposals evaluated: {self.total_proposals}')\n",
    "    self.proposed_x = None\n",
    "    self.proposed_y = None\n",
    "    self.point_proposed.set_data([], [])\n",
    "    self.points_rejected.set_data(self.rejected_x, self.rejected_y)\n",
    "    if not self.in_loop:\n",
    "      self.fig.canvas.draw()\n",
    "      self.accept.disabled = True\n",
    "      self.reject.disabled = True\n",
    "      self.propose.disabled = False\n",
    "      self.full_step.disabled = False\n",
    "      self.take_10_steps.disabled = False\n",
    "\n",
    "  def on_full_step_clicked(self, button):\n",
    "    # Automatically propose, accept if better, or reject\n",
    "    self.full_step.disabled = True\n",
    "    self.on_propose_clicked(button)\n",
    "    if self.proposed_z < self.current_z:\n",
    "        self.on_accept_clicked(button)\n",
    "    else:\n",
    "        self.on_reject_clicked(button)\n",
    "    if not self.in_loop:\n",
    "      self.full_step.disabled = False\n",
    "\n",
    "  def on_take_10_steps_clicked(self, button):\n",
    "    self.take_10_steps.disabled = True\n",
    "    self.propose.disabled = True\n",
    "    self.accept.disabled = True\n",
    "    self.reject.disabled = True\n",
    "    self.full_step.disabled = True\n",
    "    self.in_loop = True\n",
    "    for _ in range(10):\n",
    "      self.on_full_step_clicked(button)\n",
    "      self.fig.canvas.draw()\n",
    "      time.sleep(0.6)\n",
    "    self.in_loop = False\n",
    "    self.take_10_steps.disabled = False\n",
    "    self.propose.disabled = False\n",
    "    self.full_step.disabled = False\n",
    "\n",
    "  def on_reset_clicked(self, button):\n",
    "    self.total_proposals = 0\n",
    "    self.acceptance_count = 0\n",
    "    self.current_proposals = 0\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Reset. Clearing history')\n",
    "      print(f'Generating a new curve for you to find the max of.')\n",
    "    self.current_x = self.rng.uniform(self.x_bounds[0], self.y_bounds[1])\n",
    "    self.current_y = self.rng.uniform(self.y_bounds[0], self.y_bounds[1])\n",
    "    self.current_z = self.eval_function(self.current_x, self.current_y)\n",
    "    self.proposed_x = None\n",
    "    self.proposed_y = None\n",
    "    self.proposed_z = None\n",
    "    self.x_history = []\n",
    "    self.y_history = []\n",
    "    self.z_history = []\n",
    "    self.accept.disabled = True\n",
    "    self.reject.disabled = True\n",
    "    self.propose.disabled = False\n",
    "    self.point_current.set_data([self.current_x], [self.current_y])\n",
    "    self.points_history.set_data(self.x_history, self.y_history)\n",
    "    self.point_proposed.set_data([], [])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_history_toggled(self, change):\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_rejected_toggled(self, change):\n",
    "    alpha = 0.5 if self.show_rejected.value else 0\n",
    "    self.points_rejected.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "ippr = InteractivePolynomialProposeReject()\n",
    "display(ippr.fig.canvas)\n",
    "clear_output()\n",
    "display(ippr.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Depending on the shape of the function, and the initial starting point, this can work pretty well, but as in the one dimensional case there may potentially be a lot of proposals that lead to no improvement. For this particular function, which is relatively simple, propose and reject will end up accepting roughly half of the proposals, however for more exotically shaped functions this acceptance rate can be much lower. For example, if the current point is in a narrow valley, with only a very gentle downward slope, but very steep sides, then there are relatively few directions that will lead to lower values, really only steps that are oriented with this valley. Thus, once the process is in such a location we expect there to be relatively many proposals for every step taken. And, as in the one dimensional case, because we simply either accept or reject, these rejected proposal points do nothing further to guide our search for the minimizing $x$ and $y$ values, so in a sense each rejected proposal is wasted computation. In the one dimensional case we used a pertrub-measure-step approach to overcome the computational waste of rejected proposals, so that on each function evaluation we were able to make progress towards better parameter values. Now let's see what the perturb measure step approach looks like in two dimensions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# 2.1.2.3 Optimizing a Two Dimensional Function with Perturb-Measure-Step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Optimization with Perturb-Measure-Step\n",
    "# @markdown **Run this cell** to step through finding the minimum of 2-d quadratic function using a perturb-measure-step approach.\n",
    "class InteractivePolynomialSlopeStepper:\n",
    "  def __init__(self,\n",
    "               a=6.0, b=3.0, c=3.0,\n",
    "               x_bounds=(2, 6),\n",
    "               y_bounds=(2, 6),\n",
    "               test_step_size=0.025,\n",
    "               param_step_size=0.025,\n",
    "               adjustable_step_size=False,\n",
    "               seed=None):\n",
    "    #constants\n",
    "    self.a, self.b, self.c = a, b, c\n",
    "    self.x_bounds, self.y_bounds = x_bounds, y_bounds\n",
    "    #state\n",
    "    self.current_x = 3.0\n",
    "    self.current_y = 2.5\n",
    "    self.current_z = self.eval_function(self.current_x, self.current_y)\n",
    "    self.test_x, self.test_y, self.test_z = None, None, None\n",
    "    self.proposed_x, self.proposed_y, self.proposed_z = None, None, None\n",
    "    self.x_history, self.y_history, self.z_history = [], [], []\n",
    "    self.total_function_evaluations = 1\n",
    "    self.num_steps = 0\n",
    "    #buttons\n",
    "    self.test_step_slider = widgets.FloatSlider(\n",
    "        value=test_step_size, min=-0.5, max=0.5, step=0.01,\n",
    "        description='Test Size:', readout=True, readout_format='.2f')\n",
    "    self.param_step_slider = widgets.FloatSlider(\n",
    "        value=param_step_size, min=0.01, max=1.5, step=0.01,\n",
    "        description='Step Size:', readout=True, readout_format='.2f')\n",
    "    self.adjustable_step_size = adjustable_step_size\n",
    "    self.rng = np.random.default_rng(seed)\n",
    "    self.perturb_x = widgets.Button(description='Perturb x')\n",
    "    self.measure_x = widgets.Button(description='Measure x', disabled=True)\n",
    "    self.step_x = widgets.Button(description='Step x', disabled=True)\n",
    "    self.perturb_y = widgets.Button(description='Perturb y')\n",
    "    self.measure_y = widgets.Button(description='Measure y', disabled=True)\n",
    "    self.step_y = widgets.Button(description='Step y', disabled=True)\n",
    "    self.full_step = widgets.Button(description='Do It For Me', disabled=True)\n",
    "    self.take_10_steps = widgets.Button(description='Do 10 For Me', disabled=True)\n",
    "    self.reset = widgets.Button(description='Reset')\n",
    "    self.show_history = widgets.Checkbox(value=True, description='Show History')\n",
    "    #bind buttons to action to handlers\n",
    "    self.perturb_x.on_click(self.on_perturb_clicked)\n",
    "    self.measure_x.on_click(self.on_measure_clicked)\n",
    "    self.step_x.on_click(self.on_step_clicked)\n",
    "    self.perturb_y.on_click(self.on_perturb_clicked)\n",
    "    self.measure_y.on_click(self.on_measure_clicked)\n",
    "    self.step_y.on_click(self.on_step_clicked)\n",
    "    self.full_step.on_click(self.on_full_step_clicked)\n",
    "    self.take_10_steps.on_click(self.on_take_10_steps_clicked)\n",
    "    self.reset.on_click(self.on_reset_clicked)\n",
    "    self.show_history.observe(self.on_show_history_toggled, 'value')\n",
    "    self.param_step_slider.observe(self.on_step_slider_changed, 'value')\n",
    "    self.test_step_slider.observe(self.on_test_step_slider_changed, 'value')\n",
    "    #ui setup\n",
    "    self.init_plot()\n",
    "    self.narration_display = widgets.Output()\n",
    "    remove_ip_clutter(self.fig)\n",
    "    if self.adjustable_step_size:\n",
    "      buttons_layout = widgets.VBox([\n",
    "        widgets.HBox([self.perturb_x, self.measure_x, self.step_x]),\n",
    "        widgets.HBox([self.perturb_y, self.measure_y, self.step_y]),\n",
    "        widgets.HBox([self.full_step, self.take_10_steps]),\n",
    "        widgets.HBox([self.x_test_step_slider, self.x_step_slider]),\n",
    "        widgets.HBox([self.y_test_step_slider, self.y_step_slider]),\n",
    "        widgets.HBox([self.reset, self.show_history])])\n",
    "    else:\n",
    "      buttons_layout = widgets.VBox([\n",
    "        widgets.HBox([self.perturb_x, self.measure_x, self.step_x]),\n",
    "        widgets.HBox([self.perturb_y, self.measure_y, self.step_y]),\n",
    "        widgets.HBox([self.full_step, self.take_10_steps]),\n",
    "        widgets.HBox([self.reset, self.show_history])])\n",
    "    buttons_and_narration = widgets.HBox([buttons_layout, self.narration_display])\n",
    "    self.ui = widgets.VBox([self.fig.canvas, buttons_and_narration])\n",
    "\n",
    "  def eval_function(self, x, y, a=None, b=None, c=None):\n",
    "    if a is None:\n",
    "      a = self.a\n",
    "    if b is None:\n",
    "      b = self.b\n",
    "    if c is None:\n",
    "      c = self.c\n",
    "    return a * (x - b)** 2 + a * (y-b)**2 - c * y * x\n",
    "\n",
    "  def init_plot(self):\n",
    "    self.fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "    self.ax_c = axs[1, 0]  # Contour plot axis\n",
    "    self.ax_x = axs[0, 0]  # z(x), shares contour x-axis\n",
    "    self.ax_y = axs[1, 1]  # z(y), shares contour y-axis\n",
    "    self.ax_legend = axs[0, 1]  # Reserved for the legend\n",
    "    self.ax_x.sharex(self.ax_c)\n",
    "    self.ax_y.sharey(self.ax_c)\n",
    "    # Contour Plot\n",
    "    x_vals = np.linspace(self.x_bounds[0], self.x_bounds[1], 400)\n",
    "    y_vals = np.linspace(self.y_bounds[0], self.y_bounds[1], 400)\n",
    "    X, Y = np.meshgrid(x_vals, y_vals)\n",
    "    Z = self.eval_function(X, Y)\n",
    "    self.contours = self.ax_c.contour(X, Y, Z, cmap='viridis')\n",
    "    self.point_current, = self.ax_c.plot([self.current_x],\n",
    "        [self.current_y], 'bo', label='Current')\n",
    "    self.vline_current, = self.ax_c.plot([self.current_x, self.current_x],\n",
    "                                         self.y_bounds, 'k--', alpha=0.3)\n",
    "    self.hline_current, = self.ax_c.plot(self.x_bounds, [self.current_y, self.current_y],\n",
    "                                         'k--', alpha=0.3)\n",
    "    self.point_proposed, = self.ax_c.plot([], [], 'go',\n",
    "                                          label='Proposed')\n",
    "    self.points_history, = self.ax_c.plot([], [], 'ks', alpha=0.5,\n",
    "                                        label='History', markersize=4)\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "\n",
    "    #self.ax_x.set_xlabel('x')\n",
    "    self.ax_x.set_ylabel('z')\n",
    "    self.ax_c.set_ylabel('y')\n",
    "    self.ax_c.set_xlabel('x')\n",
    "    #self.ax_y.set_ylabel('y')\n",
    "    self.ax_y.set_xlabel('z')\n",
    "\n",
    "    # Adjust visibility of shared axis tick labels\n",
    "    plt.setp(self.ax_x.get_xticklabels(), visible=False)\n",
    "    plt.setp(self.ax_y.get_yticklabels(), visible=False)\n",
    "\n",
    "    # Initial empty plots for marginal plots; they will be updated dynamically\n",
    "    self.curve_z_of_x, = self.ax_x.plot([], [], 'r-', label='z(x) with y fixed')\n",
    "    self.curve_z_of_y, = self.ax_y.plot([], [], 'b-', label='z(y) with x fixed')\n",
    "    self.x_slope_line, = self.ax_x.plot([], [], 'g-')\n",
    "    self.y_slope_line, = self.ax_y.plot([], [], 'g-')\n",
    "    self.x_proposed_line, = self.ax_x.plot([], [], 'g--', alpha=0.5)\n",
    "    self.y_proposed_line, = self.ax_y.plot([], [], 'g--', alpha=0.5)\n",
    "    self.current_xz, = self.ax_x.plot([], [], 'bo')\n",
    "    self.current_yz, = self.ax_y.plot([], [], 'bo')\n",
    "    self.test_x_point, = self.ax_x.plot([], [], 'rx')\n",
    "    self.test_y_point, = self.ax_y.plot([], [], 'rx', label='Test')\n",
    "    self.xz_proposed_point, = self.ax_x.plot([], [], 'go')\n",
    "    self.yz_proposed_point, = self.ax_y.plot([], [], 'go')\n",
    "    self.update_z_of_x()\n",
    "    self.update_z_of_y()\n",
    "    self.ax_legend.axis('off')\n",
    "    handles, labels = [], []\n",
    "    for ax in [self.ax_c, self.ax_x, self.ax_y]:\n",
    "      for handle, label in zip(*ax.get_legend_handles_labels()):\n",
    "        handles.append(handle)\n",
    "        labels.append(label)\n",
    "    self.ax_legend.legend(handles, labels, loc='center')\n",
    "    plt.tight_layout()\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def update_z_of_x(self, fixed_y=None):\n",
    "    if fixed_y is None:\n",
    "      fixed_y = self.current_y\n",
    "    x_vals = np.linspace(self.x_bounds[0], self.x_bounds[1], 400)\n",
    "    z_vals = self.eval_function(x_vals, np.full_like(x_vals, fixed_y))\n",
    "    self.curve_z_of_x.set_data(x_vals, z_vals)\n",
    "    self.current_xz.set_data([self.current_x], [self.current_z])\n",
    "    min_z, max_z = z_vals.min(), z_vals.max()\n",
    "    padding = (max_z - min_z) * 0.04\n",
    "    self.ax_x.set_ylim(min_z - padding, max_z)\n",
    "\n",
    "  def update_z_of_y(self, fixed_x=None):\n",
    "    if fixed_x is None:\n",
    "      fixed_x = self.current_x\n",
    "    y_vals = np.linspace(self.y_bounds[0], self.y_bounds[1], 400)\n",
    "    z_vals = self.eval_function(np.full_like(y_vals, fixed_x), y_vals)\n",
    "    self.curve_z_of_y.set_data(z_vals, y_vals)\n",
    "    self.current_yz.set_data([self.current_z], [self.current_y])\n",
    "    min_z, max_z = z_vals.min(), z_vals.max()\n",
    "    padding = (max_z - min_z) * 0.04\n",
    "    self.ax_y.set_xlim(min_z - padding, max_z)\n",
    "\n",
    "  def update_measure_x(self):\n",
    "    rise = self.test_z - self.current_z\n",
    "    run = self.test_x - self.current_x\n",
    "    self.x_slope = rise / run\n",
    "    self.xz_intercept = self.current_z - self.x_slope * self.current_x\n",
    "    x_vals = np.linspace(self.x_bounds[0], self.x_bounds[1], 400)\n",
    "    z_vals = self.x_slope * x_vals + self.xz_intercept\n",
    "    self.x_slope_line.set_data(x_vals, z_vals)\n",
    "    self.proposed_x = self.current_x - self.param_step_slider.value * self.x_slope\n",
    "    self.step_xz = self.xz_intercept + self.x_slope * self.proposed_x\n",
    "    self.xz_proposed_point.set_data([self.proposed_x], [self.step_xz])\n",
    "    z_min, z_max = self.ax_x.get_ylim()\n",
    "    self.x_proposed_line.set_data([self.proposed_x, self.proposed_x], [z_min, z_max])\n",
    "    if self.proposed_y is None:\n",
    "      self.point_proposed.set_data([self.proposed_x], [self.current_y])\n",
    "    else:\n",
    "      self.point_proposed.set_data([self.proposed_x], [self.proposed_y])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def update_measure_y(self):\n",
    "    rise = self.test_z - self.current_z\n",
    "    run = self.test_y - self.current_y\n",
    "    self.y_slope = rise / run\n",
    "    self.yz_intercept = self.current_z - self.y_slope * self.current_y\n",
    "    y_vals = np.linspace(self.y_bounds[0], self.y_bounds[1], 400)\n",
    "    z_vals = self.y_slope * y_vals + self.yz_intercept\n",
    "    self.y_slope_line.set_data(z_vals, y_vals)\n",
    "    self.proposed_y = self.current_y - self.param_step_slider.value * self.y_slope\n",
    "    self.step_yz = self.yz_intercept + self.y_slope * self.proposed_y\n",
    "    self.yz_proposed_point.set_data([self.step_yz], [self.proposed_y])\n",
    "    z_min, z_max = self.ax_y.get_xlim()\n",
    "    self.y_proposed_line.set_data([z_min, z_max], [self.proposed_y, self.proposed_y])\n",
    "    if self.proposed_x is None:\n",
    "      self.point_proposed.set_data([self.current_x], [self.proposed_y])\n",
    "    else:\n",
    "      self.point_proposed.set_data([self.proposed_x], [self.proposed_y])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_perturb_clicked(self, button, axis=None):\n",
    "    # are we perturbing x or y use axis or infer from button description\n",
    "    if axis is None:\n",
    "      if button.description == 'Perturb x':\n",
    "        axis = 'x'\n",
    "      elif button.description == 'Perturb y':\n",
    "        axis = 'y'\n",
    "      else:\n",
    "        raise ValueError(\"Invalid button description, expected 'Perturb x' or 'Perturb y'\")\n",
    "    if axis == 'x':\n",
    "      self.test_x = self.current_x + self.test_step_slider.value\n",
    "      self.test_y = self.current_y\n",
    "      axis_is = 'x'\n",
    "    elif axis == 'y':\n",
    "      self.test_y = self.current_y + self.test_step_slider.value\n",
    "      self.test_x = self.current_x\n",
    "      axis_is = 'y'\n",
    "    else:\n",
    "      raise ValueError(\"Invalid axis, expected 'x' or 'y'\")\n",
    "    # calculate test value\n",
    "    self.test_z = self.eval_function(self.test_x, self.test_y)\n",
    "    self.total_function_evaluations += 1\n",
    "    if axis == 'x':\n",
    "      self.test_x_point.set_data([self.test_x], [self.test_z])\n",
    "      self.measure_x.disabled = False\n",
    "      self.perturb_x.disabled = True\n",
    "      self.perturb_y.disabled = True\n",
    "    elif axis == 'y':\n",
    "      self.test_y_point.set_data([self.test_z], [self.test_y])\n",
    "      self.measure_y.disabled = False\n",
    "      self.perturb_y.disabled = True\n",
    "      self.perturb_x.disabled = True\n",
    "    self.fig.canvas.draw_idle()\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Test point: x = {self.test_x:.3f}, y = {self.test_y:.3f}, z = {self.test_z:.3f}.')\n",
    "      print(f\"Click 'Measure' to propose a new {axis_is} value based on this test point.\")\n",
    "\n",
    "  def on_measure_clicked(self, button, axis=None):\n",
    "    if axis is None:\n",
    "      if button.description == 'Measure x':\n",
    "        axis = 'x'\n",
    "      elif button.description == 'Measure y':\n",
    "        axis = 'y'\n",
    "      else:\n",
    "        raise ValueError(\"Invalid button description, expected 'Measure x' or 'Measure y'\")\n",
    "    if axis == 'x':\n",
    "      self.update_measure_x()\n",
    "      with self.narration_display:\n",
    "        clear_output(wait=True)\n",
    "        print(f'Based on measurement of x slope, proposed x step from {self.current_x:.3f} to {self.proposed_x:.3f}')\n",
    "        print(\"Click 'Step x', to make the step.\")\n",
    "      self.step_x.disabled = False\n",
    "      self.measure_x.disabled = True\n",
    "    else: # axis == 'y':\n",
    "      self.update_measure_y()\n",
    "      with self.narration_display:\n",
    "        clear_output(wait=True)\n",
    "        print(f'Based on measurement of y slope, proposed y step from {self.current_y:.3f} to {self.proposed_y:.3f}')\n",
    "        print(\"Click 'Step y', to make the step.\")\n",
    "        self.step_y.disabled = False\n",
    "        self.measure_y.disabled = True\n",
    "\n",
    "  def on_step_clicked(self, button):\n",
    "    self.num_steps += 1\n",
    "    if self.proposed_x is None and self.proposed_y is None:\n",
    "      raise ValueError(\"At least one of proposed x and y values must be set before stepping.\")\n",
    "    if self.proposed_x is None:\n",
    "      self.proposed_x = self.current_x\n",
    "    if self.proposed_y is None:\n",
    "      self.proposed_y = self.current_y\n",
    "    new_z = self.eval_function(self.proposed_x, self.proposed_y)\n",
    "    self.total_function_evaluations += 1\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Stepped to x = {self.proposed_x:.3f}, y = {self.proposed_y:.3f}, z = {new_z:.3f}.')\n",
    "      print(f\"Click 'Propose' or 'Do It For Me' to try a new value.\")\n",
    "      print(f'Total function evaluations so far: {self.total_function_evaluations}')\n",
    "      print(f'Total number of steps taken so far: {self.num_steps}')\n",
    "    self.x_history.append(self.current_x)\n",
    "    self.y_history.append(self.current_y)\n",
    "    self.z_history.append(self.current_z)\n",
    "    self.points_history.set_data(self.x_history, self.y_history)\n",
    "    self.current_x = self.proposed_x\n",
    "    self.current_y = self.proposed_y\n",
    "    self.current_z = new_z\n",
    "    self.point_current.set_data([self.current_x], [self.current_y])\n",
    "    self.vline_current.set_data([self.current_x, self.current_x], self.y_bounds)\n",
    "    self.hline_current.set_data(self.x_bounds, [self.current_y, self.current_y])\n",
    "    self.test_x, self.test_y, self.test_z = None, None, None\n",
    "    self.test_x_point.set_data([], [])\n",
    "    self.test_y_point.set_data([], [])\n",
    "    self.proposed_x, self.proposed_y, self.proposed_z = None, None, None\n",
    "    self.x_proposed_line.set_data([], [])\n",
    "    self.y_proposed_line.set_data([], [])\n",
    "    self.yz_proposed_point.set_data([], [])\n",
    "    self.xz_proposed_point.set_data([], [])\n",
    "    self.point_proposed.set_data([], [])\n",
    "    self.x_slope_line.set_data([], [])\n",
    "    self.y_slope_line.set_data([], [])\n",
    "    self.update_z_of_x()\n",
    "    self.update_z_of_y()\n",
    "    self.fig.canvas.draw_idle()\n",
    "    self.step_x.disabled = True\n",
    "    self.step_y.disabled = True\n",
    "    self.perturb_x.disabled = False\n",
    "    self.perturb_y.disabled = False\n",
    "    self.full_step.disabled = False\n",
    "    self.take_10_steps.disabled = False\n",
    "\n",
    "  def on_step_slider_changed(self, change):\n",
    "    self.step_x = self.current_x + self.x_step_slider.value * self.slope\n",
    "    self.step_y = self.slope * self.step_x + self.y_intercept\n",
    "    self.step_point.set_data([self.step_x], [self.step_y])\n",
    "    y_min, y_max = self.ax.get_ylim()\n",
    "    self.step_vline.set_data([self.step_x, self.step_x], [y_min, self.step_y])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_test_step_slider_changed(self, change):\n",
    "    if self.test_step_slider.value == 0:\n",
    "      # Set to a default non-zero value\n",
    "      self.test_step_slider.value = 0.01\n",
    "      with self.narration_display:\n",
    "        print(f\"Test step size of 0 cannot be used to calculate slope. Using 0.01 to avoid division by zero in slope calculation.\")\n",
    "    self.test_x = self.current_x + self.test_step_slider.value\n",
    "    self.test_y = self.polynomial(self.test_x)\n",
    "    self.test_point.set_data([self.test_x], [self.test_y])\n",
    "    if self.step_x is not None:\n",
    "      rise = self.test_y - self.current_y\n",
    "      run = self.test_x - self.current_x\n",
    "      self.slope = rise / run\n",
    "      self.y_intercept = self.current_y - self.slope * self.current_x\n",
    "      x_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "      y_vals = self.slope * x_vals + self.y_intercept\n",
    "      self.step_line.set_data(x_vals, y_vals)\n",
    "      self.step_x = self.current_x + self.x_step_slider.value * self.slope\n",
    "      self.step_y = self.slope * self.step_x + self.y_intercept\n",
    "      self.step_point.set_data([self.step_x], [self.step_y])\n",
    "      y_min, y_max = self.ax.get_ylim()\n",
    "      self.step_vline.set_data([self.step_x, self.step_x], [y_min, self.step_y])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_full_step_clicked(self, button):\n",
    "    self.on_perturb_clicked(button, axis='x')\n",
    "    self.on_measure_clicked(button, axis='x')\n",
    "    self.on_step_clicked(button)\n",
    "    self.on_perturb_clicked(button, axis='y')\n",
    "    self.on_measure_clicked(button, axis='y')\n",
    "    self.on_step_clicked(button)\n",
    "\n",
    "  def on_take_10_steps_clicked(self, button):\n",
    "    for _ in range(10):\n",
    "      self.on_full_step_clicked(button)\n",
    "\n",
    "  def on_reset_clicked(self, button):\n",
    "    self.proposals_evaluated = 0\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Reset. Clearing history')\n",
    "      print(f'Randomizing initial x and y values.')\n",
    "    self.current_x = self.rng.uniform(self.x_bounds[0], self.x_bounds[1])\n",
    "    self.current_y = self.rng.uniform(self.y_bounds[0], self.y_bounds[1])\n",
    "    self.current_z = self.eval_function(self.current_x, self.current_y)\n",
    "    self.point_current.set_data([self.current_x], [self.current_y])\n",
    "    self.vline_current.set_data([self.current_x, self.current_x], self.y_bounds)\n",
    "    self.hline_current.set_data(self.x_bounds, [self.current_y, self.current_y])\n",
    "    self.test_x, self.test_y, self.test_z = None, None, None\n",
    "    self.test_x_point.set_data([], [])\n",
    "    self.test_y_point.set_data([], [])\n",
    "    self.proposed_x, self.proposed_y, self.proposed_z = None, None, None\n",
    "    self.x_proposed_line.set_data([], [])\n",
    "    self.y_proposed_line.set_data([], [])\n",
    "    self.yz_proposed_point.set_data([], [])\n",
    "    self.xz_proposed_point.set_data([], [])\n",
    "    self.point_proposed.set_data([], [])\n",
    "    self.x_slope_line.set_data([], [])\n",
    "    self.y_slope_line.set_data([], [])\n",
    "    self.x_history, self.y_history, self.z_history = [], [], []\n",
    "    self.points_history.set_data([], [])\n",
    "    self.update_z_of_x()\n",
    "    self.update_z_of_y()\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_curve_toggled(self, change):\n",
    "    alpha = 1 if self.show_curve.value else 0\n",
    "    self.line_polynomial.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_history_toggled(self, change):\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "\n",
    "ipss = InteractivePolynomialSlopeStepper()\n",
    "display(ipss.fig.canvas)\n",
    "clear_output()\n",
    "display(ipss.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "So for this particular function, with this particular starting point, and these step sizes, the perturb-measure-step approach is a bit more effective. Specifically, when we start at the same spot and using similar step sizes, we are able to zero in on the minimum of the curve with fewer function evaluations using perturb-measure-step than with propose-accept-reject.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "**Alogorithmic Thinking Exercise**\n",
    "\n",
    "In the 'perturb-measure-step' optimization implemented above, we perturb each parameter ($x$ or $y$), measure the effect of perturbation, and then update only the perturbed parameter. Alternatively we could have perturbed each parameter $x$, measured, then perturbed $y$ and measured, and only then simultaneously steped both parameters.\n",
    "\n",
    "1. In the implementation above how many times is the `eval_params` function called per iteration? How many times does `eval_params` need to be called to make in improvement in both parameters\n",
    "\n",
    "  (Answer: Two, once to measure the base and once to measure the perturbation. To do this for both parameters requires four evaluations in total)\n",
    "2. If we used the alternative method described above where both the $x$ and the $y$ value are updated simultaneously, after seperate measurements how many times is the `eval_params` function called per iteration? How many function evaluations are required to make in iteration in all parameters using this method?\n",
    "\n",
    "  (Answer: Three, once to evaluate the base params, once to evaluate the perturbation in $x$ and once to evaluate the perturbation in $y$ from the same base params. In this method all )\n",
    "3. If we had $n$ parameters instead of 2, how many times would the `eval_params` function need to be called to make an iteration in all parameters in implementation above?\n",
    "\n",
    "  (Answer: $2n$, this is less efficient is some sense since a new reference point is used to evaluate the perturbation in each dimension.)\n",
    "4. If we had $n$ parameters instead of 2, how many times would the `eval_params` function need to be called to make an iteration in all parameters in the alternate implementation?\n",
    "\n",
    "  (Answer: $n+1$, this is more efficient in some sense since all perturbations are compared to a single reference point)\n",
    "\n",
    "Little details like this in implementation can make big differences to algorithm speed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "For now though, let's see if we can apply these methods to our simple strike-no-strike problem where a lurk and strike predator must choose between striking and not strkining based on the activation level of a single sensory neuron."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "\n",
    "#2.1.2.4: An Artificial Neural Network Model of Striking Behaviour\n",
    "\n",
    "In the previous sequence we introduced a visual binary classification problem in which a lurking predator must choose between striking and not striking based on sensory input. The basic problem is simple. Given a sensory input pattern, in this case the intensity of a single pixel ranging from -6 to 6, determine whether to strike or not. The 'environment' of the organism consists of a data-set. There are 1125 elements in this particular data set. Each element is an $(x,y)$ pair, where $x$ is the sensory input the organism recieves, and $y$ is the correct action the organism should take. In the version of the problem we work with the organism gains a reward point if it strikes when prey is present, loses a reward point if it strikes when prey is not present, and obtains no reward if it does not strike (whether or not prey was present). You can try out this discrimination task for yourself by running the code cell below.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown **Run this cell** to try out the 'strike-no-strike' discrimination task.\n",
    "\n",
    "class InteractiveMNISTPredator():\n",
    "  def __init__(self,\n",
    "               features=Xs,\n",
    "               labels=y,\n",
    "               feedback_type='on_strike_only', seed=123):\n",
    "    # Initialize dataset, settings for image scrambling and feedback\n",
    "    self.features = features\n",
    "    self.labels = labels\n",
    "    # features is num_data_points x 64 (reshape to 8x8 for display, each cell 0-16)\n",
    "    # labels is num_data_points x 1 (values 0-9 or 0/1 depending)\n",
    "    self.feedback_type = feedback_type\n",
    "    self.rng = np.random.default_rng(seed)\n",
    "    sample_order = self.rng.permutation(self.features.shape[0])\n",
    "    self.features = self.features[sample_order]\n",
    "    self.labels = self.labels[sample_order]\n",
    "    # initialize game state\n",
    "    self.current_index = 0\n",
    "    self.score = 0\n",
    "    self.best_possible_score = 0\n",
    "    self.successful_strikes = 0\n",
    "    self.failed_strikes = 0\n",
    "    self.non_strikes = 0\n",
    "    # Initialize widgets\n",
    "    self.strike_button = widgets.Button(description='Strike')\n",
    "    self.no_strike_button = widgets.Button(description='No Strike')\n",
    "    self.score_display = widgets.Output()\n",
    "    self.feedback_display = widgets.Output()\n",
    "\n",
    "    # Initialize the figure for image display\n",
    "    self.fig, self.ax = plt.subplots(figsize=(4, 4))\n",
    "    remove_ip_clutter(self.fig)\n",
    "    self.show_next_image()\n",
    "    # Bind event handlers\n",
    "    self.strike_button.on_click(self.on_strike_clicked)\n",
    "    self.no_strike_button.on_click(self.on_no_strike_clicked)\n",
    "\n",
    "    # Arrange widgets in a layout\n",
    "    buttons_layout = widgets.HBox([self.strike_button, self.no_strike_button])\n",
    "    board_buttons = widgets.VBox([self.fig.canvas, buttons_layout])\n",
    "    self.ui = widgets.HBox([board_buttons, widgets.VBox([self.score_display,\n",
    "                                                         self.feedback_display])])\n",
    "\n",
    "  def show_next_image(self):\n",
    "    # Display the next image\n",
    "    image = self.features[self.current_index]\n",
    "    if len(image) == 64:\n",
    "        image = image.reshape(8, 8)\n",
    "    elif len(image) == 1:\n",
    "      scalar_value = image.flatten()[0]\n",
    "      # Initialize the 8x8 array with -6 (black)\n",
    "      image = np.full((8, 8), -6.0)\n",
    "      # Set the second ring to 6 (white)\n",
    "      image[1:-1, 1:-1] = 6\n",
    "      # Set the third (inner ring) back to -6 (black)\n",
    "      image[2:-2, 2:-2] = -6\n",
    "      # Assuming scalar_value is already in the range -6 to 6\n",
    "      #print(scalar_value)\n",
    "      image[3:-3, 3:-3] = scalar_value\n",
    "    else:\n",
    "      raise ValueError(f'Unexpected image shape: {image.shape}')\n",
    "    # Display the image\n",
    "    #print(image)\n",
    "    self.fig.clf()\n",
    "    self.ax = self.fig.add_subplot(111)\n",
    "    self.ax.set_xlim(-.5, 7.5)\n",
    "    self.ax.set_ylim(-0.5, 7.5)\n",
    "    self.ax.set_aspect('equal')\n",
    "    self.ax.axis('off')\n",
    "    self.ax.imshow(image, cmap='gray', vmin=-6, vmax=6)\n",
    "    self.fig.canvas.draw_idle()  # Force redraw\n",
    "\n",
    "  def on_strike_clicked(self, button):\n",
    "    self.process_decision('Strike')\n",
    "\n",
    "  def on_no_strike_clicked(self, button):\n",
    "    self.process_decision('No Strike')\n",
    "\n",
    "  def process_decision(self, decision):\n",
    "    # freeze buttons while we process\n",
    "    self.strike_button.disabled = True\n",
    "    self.no_strike_button.disabled = True\n",
    "\n",
    "    # Process the user's decision, update score, and provide feedback\n",
    "    correct_action = 'Strike' if self.labels[self.current_index] == 1 else 'No Strike'\n",
    "    if decision == 'Strike':\n",
    "      if decision == correct_action:\n",
    "        self.score += 1\n",
    "        self.successful_strikes += 1\n",
    "      else:\n",
    "        self.score -= 1\n",
    "        self.failed_strikes += 1\n",
    "    elif decision == 'No Strike':\n",
    "      self.non_strikes += 1\n",
    "      # no strike means no gain or loss\n",
    "    else:\n",
    "      raise ValueError(f'Unknown decision: {decision}')\n",
    "\n",
    "    # Show feedback and score\n",
    "    if (self.feedback_type == 'both' or\n",
    "      (self.feedback_type == 'on_strike_only' and decision == 'Strike')):\n",
    "      # Show informative feedback\n",
    "      feedback = f'Your last choice: {decision}\\nCorrect last choice: {correct_action}'\n",
    "    else:\n",
    "      # Show uninformative feedback\n",
    "      feedback = 'Feedback only available after striking.'\n",
    "    with self.feedback_display:\n",
    "      clear_output(wait=True)\n",
    "      print(feedback)\n",
    "\n",
    "    # Show score\n",
    "    with self.score_display:\n",
    "      clear_output(wait=True)\n",
    "      average_score = self.score / (self.current_index+1)\n",
    "      print(f'Total Score: {self.score}')\n",
    "      print(f'Number of Trials: {self.current_index + 1}')\n",
    "      print(f'Successful Strikes: {self.successful_strikes}')\n",
    "      print(f'Failed Strikes: {self.failed_strikes}')\n",
    "      print(f'Non-Strikes: {self.non_strikes}')\n",
    "      print(f'Average Score Per Trial: {average_score:.2f}')\n",
    "\n",
    "    # Prepare the next image\n",
    "    self.current_index += 1\n",
    "    #print(self.current_index)\n",
    "    self.show_next_image()\n",
    "    # Re-enable buttons\n",
    "    self.strike_button.disabled = False\n",
    "    self.no_strike_button.disabled = False\n",
    "\n",
    "\n",
    "scramble_01_imp = InteractiveMNISTPredator(features=X_simple_1_feature,\n",
    "                                           labels=y1_simple, feedback_type='both')\n",
    "display(scramble_01_imp.fig.canvas)\n",
    "clear_output()\n",
    "display(scramble_01_imp.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As we saw in the previous sequence, the simple association - strike when the center pixel is relatively light, don't strike when the center pixel is dark - works well. Previously we implemented this decision rule, i.e. policy, as a simple threshold. Now, instead we will implement a decision rule using a very simple (2-parameter) artificial neural network. (Recall that the dataset that underlies this strike-no-strike decision problem is sourced from the UCI Machine Learning Repository, Alpaydin,E. and Kaynak,C. 1998. https://doi.org/10.24432/C50P49). We used this data set in the last sequence, and spent some time going over the structure of the data. The next few code cells repeat the over-view of the data from the previous sequence, as a reminder of what the data looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# What is the shape and type of the data we have to work with\n",
    "print(f'')\n",
    "print(f'Input data type: {type(X_simple_1_feature)}')\n",
    "print(f'Input data shape: {X_simple_1_feature.shape}')\n",
    "print(f'Output target data type: {type(y1_simple.dtype)}')\n",
    "print(f'Output target shape: {y1_simple.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This data set consist of 1125 distinct $(\\text{input}, \\text{output})$ pairs. The goal of the organism is to learn as quickly as possible to correctly distinguish between these two different kinds of situation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# What do the ouptus look like, what is their range\n",
    "print(y1_simple[:10])\n",
    "print(f'max output value: {np.max(y1_simple)}')\n",
    "print(f'min output value: {np.min(y1_simple)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In the interactive strike-no-strik setup above we used the label '1' to correspond to situations when 'strike' is the correct action and the label '0' to correspond to situations where 'no-strike' is the correct action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# What do the inputs look like, what is there range\n",
    "print(X_simple_1_feature[:10])\n",
    "print(f'Max input value: {np.max(X_simple_1_feature)}')\n",
    "print(f'Min input value: {np.min(X_simple_1_feature)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In the visualization above a high 'feature value' corresponded to lighter colors in the center pixels and a lower feature value corresponded to darker center pixels. Now that we have a sense of the type and range of the input and output pairs let's visualize the whole dataset. For a simple dataset like this we can visualize the distribution of the input values conditional on the two different \"correct\" outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# For scalar data always good to look at a histogram\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "remove_ip_clutter(fig)\n",
    "ax1.hist(X_simple_1_feature[y1_simple.flatten() == 1])\n",
    "ax1.set_title('Feature Distribution When Strike is Correct')\n",
    "ax2.hist(X_simple_1_feature[y1_simple.flatten() == 0])\n",
    "ax2.set_title('Feature Distribution When No-Strike is Correct')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In the previous sequence we were able to dial in an optimal threshold value. You can do that again if you'd like by running the code cell below and interacting with the widget."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Dialing in The Optimal Threshold\n",
    "# @markdown **Run this cell** to dial in the optimal threshold\n",
    "class InteractiveThresholdDialer:\n",
    "  def __init__(self,\n",
    "               features=X_simple_1_feature,\n",
    "               labels=y1_simple):\n",
    "    self.features = features\n",
    "    self.labels = labels\n",
    "    # maybe rewards have a slider ?\n",
    "    self.correct_strike_r = 1\n",
    "    self.false_strike_r = -1\n",
    "    self.correct_non_strike_r = 0\n",
    "    self.false_non_strike_r = 0\n",
    "    self.bounds = [min(features)-0.5, max(features)+0.5]\n",
    "    self.threshold_slider = widgets.FloatSlider(\n",
    "        value=0, min=self.bounds[0], max=self.bounds[1], step=0.1,\n",
    "        description='Threshold:', readout=True, readout_format='.2f')\n",
    "    self.fig, (self.hist_ax, self.r_ax) = plt.subplots(2, 1, figsize=(8, 6),\n",
    "                                                       sharex=True)\n",
    "    self.narration_display = widgets.Output()\n",
    "    self.init_plot()\n",
    "    remove_ip_clutter(self.fig)\n",
    "\n",
    "    # Arrange widgets in a layout\n",
    "    self.ui = widgets.VBox([\n",
    "        widgets.HBox([self.fig.canvas,]),\n",
    "        widgets.HBox([self.threshold_slider, self.narration_display])\n",
    "    ])\n",
    "    self.threshold_slider.observe(self.on_threshold_slider_changed, 'value')\n",
    "    print(\"We have narration display\", hasattr(self, 'narration_display'))\n",
    "\n",
    "\n",
    "  def eval_threshold(self, t):\n",
    "    t = np.asarray(t).reshape(1, -1)  # 1 x len(t)\n",
    "    features = self.features.reshape(-1, 1)  # len(features) x 1\n",
    "    labels = self.labels.reshape(-1, 1)  # len(labels) x 1\n",
    "    strikes = features > t # len(features) x len(t)\n",
    "    non_strikes = features <= t # len(feature) x len(t)\n",
    "    should_strike = labels == 1 # len(labels) x 1\n",
    "    should_not_strike = labels == 0 #len(labels) x 1\n",
    "\n",
    "    correct_strikes = strikes & should_strike #len(labels/features) x len(t)\n",
    "    false_strikes = strikes & should_not_strike #len(labels/features) x len(t)\n",
    "    correct_non_strikes = non_strikes & should_not_strike #len(labels/features) x len(t)\n",
    "    false_non_strikes = non_strikes & should_strike #len(labels/features) x len(t)\n",
    "\n",
    "    r = (self.correct_strike_r * np.sum(correct_strikes, axis=0) +\n",
    "         self.false_strike_r * np.sum(false_strikes, axis=0) +\n",
    "         self.correct_non_strike_r * np.sum(correct_non_strikes, axis=0) +\n",
    "         self.false_non_strike_r * np.sum(false_non_strikes, axis=0))\n",
    "    r = r.flatten()\n",
    "    if len(r) == 1:\n",
    "      r = r[0]\n",
    "      # for single threshold evaluations\n",
    "      num_correct_strikes = np.sum(correct_strikes)\n",
    "      num_false_strikes = np.sum(false_strikes)\n",
    "      num_correct_non_strikes = np.sum(correct_non_strikes)\n",
    "      num_false_non_strikes = np.sum(false_non_strikes)\n",
    "      # Prepare a text-based confusion matrix\n",
    "      confusion_matrix_data = [\n",
    "          [\"Should Strike\", num_correct_strikes, num_false_non_strikes],\n",
    "          [\"Should Not Strike\", num_false_strikes, num_correct_non_strikes]]\n",
    "      headers = [\"\", \"Will Strike\", \"Will Not Strike\"]\n",
    "      confusion_matrix_table = tabulate(confusion_matrix_data, headers, tablefmt=\"grid\")\n",
    "      message = f\"Confusion Matrix for threshold {t[0][0]:.2f}:\\n{confusion_matrix_table}\\n\\nTotal Reward: {r}\"\n",
    "      self.narration_display.clear_output(wait=True)\n",
    "      with self.narration_display:\n",
    "        clear_output()\n",
    "        print(message)\n",
    "    return r\n",
    "\n",
    "  def on_threshold_slider_changed(self, change):\n",
    "    self.plot_threshold(self.threshold_slider.value)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def plot_threshold(self, t):\n",
    "    r = self.eval_threshold(t)\n",
    "    self.threshold_vline.set_data([t, t], [0, r])\n",
    "    y_min, y_max = self.hist_ax.get_ylim()\n",
    "    self.hist_vline.set_data([t, t], [y_min, y_max])\n",
    "\n",
    "  def init_plot(self):\n",
    "    \"\"\"Initialize the plot with placeholder data.\"\"\"\n",
    "    t_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "    r_vals = self.eval_threshold(t_vals)\n",
    "    # Initial plot commands return line objects, keep references to them\n",
    "    self.threshold_vline, = self.r_ax.plot([],[] ,color='r', linestyle='--', label='Threshold')\n",
    "    self.hist_vline, = self.hist_ax.plot([], [], color='r', linestyle='--', label='Threshold')\n",
    "    self.reward_curve, = self.r_ax.plot(t_vals, r_vals, alpha=1.0, label='Expected Reward')\n",
    "    self.hist_ax.hist(self.features[self.labels.flatten() == 1], alpha=0.5, label='Strike')\n",
    "    self.hist_ax.hist(self.features[self.labels.flatten() == 0], alpha=0.5, label='No Strike')\n",
    "    self.hist_ax.set_xlabel('Feature Value')\n",
    "    self.hist_ax.set_ylabel('Counts')\n",
    "\n",
    "    self.fig.suptitle('Threshold Evaluation')\n",
    "    self.r_ax.set_xlabel('Threshold')\n",
    "    self.r_ax.set_ylabel('Total Reward\\n(Over 1125 trials)')\n",
    "    self.plot_threshold(self.threshold_slider.value)\n",
    "    self.hist_ax.legend()\n",
    "    self.r_ax.legend()\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "\n",
    "itd = InteractiveThresholdDialer()\n",
    "display(itd.fig.canvas)\n",
    "clear_output()\n",
    "display(itd.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "That was our threshold rule. This threshold rule works well, but as we can see in the widget above, the expected reward for a given threshold is a step function the threshold (this largely stems from the fact that reward is determined by performance over a finite and discrete data set.) This flatness of the reward function with respect to changes in the threshold made it difficult for our propose and reject method as we needed big proposal jumps to step over flat regions, but then we potentially spent lots of time overshooting the peak. This flatness was even more problematic for our perturb-measure-step rule, since perturb-measure-step relied upon estimating the slope of the reward function based on a small perturbation. However, the slope is flat at most points on this curve, so this pertubation approach does not not provide any useful information to guide parameter updates, unless of course perturbations are large enough that that span the width of the steps in this step function, but having such large steps introduces a host of other issues.\n",
    "\n",
    "As we will see here (and many times throughout the book) stochasticity can provide a kind \"fuzzing\" effect, a softening of the hard edges of step-wise functions like this. Note that stochasticity might be introduced both through the behaviour of the organism (e.g. it strikes with a probability determined by its sensory inputs), or in the nature of the environment, (e.g. instead of computing the reward based on a finite and discrete set of 1125 input-output pairs in our dataset, we could instead have the reward be determined a random sample from a continuous distribution of input-output pairings. In either of these cases a decision rule with the exact same parameters may potentially yeild different amounts of reward on different 'runs' of the game, i.e. reward will be a random variable. In this case we shift our focus to maximising total expected reward, i.e. the average reward the organism would recieive over many iterations of the game. Note that in an evolutionary context, expected fitness is roughly what is being \"optimized\" for, but note that simply maximizing the expected \"score\" in many of the sub games of life, e.g. eating food, not being eaten, finding mates, etc. will not be what maximizes fitness. See sequence P1C3_S3). For now we'll leave our environment as totally deterministic, and introduce stochasticity into the behaviour of the organism. This will come quite naturally out of our (very simple) artifical neural network, or 'connectionist', decision rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As inspiration for our decision rule we imagine a very simple organism. One that has a single sensory input neuron, in turn connected to a single output neuron by single synaptic weight. If the output neuron fires (spikes) the predator strikes, and if it does not fire the predator does not strike.\n",
    "\n",
    "We model this creature's sensory-behaviour system as follows. Let $x$ be the raw sensory input (scalar) in a given episode. We imagine that $x$ corresponds to the activation level and firing rate of a single photosensitive neuron. This input neuron is then connected by a synapse to a single output neuron. The activation level of this output neuron is computed as\n",
    "$$y = wx + b$$\n",
    "Here, $b$ is the (scalar) bias, or baseline activation level of the output neuron and $w$ is the strength of the synaptic weight between the input neuron and the output neuron. Is this case there is only one output and one input so $w$ is a scalar. In cases with multiple inputs and outputs we would use $\\mathbf{W}$ to denote the matrix of such synaptic weights between all inputs and outputs and $\\mathbf{x}$ to denote the vector of sensory inputs. (A quick notation reminder: bold lowercase letters typically represent column vectors, bold uppercase letters typically denote matrices or higher-order tensors.) We imagine that the probabilistic spiking of this output neuron determines the strike-no-strike behaviour of the organism, specifically:\n",
    "$$ \\Pr \\{\\text{strike}\\} = \\sigma(y) $$\n",
    "$$ \\Pr \\{\\text{no strike}\\} = 1 - \\sigma(y)$$\n",
    "\n",
    "Here $\\sigma(y): \\frac{1}{1+e^{-y}} = \\frac{e^y}{1+e^y}$ is the standard logistic (sigmoid) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "--Picture of this very simple neural circuit here--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "**Quick Math Exercise: The Connection Between Softmax Normalization and the Standard Logistic Sigmoid.**\n",
    "\n",
    "Consider a random variable with two possible outcomes, $A$ and $B$. The probability of each outcome is determined by applying the softmax function to their respective scores, $a$ and $b$. Specifically, the probability of outcome $A$ occurring is given by the softmax formula:\n",
    "$$ \\Pr \\{A\\} = \\frac{e^a}{e^a + e^b}$$\n",
    "Interestingly, $\\Pr\\{A\\}$ can be expressed in terms of the logistic (sigmoid) function, $\\sigma(x)$, where $x$ is a function of the scores $a$ and $b$. Your task is to determine this function, denoted as $f(a, b)$, so that $\\Pr{A} = \\sigma(f(a, b))$.\n",
    "\n",
    "(Answer: $$\\frac{e^a}{e^a + e^b} = \\frac{1}{1 + e^{b-a}} = \\sigma(a-b)$$\n",
    "The sigmoid of the difference in the scores gives the probability. This is the sense in which softmax normalization can be viewed as the multi-variate extension of the logistic sigmoid, and softmax normalization plays a the same role in multi-class regression as the the logistic sigmoid does in binary-class or logistic regression.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "By playing with the sliders in the simualtion below, you can see how changing the parameters $w$ and $b$ affects the probability of striking across the range of possible $x$ values. See if you can dial in the optimal setting for $w$ and $b$, in the interactive exercise below. (Hint, for precise parameter dialing you can use the left and right arrows on your keyboard to change the slider values of a selected slider, you don't have to use ultra-precise mouse twitches.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Dialing in The Optimal Synaptic Weight and Bias Parameters\n",
    "# @markdown **Run this cell** to dial in the optimal parameters for our simple neural circuit\n",
    "class InteractiveANNDialer:\n",
    "  def __init__(self,\n",
    "               features=X_simple_1_feature,\n",
    "               labels=y1_simple):\n",
    "    self.features = features\n",
    "    self.labels = labels\n",
    "    # maybe rewards have a slider ?\n",
    "    self.correct_strike_r = 1\n",
    "    self.false_strike_r = -1\n",
    "    self.correct_non_strike_r = 0\n",
    "    self.false_non_strike_r = 0\n",
    "    self.bounds = [min(features)-0.5, max(features)+0.5]\n",
    "    self.w_slider = widgets.FloatSlider(\n",
    "        value=0, min=-5, max=50, step=0.1,\n",
    "        description='Weight:', readout=True, readout_format='.1f')\n",
    "    self.b_slider = widgets.FloatSlider(\n",
    "        value=0, min=-5, max=50, step=0.1,\n",
    "        description='Bias:', readout=True, readout_format='.1f')\n",
    "    self.fig, self.hist_ax = plt.subplots(figsize=(8, 4))\n",
    "    self.strike_prob_ax = self.hist_ax.twinx()\n",
    "    self.narration_display = widgets.Output()\n",
    "    self.init_plot()\n",
    "    remove_ip_clutter(self.fig)\n",
    "\n",
    "    # Arrange widgets in a layout\n",
    "    self.ui = widgets.VBox([\n",
    "        widgets.HBox([self.fig.canvas,]),\n",
    "        widgets.HBox([widgets.VBox([self.w_slider, self.b_slider]),\n",
    "                      self.narration_display])\n",
    "    ])\n",
    "    self.w_slider.observe(self.on_slider_changed, 'value')\n",
    "    self.b_slider.observe(self.on_slider_changed, 'value')\n",
    "\n",
    "  def sigmoid(self, x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "  def compute_strike_prob(self, w, b, x=None):\n",
    "    if x is None:\n",
    "      x = self.features[:, None, None] # (n_bacth, 1, 1)\n",
    "    W, B = np.meshgrid(w, b) # (n_w, n_b)\n",
    "    y = W * x + B # (n_batch, n_w, n_b)\n",
    "    p_strike = self.sigmoid(y) # (n_batch, n_w, n_b)\n",
    "    return p_strike\n",
    "\n",
    "  def eval_params_expected(self, w, b, x=None, y=None, verbose=True):\n",
    "    if x is None:\n",
    "      x = self.features[:, None, None] # (n_bacth, 1, 1)\n",
    "    p_strike = self.compute_strike_prob(w, b, x) # (n_batch, n_w, n_b)\n",
    "    p_no_strike = 1 - p_strike\n",
    "    if y is None:\n",
    "      y = self.labels.copy() # (n_batch,)\n",
    "    should_did = np.sum(p_strike[y == 1], axis=0)\n",
    "    should_but_did_not = np.sum(p_no_strike[y == 1], axis=0)\n",
    "    should_not_did_not = np.sum(p_no_strike[y == 0], axis=0)\n",
    "    should_not_but_did = np.sum(p_strike[y == 0], axis=0)\n",
    "    expected_reward = (should_did * self.correct_strike_r +\n",
    "                       should_not_but_did * self.false_strike_r +\n",
    "                       should_not_did_not * self.correct_non_strike_r +\n",
    "                       should_but_did_not * self.false_non_strike_r)\n",
    "    if expected_reward.shape == (1,1):\n",
    "      # we are dealing with a single w and b not a bunch w and b values\n",
    "      expected_reward = expected_reward[0,0]\n",
    "      strike_prob = p_strike[:,0,0]\n",
    "      confusion_matrix_data = [\n",
    "          [\"Should Strike\", should_did[0,0], should_but_did_not[0,0]],\n",
    "          [\"Should Not Strike\", should_not_but_did[0,0], should_not_did_not[0,0]]]\n",
    "      headers = [\"\", \"Will Strike\", \"Will Not Strike\"]\n",
    "      confusion_matrix_table = tabulate(confusion_matrix_data, headers, tablefmt=\"grid\")\n",
    "      message = f\"Confusion Matrix for weight {w:.1f} and bias {b:.1f}:\\n{confusion_matrix_table}\\n\\nTotal Expected Reward: {expected_reward}\"\n",
    "      self.narration_display.clear_output(wait=True)\n",
    "      with self.narration_display:\n",
    "        clear_output()\n",
    "        print(message)\n",
    "    return expected_reward\n",
    "\n",
    "  def on_slider_changed(self, change):\n",
    "    w = self.w_slider.value\n",
    "    b = self.b_slider.value\n",
    "    self.plot_decision_rule(w, b)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def plot_decision_rule(self, w, b):\n",
    "    _  = self.eval_params_expected(w, b)\n",
    "\n",
    "    feature_vals = np.linspace(self.bounds[0], self.bounds[1], 400)\n",
    "    strike_probs = self.compute_strike_prob(w, b, feature_vals)\n",
    "    self.strike_prob_curve.set_data(feature_vals, strike_probs)\n",
    "\n",
    "  def init_plot(self):\n",
    "    \"\"\"Initialize the plot with placeholder data.\"\"\"\n",
    "    # Initial plot commands return line objects, keep references to them\n",
    "    self.hist_ax.hist(self.features[self.labels.flatten() == 1], alpha=0.5, label='Should Strike')\n",
    "    self.hist_ax.hist(self.features[self.labels.flatten() == 0], alpha=0.5, label='Should Not Strike')\n",
    "\n",
    "    self.strike_prob_curve, = self.strike_prob_ax.plot([], [], color='r', linestyle='--', label='Strike Prob')\n",
    "    self.strike_prob_ax.set_ylim(-0.01, 1.01)\n",
    "    self.hist_ax.set_xlabel('Feature Value')\n",
    "    self.hist_ax.set_ylabel('Counts')\n",
    "    self.strike_prob_ax.set_ylabel('Strike Probability')\n",
    "\n",
    "    self.strike_prob_ax.spines['right'].set_visible(True)\n",
    "    self.strike_prob_ax.spines['right'].set_linewidth(1.2)\n",
    "\n",
    "    self.fig.suptitle('Parameter Evaluation')\n",
    "    self.plot_decision_rule(self.w_slider.value, self.b_slider.value)\n",
    "\n",
    "    handles1, labels1 = self.hist_ax.get_legend_handles_labels()\n",
    "    handles2, labels2 = self.strike_prob_ax.get_legend_handles_labels()\n",
    "    self.hist_ax.legend(handles1 + handles2, labels1 + labels2,)\n",
    "\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "\n",
    "iannd = InteractiveANNDialer()\n",
    "display(iannd.fig.canvas)\n",
    "clear_output()\n",
    "display(iannd.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "One way to concieve of what we are doing above, is trying to get as much of the blue (should strike) cases below the striking probability curve, while keeping as much of the pink (should not strike) cases above the striking probability curve.\n",
    "\n",
    "**Reflect:**\n",
    "1. How confident are you that you have found the best possible $w$ and $b$ given the available parameter ranges?\n",
    "2. What kind of strategy did you use to find good $w$ and $b$ values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Twiddling the parameter weights using feedback on the types of errors and the changes in total expected reward is good, but to have more confidence in the process it would be nice to have an overview of the reward 'landscape' as a function of the two parameters. That would look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown **Run this cell** to visualize the reward landscape as a function of the parameters $w$ and $b$.\n",
    "x = X_simple_1_feature.flatten()[:, None, None].copy() # (n_bacth, 1, 1)\n",
    "y = y1_simple.flatten() # (n_batch)\n",
    "w = np.linspace(9, 13, 100)\n",
    "b = np.linspace(32, 44, 100)\n",
    "\n",
    "def sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "def compute_strike_prob(w, b, x):\n",
    "  W, B = np.meshgrid(w, b) # (n_w, n_b)\n",
    "  output = W * x + B # (n_batch, n_w, n_b)\n",
    "  p_strike = sigmoid(output) # (n_batch, n_w, n_b)\n",
    "  return p_strike\n",
    "\n",
    "def eval_params_expected(w, b, x, y):\n",
    "  #correct_strike_r = 1\n",
    "  #false_strike_r = -1\n",
    "  #correct_non_strike_r = 0\n",
    "  #false_non_strike_r = 0\n",
    "  p_strike = compute_strike_prob(w, b, x) # (n_batch, n_w, n_b)\n",
    "  # p_no_strike = 1 - p_strike\n",
    "  should_did = np.sum(p_strike[y == 1], axis=0)\n",
    "  #should_but_did_not = np.sum(p_no_strike[y == 1], axis=0)\n",
    "  #should_not_did_not = np.sum(p_no_strike[y == 0], axis=0)\n",
    "  should_not_but_did = np.sum(p_strike[y == 0], axis=0)\n",
    "  expected_reward = should_did - should_not_but_did\n",
    "  return expected_reward\n",
    "\n",
    "expected_reward = eval_params_expected(w, b, x, y)\n",
    "fig, ax = plt.subplots(figsize=(10, 8))\n",
    "contours = ax.contour(w, b, expected_reward, levels=30, colors='black')\n",
    "ax.clabel(contours, inline=True, fontsize=8, fmt='%1.1f')\n",
    "#contour = ax.contourf(w, b, expected_reward, levels=50, cmap='viridis')\n",
    "#fig.colorbar(contour, ax=ax, label='Expected Reward')  # Add a colorbar to the plot\n",
    "\n",
    "slope = 3.38\n",
    "y_lim = ax.get_ylim()\n",
    "line_x = np.array(ax.get_xlim())  # Use the current x-axis limits for the line's x-values\n",
    "line_y = slope * line_x  # Calculate y-values based on the slope\n",
    "ax.plot(line_x, line_y, 'r--', label=f'Slope = {slope:.2f}')  # Plot the line\n",
    "ax.set_ylim(y_lim)  # Set the y-axis limits to the same as before\n",
    "ax.set_xlabel('Weight (w)')  # Set x-axis label\n",
    "ax.set_ylabel('Bias (b)')  # Set y-axis label\n",
    "ax.set_title('Reward Landscape')  # Set title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "So this tells us that there is a long (almost flat) ridge in the reward landscape roughly along the line $\\frac{b}{w} = 3.8$. In other words past a certain point it's really about the relative ratio of the $b$ and the $w$ values. This makes sense as it is the ratio of these two values that determines where the inflection point of the sigmoid is, and the relative magnitude of these paramters that determines the steepness of the transition from low to high probability as a function of the senory input signal, past a certain point there is little reward to be gained from making that transition steeper. Looking at this countour plot of the reward landscape can make us more confident that we have found, if not the best possible values for $w$ and $b$, something that is at least very close to them in terms of the total expected reward achieved. Twiddling the dials though is not a particularly scalable optimization solution, so now we are going to see how our propose and reject and our perturb-measure-step approaches work in this slightly more complex two dimensional problem. First though a quick detour looking at the details of how total expected reward, the qunatity we are using the evaluate parameter pairs $(w, b)$ is computed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "A critical enabler of being able to dial in good $w$ and $b$ parameter values was having quick feedback on the total expected reward given the parameter values. In the coding exercise below we go over a two different ways of computing this value and then compare their efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO for students: Complete the lines with ... to implement a parameter\n",
    "# evaluation function\n",
    "raise NotImplementedError(\"Exercise: parameter evaluation\")\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def np_sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def eval_params_slow(w, b, x, y):\n",
    "  \"\"\"\n",
    "  evaluates parameters of simple behaviour circuit given inputs and target\n",
    "  outputs, use for loops to think carefully about what we're doing\n",
    "  Args:\n",
    "    w: (scalar) weight between sensory and output neuron\n",
    "    b: (scalar) bias of behavioural output neuron\n",
    "    x: (1 np.array x batch) sensory input\n",
    "       (can be single input, mini-batch of inputs or the whole batch of inputs)\n",
    "    y: (1 np.array x batch) target behavioural output (can be a single target,\n",
    "       mini-batch of targets, or whole batch), needs to correspond to input\n",
    "\n",
    "  Returns:\n",
    "    R_bar: the average/expected reward obtained given the parameters, over the\n",
    "           (mini-)batch of inputs and targets. (mini-batch could be size 1)\n",
    "  \"\"\"\n",
    "  batch_len = x.shape[1]\n",
    "  h = np.zeros((1, batch_len))\n",
    "  y_hat = np.zeros((1, batch_len))\n",
    "  R_total = 0\n",
    "  for ii in range(batch_len):\n",
    "    h[0,ii] = ...\n",
    "    y_hat[0,ii] = np_sigmoid(...)\n",
    "    # y_hat is our probability of striking\n",
    "    # compute the expected score\n",
    "    if y[0,ii] == 1:\n",
    "      # supposed to strike\n",
    "      # with probability y_hat creature strikes and gets a point\n",
    "      R_total += y_hat[0,ii] * 1.0\n",
    "      # with probability 1-y_hat creature doesn't strike and gets zero points\n",
    "      R_total += (1-y_hat[0,ii]) * 0.0\n",
    "    elif y[0,ii] == 0:\n",
    "      # not supposed to strike\n",
    "      # with probability y_hat creature strikes and loses a point\n",
    "      R_total += y_hat[0,ii] * -1.0\n",
    "      # with probability 1-y_hat creature doesn't strike and gets zero points\n",
    "      R_total += (1-y_hat[0,ii]) * 0.0\n",
    "    else:\n",
    "      raise ValueError(f'Unexpected target: {y[ii,0]}')\n",
    "  R_avg = R_total / batch_len\n",
    "  return R_avg\n",
    "\n",
    "\n",
    "def eval_params(w, b, x, y):\n",
    "  \"\"\"\n",
    "  evaluates parameters of simple behaviour circuit given inputs and target\n",
    "  outputs, use numpy broadcasting to be fast and concise\n",
    "  Args:\n",
    "    w: (scalar) weight between sensory and output neuron\n",
    "    b: (scalar) bias of behavioural output neuron\n",
    "    x: (batch x 1 np.array) sensory input\n",
    "       (can be single input, mini-batch of inputs or the whole batch of inputs)\n",
    "    y: (batch x 1 np.array) target behavioural output (can be a single target,\n",
    "       mini-batch of targets, or whole batch), needs to correspond to input\n",
    "\n",
    "  Returns:\n",
    "    R_bar: the average/expected reward obtained given the parameters, over the\n",
    "           (mini-)batch of inputs and targets. (mini-batch could be size 1)\n",
    "  \"\"\"\n",
    "  h = w * x + b\n",
    "  y_hat = np_sigmoid(h)\n",
    "  y_score = np.copy(y)\n",
    "  y_score[y_score == 0] = -1\n",
    "  batch_expected_reward = y_score * y_hat\n",
    "  R_avg = np.mean(batch_expected_reward)\n",
    "  return R_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/dcownden/PerennialProblemsOfLifeWithABrain/tree/main//sequences/P2C1_Optimization/solutions/P2C1_Sequence2_Solution_d8158759.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In this exercise, we actually implemented the same function twice, once using a for loop to iterate over the (mini-)batch of inputs and targets, and once using NumPy broadcasting to compute the batch reward (roughly) in parallel. Run the following code cells to see what kind of computational efficiency this buys us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "X_simple_1_feature.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "eval_params_slow(1, 0, X_simple_1_feature.T, y1_simple.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "eval_params(1, 0, X_simple_1_feature.T, y1_simple.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "%timeit eval_params_slow(1, 0, X_simple_1_feature.T, y1_simple.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "%timeit eval_params(1, 0, X_simple_1_feature.T, y1_simple.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In our specific example (on the specific COLAB instance we're writing this on in 2024), the broadcasting approach in Python, using NumPy, is approximately 50 times faster than using for-loops. This is because for-loops in interpreted languages like Python incur significant overhead at each iteration, but also because potential dependencies between loop iterations limit parallelization. In contrast, broadcasting allows for vectorized operations, enabling parallel execution that can harness more of the underlying hardware's computational power. NumPy enhances this efficiency further by utilizing highly optimized, pre-compiled linear algebra libraries (primarily hardware-specific implementations of BLAS and LAPACK). The same principles apply (though are sometimes less critical) in compiled languages or with Just-In-Time (JIT) compilation frameworks like JAX. Broadcasting or tensor notation not only improves performance but also maintains code brevity and alignment with mathematical notation. As scientists and programmers, we do not need to understand every detail of how the magic of computational parallelism allows for fast linear algebra, but it is crucial to appreciate the potential impacts on computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "With that little detour into parallel computation done, let's get into using propose and reject to optimize our behaviour generating network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# 2.1.2.5 Propose and Reject for A Simple Neural Network\n",
    "\n",
    "Let's step through propose and reject for this simple network, using the widget below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Optimize a Simple Network with Propose and Reject\n",
    "# @markdown **Run this cell** to step through propose and reject optimization of our simple network.\n",
    "class Interactive2ParamANNProposeReject:\n",
    "  def __init__(self,\n",
    "               w_bounds=(9, 13),\n",
    "               b_bounds=(32, 44),\n",
    "               inputs=X_simple_1_feature,\n",
    "               labels=y1_simple,\n",
    "               step_size=0.2, seed=None):\n",
    "    self.w_bounds = w_bounds\n",
    "    self.b_bounds = b_bounds\n",
    "    self.strike_reward = 1\n",
    "    self.strike_cost = -1\n",
    "    self.non_strike_reward = 0\n",
    "    self.non_strike_cost = 0\n",
    "    self.inputs = inputs\n",
    "    self.labels = labels\n",
    "    self.step_size = step_size\n",
    "    self.rng = np.random.default_rng(seed)\n",
    "    self.current_w = 9.5\n",
    "    self.current_b = 36.0\n",
    "    self.current_r, _, _ = self.eval_function(self.current_w, self.current_b)\n",
    "    self.current_r = self.current_r[0,0]\n",
    "    self.proposed_w = None\n",
    "    self.proposed_b = None\n",
    "    self.proposed_r = None\n",
    "    self.w_history = []\n",
    "    self.b_history = []\n",
    "    self.r_history = []\n",
    "    self.rejected_w = []\n",
    "    self.rejected_b = []\n",
    "    self.total_proposals = 0\n",
    "    self.acceptance_count = 0\n",
    "    self.current_proposals = 0\n",
    "    self.fig, self.ax = plt.subplots(figsize=(6, 4))\n",
    "    self.propose = widgets.Button(description='Propose')\n",
    "    self.accept = widgets.Button(description='Accept', disabled=True)\n",
    "    self.reject = widgets.Button(description='Reject', disabled=True)\n",
    "    self.full_step = widgets.Button(description='Do It For Me', disabled=True)\n",
    "    self.take_10_steps = widgets.Button(description='Do 10 For Me', disabled=True)\n",
    "    self.keep_going = widgets.Button(description='Do It All For Me', disabled=True)\n",
    "    self.reset = widgets.Button(description='Reset')\n",
    "    self.show_history = widgets.Checkbox(value=True, description='Show History')\n",
    "    self.show_rejected = widgets.Checkbox(value=True, description='Show Rejected')\n",
    "    self.in_loop = False\n",
    "    self.init_plot()\n",
    "    self.narration_display = widgets.Output()\n",
    "    remove_ip_clutter(self.fig)\n",
    "    # Arrange widgets in a layout\n",
    "    buttons_layout = widgets.VBox([\n",
    "        widgets.HBox([self.propose, self.accept, self.reject]),\n",
    "        widgets.HBox([self.full_step, self.take_10_steps, self.keep_going]),\n",
    "        widgets.HBox([self.reset, self.show_history, self.show_rejected])])\n",
    "    buttons_and_narration = widgets.HBox([buttons_layout, self.narration_display])\n",
    "    self.ui = widgets.VBox([self.fig.canvas, buttons_and_narration])\n",
    "    #bind actions to handlers\n",
    "    self.propose.on_click(self.on_propose_clicked)\n",
    "    self.accept.on_click(self.on_accept_clicked)\n",
    "    self.reject.on_click(self.on_reject_clicked)\n",
    "    self.full_step.on_click(self.on_full_step_clicked)\n",
    "    self.take_10_steps.on_click(self.on_take_10_steps_clicked)\n",
    "    self.keep_going.on_click(self.on_keep_going_clicked)\n",
    "    self.reset.on_click(self.on_reset_clicked)\n",
    "    self.show_rejected.observe(self.on_show_rejected_toggled, 'value')\n",
    "    self.show_history.observe(self.on_show_history_toggled, 'value')\n",
    "\n",
    "  def init_plot(self):\n",
    "    \"\"\"Initialize the plot with placeholder data.\"\"\"\n",
    "    w_vals = np.linspace(self.w_bounds[0], self.w_bounds[1], 100)\n",
    "    b_vals = np.linspace(self.b_bounds[0], self.b_bounds[1], 100)\n",
    "    R, W, B = self.eval_function(w_vals, b_vals)\n",
    "    # Initial plot commands return line objects, keep references to them\n",
    "    self.contours = self.ax.contour(W, B, R, cmap='viridis')\n",
    "    self.point_current, = self.ax.plot([self.current_w], [self.current_b], 'bo', label='Current')\n",
    "    self.point_proposed, = self.ax.plot([], [], 'go', label='Proposed')  # Empty data to start\n",
    "    self.points_history, = self.ax.plot([], [], 'ks', alpha=0.5, label='History')  # Empty data to start\n",
    "    self.points_rejected, = self.ax.plot([], [], 'kx', label='Rejected')  # Empty data to start\n",
    "    self.ax.legend()\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "    alpha = 0.5 if self.show_rejected.value else 0\n",
    "    self.points_rejected.set_alpha(alpha)\n",
    "    self.ax.set_xlabel('w')\n",
    "    self.ax.set_ylabel('b')\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def eval_function (self, w, b,\n",
    "                     sc=None, sr=None, nsc=None, nsr=None):\n",
    "    sc = self.strike_cost if sc is None else sc\n",
    "    sr = self.strike_reward if sr is None else sr\n",
    "    nsc = self.non_strike_cost if nsc is None else nsc\n",
    "    nsr = self.non_strike_reward if nsr is None else nsr\n",
    "    inputs = self.inputs.flatten()[:, None, None].copy() # (n_bacth, 1, 1)\n",
    "    targets = self.labels.flatten() # (n_batch)\n",
    "    W, B = np.meshgrid(w, b) # (n_w, n_b)\n",
    "    outputs = W * inputs + B # (n_batch, n_w, n_b)\n",
    "    p_strike = sigmoid(outputs) # (n_batch, n_w, n_b)\n",
    "    p_no_strike = 1 - p_strike\n",
    "    should_did = np.sum(p_strike[targets == 1], axis=0)\n",
    "    should_but_did_not = np.sum(p_no_strike[targets == 1], axis=0)\n",
    "    should_not_did_not = np.sum(p_no_strike[targets == 0], axis=0)\n",
    "    should_not_but_did = np.sum(p_strike[targets == 0], axis=0)\n",
    "    expected_reward = (should_did * sr + should_not_but_did * sc +\n",
    "                       should_but_did_not * nsc + should_not_did_not * nsr)\n",
    "    return expected_reward, W, B\n",
    "\n",
    "  def on_propose_clicked(self, button):\n",
    "    self.total_proposals += 1\n",
    "    self.current_proposals += 1\n",
    "    perturbation_w, perturbation_b = self.rng.standard_normal(size=2) * self.step_size\n",
    "    self.proposed_w = self.current_w + perturbation_w\n",
    "    self.proposed_b = self.current_b + perturbation_b\n",
    "    self.proposed_r, _, _ = self.eval_function(self.proposed_w, self.proposed_b)\n",
    "    self.proposed_r = self.proposed_r[0,0]\n",
    "    self.point_proposed.set_data([self.proposed_w], [self.proposed_b])\n",
    "    with self.narration_display:\n",
    "      clear_output()\n",
    "      print(f'Proposed w: {self.proposed_w:.3f}, b: {self.proposed_b:.3f}, r: {self.proposed_r:.3f}.')\n",
    "      print(f' Current w: {self.current_w:.3f}, b: {self.current_b:.3f}, r: {self.current_r}')\n",
    "      print(\"Click 'Accept' or 'Reject' to accept or reject this proposed w,b\")\n",
    "      print(f'Proposals evaluated since last step: {self.current_proposals}')\n",
    "      print(f'Total number of proposals evaluated: {self.total_proposals}')\n",
    "      if self.acceptance_count > 0:\n",
    "        print(f'Average proposals per step: {self.total_proposals / self.acceptance_count:.3f}')\n",
    "    if not self.in_loop:\n",
    "      self.fig.canvas.draw()\n",
    "      self.accept.disabled = False\n",
    "      self.reject.disabled = False\n",
    "      self.propose.disabled = True\n",
    "      self.full_step.disabled = True\n",
    "      self.take_10_steps.disabled = True\n",
    "      self.keep_going.disabled = True\n",
    "\n",
    "  def on_accept_clicked(self, button):\n",
    "    self.acceptance_count += 1\n",
    "    self.current_proposals = 0\n",
    "    with self.narration_display:\n",
    "      clear_output()\n",
    "      print(f'Accepted w: {self.proposed_w:.3f}, b: {self.proposed_b:.3f}, reward: {self.proposed_r:.3f}.')\n",
    "      print(f\"Click 'Propose' or 'Do It For Me' to try a new value.\")\n",
    "      print(f'Proposals evaluated since last step: {self.current_proposals}')\n",
    "      print(f'Total number of proposals evaluated: {self.total_proposals}')\n",
    "      print(f'Total number of proposals accepted: {self.acceptance_count}')\n",
    "      print(f'Average evaluations per step taken: {self.total_proposals / self.acceptance_count:.3f}')\n",
    "    self.w_history.append(self.current_w)\n",
    "    self.b_history.append(self.current_b)\n",
    "    self.r_history.append(self.current_r)\n",
    "    self.current_w = self.proposed_w\n",
    "    self.current_b = self.proposed_b\n",
    "    self.current_r = self.proposed_r\n",
    "    self.proposed_w = None\n",
    "    self.proposed_b = None\n",
    "    self.proposed_r = None\n",
    "    self.rejected_w = []\n",
    "    self.rejected_b = []\n",
    "    self.point_current.set_data([self.current_w], [self.current_b])\n",
    "    self.points_history.set_data(self.w_history, self.b_history)\n",
    "    self.point_proposed.set_data([], [])\n",
    "    self.points_rejected.set_data([], [])\n",
    "    if not self.in_loop:\n",
    "      self.fig.canvas.draw()\n",
    "      self.accept.disabled = True\n",
    "      self.reject.disabled = True\n",
    "      self.propose.disabled = False\n",
    "      self.full_step.disabled = False\n",
    "      self.take_10_steps.disabled = False\n",
    "      self.keep_going.disabled = False\n",
    "\n",
    "  def on_reject_clicked(self, button):\n",
    "    self.rejected_w.append(self.proposed_w)\n",
    "    self.rejected_b.append(self.proposed_b)\n",
    "    with self.narration_display:\n",
    "      clear_output()\n",
    "      print(f'Rejected w: {self.proposed_w:.3f}, b: {self.proposed_b:.3f}, reward: {self.proposed_r:.3f}.')\n",
    "      print(f' Keeping w: {self.current_w:.3f}, b: {self.current_b:.3f}, reward: {self.current_r:.3f}.')\n",
    "      print(f\"Click 'Propose' or 'Do It For Me' to try a new value.\")\n",
    "      print(f'Proposals evaluated since last step: {self.current_proposals}')\n",
    "      print(f'Total number of proposals evaluated: {self.total_proposals}')\n",
    "      if self.acceptance_count > 0:\n",
    "        print(f'Average proposals per step: {self.total_proposals / self.acceptance_count:.3f}')\n",
    "    self.proposed_w = None\n",
    "    self.proposed_b = None\n",
    "    self.point_proposed.set_data([], [])\n",
    "    self.points_rejected.set_data(self.rejected_w, self.rejected_b)\n",
    "    if not self.in_loop:\n",
    "      self.fig.canvas.draw()\n",
    "      self.accept.disabled = True\n",
    "      self.reject.disabled = True\n",
    "      self.propose.disabled = False\n",
    "      self.full_step.disabled = False\n",
    "      self.take_10_steps.disabled = False\n",
    "      self.keep_going.disabled = False\n",
    "\n",
    "  def on_full_step_clicked(self, button):\n",
    "    # Automatically propose, accept if better, or reject\n",
    "    self.full_step.disabled = True\n",
    "    self.propose.disabled = True\n",
    "    self.accept.disabled = True\n",
    "    self.reject.disabled = True\n",
    "    self.keep_going.disabled = True\n",
    "    self.take_10_steps.disabled = True\n",
    "    self.on_propose_clicked(button)\n",
    "    if self.proposed_r > self.current_r:\n",
    "        self.on_accept_clicked(button)\n",
    "    else:\n",
    "        self.on_reject_clicked(button)\n",
    "    if not self.in_loop:\n",
    "      self.full_step.disabled = False\n",
    "      self.propose.disabled = False\n",
    "      self.take_10_steps.disabled = False\n",
    "      self.keep_going.disabled = False\n",
    "\n",
    "\n",
    "  def on_take_10_steps_clicked(self, button):\n",
    "    self.take_10_steps.disabled = True\n",
    "    self.propose.disabled = True\n",
    "    self.accept.disabled = True\n",
    "    self.reject.disabled = True\n",
    "    self.full_step.disabled = True\n",
    "    self.keep_going.disabled = True\n",
    "    self.in_loop = True\n",
    "    for _ in range(10):\n",
    "      self.on_full_step_clicked(button)\n",
    "      self.fig.canvas.draw()\n",
    "      time.sleep(0.6)\n",
    "    self.in_loop = False\n",
    "    self.take_10_steps.disabled = False\n",
    "    self.propose.disabled = False\n",
    "    self.full_step.disabled = False\n",
    "    self.keep_going.disabled = False\n",
    "\n",
    "  def on_keep_going_clicked(self, button):\n",
    "    self.take_10_steps.disabled = True\n",
    "    self.propose.disabled = True\n",
    "    self.accept.disabled = True\n",
    "    self.reject.disabled = True\n",
    "    self.full_step.disabled = True\n",
    "    self.keep_going.disabled = True\n",
    "    self.in_loop = True\n",
    "    while self.current_r < 556.9:\n",
    "      self.on_full_step_clicked(button)\n",
    "      self.fig.canvas.draw()\n",
    "      time.sleep(0.6)\n",
    "    self.in_loop = False\n",
    "    self.take_10_steps.disabled = False\n",
    "    self.propose.disabled = False\n",
    "    self.full_step.disabled = False\n",
    "    self.keep_going.disabled = False\n",
    "\n",
    "  def on_reset_clicked(self, button):\n",
    "    self.total_proposals = 0\n",
    "    self.acceptance_count = 0\n",
    "    self.current_proposals = 0\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Reset. Clearing history')\n",
    "      print(f'Generating a new curve for you to find the max of.')\n",
    "    self.current_w = self.rng.uniform(self.w_bounds[0], self.w_bounds[1])\n",
    "    self.current_b = self.rng.uniform(self.b_bounds[0], self.b_bounds[1])\n",
    "    self.current_r = self.eval_function(self.current_w, self.current_b)\n",
    "    self.proposed_w = None\n",
    "    self.proposed_b = None\n",
    "    self.proposed_r = None\n",
    "    self.w_history = []\n",
    "    self.b_history = []\n",
    "    self.r_history = []\n",
    "    self.accept.disabled = True\n",
    "    self.reject.disabled = True\n",
    "    self.propose.disabled = False\n",
    "    self.point_current.set_data([self.current_w], [self.current_b])\n",
    "    self.points_history.set_data(self.w_history, self.b_history)\n",
    "    self.point_proposed.set_data([], [])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_history_toggled(self, change):\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_rejected_toggled(self, change):\n",
    "    alpha = 0.5 if self.show_rejected.value else 0\n",
    "    self.points_rejected.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "i2pnnpr = Interactive2ParamANNProposeReject()\n",
    "display(i2pnnpr.fig.canvas)\n",
    "clear_output()\n",
    "display(i2pnnpr.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "So this makes good progress at first, requiring roughly two evaluations per step. But later on in the process as it comes time to ascend the flat narrow ridge in the reward-parameter landscape, many more evaluations are required before a lucky proposal is made in the, now much narrower, direction of improvement. Smaller step sizes will improve the acceptance rate, but will slow down progress per step taken because the steps are smaller! Now lets see how perturb-measure-step fares on this slightly more challenging shape (i.e. a narrow ridge as contrasted with a symmetric and nicely rounded bowl of a quadratic function.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# 2.1.2.6 Perturb-Measure-Step for a Simple Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Optimize a Simple Network with Perturb-Measure-Step\n",
    "# @markdown **Run this cell** to step through finding the best weight and bias parameters for a 2 parameter network governing strike-no-strike behaviour.\n",
    "class InteractiveWBSlopeStepper:\n",
    "  def __init__(self,\n",
    "               w_bounds=(9, 13),\n",
    "               b_bounds=(32, 44),\n",
    "               inputs=X_simple_1_feature,\n",
    "               labels=y1_simple,\n",
    "               step_size=0.01, seed=None):\n",
    "    # constants\n",
    "    self.w_bounds = w_bounds\n",
    "    self.b_bounds = b_bounds\n",
    "    self.strike_reward = 1\n",
    "    self.strike_cost = -1\n",
    "    self.non_strike_reward = 0\n",
    "    self.non_strike_cost = 0\n",
    "    self.inputs = inputs\n",
    "    self.labels = labels\n",
    "    self.rng = np.random.default_rng(seed)\n",
    "    self.step_size = step_size\n",
    "    # state\n",
    "    self.current_w = 9.75\n",
    "    self.current_b = 36.0\n",
    "    self.current_r, _, _ = self.eval_function(self.current_w, self.current_b)\n",
    "    self.current_r = self.current_r[0,0]\n",
    "    self.total_function_evaluations = 1\n",
    "    self.num_steps = 0\n",
    "    self.test_b, self.test_w, self.test_r = None, None, None\n",
    "    self.proposed_b, self.proposed_w, self.proposed_r = None, None, None\n",
    "    self.b_history, self.w_history, self.r_history = [], [], []\n",
    "    #buttons\n",
    "    self.rng = np.random.default_rng(seed)\n",
    "    self.perturb_w = widgets.Button(description='Perturb w')\n",
    "    self.measure_w = widgets.Button(description='Measure w', disabled=True)\n",
    "    self.step_w = widgets.Button(description='Step w', disabled=True)\n",
    "    self.perturb_b = widgets.Button(description='Perturb b')\n",
    "    self.measure_b = widgets.Button(description='Measure b', disabled=True)\n",
    "    self.step_b = widgets.Button(description='Step b', disabled=True)\n",
    "    self.full_step = widgets.Button(description='Do It For Me', disabled=True)\n",
    "    self.take_10_steps = widgets.Button(description='Do 10 For Me', disabled=True)\n",
    "    self.reset = widgets.Button(description='Reset')\n",
    "    self.show_history = widgets.Checkbox(value=True, description='Show History')\n",
    "    #bind buttons to action to handlers\n",
    "    self.perturb_w.on_click(self.on_perturb_clicked)\n",
    "    self.measure_w.on_click(self.on_measure_clicked)\n",
    "    self.step_w.on_click(self.on_step_clicked)\n",
    "    self.perturb_b.on_click(self.on_perturb_clicked)\n",
    "    self.measure_b.on_click(self.on_measure_clicked)\n",
    "    self.step_b.on_click(self.on_step_clicked)\n",
    "    self.full_step.on_click(self.on_full_step_clicked)\n",
    "    self.take_10_steps.on_click(self.on_take_10_steps_clicked)\n",
    "    self.reset.on_click(self.on_reset_clicked)\n",
    "    self.show_history.observe(self.on_show_history_toggled, 'value')\n",
    "    #ui setup\n",
    "    self.narration_display = widgets.Output()\n",
    "    self.init_plot()\n",
    "    #remove_ip_clutter(self.fig)\n",
    "    buttons_layout = widgets.VBox([\n",
    "      widgets.HBox([self.perturb_w, self.measure_w, self.step_w]),\n",
    "      widgets.HBox([self.perturb_b, self.measure_b, self.step_b]),\n",
    "      widgets.HBox([self.full_step, self.take_10_steps]),\n",
    "      widgets.HBox([self.reset, self.show_history])])\n",
    "    buttons_and_narration = widgets.HBox([buttons_layout, self.narration_display])\n",
    "    self.ui = widgets.VBox([self.fig.canvas, buttons_and_narration])\n",
    "\n",
    "  def eval_function (self, w, b,\n",
    "                     sc=None, sr=None, nsc=None, nsr=None):\n",
    "    sc = self.strike_cost if sc is None else sc\n",
    "    sr = self.strike_reward if sr is None else sr\n",
    "    nsc = self.non_strike_cost if nsc is None else nsc\n",
    "    nsr = self.non_strike_reward if nsr is None else nsr\n",
    "    inputs = self.inputs.flatten()[:, None, None].copy() # (n_bacth, 1, 1)\n",
    "    targets = self.labels.flatten() # (n_batch)\n",
    "    W, B = np.meshgrid(w, b) # (n_w, n_b)\n",
    "    outputs = W * inputs + B # (n_batch, n_w, n_b)\n",
    "    p_strike = sigmoid(outputs) # (n_batch, n_w, n_b)\n",
    "    p_no_strike = 1 - p_strike\n",
    "    should_did = np.sum(p_strike[targets == 1], axis=0)\n",
    "    should_but_did_not = np.sum(p_no_strike[targets == 1], axis=0)\n",
    "    should_not_did_not = np.sum(p_no_strike[targets == 0], axis=0)\n",
    "    should_not_but_did = np.sum(p_strike[targets == 0], axis=0)\n",
    "    expected_reward = (should_did * sr + should_not_but_did * sc +\n",
    "                       should_but_did_not * nsc + should_not_did_not * nsr)\n",
    "    return expected_reward, W, B\n",
    "\n",
    "  def init_plot(self):\n",
    "    self.fig, axs = plt.subplots(2, 2, figsize=(10, 8))\n",
    "    self.ax_c = axs[1, 0]  # Contour plot axis\n",
    "    self.ax_w = axs[0, 0]  # z(x), shares contour x-axis\n",
    "    self.ax_b = axs[1, 1]  # z(y), shares contour y-axis\n",
    "    self.ax_legend = axs[0, 1]  # Reserved for the legend\n",
    "    self.ax_w.sharex(self.ax_c)\n",
    "    self.ax_b.sharey(self.ax_c)\n",
    "    # Contour Plot\n",
    "    w_vals = np.linspace(self.w_bounds[0], self.w_bounds[1], 200)\n",
    "    b_vals = np.linspace(self.b_bounds[0], self.b_bounds[1], 200)\n",
    "    R, W, B = self.eval_function(w_vals, b_vals)\n",
    "    self.contours = self.ax_c.contour(W, B, R, cmap='viridis')\n",
    "    self.point_current, = self.ax_c.plot([self.current_w],\n",
    "        [self.current_b], 'bo', label='Current')\n",
    "    self.vline_current, = self.ax_c.plot([self.current_w, self.current_w],\n",
    "                                         self.b_bounds, 'k--', alpha=0.3)\n",
    "    self.hline_current, = self.ax_c.plot(self.w_bounds, [self.current_b, self.current_b],\n",
    "                                         'k--', alpha=0.3)\n",
    "    self.point_proposed, = self.ax_c.plot([], [], 'go',\n",
    "                                          label='Proposed')\n",
    "    self.points_history, = self.ax_c.plot([], [], 'ks', alpha=0.5,\n",
    "                                        label='History', markersize=4)\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "\n",
    "    #self.ax_x.set_xlabel('x')\n",
    "    self.ax_w.set_ylabel('Reward')\n",
    "    self.ax_c.set_ylabel('b')\n",
    "    self.ax_c.set_xlabel('w')\n",
    "    #self.ax_y.set_ylabel('y')\n",
    "    self.ax_b.set_xlabel('Reward')\n",
    "\n",
    "    # Adjust visibility of shared axis tick labels\n",
    "    plt.setp(self.ax_w.get_xticklabels(), visible=False)\n",
    "    plt.setp(self.ax_b.get_yticklabels(), visible=False)\n",
    "\n",
    "    # Initial empty plots for marginal plots; they will be updated dynamically\n",
    "    self.curve_r_of_w, = self.ax_w.plot([], [], 'r-', label='R(w) with b fixed')\n",
    "    self.curve_r_of_b, = self.ax_b.plot([], [], 'b-', label='R(b) with w fixed')\n",
    "    self.w_slope_line, = self.ax_w.plot([], [], 'g-')\n",
    "    self.b_slope_line, = self.ax_b.plot([], [], 'g-')\n",
    "    self.w_proposed_line, = self.ax_w.plot([], [], 'g--', alpha=0.5)\n",
    "    self.b_proposed_line, = self.ax_b.plot([], [], 'g--', alpha=0.5)\n",
    "    self.current_wr, = self.ax_w.plot([], [], 'bo')\n",
    "    self.current_br, = self.ax_b.plot([], [], 'bo')\n",
    "    self.test_w_point, = self.ax_w.plot([], [], 'rx')\n",
    "    self.test_b_point, = self.ax_b.plot([], [], 'rx', label='Test')\n",
    "    self.wr_proposed_point, = self.ax_w.plot([], [], 'go')\n",
    "    self.br_proposed_point, = self.ax_b.plot([], [], 'go')\n",
    "    self.update_r_of_w()\n",
    "    self.update_r_of_b()\n",
    "    self.ax_legend.axis('off')\n",
    "    handles, labels = [], []\n",
    "    for ax in [self.ax_c, self.ax_w, self.ax_b]:\n",
    "      for handle, label in zip(*ax.get_legend_handles_labels()):\n",
    "        handles.append(handle)\n",
    "        labels.append(label)\n",
    "    self.ax_legend.legend(handles, labels, loc='center')\n",
    "    plt.tight_layout()\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def update_r_of_w(self, fixed_b=None):\n",
    "    if fixed_b is None:\n",
    "      fixed_b = self.current_b\n",
    "    w_vals = np.linspace(self.w_bounds[0], self.w_bounds[1], 400)\n",
    "    r_vals, _, _ = self.eval_function(w_vals, fixed_b)\n",
    "    r_vals = r_vals.flatten()\n",
    "    self.curve_r_of_w.set_data(w_vals, r_vals)\n",
    "    self.current_wr.set_data([self.current_w], [self.current_r])\n",
    "    min_r, max_r = r_vals.min(), r_vals.max()\n",
    "    padding = (max_r - min_r) * 0.04\n",
    "    self.ax_w.set_ylim(min_r, max_r + padding)\n",
    "\n",
    "  def update_r_of_b(self, fixed_w=None):\n",
    "    if fixed_w is None:\n",
    "      fixed_w = self.current_w\n",
    "    b_vals = np.linspace(self.b_bounds[0], self.b_bounds[1], 400)\n",
    "    r_vals, _, _ = self.eval_function(fixed_w, b_vals)\n",
    "    r_vals = r_vals.flatten()\n",
    "    self.curve_r_of_b.set_data(r_vals, b_vals)\n",
    "    self.current_br.set_data([self.current_r], [self.current_b])\n",
    "    min_r, max_r = r_vals.min(), r_vals.max()\n",
    "    padding = (max_r - min_r) * 0.04\n",
    "    self.ax_b.set_xlim(min_r, max_r + padding)\n",
    "\n",
    "  def update_measure_w(self):\n",
    "    rise = self.test_r - self.current_r\n",
    "    run = self.test_w - self.current_w\n",
    "    self.w_slope = rise / run\n",
    "    self.wr_intercept = self.current_r - self.w_slope * self.current_w\n",
    "    w_vals = np.linspace(self.w_bounds[0], self.w_bounds[1], 400)\n",
    "    r_vals = self.w_slope * w_vals + self.wr_intercept\n",
    "    self.w_slope_line.set_data(w_vals, r_vals)\n",
    "    self.proposed_w = self.current_w + self.step_size * self.w_slope\n",
    "    self.step_wr = self.wr_intercept + self.w_slope * self.proposed_w\n",
    "    self.wr_proposed_point.set_data([self.proposed_w], [self.step_wr])\n",
    "    r_min, r_max = self.ax_w.get_ylim()\n",
    "    self.w_proposed_line.set_data([self.proposed_w, self.proposed_w], [r_min, r_max])\n",
    "    if self.proposed_b is None:\n",
    "      self.point_proposed.set_data([self.proposed_w], [self.current_b])\n",
    "    else:\n",
    "      self.point_proposed.set_data([self.proposed_w], [self.proposed_b])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def update_measure_b(self):\n",
    "    rise = self.test_r - self.current_r\n",
    "    run = self.test_b - self.current_b\n",
    "    self.b_slope = rise / run\n",
    "    self.br_intercept = self.current_r - self.b_slope * self.current_b\n",
    "    b_vals = np.linspace(self.b_bounds[0], self.b_bounds[1], 400)\n",
    "    r_vals = self.b_slope * b_vals + self.br_intercept\n",
    "    self.b_slope_line.set_data(r_vals, b_vals)\n",
    "    self.proposed_b = self.current_b + self.step_size * self.b_slope\n",
    "    self.step_br = self.br_intercept + self.b_slope * self.proposed_b\n",
    "    self.br_proposed_point.set_data([self.step_br], [self.proposed_b])\n",
    "    r_min, r_max = self.ax_b.get_xlim()\n",
    "    self.b_proposed_line.set_data([r_min, r_max], [self.proposed_b, self.proposed_b])\n",
    "    if self.proposed_w is None:\n",
    "      self.point_proposed.set_data([self.current_w], [self.proposed_b])\n",
    "    else:\n",
    "      self.point_proposed.set_data([self.proposed_w], [self.proposed_b])\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_perturb_clicked(self, button, axis=None):\n",
    "    # are we perturbing x or y use axis or infer from button description\n",
    "    if axis is None:\n",
    "      if button.description == 'Perturb w':\n",
    "        axis = 'w'\n",
    "      elif button.description == 'Perturb b':\n",
    "        axis = 'b'\n",
    "      else:\n",
    "        raise ValueError(\"Invalid button description, expected 'Perturb w' or 'Perturb b'\")\n",
    "    if axis == 'w':\n",
    "      self.test_w = self.current_w + self.step_size\n",
    "      self.test_b = self.current_b\n",
    "    elif axis == 'b':\n",
    "      self.test_b = self.current_b + self.step_size\n",
    "      self.test_w = self.current_w\n",
    "    else:\n",
    "      raise ValueError(\"Invalid axis, expected 'w' or 'b'\")\n",
    "    # calculate test value\n",
    "    self.test_r, _, _ = self.eval_function(self.test_w, self.test_b)\n",
    "    self.test_r = self.test_r[0,0]\n",
    "    self.total_function_evaluations += 1\n",
    "    if axis == 'w':\n",
    "      self.test_w_point.set_data([self.test_w], [self.test_r])\n",
    "      self.measure_w.disabled = False\n",
    "      self.perturb_w.disabled = True\n",
    "      self.perturb_b.disabled = True\n",
    "    elif axis == 'b':\n",
    "      self.test_b_point.set_data([self.test_r], [self.test_b])\n",
    "      self.measure_b.disabled = False\n",
    "      self.perturb_b.disabled = True\n",
    "      self.perturb_w.disabled = True\n",
    "    self.fig.canvas.draw_idle()\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Test point: w = {self.test_w:.3f}, b = {self.test_b:.3f}, reward = {self.test_r:.3f}.')\n",
    "      print(f\"Click 'Measure' to propose a new {axis} value based on this test point.\")\n",
    "\n",
    "  def on_measure_clicked(self, button, axis=None):\n",
    "    if axis is None:\n",
    "      if button.description == 'Measure w':\n",
    "        axis = 'w'\n",
    "      elif button.description == 'Measure b':\n",
    "        axis = 'b'\n",
    "      else:\n",
    "        raise ValueError(\"Invalid button description, expected 'Measure w' or 'Measure b'\")\n",
    "    if axis == 'w':\n",
    "      self.update_measure_w()\n",
    "      with self.narration_display:\n",
    "        clear_output(wait=True)\n",
    "        print(f'Based on measurement of w slope, proposed w step from {self.current_w:.3f} to {self.proposed_w:.3f}')\n",
    "        print(\"Click 'Step w', to make the step.\")\n",
    "      self.step_w.disabled = False\n",
    "      self.measure_w.disabled = True\n",
    "    else: # axis == 'y':\n",
    "      self.update_measure_b()\n",
    "      with self.narration_display:\n",
    "        clear_output(wait=True)\n",
    "        print(f'Based on measurement of b slope, proposed b step from {self.current_b:.3f} to {self.proposed_b:.3f}')\n",
    "        print(\"Click 'Step b', to make the step.\")\n",
    "        self.step_b.disabled = False\n",
    "        self.measure_b.disabled = True\n",
    "\n",
    "  def on_step_clicked(self, button):\n",
    "    self.num_steps += 1\n",
    "    if self.proposed_w is None and self.proposed_b is None:\n",
    "      raise ValueError(\"At least one of proposed w and b values must be set before stepping.\")\n",
    "    if self.proposed_w is None:\n",
    "      self.proposed_w = self.current_w\n",
    "    if self.proposed_b is None:\n",
    "      self.proposed_b = self.current_b\n",
    "    new_r, _, _ = self.eval_function(self.proposed_w, self.proposed_b)\n",
    "    new_r = new_r[0,0]\n",
    "    self.total_function_evaluations += 1\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Stepped to w = {self.proposed_w:.3f}, b = {self.proposed_b:.3f}, reward = {new_r:.3f}.')\n",
    "      print(f\"Click 'Propose' or 'Do It For Me' to try a new value.\")\n",
    "      print(f'Total function evaluations so far: {self.total_function_evaluations}')\n",
    "      print(f'Total number of steps taken so far: {self.num_steps}')\n",
    "    self.w_history.append(self.current_w)\n",
    "    self.b_history.append(self.current_b)\n",
    "    self.r_history.append(self.current_r)\n",
    "    self.points_history.set_data(self.w_history, self.b_history)\n",
    "    self.current_w = self.proposed_w\n",
    "    self.current_b = self.proposed_b\n",
    "    self.current_r = new_r\n",
    "    self.point_current.set_data([self.current_w], [self.current_b])\n",
    "    self.vline_current.set_data([self.current_w, self.current_w], self.b_bounds)\n",
    "    self.hline_current.set_data(self.w_bounds, [self.current_b, self.current_b])\n",
    "    self.test_w, self.test_b, self.test_r = None, None, None\n",
    "    self.test_w_point.set_data([], [])\n",
    "    self.test_b_point.set_data([], [])\n",
    "    self.proposed_w, self.proposed_b, self.proposed_r = None, None, None\n",
    "    self.w_proposed_line.set_data([], [])\n",
    "    self.b_proposed_line.set_data([], [])\n",
    "    self.br_proposed_point.set_data([], [])\n",
    "    self.wr_proposed_point.set_data([], [])\n",
    "    self.point_proposed.set_data([], [])\n",
    "    self.w_slope_line.set_data([], [])\n",
    "    self.b_slope_line.set_data([], [])\n",
    "    self.update_r_of_w()\n",
    "    self.update_r_of_b()\n",
    "    self.fig.canvas.draw_idle()\n",
    "    self.step_w.disabled = True\n",
    "    self.step_b.disabled = True\n",
    "    self.perturb_w.disabled = False\n",
    "    self.perturb_b.disabled = False\n",
    "    self.full_step.disabled = False\n",
    "    self.take_10_steps.disabled = False\n",
    "\n",
    "  def on_full_step_clicked(self, button):\n",
    "    self.on_perturb_clicked(button, axis='w')\n",
    "    self.on_measure_clicked(button, axis='w')\n",
    "    self.on_step_clicked(button)\n",
    "    self.on_perturb_clicked(button, axis='b')\n",
    "    self.on_measure_clicked(button, axis='b')\n",
    "    self.on_step_clicked(button)\n",
    "\n",
    "  def on_take_10_steps_clicked(self, button):\n",
    "    for _ in range(10):\n",
    "      self.on_full_step_clicked(button)\n",
    "\n",
    "  def on_reset_clicked(self, button):\n",
    "    self.proposals_evaluated = 0\n",
    "    with self.narration_display:\n",
    "      clear_output(wait=True)\n",
    "      print(f'Reset. Clearing history')\n",
    "      print(f'Randomizing initial w and b values.')\n",
    "    self.current_w = self.rng.uniform(self.w_bounds[0], self.w_bounds[1])\n",
    "    self.current_b = self.rng.uniform(self.b_bounds[0], self.b_bounds[1])\n",
    "    current_r, _, _ = self.eval_function(self.current_w, self.current_b)\n",
    "    self.current_r = current_r[0,0]\n",
    "    self.point_current.set_data([self.current_w], [self.current_b])\n",
    "    self.vline_current.set_data([self.current_w, self.current_w], self.b_bounds)\n",
    "    self.hline_current.set_data(self.w_bounds, [self.current_b, self.current_b])\n",
    "    self.test_w, self.test_b, self.test_r = None, None, None\n",
    "    self.test_w_point.set_data([], [])\n",
    "    self.test_b_point.set_data([], [])\n",
    "    self.proposed_w, self.proposed_b, self.proposed_r = None, None, None\n",
    "    self.w_proposed_line.set_data([], [])\n",
    "    self.b_proposed_line.set_data([], [])\n",
    "    self.br_proposed_point.set_data([], [])\n",
    "    self.wr_proposed_point.set_data([], [])\n",
    "    self.point_proposed.set_data([], [])\n",
    "    self.w_slope_line.set_data([], [])\n",
    "    self.b_slope_line.set_data([], [])\n",
    "    self.w_history, self.b_history, self.r_history = [], [], []\n",
    "    self.points_history.set_data([], [])\n",
    "    self.update_r_of_w()\n",
    "    self.update_r_of_b()\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_curve_toggled(self, change):\n",
    "    alpha = 1 if self.show_curve.value else 0\n",
    "    self.line_polynomial.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "  def on_show_history_toggled(self, change):\n",
    "    alpha = 0.5 if self.show_history.value else 0\n",
    "    self.points_history.set_alpha(alpha)\n",
    "    self.fig.canvas.draw_idle()\n",
    "\n",
    "\n",
    "iwbss = InteractiveWBSlopeStepper()\n",
    "display(iwbss.fig.canvas)\n",
    "clear_output()\n",
    "display(iwbss.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "So this isn't really much better than propose and reject. Like propose and reject there is rapid progress early on, but once the process reaches the flatish narrow ridge of the reward-parameter landscape, improvement slows down. Now, notably there is not much improvement to be had here. The optimal threshold achieves a score of 557, and this process finds a parameter configuration with reward very close to this optimal value relatively quickly. Scale really matters. How important is the difference between 557 and 556.709 in terms of the fitness of the organism. If this is neglibable, getting close is good enough, if this is the difference between life and death then getting close is not enough from an evolutionary perspective. Without further context we can't say much about whether this learning algorithm is quick enough or not. This is the kind of context we will slowly develop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_M5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown **Run this cell** to take the quiz\n",
    "comprehension_quiz = [\n",
    "  {\n",
    "    \"question\": \"How does the complexity of a neural circuit (number of parameters) impact the number of learning iterations and hence time to learn using a 'measure and update' learning process?\",\n",
    "    \"type\": \"multiple_choice\",\n",
    "    \"answers\": [\n",
    "      {\n",
    "        \"answer\": \"It does not affect the number of iterations required; the process scales well regardless of circuit complexity.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Actually, the the number of iterations required grows with the complexity of the circuit due to more parameters requiring optimization.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"The process requires few learning iterations, by leveraging algorithmic economies of scale\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Contrary to this, an increase in parameters leads the more learning iterations being required.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"The process becomes requires more learning episodes for larger, more complex circuits.\",\n",
    "        \"correct\": True,\n",
    "        \"feedback\": \"Correct! More parameters mean more complexity and thus more learning episodes are needed.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"The number of learning iterations needed is solely dependent on the type of learning task, not the circuit complexity.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Circuit complexity, particularly the number of parameters, plays a significant role in the number of learning iterations needed.\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Why was the introduction of a 'hidden layer' beneficial in our complex discrimination tasks?\",\n",
    "    \"type\": \"multiple_choice\",\n",
    "    \"answers\": [\n",
    "      {\n",
    "        \"answer\": \"It allowed the model to perform tasks more quickly but with reduced accuracy.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"The hidden layer's primary benefit is not speed at the cost of accuracy, but rather an enhancement in handling complex patterns.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It introduces feature interactions and non-linearities, enabling the model to capture complex patterns.\",\n",
    "        \"correct\": True,\n",
    "        \"feedback\": \"Exactly! Hidden layers allow for complex interactions and non-linear processing of features, which can be crucial for generating behaviour contingent on rich sensory input.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It reduces the number of parameters needed, simplifying the model.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Adding a hidden layer typically increases the number of parameters, adding complexity to the model.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It primarily improves the model's visualization, making it easier to interpret.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"While interpretability is important, this is not an advantage of adding a hidden layer.\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"In the context of machine learning, what is the impact of using a 'mini-batch' approach?\",\n",
    "    \"type\": \"multiple_choice\",\n",
    "    \"answers\": [\n",
    "      {\n",
    "        \"answer\": \"It guarantees a 10x speedup in learning algorithms.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"While mini-batches can speed up learning, the magnitude of this speed-up will depend on choice of mini-batch size and the interaction of this size with underlying algorithmic efficiencies of scale at the hardware implementation level.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It reduces the time for evaluations by using a smaller, representative data sample.\",\n",
    "        \"correct\": True,\n",
    "        \"feedback\": \"Correct! A mini-batch approach uses a smaller subset of data for quicker evaluations, though it introduces some noise to the estimates.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It decreases the accuracy of parameter evaluation\",\n",
    "        \"correct\": True,\n",
    "        \"feedback\": \"Correct! Mini-batches do introduce some noise to parameter evaluation, but is used thoughtfully this usually isn't an issue.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It eliminates the need for parameter updates in the learning process.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Mini-batches still require parameter updates; they just alter the way data is processed during learning.\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What challenge arises when comparing different machine learning algorithms?\",\n",
    "    \"type\": \"multiple_choice\",\n",
    "    \"answers\": [\n",
    "      {\n",
    "        \"answer\": \"Algorithms cannot be compared due to their differing objectives.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"While objectives can vary, this doesn't make comparison impossible; it's more about how different parameters and conditions affect performance.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"All algorithms perform similarly when given the same data and task.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Performance can vary significantly between algorithms depending on their design and the specificities of the task and data.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"Performance is highly dependent on meta-parameter choices, making direct comparisons challenging.\",\n",
    "        \"correct\": True,\n",
    "        \"feedback\": \"Variations in learning rate, perturbation scale, mini-batch size, and other meta-parameters can significantly impact algorithm performance, complicating direct comparisons.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"Algorithms' performance cannot be measured or quantified.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Performance can indeed be measured and quantified, but the challenge lies in accounting for differences in meta-parameters and conditions.\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\n",
    "display_quiz(comprehension_quiz)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "P2C1_Sequence2",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
