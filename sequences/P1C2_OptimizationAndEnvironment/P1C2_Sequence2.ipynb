{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcownden/PerennialProblemsOfLifeWithABrain/blob/P1C2_S2/sequences/P1C2_OptimizationAndEnvironment/P1C2_Sequence2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "oTAt41vK5MKf"
      },
      "source": [
        "The following is a fifth test for an upcoming text book on computational neuroscience from an optimization/learning perspective. The book will start with evolution because ultimately, all aspects of the brain are shaped by evolution and, as we will see, evolution can also be seen as a learning algorithm. We are sharing it now to get feedback on what works and what does not and the developments we should do.\n",
        "\n",
        "# **Part 1 Behaviour, Environments and Optimization: Evolution and Learning**\n",
        "\n",
        "### **Animals are adapted to their specific environments; their behaviour is best understood within the context of their evolutionary environment.**\n",
        "\n",
        "### Objective: Part 1 of the book aims to introduce the fundamental concepts of\n",
        "* **environment**, the (statistical) properties of where an organism lives\n",
        "* **behaviour**, the statistics of what the organism does\n",
        "* **optimization**, how learning and evolution shape an organism's behaviour to make it better suited to its environment\n",
        "\n",
        "This very much is the core of why we are writing this book: we can view pretty much anything happening in the brain (and biology) as being part of a process that brings about improvement in this sense."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "90Oxmk7r5MKk"
      },
      "source": [
        "___\n",
        "# Chapter 1.2 Optimizing Behaviour - Environment is Central\n",
        "\n",
        "### Objective: In the previous chapter we learned to describe and think about behaviour as a policy and to evaluate an organism's behaviour relative to the goals implied by the organism's environmental niche. In this next chapter we are going to really focus on ***Optimization***, different ways of making a policy better, different ways an organism might become better suited to its niche.\n",
        "\n",
        "You will learn:\n",
        "*   How to formally define an objective function. In the last chapter our policy goals were loosely stated as 'eat lots of food'. In this chapter we will better formalize goals, eventually using mathematic and the Markov Decision Process framework, so that these goals can directly guide policy improvement.\n",
        "*   Different optimization methods. There are many different methods for modifying a policy to improve its performance, and we will begin to explore several of these (guess and check, grid search,  propose and test, evolutionary algorithms).\n",
        "*   How evolutionary processes - selection applied to variation in population - are a form of optimization.\n",
        "*   How competition and interaction complicate optimization. Optimization in a strict sense does not directly apply to situations with multiple interacting organisms, each with their own goals that they are simultaneously optimizing for. Ideas from Game Theory and dynamical systems are required to do multi-organism 'optimization' the right way.\n",
        "*   The conditions where competition and interaction 'average out' and a naive optimization perspective is appropriate. As we will see, for neural systems, a naive optimization perspective, without the complications of Game Theory, is often sufficient."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "dcvCGTYA5MKm"
      },
      "source": [
        "___\n",
        "# **Sequence 1.2.2: What's good depends on the niche**\n",
        "\n",
        "### Objective: In this sequence we will see how what is good policy in one environmental context may not be such a good policy in another environmental context. We will continue to use our 'Parameterized Weights' policy in a solo Gridworld environment, but now we will see what happens when the rules of Gridworld change slightly. What happens to policy effectiveness, can re-optimization help? In this sequence you will:\n",
        "* See how a policy well suited to one environment can utterly fail in a new environment.\n",
        "* Apply our propose and reject optimization procedure in this new environment\n",
        "* Implement a more complex policy with a larger perceptive field and an awareness of the edges of Gridworld.\n",
        "* See how our propose and reject optimization procedure can be used to update policy parameters in a changing environment.\n",
        "\n",
        "Here we focus on how an optimization process can be used to continuously adapt a policy to a changing environment."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Picture of a simplified foodweb giving a simplified description of the policy that each organism is running. Driving home that policy depends on niche. This is a placeholder image from wikipedia.\n",
        "![Placeholder Food Web](https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/P1C2_S2/sequences/Art/1920px-TrophicWeb.jpg)"
      ],
      "metadata": {
        "id": "Sh0-wVl9qEyc"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "atcgH_iC5MKo"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Run the following cell to setup and install the various dependencies and helper functions for this sequence."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {},
        "id": "0ByL7ig45MKp",
        "outputId": "07402637-db69-4edc-a2a1-f5e86877adad",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "cellView": "form"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed 2021 has been set.\n",
            "This notebook isn't using and doesn't need a GPU. Good.\n",
            "Running in colab\n"
          ]
        }
      ],
      "source": [
        "# @title Dependencies, Imports and Setup\n",
        "# @markdown You don't need to worry about how this code works â€“ but you do need to **run the cell**\n",
        "\n",
        "!pip install ipympl vibecheck datatops jupyterquiz > /dev/null 2> /dev/null #google.colab\n",
        "\n",
        "import requests\n",
        "import numpy as np\n",
        "import itertools\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from copy import copy\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.stats import norm\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tabulate import tabulate\n",
        "from IPython.display import display, clear_output, Markdown\n",
        "from jupyterquiz import display_quiz\n",
        "from vibecheck import DatatopsContentReviewContainer\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "# random seed settings and\n",
        "# getting torch to use gpu if it's there\n",
        "\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  \"\"\"\n",
        "  Function that controls randomness. NumPy and random modules must be imported.\n",
        "\n",
        "  Args:\n",
        "    seed : Integer\n",
        "      A non-negative integer that defines the random state. Default is `None`.\n",
        "    seed_torch : Boolean\n",
        "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
        "      must be imported. Default is `True`.\n",
        "\n",
        "  Returns:\n",
        "    Nothing.\n",
        "  \"\"\"\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "  \"\"\"\n",
        "  DataLoader will reseed workers following randomness in\n",
        "  multi-process data loading algorithm.\n",
        "\n",
        "  Args:\n",
        "    worker_id: integer\n",
        "      ID of subprocess to seed. 0 means that\n",
        "      the data will be loaded in the main process\n",
        "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def set_device():\n",
        "  \"\"\"\n",
        "  Set the device. CUDA if available, CPU otherwise\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"This notebook isn't using and doesn't need a GPU. Good.\")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook but not needed.\")\n",
        "    print(\"If possible, in the menu under `Runtime` -> \")\n",
        "    print(\"`Change runtime type.`  select `CPU`\")\n",
        "\n",
        "  return device\n",
        "\n",
        "\n",
        "SEED = 2021\n",
        "set_seed(seed=SEED)\n",
        "DEVICE = set_device()\n",
        "\n",
        "\n",
        "def printmd(string):\n",
        "  display(Markdown(string))\n",
        "\n",
        "\n",
        "# the different utility .py files used in this notebook\n",
        "filenames = ['gw_plotting.py', 'gw_board.py', 'gw_game.py',\n",
        "             'gw_widgets.py', 'gw_NN_RL.py']\n",
        "#filenames = []\n",
        "# just run the code straight out of the response, no local copies needed!\n",
        "for filename in filenames:\n",
        "  url = f'https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/utils/{filename}'\n",
        "  response = requests.get(url)\n",
        "  # Check that we got a valid response\n",
        "  if response.status_code == 200:\n",
        "    code = response.content.decode()\n",
        "    exec(code)\n",
        "  else:\n",
        "    print(f'Failed to download {url}')\n",
        "\n",
        "# environment contingent imports\n",
        "try:\n",
        "  print('Running in colab')\n",
        "  from google.colab import output\n",
        "  output.enable_custom_widget_manager()\n",
        "  #from google.colab import output as colab_output\n",
        "  #colab_output.enable_custom_widget_manager()\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "  print('Not running in colab')\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib widget\n",
        "plt.style.use(\"https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/pplb.mplstyle\")\n",
        "plt.ioff() #need to use plt.show() or display explicitly\n",
        "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)\n",
        "\n",
        "\n",
        "def content_review(notebook_section: str):\n",
        "  return DatatopsContentReviewContainer(\n",
        "    \"\",  # No text prompt\n",
        "    notebook_section,\n",
        "    {\n",
        "      \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
        "      \"name\": \"neuro_book\",\n",
        "      \"user_key\": \"xuk960xj\",\n",
        "    },\n",
        "  ).render()\n",
        "feedback_prefix = \"P1C2_S2\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################################################\n",
        "# refactor Monte Carlo for boards that support multiple critters\n",
        "################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MonteCarlo():\n",
        "  \"\"\"\n",
        "  Implementation of Monte Carlo Algorithm\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, game, nnet, default_depth=5, random_seed=None):\n",
        "    \"\"\"\n",
        "    Initialize Monte Carlo Parameters\n",
        "\n",
        "    Args:\n",
        "      game: Gridworld Game instance\n",
        "        Instance of the gridworldGame class above;\n",
        "      nnet: gridworldNet instance\n",
        "        Instance of the gridworldNNet class above;\n",
        "      args: dictionary\n",
        "        Instantiates number of iterations and episodes, controls temperature threshold, queue length,\n",
        "        arena, checkpointing, and neural network parameters:\n",
        "        learning-rate: 0.001, dropout: 0.3, epochs: 10, batch_size: 64,\n",
        "        num_channels: 512\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    self.game = game\n",
        "    self.nnet = nnet\n",
        "    self.default_depth = default_depth\n",
        "    self.rng = np.random.default_rng(seed=random_seed)\n",
        "\n",
        "\n",
        "  def pis_vs_from_board(self, board, critter):\n",
        "    #helper function, to put board in canonical form that nn was trained on\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    co_pieces = board['pieces'].copy()\n",
        "    this_critter_locs = np.where(co_pieces == critter)\n",
        "    all_critter_locs = np.where(co_pieces >= 1)\n",
        "    # other critters are invisible to this player\n",
        "    co_pieces[all_critter_locs] = 0\n",
        "    # nnet trained to see self as 1\n",
        "    co_pieces[this_critter_locs] = 1\n",
        "    scalar_rounds_left = board['rounds_left'][0]\n",
        "    co_rounds_left = scalar_rounds_left // self.game.num_critters\n",
        "    if critter-1 < scalar_rounds_left % self.game.num_critters:\n",
        "       # add an extra if we haven't had this players turn yet in the round cycle\n",
        "       co_rounds_left = co_rounds_left + 1\n",
        "    co_rounds_left = np.array([co_rounds_left]*batch_size)\n",
        "    pis, vs = self.nnet.predict(co_pieces,\n",
        "                                board['scores'][:,critter-1],\n",
        "                                co_rounds_left)\n",
        "    return pis, vs\n",
        "\n",
        "\n",
        "  def simulate(self, board, actions, action_indexes, critter=1, depth=None):\n",
        "    \"\"\"\n",
        "    Helper function to simulate one Monte Carlo rollout\n",
        "\n",
        "    Args:\n",
        "      board: triple (batch_size x x_size x y_size np.array of board position,\n",
        "                     scalar of current score,\n",
        "                     scalar of rounds left\n",
        "      actions: batch size list/array of integer indexes for moves on each board\n",
        "      these are assumed to be legal, no check for validity of moves\n",
        "    Returns:\n",
        "      temp_v:\n",
        "        Terminal State\n",
        "    \"\"\"\n",
        "    batch_size, x_size, y_size = board['pieces'].shape\n",
        "    next_board = self.game.get_next_state(board, critter,\n",
        "                                          actions, action_indexes)\n",
        "    # in this version of the mc player, the existence of other players is\n",
        "    # ignored, in another version of mc other players moves might be simulated\n",
        "    next_board['active_player'] = critter-1\n",
        "\n",
        "    if depth is None:\n",
        "      depth = self.default_depth\n",
        "    # potentially expand the game tree here,\n",
        "    # but just do straight rollouts after this\n",
        "    # doesn't expand to deal with all random food generation possibilities\n",
        "    # just expands based on the actions given\n",
        "    expand_bs, _, _ = next_board['pieces'].shape\n",
        "\n",
        "    for i in range(depth):  # maxDepth\n",
        "      if next_board['rounds_left'][0] <= 0:\n",
        "        # check that game isn't over\n",
        "        # assumes all boards have the same rounds left\n",
        "        # no rounds left return scores as true values\n",
        "        terminal_vs = next_board['scores'][:,critter-1].copy()\n",
        "        return terminal_vs\n",
        "      else:\n",
        "        #pis, vs = self.nnet.predict(next_board['pieces'], next_board['scores'], next_board['rounds_left'])\n",
        "        pis, vs = self.pis_vs_from_board(next_board, critter)\n",
        "        valids = self.game.get_valid_actions(next_board, critter)\n",
        "        masked_pis = pis * valids\n",
        "        sum_pis = np.sum(masked_pis, axis=1)\n",
        "        probs = np.array(\n",
        "            [masked_pi / masked_pi.sum() if masked_pi.sum() > 0\n",
        "             else valid / valid.sum()\n",
        "             for valid, masked_pi in zip(valids, masked_pis)])\n",
        "        samp = self.rng.uniform(size = expand_bs).reshape((expand_bs,1))\n",
        "        sampled_actions = np.argmax(probs.cumsum(axis=1) > samp, axis=1)\n",
        "      next_board = self.game.get_next_state(next_board, critter,\n",
        "                                            sampled_actions)\n",
        "      # in this version of the mc player, existence of other players is ignored\n",
        "      # in another better version other players moves might be simulated, either\n",
        "      # as copies of self, or as distinct environmental dynamics\n",
        "      next_board['active_player'] = critter-1\n",
        "\n",
        "\n",
        "    pis, vs = self.pis_vs_from_board(next_board, critter)\n",
        "    #pis, vs = self.nnet.predict(next_board['pieces'], next_board['scores'],\n",
        "    #                            next_board['rounds_left'])\n",
        "    #print(vs.shape)\n",
        "    return vs\n",
        "\n",
        "\n",
        "\n",
        "# @title plotting functions\n",
        "#################################################\n",
        "# More plotting functions\n",
        "#################################################\n",
        "\n",
        "\n",
        "def plot_directions(fig, ax, loc_prob_dict, critter, deterministic=False,\n",
        "                    name=None):\n",
        "  \"\"\"\n",
        "  Plot vector field indicating critter direction probabilities.\n",
        "\n",
        "  Args:\n",
        "    fig, ax (matplotlib objects): Figure and axes objects for plotting.\n",
        "    loc_prob_dict (dict): Dictionary with keys as (row, col) location tuples\n",
        "      and values as lists of direction probabilities corresponding to the\n",
        "      directions ['right', 'down', 'left', 'up'].\n",
        "    critter (int): Identifier for which critter directions are associated with.\n",
        "    deterministic (bool, optional): If True, the probabilities array is\n",
        "      converted to 1-hot, and the arrows are plotted at the center of the cell\n",
        "      and are larger. Defaults to False.\n",
        "  \"\"\"\n",
        "\n",
        "  #looks like direction ignores inverted axis\n",
        "  direction_vectors = {'right': (1, 0), 'down': (0, -1),\n",
        "                       'left': (-1, 0), 'up': (0, 1)}\n",
        "  # but offsets need to be aware of inverted\n",
        "  direction_offsets = {'right': (0.1, 0), 'down': (0, 0.1),\n",
        "                       'left': (-0.1, 0), 'up': (0, -0.1)}\n",
        "  # Offsets for each critter type 1 and 2 to be used together, 0 by itself\n",
        "  critter_offsets = {0: (0, 0), 1: (-0.05, -0.05), 2: (0.05, 0.05)}\n",
        "  # same logic for colors\n",
        "  critter_colors = {0: 'black', 1: 'red', 2: 'blue'}\n",
        "  # Get the offset and color for this critter\n",
        "  critter_offset = critter_offsets[critter]\n",
        "  critter_color = critter_colors[critter]\n",
        "\n",
        "  # Add legend only if critter is not 0\n",
        "  custom_leg_handles = []\n",
        "  if critter != 0:\n",
        "    if name is None:\n",
        "      name = f'Critter {critter}'\n",
        "    legend_patch = mpatches.Patch(color=critter_color, label=name)\n",
        "    # Add the legend for this critter\n",
        "    custom_leg_handles.append(legend_patch)\n",
        "\n",
        "  C, R, U, V, A = [], [], [], [], []\n",
        "\n",
        "  for loc in loc_prob_dict.keys():\n",
        "    row, col = loc\n",
        "    probs = loc_prob_dict[loc]\n",
        "    for dir_key, prob in probs.items():\n",
        "      C.append(col + critter_offset[0] + direction_offsets[dir_key][0])\n",
        "      R.append(row + critter_offset[1] + direction_offsets[dir_key][1])\n",
        "      U.append(direction_vectors[dir_key][0])\n",
        "      V.append(direction_vectors[dir_key][1])\n",
        "\n",
        "      if deterministic:\n",
        "        A.append(1 if prob == max(probs.values()) else 0)\n",
        "      else:\n",
        "        A.append(prob)\n",
        "\n",
        "  linewidth = 1.5 if deterministic else 0.5\n",
        "  scale = 15 if deterministic else 30\n",
        "\n",
        "  ax.quiver(C, R, U, V, alpha=A, color=critter_color,\n",
        "            scale=scale, linewidth=linewidth)\n",
        "  return fig, ax, custom_leg_handles\n",
        "\n",
        "def make_grid(num_rows, num_cols, figsize=(7,6), title=None):\n",
        "  \"\"\"Plots an n_rows by n_cols grid with cells centered on integer indices and\n",
        "  returns fig and ax handles for futher use\n",
        "  Args:\n",
        "    num_rows (int): number of rows in the grid (vertical dimension)\n",
        "    num_cols (int): number of cols in the grid (horizontal dimension)\n",
        "\n",
        "  Returns:\n",
        "    fig (matplotlib.figure.Figure): figure handle for the grid\n",
        "    ax: (matplotlib.axes._axes.Axes): axes handle for the grid\n",
        "  \"\"\"\n",
        "  # Create a new figure and axes with given figsize\n",
        "  fig, ax = plt.subplots(figsize=figsize, layout='constrained')\n",
        "  # Set width and height padding, remove horizontal and vertical spacing\n",
        "  fig.get_layout_engine().set(w_pad=4 / 72, h_pad=4 / 72, hspace=0, wspace=0)\n",
        "  # Show right and top borders (spines) of the plot\n",
        "  ax.spines[['right', 'top']].set_visible(True)\n",
        "  # Set major ticks (where grid lines will be) on x and y axes\n",
        "  ax.set_xticks(np.arange(0, num_cols, 1))\n",
        "  ax.set_yticks(np.arange(0, num_rows, 1))\n",
        "  # Set labels for major ticks with font size of 8\n",
        "  ax.set_xticklabels(np.arange(0, num_cols, 1),fontsize=8)\n",
        "  ax.set_yticklabels(np.arange(0, num_rows, 1),fontsize=8)\n",
        "  # Set minor ticks (no grid lines here) to be between major ticks\n",
        "  ax.set_xticks(np.arange(0.5, num_cols-0.5, 1), minor=True)\n",
        "  ax.set_yticks(np.arange(0.5, num_rows-0.5, 1), minor=True)\n",
        "  # Move x-axis ticks to the top of the plot\n",
        "  ax.xaxis.tick_top()\n",
        "  # Set grid lines based on minor ticks, make them grey, dashed, and half transparent\n",
        "  ax.grid(which='minor', color='grey', linestyle='-', linewidth=2, alpha=0.5)\n",
        "  # Remove minor ticks (not the grid lines)\n",
        "  ax.tick_params(which='minor', bottom=False, left=False)\n",
        "  # Set limits of x and y axes\n",
        "  ax.set_xlim(( -0.5, num_cols-0.5))\n",
        "  ax.set_ylim(( -0.5, num_rows-0.5))\n",
        "  # Invert y axis direction\n",
        "  ax.invert_yaxis()\n",
        "  # If title is provided, set it as the figure title\n",
        "  if title is not None:\n",
        "    fig.suptitle(title)\n",
        "  # Hide header and footer, disable toolbar and resizing of the figure\n",
        "  fig.canvas.header_visible = False\n",
        "  fig.canvas.toolbar_visible = False\n",
        "  fig.canvas.resizable = False\n",
        "  fig.canvas.footer_visible = False\n",
        "  # Redraw the figure with these settings\n",
        "  fig.canvas.draw()\n",
        "  # Return figure and axes handles for further customization\n",
        "  return fig, ax\n",
        "\n",
        "\n",
        "def plot_food(fig, ax, rc_food_loc, food=None):\n",
        "  \"\"\"\n",
        "  Plots \"food\" on a grid implied by the given fig, ax arguments\n",
        "\n",
        "  Args:\n",
        "    fig, ax: matplotlib figure and axes objects\n",
        "    rc_food_loc: ndarry(int) of shape (N:num_food x 2:row,col)\n",
        "    food: a handle for the existing food matplotlib PatchCollenction object\n",
        "    if one exists\n",
        "  Returns:\n",
        "    a handle for matplotlib PathCollection object of food scatter plot, either\n",
        "    new if no handle was passed or updated if it was\n",
        "  \"\"\"\n",
        "  # if no PathCollection handle passed in:\n",
        "  if food is None:\n",
        "    food = ax.scatter([], [], s=150, marker='o', color='red', label='Food')\n",
        "  rc_food_loc = np.array(rc_food_loc, dtype=int)\n",
        "  #matrix indexing convention is is [row-vertical, col-horizontal]\n",
        "  #plotting indexing convention is (x-horizontal,y-vertical), hence flip\n",
        "  food.set_offsets(np.fliplr(rc_food_loc))\n",
        "  return food\n",
        "\n",
        "\n",
        "def plot_critters(fig, ax, critter_specs: List[Dict[str, object]]) -> List[Dict[str, object]]:\n",
        "  \"\"\"\n",
        "  Plots multiple types of \"critters\" on a grid implied by the given\n",
        "  fig, ax arguments.\n",
        "\n",
        "  Args:\n",
        "    fig, ax: matplotlib figure and axes objects.\n",
        "    critter_specs: List of dictionaries with keys 'location', 'name', 'color',\n",
        "    'marker', 'int_id', 'rc_critter_loc' and optionally 'handle' for each\n",
        "    critter.\n",
        "\n",
        "  Returns:\n",
        "    Updated critter_specs with handles.\n",
        "  \"\"\"\n",
        "  for spec in critter_specs:\n",
        "    # Ensure required keys are present\n",
        "    for key in ['marker', 'color', 'name', 'rc_loc']:\n",
        "      if key not in spec:\n",
        "        raise ValueError(f\"Key '{key}' missing in critter spec.\")\n",
        "    handle_ = spec.get('handle')\n",
        "    if handle_ is None:\n",
        "      handle_ = ax.scatter([], [], s=250, marker=spec['marker'],\n",
        "                           color=spec['color'], label=spec['name'])\n",
        "    handle_.set_offsets(np.flip(spec['rc_loc']))\n",
        "    spec.update({'handle': handle_})\n",
        "  return critter_specs\n",
        "\n",
        "\n",
        "def plot_critter(fig, ax, rc_critter_loc,\n",
        "                 critter=None, critter_name='Critter'):\n",
        "  \"\"\"\n",
        "  Plots \"critter\" on a grid implied by the given fig, ax arguments\n",
        "\n",
        "  Args:\n",
        "    fig, ax: matplotlib figure and axes objects\n",
        "    rc_critter_loc: ndarry(int) of shape (N:num_critters x 2:row,col)\n",
        "    critter: a handle for the existing food matplotlib PatchCollenction object\n",
        "    if one exists\n",
        "  Returns:\n",
        "    a handle for matplotlib PathCollection object of critter scatter plot,\n",
        "    either new if no handle was passed in or updated if it was.\n",
        "  \"\"\"\n",
        "  if critter is None:\n",
        "    critter = ax.scatter([], [], s=250, marker='h',\n",
        "                         color='blue', label=critter_name)\n",
        "  # matrix indexing convention is is [row-vertical, col-horizontal]\n",
        "  # plotting indexing convention is (x-horizontal,y-vertical), hence flip\n",
        "  critter.set_offsets(np.flip(rc_critter_loc))\n",
        "  return critter\n",
        "\n",
        "\n",
        "def plot_fov(fig, ax, rc_critter, n_rows, n_cols, radius, has_fov, fov=None):\n",
        "  \"\"\"\n",
        "  Plots a mask on a grid implied by the given fig, ax arguments\n",
        "\n",
        "  Args:\n",
        "    fig, ax: matplotlib figure and axes objects\n",
        "    rc_critter: ndarry(int) (row,col) of the critter\n",
        "    mask: a handle for the existing mask matplotlib Image object if one exists\n",
        "  Returns:\n",
        "    a handle for matplotlib Image object of mask, either new if no handle\n",
        "    was passed in or updated if it was.\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize mask as a semi-transparent overlay for the entire grid\n",
        "  mask_array = np.ones((n_rows, n_cols, 4))\n",
        "  mask_array[:, :, :3] = 0.5  # light grey color\n",
        "  if has_fov == True:\n",
        "    mask_array[:, :, 3] = 0.5  # 50% opacity\n",
        "    # Create arrays representing the row and column indices\n",
        "    rows = np.arange(n_rows)[:, np.newaxis]\n",
        "    cols = np.arange(n_cols)[np.newaxis, :]\n",
        "    # Iterate over each critter location\n",
        "    dist = np.abs(rows - rc_critter[0]) + np.abs(cols - rc_critter[1])\n",
        "    # Set the region within the specified radius around the critter to transparent\n",
        "    mask_array[dist <= radius, 3] = 0\n",
        "  else:\n",
        "    mask_array[:, :, 3] = 0\n",
        "\n",
        "  if fov is None:\n",
        "    fov = ax.imshow(mask_array, origin='lower', zorder=2)\n",
        "  else:\n",
        "    fov.set_data(mask_array)\n",
        "\n",
        "  return fov\n",
        "\n",
        "\n",
        "def remove_ip_clutter(fig):\n",
        "  fig.canvas.header_visible = False\n",
        "  fig.canvas.toolbar_visible = False\n",
        "  fig.canvas.resizable = False\n",
        "  fig.canvas.footer_visible = False\n",
        "  fig.canvas.draw()\n",
        "\n",
        "\n",
        "\n",
        "#\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title GridworldBoard class\n",
        "#######################################################################\n",
        "# extend GridworldGame class locally before integrating in shared utils\n",
        "#######################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class GridworldBoard():\n",
        "  \"\"\"\n",
        "  A collection methods and parameters of a gridworld game board that\n",
        "  define the logic of the game, and allows for multiple critters on the same\n",
        "  board\n",
        "\n",
        "  board state is represented by primarily by pieces, score, and rounds left\n",
        "  pieces is a batch x n_rows x n_cols numpy array positive integers are critter\n",
        "  locations 0's are empty space and -1's are food.\n",
        "\n",
        "  For pieces first dim is batch, second dim row , third is col,\n",
        "  so pieces[0][1][7] is the square in row 2, in column 8 of the first board in\n",
        "  the batch of boards.\n",
        "\n",
        "  scores is a batchsize x num_critters numpy array giving the scores for each\n",
        "  critter on each board in the batch (note off by one indexing)\n",
        "\n",
        "  rounds_left is how many rounds are left in the game.\n",
        "\n",
        "  active_player keeps track of which players turn it is\n",
        "\n",
        "  Note:\n",
        "    In 2d np.array first dim is row (vertical), second dim is col (horizontal),\n",
        "    i.e. top left corner is (0,0), so take care when visualizing/plotting\n",
        "    as np.array visualization inline with typical tensor notation but at odds\n",
        "    with conventional plotting where (0,0) is bottom left, first dim, x, is\n",
        "    horizontal, second dim, y, is vertical\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, batch_size=1,\n",
        "               n_rows=7, n_cols=7,\n",
        "               num_critters=2, num_food=10,\n",
        "               lifetime=30, rng = None):\n",
        "    \"\"\"Set the parameters of the game.\"\"\"\n",
        "    self.n_rows = n_rows\n",
        "    self.n_cols = n_cols\n",
        "    self.batch_size = batch_size\n",
        "    self.num_critters = num_critters\n",
        "    self.num_food = num_food\n",
        "    self.lifetime = lifetime\n",
        "    if rng is None:\n",
        "      self.rng = np.random.default_rng(seed=SEED)\n",
        "    else:\n",
        "      self.rng = rng\n",
        "\n",
        "\n",
        "  def init_loc(self, n_rows, n_cols, num, rng=None):\n",
        "    \"\"\"\n",
        "    Samples random 2d grid locations without replacement\n",
        "\n",
        "    Args:\n",
        "      n_rows: int, number of rows in the grid\n",
        "      n_cols: int, number of columns in the grid\n",
        "      num:    int, number of samples to generate. Should throw an error if num > n_rows x n_cols\n",
        "      rng:    instance of numpy.random's default rng. Used for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "      int_loc: ndarray(int) of shape (num,), flat indices for a 2D grid flattened into 1D\n",
        "      rc_index: tuple(ndarray(int), ndarray(int)), a pair of arrays with the first giving\n",
        "        the row indices and the second giving the col indices. Useful for indexing into\n",
        "        an n_rows by n_cols numpy array.\n",
        "      rc_plotting: ndarray(int) of shape (num, 2), 2D coordinates suitable for matplotlib plotting\n",
        "    \"\"\"\n",
        "\n",
        "    # Set up default random generator, use the boards default if none explicitly given\n",
        "    if rng is None:\n",
        "      rng = self.rng\n",
        "    # Choose 'num' unique random indices from a flat 1D array of size n_rows*n_cols\n",
        "    int_loc = rng.choice(n_rows * n_cols, num, replace=False)\n",
        "    # Convert the flat indices to 2D indices based on the original shape (n_rows, n_cols)\n",
        "    rc_index = np.unravel_index(int_loc, (n_rows, n_cols))\n",
        "    # Transpose indices to get num x 2 array for easy plotting with matplotlib\n",
        "    rc_plotting = np.array(rc_index).T\n",
        "    # Return 1D flat indices, 2D indices for numpy array indexing and 2D indices for plotting\n",
        "    return int_loc, rc_index, rc_plotting\n",
        "\n",
        "\n",
        "  def get_init_board_state(self):\n",
        "    \"\"\"Set up starting board using game parameters\"\"\"\n",
        "    #set rounds_left and score\n",
        "    self.rounds_left = (np.ones(self.batch_size) *\n",
        "                        self.lifetime * self.num_critters)\n",
        "    # each players move counts down the clock so making this a multiple of the\n",
        "    # number of critters ensures every player gets an equal number of turns\n",
        "    self.scores = np.zeros((self.batch_size, self.num_critters))\n",
        "    # create an empty board array.\n",
        "    self.pieces = np.zeros((self.batch_size, self.n_rows, self.n_cols))\n",
        "    # Place critter and initial food items on the board randomly\n",
        "    for ii in np.arange(self.batch_size):\n",
        "      # num_food+num_critter because we want critter and food locations\n",
        "      int_loc, rc_idx, rc_plot = self.init_loc(\n",
        "        self.n_rows, self.n_cols, self.num_food+self.num_critters)\n",
        "      # critter random start locations\n",
        "      for c_ in np.arange(self.num_critters):\n",
        "        self.pieces[(ii, rc_idx[0][c_], rc_idx[1][c_])] = c_ + 1\n",
        "      # food random start locations\n",
        "      self.pieces[(ii, rc_idx[0][self.num_critters:],\n",
        "                   rc_idx[1][self.num_critters:])] = -1\n",
        "    self.active_player = 0\n",
        "    state = {'pieces': self.pieces.copy(),\n",
        "             'scores': self.scores.copy(),\n",
        "             'rounds_left': self.rounds_left.copy(),\n",
        "             'active_player': copy(self.active_player)}\n",
        "    return state\n",
        "\n",
        "\n",
        "  def set_state(self, board):\n",
        "    \"\"\" board is dictionary giving game state a triple of np arrays\n",
        "      pieces:        numpy array (batch_size x n_rows x n_cols),\n",
        "      scores:        numpy array (batch_size x num_critters)\n",
        "      rounds_left:   numpy array (batch_size)\n",
        "      active_player: int\n",
        "    \"\"\"\n",
        "    self.pieces = board['pieces'].copy()\n",
        "    self.scores = board['scores'].copy()\n",
        "    self.rounds_left = board['rounds_left'].copy()\n",
        "    self.active_player = copy(board['active_player'])\n",
        "\n",
        "\n",
        "  def get_state(self):\n",
        "    \"\"\" returns a board state, which is a triple of np arrays\n",
        "    pieces,       - batch_size x n_rows x n_cols\n",
        "    scores,       - batch_size\n",
        "    rounds_left   - batch_size\n",
        "    \"\"\"\n",
        "    state = {'pieces': self.pieces.copy(),\n",
        "             'scores': self.scores.copy(),\n",
        "             'rounds_left': self.rounds_left.copy(),\n",
        "             'active_player': copy(self.active_player)}\n",
        "    return state\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.pieces[index]\n",
        "\n",
        "\n",
        "  def execute_moves(self, moves, critter):\n",
        "    \"\"\"\n",
        "    Updates the state of the board given the moves made.\n",
        "\n",
        "    Args:\n",
        "      moves: a 3-tuple of 1-d arrays each of length batch_size,\n",
        "        the first array gives the specific board within the batch,\n",
        "        the second array in the tuple gives the new row coord for each critter\n",
        "        on each board and the third gives the new col coord.\n",
        "\n",
        "    Notes:\n",
        "      Assumes that there is exactly one valid move for each board in the\n",
        "      batch of boards for the critter type given. i.e. it does't check for\n",
        "      bounce/reflection on edges or with other critters, or for multiple move\n",
        "      made on the same board. It only checks for eating food and adds new food\n",
        "      when appropriate. Invalid moves could lead to illegal teleporting\n",
        "      behavior, critter duplication, or index out of range errors.\n",
        "\n",
        "      Currently just prints a message if critter making the move is not the\n",
        "      active player, could enforce this more strictly if needed.\n",
        "    \"\"\"\n",
        "    if critter-1 != self.active_player:\n",
        "      # note critter is [1 to num_critter] inclusive so that it can be used\n",
        "      # directly in where statements on pieces but self.active_player is\n",
        "      # [0 to numcritter-1] inclusive so that it can be used directly in\n",
        "      # indexing player lists\n",
        "      raise ValueError(\"Warning! The critter moving is not the expected active player\")\n",
        "    #critters leave their spots\n",
        "    self.pieces[self.pieces==critter] = 0\n",
        "    #which critters have food in their new spots\n",
        "    eats_food = self.pieces[moves] == -1\n",
        "    # some critters eat and their scores go up\n",
        "    # note critter is +int so need to -1 for indexing\n",
        "    self.scores[:,critter-1] = self.scores[:,critter-1] + eats_food\n",
        "\n",
        "    num_empty_after_eat = (self.n_rows*self.n_cols - self.num_food -\n",
        "                           self.num_critters + 1) # +1 for the food just eaten\n",
        "    # which boards in the batch had eating happen\n",
        "    g_eating = np.where(eats_food)[0]\n",
        "    # put critters in new positions\n",
        "    self.pieces[moves] = critter\n",
        "    if np.any(eats_food):\n",
        "      # add random food to replace what is eaten\n",
        "      possible_new_locs = np.where(np.logical_and(\n",
        "          self.pieces == 0, #the spot is empty\n",
        "          eats_food.reshape(self.batch_size, 1, 1))) #food eaten on that board\n",
        "      food_sample_ = self.rng.choice(num_empty_after_eat,\n",
        "                                     size=np.sum(eats_food))\n",
        "      food_sample = food_sample_ + np.arange(len(g_eating))*num_empty_after_eat\n",
        "      assert np.all(self.pieces[(possible_new_locs[0][food_sample],\n",
        "                                 possible_new_locs[1][food_sample],\n",
        "                                 possible_new_locs[2][food_sample])] == 0)\n",
        "      #put new food on the board\n",
        "      self.pieces[(possible_new_locs[0][food_sample],\n",
        "                   possible_new_locs[1][food_sample],\n",
        "                   possible_new_locs[2][food_sample])] = -1\n",
        "    self.rounds_left = self.rounds_left - 1\n",
        "    if not np.all(self.pieces.sum(axis=(1,2)) ==\n",
        "                  ((self.num_food * -1) + np.sum(np.arange(self.num_critters)+1))):\n",
        "      print(self.pieces.sum(axis=(1,2)))\n",
        "      print(((self.num_food * -1) + np.sum(np.arange(self.num_critters)+1)))\n",
        "    assert np.all(self.pieces.sum(axis=(1,2)) ==\n",
        "                  ((self.num_food * -1) + np.sum(np.arange(self.num_critters)+1)))\n",
        "    # next player's turn\n",
        "    self.active_player = (self.active_player + 1) % (self.num_critters)\n",
        "\n",
        "\n",
        "  def execute_drift(self, offset_probs, wrapping=False):\n",
        "    \"\"\"\n",
        "    Drift the food on the board based on the given offsets probabilities.\n",
        "    Collisions handled by checking possible new locations in a random order and\n",
        "    cancelling moves that result in a collision.\n",
        "\n",
        "    Parameters:\n",
        "    - offset_probs: Probabilities corresponding to each offset, note implicit\n",
        "    oreder dependence here\n",
        "\n",
        "\n",
        "    Returns:\n",
        "    - nothing, just updates self.peices\n",
        "    \"\"\"\n",
        "    # Check the length of offset_probs\n",
        "    #if len(offset_probs) != 5:\n",
        "    #    raise ValueError(\"offset_probs should be of length 5.\")\n",
        "    # Check if values are non-negative\n",
        "    #if any(p < 0 for p in offset_probs):\n",
        "    #    raise ValueError(\"All probabilities in offset_probs should be non-negative.\")\n",
        "    # Normalize the probabilities\n",
        "    #offset_probs = np.array(offset_probs) / np.sum(offset_probs)\n",
        "    # Convert offsets to a 2D numpy array\n",
        "    possible_offsets = np.array([[ 0, -1,  0], # up\n",
        "                                 [ 0,  1,  0], # down\n",
        "                                 [ 0,  0, -1], # left\n",
        "                                 [ 0,  0,  1], # right\n",
        "                                 [ 0,  0,  0]]) # still\n",
        "    batch_size, n_rows, n_cols = self.pieces.shape\n",
        "    # original food locations\n",
        "    food_locations = np.argwhere(self.pieces == -1)\n",
        "    # Sample offsets for each food location\n",
        "    num_food = food_locations.shape[0]\n",
        "    sampled_offsets = possible_offsets[self.rng.choice(\n",
        "        np.arange(possible_offsets.shape[0]),\n",
        "        size=num_food, replace=True, p=offset_probs)]\n",
        "    # Possible new food locations\n",
        "    possible_new_locations = food_locations + sampled_offsets\n",
        "    possible_wrap_row_indexes = self.rng.choice(np.arange(n_rows),\n",
        "                                                size=num_food)\n",
        "    possible_wrap_col_indexes = self.rng.choice(np.arange(n_cols),\n",
        "                                                size=num_food)\n",
        "\n",
        "    # Randomly iterate through the possible new locations\n",
        "    random_order = np.random.permutation(num_food)\n",
        "    for idx in random_order:\n",
        "      g, r, c = possible_new_locations[idx]\n",
        "      # Check if the new location is inside the boundaries of the board\n",
        "      if 0 <= r < self.pieces.shape[1] and 0 <= c < self.pieces.shape[2]:\n",
        "        # Check if the new location is empty or contains a critter\n",
        "        if self.pieces[g, r, c] == 0:\n",
        "          # Update the board\n",
        "          old_g, old_r, old_c = food_locations[idx]\n",
        "          self.pieces[g, r, c] = -1\n",
        "          self.pieces[old_g, old_r, old_c] = 0\n",
        "      elif wrapping == True:\n",
        "        # If wrapping is on then food can drift off the edge of the board and\n",
        "        # 'new' food will apear in a random loc on the opposite side\n",
        "        # Determine the opposite edge\n",
        "        if r < 0:  # Top edge\n",
        "          opposite_r = n_rows - 1\n",
        "          opposite_c = possible_wrap_col_indexes[idx]\n",
        "        elif r >= n_rows:  # Bottom edge\n",
        "          opposite_r = 0\n",
        "          opposite_c = possible_wrap_col_indexes[idx]\n",
        "        elif c < 0:  # Left edge\n",
        "          opposite_c = n_cols - 1\n",
        "          opposite_r = possible_wrap_row_indexes[idx]\n",
        "        elif c >= n_cols:  # Right edge\n",
        "          opposite_c = 0\n",
        "          opposite_r = possible_wrap_row_indexes[idx]\n",
        "\n",
        "        # Check if the opposite location is unoccupied\n",
        "        if self.pieces[g, opposite_r, opposite_c] == 0:\n",
        "          old_g, old_r, old_c = food_locations[idx]\n",
        "          self.pieces[g, opposite_r, opposite_c] = -1\n",
        "          self.pieces[old_g, old_r, old_c] = 0\n",
        "\n",
        "\n",
        "  def get_legal_moves(self, critter):\n",
        "    \"\"\"\n",
        "    Identifies all legal moves for the critter, taking into acount\n",
        "    bouncing/reflection at edges,\n",
        "\n",
        "    Returns:\n",
        "      A numpy int array of size batch x 3(g,x,y) x 4(possible moves)\n",
        "\n",
        "    Note:\n",
        "      moves[0,1,3] is the x coordinate of the move corresponding to the\n",
        "      fourth offstet on the first board.\n",
        "      moves[1,:,1] will give the g,x,y triple corresponding to the\n",
        "      move on the second board and the second offset, actions are integers\n",
        "    \"\"\"\n",
        "    # can only move one cell down, up, right, and left from current location\n",
        "    critter_locs = np.array(np.where(self.pieces == critter))\n",
        "    legal_offsets = np.stack([\n",
        "      critter_locs + np.array([np.array([0,  1, 0])]*self.batch_size).T,\n",
        "      critter_locs + np.array([np.array([0, -1, 0])]*self.batch_size).T,\n",
        "      critter_locs + np.array([np.array([0, 0,  1])]*self.batch_size).T,\n",
        "      critter_locs + np.array([np.array([0, 0, -1])]*self.batch_size).T])\n",
        "    legal_offsets = np.vstack(np.transpose(legal_offsets, (0, 2, 1)))\n",
        "    legal_offsets = set([tuple(m_) for m_ in legal_offsets])\n",
        "    # must land on the board and not on another critter\n",
        "    legal_destinations = np.where(self.pieces <= 0)\n",
        "    legal_destinations = set([(g, r, c) for\n",
        "                              g, r, c in zip(*legal_destinations)])\n",
        "    # legal moves satisfy both these conditions\n",
        "    legal_moves = legal_offsets.intersection(legal_destinations)\n",
        "    return legal_moves\n",
        "\n",
        "\n",
        "  def get_perceptions(self, radius, critter):\n",
        "    \"\"\"\n",
        "    Generates a vector representation of the critter perceptions, oriented\n",
        "    around the critter.\n",
        "\n",
        "    Args:\n",
        "      radius: int, how many grid squared the critter can see around it\n",
        "        using L1  (Manhattan/cityblock) distance\n",
        "\n",
        "    Returns:\n",
        "      A batch_size x 2*radius*(radius+1) + 1, giving the values\n",
        "      of the percept reading left to right, top to bottom over the board,\n",
        "      for each board in the batch\n",
        "    \"\"\"\n",
        "    # define the L1 ball mask\n",
        "    diameter = radius*2+1\n",
        "    mask = np.zeros((diameter, diameter), dtype=bool)\n",
        "    mask_coords = np.array([(i-radius, j-radius)\n",
        "      for i in range(diameter)\n",
        "        for j in range(diameter)])\n",
        "    mask_distances = cdist(mask_coords, [[0, 0]],\n",
        "                           'cityblock').reshape(mask.shape)\n",
        "    mask[mask_distances <= radius] = True\n",
        "    mask[radius,radius] = False  # exclude the center\n",
        "\n",
        "    # pad the array\n",
        "    padded_arr = np.pad(self.pieces, ((0, 0), (radius, radius),\n",
        "     (radius, radius)), constant_values=-2)\n",
        "\n",
        "    # get locations of critters\n",
        "    critter_locs = np.argwhere(padded_arr == critter)\n",
        "\n",
        "    percepts = []\n",
        "    for critter_loc in critter_locs:\n",
        "      b, r, c = critter_loc\n",
        "      surrounding = padded_arr[b, r-radius:r+radius+1, c-radius:c+radius+1]\n",
        "      percept = surrounding[mask]\n",
        "      percepts.append(percept)\n",
        "    return(np.array(percepts))"
      ],
      "metadata": {
        "id": "aWUSuJjttX3H",
        "cellView": "form"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title GridworldGame class\n",
        "#######################################################################\n",
        "# extend GridworldGame class locally before integrating in shared utils\n",
        "#######################################################################\n",
        "\n",
        "\n",
        "\n",
        "class GridworldGame():\n",
        "  \"\"\"\n",
        "  A collection methods and parameters of a gridworld game that allow\n",
        "  for interaction with and display of GridwordlBoard objects.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, batch_size=1, n_rows=7, n_cols=7,\n",
        "               num_critters=2, num_food=10,\n",
        "               lifetime=30, rng=None, drift_probs=None,\n",
        "               wrapping=False, drift_after_move=False):\n",
        "    \"\"\"\n",
        "    Initializes an instance of the class with the specified parameters.\n",
        "\n",
        "    Args:\n",
        "      batch_size (int, optional): Number of instances in a batch. Default is 1.\n",
        "      n_rows (int, optional): Number of rows in the grid. Default is 7.\n",
        "      n_cols (int, optional): Number of columns in the grid. Default is 7.\n",
        "      num_critters (int, optional): Number of different agents running around\n",
        "        on each board in the batch. Default is 2.\n",
        "      num_food (int, optional): Number of food items. Default is 10.\n",
        "      lifetime (int, optional): Time before critter's life ends, in terms of\n",
        "        time steps. Default is 30.\n",
        "      rng (numpy random number generator, optional): Random number generator\n",
        "        for reproducibility. If None, uses default RNG with a preset seed.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check for positive integer inputs\n",
        "    assert all(isinstance(i, int) and i >= 0\n",
        "               for i in [batch_size, n_rows, n_cols, num_critters, num_food,\n",
        "                         lifetime]), \"All inputs must be non-negative integers.\"\n",
        "    self.batch_size = batch_size\n",
        "    self.n_rows = n_rows\n",
        "    self.n_cols = n_cols\n",
        "    self.num_critters = num_critters\n",
        "    # Check for num_food exceeding maximum possible value\n",
        "    max_food = n_rows * n_cols - num_critters\n",
        "    if num_food > max_food:\n",
        "      print(f'num_food is too large, setting it to maximum possible value: {max_food}')\n",
        "      num_food = max_food\n",
        "    self.num_food = num_food\n",
        "    self.lifetime = lifetime\n",
        "    # Set up random number generator\n",
        "    if rng is None:\n",
        "      self.rng = np.random.default_rng(seed=SEED)\n",
        "    else:\n",
        "      self.rng = rng\n",
        "    self.drift_probs = drift_probs\n",
        "    self.wrapping = wrapping\n",
        "    self.drift_after_move = drift_after_move\n",
        "\n",
        "\n",
        "  def get_init_board(self):\n",
        "    \"\"\"\n",
        "    Generates a starting board given the parameters of the game.\n",
        "    Returns a tuple giving current state of the game\n",
        "    \"\"\"\n",
        "    # current score, and rounds left in the episode\n",
        "    b = GridworldBoard(batch_size=self.batch_size, n_rows=self.n_rows,\n",
        "                       n_cols=self.n_cols, num_critters=self.num_critters,\n",
        "                       num_food=self.num_food, lifetime=self.lifetime,\n",
        "                       rng=self.rng)\n",
        "    return b.get_init_board_state()\n",
        "\n",
        "\n",
        "  def get_board_size(self):\n",
        "    \"\"\"Shape of a single board, doesn't give batch size\"\"\"\n",
        "    return (self.n_rows, self.n_cols)\n",
        "\n",
        "\n",
        "  def get_action_size(self):\n",
        "    \"\"\"\n",
        "    Returns the number of all possible actions, even though only  2-4 of\n",
        "    these will ever be valid on a given turn.\n",
        "    Actions correspond to integer indexes of board locations,\n",
        "    moves to g,r,c coordinate indexes of board locations\n",
        "    \"\"\"\n",
        "    return self.n_rows * self.n_cols\n",
        "\n",
        "\n",
        "  def get_batch_size(self):\n",
        "    \"\"\"\n",
        "    Returns the number of actions, only 0-4 of these will ever be valid.\n",
        "    Actions correspond to integer indexes of board locations,\n",
        "    moves to r,c indexes of board locations\n",
        "    \"\"\"\n",
        "    return self.batch_size\n",
        "\n",
        "\n",
        "  def string_rep(self, board, g=0):\n",
        "    \"\"\" A bytestring representation board g's state in the batch of boards\"\"\"\n",
        "    return (board['pieces'][g].tobytes() + board['scores'][g].tobytes() +\n",
        "            board['rounds_left'][g].tobytes())\n",
        "\n",
        "\n",
        "  def get_square_symbol(self, piece):\n",
        "    \"\"\" Translate integer piece value to symbol for display\"\"\"\n",
        "    if piece == -1:\n",
        "      return \"X\"\n",
        "    elif piece == 0:\n",
        "      return \"-\"\n",
        "    elif piece >= 1:\n",
        "      return \"0\"\n",
        "    else:\n",
        "      return \"???????????????????????????\"\n",
        "\n",
        "\n",
        "  def string_rep_readable(self, board, g=0):\n",
        "    \"\"\" A human readable representation of g-th board's state in the batch\"\"\"\n",
        "    board_s = \"\".join([self.get_square_symbol(square)\n",
        "                        for row in board['pieces'][g]\n",
        "                          for square in row])\n",
        "    board_s = board_s + '_' + str(board['scores'][g])\n",
        "    board_s = board_s + '_' + str(board['rounds_left'][g])\n",
        "    return board_s\n",
        "\n",
        "\n",
        "  def get_scores(self, board):\n",
        "    return board['scores'].copy()\n",
        "\n",
        "\n",
        "  def get_rounds_left(self, board):\n",
        "    return board['rounds_left'].copy()\n",
        "\n",
        "\n",
        "  def display(self, board, g=0):\n",
        "    \"\"\"Displays the g-th games in the batch of boards\"\"\"\n",
        "    print(\"   \", end=\"\")\n",
        "    for c_ in range(self.n_cols):\n",
        "      print(c_, end=\" \")\n",
        "    print(\"\")\n",
        "    print(\"-----------------------\")\n",
        "    for c_ in range(self.n_cols):\n",
        "      print(c_, \"|\", end=\"\")    # Print the row\n",
        "      for r_ in range(self.n_rows):\n",
        "        piece = board['pieces'][g,c_,r_]    # Get the piece to print\n",
        "        #print(piece)\n",
        "        print(self.get_square_symbol(piece), end=\" \")\n",
        "      print(\"|\")\n",
        "    print(\"-----------------------\")\n",
        "    print(\"Rounds Left: \" + str(board['rounds_left'][g]))\n",
        "    print(\"Score: \" + str(board['scores'][g]))\n",
        "\n",
        "\n",
        "  def get_critter_rc(self, board, g, critter_index):\n",
        "    return np.squeeze(np.array(np.where(board['pieces'][g]==critter_index)))\n",
        "\n",
        "\n",
        "  def plot_moves(self, board, player0, g=0, player1=None,\n",
        "                 fig=None, ax=None, p0_name='Player 0', p1_name='Player 1',\n",
        "                 figsize=(6,5), critter_name='Critter', title=None,\n",
        "                 deterministic=False):\n",
        "    \"\"\"\n",
        "    Uses plotting functions to make picture of the current board state, and what\n",
        "    a critter would do at each non-food location in the current board state\n",
        "    \"\"\"\n",
        "    def make_prob_dict(critter_locs, play):\n",
        "      offset_dict = {(0, 1): 'right',\n",
        "                     (0,-1): 'left',\n",
        "                     ( 1, 0): 'down',\n",
        "                     (-1, 0): 'up'}\n",
        "      index_probs = play[2].copy()\n",
        "      loc_prob_dict = {}\n",
        "      # for each non food locations\n",
        "      for g, loc_ in enumerate(critter_locs):\n",
        "        # this is the location as an r, c tuple\n",
        "        rc_tup = tuple((loc_[1], loc_[2]))\n",
        "        # the relevant probabilities\n",
        "        raw_probs = index_probs[g]\n",
        "        probs = raw_probs[raw_probs > 0]\n",
        "        indexes = np.argwhere(raw_probs > 0)\n",
        "        # turn the probability indexes into r, c coords\n",
        "        rows = np.floor_divide(indexes, gwg.n_cols)\n",
        "        cols = np.remainder(indexes, gwg.n_cols)\n",
        "        moves = np.squeeze(np.array([z for z in zip(rows, cols)]), axis=2)\n",
        "        #compute the offsets and turn them to strings\n",
        "        offsets = moves - loc_[1:]\n",
        "        str_offsets = np.array(list(map(offset_dict.get, map(tuple, offsets))))\n",
        "        # update the loc_prob_dict for plotting\n",
        "        prob_dict = dict(zip(str_offsets, probs))\n",
        "        loc_prob_dict.update({rc_tup: prob_dict})\n",
        "      return loc_prob_dict\n",
        "\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    plt.ioff()\n",
        "    if fig is None and ax is None:\n",
        "      fig, ax = make_grid(n_rows, n_cols, figsize=figsize, title=title)\n",
        "\n",
        "    rc_food_index = np.array(np.where(board['pieces'][g] == -1))\n",
        "    rc_food_plotting = np.array(rc_food_index).T\n",
        "    food = plot_food(fig, ax, rc_food_plotting)\n",
        "\n",
        "    expanded_board = self.critter_everywhere_state_expansion(\n",
        "      board, player0.critter_index, to_expand=g)\n",
        "    critter_locs = np.argwhere(expanded_board['pieces']==player0.critter_index)\n",
        "    #play the expanded state\n",
        "    p0_play = player0.play(expanded_board)\n",
        "    #get the prob dict\n",
        "    p0_loc_prob_dict = make_prob_dict(critter_locs, p0_play)\n",
        "    # same for player1 if there is one\n",
        "    if player1 is not None:\n",
        "      p1_play = player1.play(expanded_board)\n",
        "      p1_loc_prob_dict = make_prob_dict(critter_locs, p1_play)\n",
        "\n",
        "    existing_handels, _ = ax.get_legend_handles_labels()\n",
        "    if player1 is None:\n",
        "      fig, ax, leg_handles_0 = plot_directions(fig, ax, p0_loc_prob_dict,\n",
        "        critter=0, deterministic=deterministic)\n",
        "      leg_handles = existing_handels\n",
        "    else:\n",
        "      fig, ax, leg_handles_0 = plot_directions(fig, ax, p0_loc_prob_dict,\n",
        "        critter=1, deterministic=deterministic, name=p0_name)\n",
        "      fig, ax, leg_handles_1 = plot_directions(fig, ax, p1_loc_prob_dict,\n",
        "        critter=2, deterministic=deterministic, name=p1_name)\n",
        "      leg_handles = existing_handels + leg_handles_0 + leg_handles_1\n",
        "\n",
        "    fig.legend(handles=leg_handles, loc=\"outside right upper\")\n",
        "    fig.canvas.draw()\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "  def plot_board(self, board, g=0,\n",
        "                 fig=None, ax=None, critter_specs=None, food=None, fov=None,\n",
        "                 legend_type='included',\n",
        "                 has_fov=False, #fog_of_war feild_of_view\n",
        "                 radius=2, figsize=(6,5), title=None,\n",
        "                 name='Critter'):\n",
        "    \"\"\"Uses plotting functions to make picture of the current board state\"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    plt.ioff()\n",
        "    if fig is None and ax is None:\n",
        "      fig, ax = make_grid(n_rows, n_cols, figsize=figsize, title=title)\n",
        "\n",
        "    # generate critter plotting specs if we don't already have them\n",
        "    if critter_specs is None:\n",
        "      critter_specs = []\n",
        "      markers = ['h', 'd']  # hexagon and diamond\n",
        "      colors = sns.color_palette(\"colorblind\")\n",
        "      for i in range(self.num_critters):\n",
        "        critter_name = name if self.num_critters == 1 else f'{name} {i+1}'\n",
        "        spec = {'marker': markers[i % len(markers)],\n",
        "                'color': colors[i // len(markers) % len(colors)],\n",
        "                'name': critter_name,\n",
        "                'int_id': i+1}\n",
        "        critter_specs.append(spec)\n",
        "    # get critter locs and plot them\n",
        "    assert len(critter_specs) == self.num_critters, \"More/fewer specs than critters\"\n",
        "    for spec in critter_specs:\n",
        "      rc_loc = np.array(np.where(board['pieces'][g] == spec['int_id'])).T\n",
        "      spec.update({'rc_loc': rc_loc})\n",
        "    critter_specs = plot_critters(fig, ax, critter_specs)\n",
        "\n",
        "    # get food locs and plot them\n",
        "    rc_food_index = np.array(np.where(board['pieces'][g] == -1))\n",
        "    rc_food_plotting = np.array(rc_food_index).T\n",
        "    if food is None:\n",
        "      food = plot_food(fig, ax, rc_food_plotting)\n",
        "    else:\n",
        "      food = plot_food(fig, ax, rc_food_plotting, food)\n",
        "\n",
        "    #plot field of view if doing that\n",
        "    if has_fov:\n",
        "      # will need to think about how to do this for multiple\n",
        "      # critters, currently just use rc of first critter in the spec list\n",
        "      if fov is None:\n",
        "        fov = plot_fov(fig, ax, critter_specs[0]['rc_loc'], n_rows, n_cols,\n",
        "                       radius, has_fov)\n",
        "      else:\n",
        "        fov = plot_fov(fig, ax, critter_specs[0]['rc_loc'], n_rows, n_cols,\n",
        "                       radius, has_fov, fov)\n",
        "    # make legend and draw and return figure\n",
        "    if legend_type == 'included':\n",
        "      fig.legend(loc = \"outside right upper\", markerscale=0.8)\n",
        "      fig.canvas.draw()\n",
        "      return fig, ax, critter_specs, food, fov\n",
        "    elif legend_type == 'separate':\n",
        "      fig_legend, ax_legend = plt.subplots(figsize=(1.5,1.5), layout='constrained')\n",
        "      fig_legend.get_layout_engine().set(w_pad=0, h_pad=0, hspace=0, wspace=0)\n",
        "      handles, labels = ax.get_legend_handles_labels()\n",
        "      ax_legend.legend(handles, labels, loc='center', markerscale=0.8)\n",
        "      ax_legend.axis('off')\n",
        "      fig_legend.canvas.header_visible = False\n",
        "      fig_legend.canvas.toolbar_visible = False\n",
        "      fig_legend.canvas.resizable = False\n",
        "      fig_legend.canvas.footer_visible = False\n",
        "      fig_legend.canvas.draw()\n",
        "      return fig, ax, critter_specs, food, fov, fig_legend, ax_legend\n",
        "    else: #no legend\n",
        "      fig.canvas.draw()\n",
        "      return fig, ax, critter_specs, food, fov\n",
        "\n",
        "\n",
        "  def get_valid_actions(self, board, critter):\n",
        "    \"\"\"\n",
        "    A Helper function to translate the g,x,y, tuples provided the\n",
        "    GridworldBoard.get_legal_moves method into valid actions, represented\n",
        "    as binary vectors of len num_actions.\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "\n",
        "    Returns:\n",
        "      valids: np.ndarray(binary) batch_size x num_actions, 1's represent\n",
        "              valid moves\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    b = GridworldBoard(batch_size=batch_size, n_rows=n_rows,\n",
        "                       n_cols=n_cols, num_critters=self.num_critters,\n",
        "                       num_food=self.num_food, lifetime=self.lifetime,\n",
        "                       rng=self.rng)\n",
        "    b.set_state(board)\n",
        "    legal_moves =  b.get_legal_moves(critter)\n",
        "    valids = np.zeros((batch_size, n_rows * n_cols))\n",
        "    for g, r, c in legal_moves:\n",
        "      valids[g, r * n_cols + c] = 1\n",
        "    return valids\n",
        "\n",
        "\n",
        "  def display_moves(self, board, critter=1, g=0):\n",
        "    \"\"\"Displays possible moves for the g-th games in the batch of boards\"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    A=np.reshape(self.get_valid_actions(board, critter)[g],\n",
        "                 (n_rows, n_cols))\n",
        "    print(\"  \")\n",
        "    print(\"possible moves\")\n",
        "    print(\"   \", end=\"\")\n",
        "    for col in range(self.n_cols):\n",
        "      print(col, end=\" \")\n",
        "    print(\"\")\n",
        "    print(\"-----------------------\")\n",
        "    for col in range(self.n_cols):\n",
        "      print(col, \"|\", end=\"\")    # Print the row\n",
        "      for row in range(self.n_rows):\n",
        "        piece = A[col][row]    # Get the piece to print\n",
        "        print(self.get_square_symbol(piece), end=\" \")\n",
        "      print(\"|\")\n",
        "    print(\"-----------------------\")\n",
        "\n",
        "\n",
        "  def get_perceptions(self, board, radius, critter):\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    b = GridworldBoard(batch_size=batch_size, n_rows=n_rows,\n",
        "                       n_cols=n_cols, num_critters=self.num_critters,\n",
        "                       num_food=self.num_food, lifetime=self.lifetime,\n",
        "                       rng=self.rng)\n",
        "    b.set_state(board)\n",
        "    return(b.get_perceptions(radius, critter))\n",
        "\n",
        "\n",
        "  def get_next_state(self, board, critter, actions, a_indx=None):\n",
        "    \"\"\"\n",
        "    Helper function using GridworldBoard.execute_moves to update board state\n",
        "    given actions on a batch of boards, for a given critter\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "      critter: integer index of the critter type\n",
        "      actions: list of flat integer indexes of critter's new board positions\n",
        "      a_indx: list of integer indexes indicating which actions are being taken\n",
        "        on which boards in the batch\n",
        "\n",
        "    Returns:\n",
        "      a board triple signifying next state\n",
        "\n",
        "    Note:\n",
        "      if len(actions) > batch_size of board the returned board state will have\n",
        "      an expanded batch size, allowing multiple paths in the game tree to be\n",
        "      explored in parallel\n",
        "\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    if board['rounds_left'][0] <= 0:\n",
        "      # assumes all boards in the batch have the same rounds left\n",
        "      # no rounds left return the board unchanged\n",
        "      return board\n",
        "    else:\n",
        "      moves = self.actions_to_moves(actions)\n",
        "      b = GridworldBoard(batch_size=len(actions), n_rows=n_rows,\n",
        "                         n_cols=n_cols, num_critters=self.num_critters,\n",
        "                         num_food=self.num_food, lifetime=self.lifetime,\n",
        "                         rng=self.rng)\n",
        "      if a_indx is None:\n",
        "        # just one move on each board in the batch\n",
        "        assert batch_size == len(actions)\n",
        "        b.set_state(board)\n",
        "      else:\n",
        "        # potentially multiple moves on each board, expand the batch\n",
        "        assert len(actions) == len(a_indx)\n",
        "        new_pieces = np.array([board['pieces'][ai].copy() for ai in a_indx])\n",
        "        new_scores = np.array([board['scores'][ai].copy() for ai in a_indx])\n",
        "        new_rounds_left = np.array([board['rounds_left'][ai].copy() for ai in a_indx])\n",
        "        new_active_player = copy(board['active_player'])\n",
        "        new_state = {'pieces': new_pieces,\n",
        "                     'scores': new_scores,\n",
        "                     'rounds_left': new_rounds_left,\n",
        "                     'active_player': new_active_player}\n",
        "        b.set_state(new_state)\n",
        "      if self.drift_after_move:\n",
        "        b.execute_moves(moves, critter)\n",
        "        if self.drift_probs is not None:\n",
        "          b.execute_drift(self.drift_probs, self.wrapping)\n",
        "      else: # drift before move very unfair, critter has to anticipate movement\n",
        "        if self.drift_probs is not None:\n",
        "          b.execute_drift(self.drift_probs, self.wrapping)\n",
        "        b.execute_moves(moves, critter)\n",
        "      return b.get_state()\n",
        "\n",
        "\n",
        "  def actions_to_moves(self, actions):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      actions: a batch length list of integer indexes for the flattened boards,\n",
        "      i.e. in the range(n_cols * n_rows) actions are often much easier to use\n",
        "      as training targets for NN based RL agents.\n",
        "    Returns\n",
        "      moves: a 3-tuple of 1-d arrays each of length batch_size,\n",
        "        the first array gives the specific board within the batch,\n",
        "        the second array in the tuple gives the new row coord for each critter\n",
        "        on each board and the third gives the new col coord. Note this is\n",
        "        exactly the format expected by GridworldBoard.execute_moves, and\n",
        "        is a canonical way of indexing arrays for quick numpy operations.\n",
        "    \"\"\"\n",
        "    moves = (np.arange(len(actions)),\n",
        "             np.floor_divide(actions, self.n_cols),\n",
        "             np.remainder(actions, self.n_cols))\n",
        "    return moves\n",
        "\n",
        "\n",
        "  def moves_to_actions(self, moves):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      moves: a 3-tuple of 1-d arrays each of length batch_size,\n",
        "        the first array gives the specific board within the batch,\n",
        "        the second array in the tuple gives the new row coord for each critter\n",
        "        on each board and the third gives the new col coord. Note this is\n",
        "        exactly the format expected by GridworldBoard.execute_moves, and\n",
        "        is a canonical way of indexing arrays for quick numpy operations.\n",
        "    Returns:\n",
        "      actions: a batch length list of integer indexes for the flattened boards,\n",
        "      i.e. in the range(n_cols * n_rows) actions are often much easier to use\n",
        "      as training targets for NN based RL agents.\n",
        "    \"\"\"\n",
        "    _, rows, cols = moves\n",
        "    actions = rows * self.n_cols + cols\n",
        "    return actions\n",
        "\n",
        "\n",
        "  def critter_oriented_get_next_state(self, board, critter, offsets):\n",
        "    \"\"\"\n",
        "    Translates directions in reference to the critter's location into\n",
        "    moves on the board in absolute terms, while checking for\n",
        "    bouncing/reflecting then get's the next state.\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "      offsets: batch length list of strings one 'up', 'down', 'left', 'right'\n",
        "\n",
        "    Returns:\n",
        "      a board triple signifying next state\n",
        "\n",
        "    Note:\n",
        "      Unlike get_next_state, this method does not allow for expansion\n",
        "      of the game tree, i.e. len(offsets)==batch_size required\n",
        "    \"\"\"\n",
        "    assert len(offsets) == board['pieces'].shape[0]\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    b = GridworldBoard(batch_size=batch_size, n_rows=n_rows,\n",
        "                       n_cols=n_cols, num_critters=self.num_critters,\n",
        "                       num_food=self.num_food, lifetime=self.lifetime,\n",
        "                       rng=self.rng)\n",
        "    b.set_state(board)\n",
        "    moves = self.critter_direction_to_move(board, offsets, critter)\n",
        "    if self.drift_after_move:\n",
        "      b.execute_moves(moves, critter)\n",
        "      if self.drift_probs is not None:\n",
        "        b.execute_drift(self.drift_probs, self.wrapping)\n",
        "    else: # drift before move very unfair, critter has to anticipate movement\n",
        "      if self.drift_probs is not None:\n",
        "        b.execute_drift(self.drift_probs, self.wrapping)\n",
        "      b.execute_moves(moves, critter)\n",
        "    return(b.get_state())\n",
        "\n",
        "\n",
        "  def critter_direction_to_move(self, board, offsets, critter):\n",
        "    \"\"\"\n",
        "    Translates directions in reference to the critter's location into\n",
        "    moves on the board in absolute terms, while checking for\n",
        "    bouncing/reflecting then returns moves. Doesn't check for collisions with\n",
        "    other critters though. In general player's move methods should be checking\n",
        "    valid moves and only making legal ones.\n",
        "\n",
        "    Args:\n",
        "      board: dict of np arrays representing board state\n",
        "        'pieces':       batch_size x n_rows x n_cols\n",
        "        'scores':       batch_size\n",
        "        'rounds_left':  batch_size\n",
        "      offsets: batch length list of strings,\n",
        "        one of 'up', 'down', 'left', 'right'\n",
        "      critter: integer index for the critter we want moves for\n",
        "\n",
        "    Returns:\n",
        "      moves: a 3-tuple of 1-d arrays each of length batch_size,\n",
        "        the first array gives the specific board within the batch,\n",
        "        the second array in the tuple gives the new row coord for each critter\n",
        "        on each board and the third gives the new col coord. Note this is\n",
        "        exactly the format expected by GridworldBoard.execute_moves, and\n",
        "        is a canonical way of indexing arrays for numpy.\n",
        "\n",
        "    Note:\n",
        "      Unlike get_next_state, this method does not allow for expansion\n",
        "      of the game tree, i.e. len(offsets)==batch_size required\n",
        "    \"\"\"\n",
        "    assert len(offsets) == board['pieces'].shape[0]\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    offset_dict = {'up': (0, -1, 0),\n",
        "                   'down': (0, 1, 0),\n",
        "                   'left': (0, 0, -1),\n",
        "                   'right': (0, 0, 1),\n",
        "                   'still': (0, 0, 0)}\n",
        "    this_critter_locs = np.where(board['pieces'] == critter)\n",
        "    all_critter_locs = np.where(board['pieces'] >= 1)\n",
        "    offsets_array = np.hstack([np.array(offset_dict[ost_]).reshape((3,1))\n",
        "                           for ost_ in offsets])\n",
        "    new_locs = np.array(this_critter_locs) + offsets_array\n",
        "    #check bounces at boundaries\n",
        "    new_locs[1,:] = np.where(new_locs[1] >=\n",
        "                               n_rows, n_rows-2, new_locs[1])\n",
        "    new_locs[2,:] = np.where(new_locs[2,:] >=\n",
        "                               n_cols, n_cols-2, new_locs[2,:])\n",
        "    new_locs[1,:] = np.where(new_locs[1,:] < 0, 1, new_locs[1,:])\n",
        "    new_locs[2,:] = np.where(new_locs[2,:] < 0, 1, new_locs[2,:])\n",
        "    moves = tuple(new_locs)\n",
        "    return moves\n",
        "\n",
        "\n",
        "  def direction_probs_to_flat_probs(self, board, direction_probs, critter):\n",
        "    \"\"\"\n",
        "    Converts direction probabilities in reference to the critter's location into\n",
        "    probability arrays on the flattened board.\n",
        "\n",
        "    Args:\n",
        "      board: dict of np arrays representing board state\n",
        "        'pieces':       batch_size x n_rows x n_cols\n",
        "        'scores':       batch_size\n",
        "        'rounds_left':  batch_size\n",
        "      direction_probs: batch length list of dictionaries with keys\n",
        "        ['up', 'down', 'left', 'right'] and corresponding probabilities.\n",
        "\n",
        "    Returns:\n",
        "      probs_arrays: list of arrays, where each array is of length n_rows*n_cols\n",
        "                    and represents the flattened probability distribution for\n",
        "                    board in the batch.\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    offset_dict = {\n",
        "        'up': np.array((0, -1, 0)),\n",
        "        'down': np.array((0, 1, 0)),\n",
        "        'left': np.array((0, 0, -1)),\n",
        "        'right': np.array((0, 0, 1))}\n",
        "    critter_locs = np.where(board['pieces'] == critter)\n",
        "    probs_arrays = np.zeros((batch_size, n_rows * n_cols))\n",
        "    for batch_index in range(batch_size):\n",
        "      prob_array = np.zeros(n_rows * n_cols)\n",
        "      for direction, prob in direction_probs[batch_index].items():\n",
        "          offset = offset_dict[direction]\n",
        "          new_loc = np.array(critter_locs)[:, batch_index] + offset\n",
        "          # Check bounces at boundaries\n",
        "          new_loc[1] = np.where(new_loc[1] >= n_rows, n_rows-2, new_loc[1])\n",
        "          new_loc[2] = np.where(new_loc[2] >= n_cols, n_cols-2, new_loc[2])\n",
        "          new_loc[1] = np.where(new_loc[1] < 0, 1, new_loc[1])\n",
        "          new_loc[2] = np.where(new_loc[2] < 0, 1, new_loc[2])\n",
        "          # Convert 2D location to flattened index\n",
        "          flattened_index = new_loc[1] * n_cols + new_loc[2]\n",
        "          prob_array[flattened_index] += prob\n",
        "      probs_arrays[batch_index, :] = prob_array\n",
        "    return list(probs_arrays)\n",
        "\n",
        "\n",
        "  def action_to_critter_direction(self, board, critter, actions):\n",
        "    \"\"\"\n",
        "    Translates an integer index action into up/down/left/right\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "      actions: a batch size ndarry of integer indexes for actions on each board\n",
        "\n",
        "    Returns:\n",
        "      offsets: a batch length list of strings 'up', 'down', 'left', 'right'\n",
        "    \"\"\"\n",
        "    offset_dict = {(0, 0, 1): 'right',\n",
        "                   (0, 0,-1): 'left',\n",
        "                   (0, 1, 0): 'down',\n",
        "                   (0,-1, 0): 'up'}\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    critter_locs = np.where(board['pieces'] == critter)\n",
        "    moves = (np.arange(len(actions)),\n",
        "               np.floor_divide(actions, n_cols),\n",
        "               np.remainder(actions, n_cols))\n",
        "    # need to reverse this from above, moves is equiv to new_locs\n",
        "    # new_locs = np.array(critter_locs) + offsets_array\n",
        "    offsets_array = np.array(moves) - np.array(critter_locs)\n",
        "    offsets = [offset_dict[tuple(o_)] for o_ in offsets_array.T]\n",
        "    return offsets\n",
        "\n",
        "\n",
        "  def get_valid_directions(self, board, critter):\n",
        "    \"\"\"\n",
        "    Transforms output of get_valid_actions to a list of the valid directions\n",
        "    for each board in the batch for a given critter.\n",
        "    \"\"\"\n",
        "    offset_dict = {( 0, 1): 'right',\n",
        "                   ( 0,-1): 'left',\n",
        "                   ( 1, 0): 'down',\n",
        "                   (-1, 0): 'up'}\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    valid_actions = self.get_valid_actions(board, critter)\n",
        "    if batch_size != len(valid_actions):\n",
        "      raise ValueError(\"Need Exactly one set of valid actions per board in batch\")\n",
        "    critter_locs = np.column_stack(np.where(board['pieces'] == critter))\n",
        "    valid_directions = []\n",
        "    for g, batch_valid in enumerate(valid_actions):\n",
        "      valid_int_indices = np.where(batch_valid==1)[0]\n",
        "      critter_loc = critter_locs[critter_locs[:, 0] == g, 1:]\n",
        "      # critter_loc shape is (1, 2)\n",
        "      critter_loc = np.squeeze(critter_loc)\n",
        "      moves = np.column_stack([valid_int_indices // n_cols, valid_int_indices % n_cols])\n",
        "      offsets = moves - critter_loc\n",
        "      batch_valid_directions = [offset_dict[tuple(offset)] for offset in offsets]\n",
        "      valid_directions.append(batch_valid_directions)\n",
        "    return valid_directions\n",
        "\n",
        "\n",
        "  def get_game_ended(self, board):\n",
        "    \"\"\"\n",
        "    Helper function to signify if game has ended\n",
        "    Returns a batch size np.array of -1 if not ended, and scores for each game\n",
        "    in the batch if it is ended, note only returns scores if all games in the\n",
        "    batch have ended\n",
        "    \"\"\"\n",
        "    rounds_left = board['rounds_left']\n",
        "    scores = board['scores']\n",
        "    if np.any(rounds_left >= 1):\n",
        "      return np.ones(self.batch_size) * -1.0\n",
        "    else:\n",
        "      return scores\n",
        "\n",
        "\n",
        "  def critter_everywhere_state_expansion(self, board_state,\n",
        "                                         critter=1, to_expand=0):\n",
        "    \"\"\"\n",
        "    Expand a given board state by placing a critter at each non-food location.\n",
        "\n",
        "    The function takes a game state and returns an expanded version of it. For\n",
        "    each board in the state, it creates a new version of the board for every\n",
        "    non-food location, placing a critter at that location. The scores and\n",
        "    remaining rounds are copied for each new board. The result is a new game state\n",
        "    with a larger number of boards, each representing a possible configuration\n",
        "    with a critter at a different location.\n",
        "\n",
        "    Args:\n",
        "      board_state (dict): A dictionary containing the current game state.\n",
        "      It should have the following keys:\n",
        "        - 'pieces': a 3D numpy array (batch x n_col x n_row) representing the game\n",
        "          board. -1 -> food, 0 -> empty cell, and 1 -> critter.\n",
        "        - 'scores': 1D numpyp array of the score for each board in the batch.\n",
        "        - 'rounds_left': a 1D numpy array of the rounds left for\n",
        "          each board in the batch.\n",
        "      critter: integer index to place on the expanded board state\n",
        "      to_expand (list (int)): list of batch indices to have state expanded\n",
        "\n",
        "    Returns:\n",
        "      dict: A dictionary containing the expanded game state with the same keys\n",
        "        as the input. The number of boards will be larger than the input state.\n",
        "    \"\"\"\n",
        "    pieces = board_state['pieces'].copy()\n",
        "    scores = board_state['scores'].copy()\n",
        "    rounds_left = board_state['rounds_left'].copy()\n",
        "    active_player = copy(board_state['active_player'])\n",
        "    # Determine non-food locations\n",
        "    non_food_locs = np.argwhere(pieces[to_expand] != -1)\n",
        "    #scrub all existing critter locations,\n",
        "    # maybe later only scrub specific critter type\n",
        "    pieces[pieces >= 1] = 0\n",
        "    # lists to store expanded states\n",
        "    expanded_pieces = []\n",
        "    expanded_scores = []\n",
        "    expanded_rounds_left = []\n",
        "    # Iterate over each non-food location\n",
        "    for i in range(non_food_locs.shape[0]):\n",
        "      # Create a copy of the board\n",
        "      expanded_board = np.copy(pieces[to_expand])\n",
        "      # Place the critter at the non-food location\n",
        "      # later consider only placing at non-food,\n",
        "      # non-other critter locs\n",
        "      expanded_board[tuple(non_food_locs[i])] = critter\n",
        "      # Add the expanded board to the list along score and rounds_left\n",
        "      expanded_pieces.append(expanded_board)\n",
        "      expanded_scores.append(scores[to_expand])\n",
        "      expanded_rounds_left.append(rounds_left[to_expand])\n",
        "    # Convert to arrays and create expanded board state\n",
        "    expanded_state = {'pieces': np.stack(expanded_pieces),\n",
        "                      'scores': np.array(expanded_scores),\n",
        "                      'rounds_left': np.array(expanded_rounds_left),\n",
        "                      'active_player': active_player}\n",
        "    return expanded_state\n",
        "\n",
        "\n",
        "  def play_game(self, players=[], collect_fov_data=False, fov_radius=2,\n",
        "                visualize = False):\n",
        "    \"\"\"This method takes a list of players the same length as num_critters,\n",
        "        and then plays a batch of games with them and returns the final board\n",
        "        state\"\"\"\n",
        "    if len(players) != self.num_critters:\n",
        "      raise ValueError(\"number of players different than expected\")\n",
        "\n",
        "    board = self.get_init_board()\n",
        "    if visualize == True:\n",
        "      self.display(board, 0)\n",
        "\n",
        "    if collect_fov_data is True:\n",
        "      batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "      b = GridworldBoard(batch_size=batch_size,\n",
        "                         n_rows=n_rows, n_cols=n_cols,\n",
        "                         num_critters=self.num_critters,\n",
        "                         num_food=self.gwg.num_food,\n",
        "                         lifetime=self.gwg.lifetime,\n",
        "                         rng=self.gwg.rng)\n",
        "\n",
        "\n",
        "    for ii in range(self.lifetime):\n",
        "      for jj, player in enumerate(players):\n",
        "        active_player_index = board['active_player']\n",
        "        old_scores = board['scores']\n",
        "        if collect_fov_data is True:\n",
        "          b.set_state(board)\n",
        "          percepts = b.get_perceptions(fov_radius)\n",
        "\n",
        "        a_player, _, _ = players[active_player_index].play(board)\n",
        "        board = self.get_next_state(board, active_player_index+1, a_player)\n",
        "        if visualize == True:\n",
        "          self.display(board, 0)\n",
        "    return board"
      ],
      "metadata": {
        "id": "wKx38G-jmAfy",
        "cellView": "form"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title player zoo\n",
        "###########################################################################\n",
        "# make a separate player zoo\n",
        "###########################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class RandomValidPlayer():\n",
        "  \"\"\"\n",
        "  Instantiate random player for GridWorld\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, game, critter_index=1):\n",
        "    self.game = game\n",
        "    self.critter_index = critter_index\n",
        "    assert (isinstance(critter_index, int) and\n",
        "        0 < critter_index <= game.num_critters), \"Value is not a positive integer or exceeds the upper limit.\"\n",
        "\n",
        "\n",
        "  def play(self, board):\n",
        "    \"\"\"\n",
        "    Simulates a batch of random game plays based on the given board state.\n",
        "\n",
        "    This function computes the probability of each valid move being played\n",
        "    (uniform for valid moves, 0 for others), then selects a move randomly for\n",
        "    each game in the batch based on these probabilities.\n",
        "\n",
        "    Args:\n",
        "      board (dict): A dictionary representing the state of the game. It\n",
        "          contains:\n",
        "          - 'pieces': A (batch_size, x_size, y_size) numpy array indicating\n",
        "                      the pieces on the board.\n",
        "          - 'scores' (not used directly in this function, but expected in dict)\n",
        "          - 'rounds_left' (not used directly in this function, but expected in dict)\n",
        "\n",
        "    Returns:\n",
        "      tuple:\n",
        "      - a (numpy array): An array of shape (batch_size,) containing randomly\n",
        "                         chosen actions for each game in the batch.\n",
        "      - a_1hots (numpy array): An array of shape (batch_size, action_size)\n",
        "                               with one-hot encoded actions.\n",
        "      - probs (numpy array): An array of the same shape as 'valids' containing\n",
        "                             the probability of each move being played.\n",
        "    \"\"\"\n",
        "    batch_size, x_size, y_size = board['pieces'].shape\n",
        "    valids = self.game.get_valid_actions(board, self.critter_index)\n",
        "    action_size = self.game.get_action_size()\n",
        "\n",
        "    probs = valids / np.sum(valids, axis=1).reshape(batch_size,1)\n",
        "\n",
        "    a = [self.game.rng.choice(action_size, p=probs[ii])\n",
        "                                for ii in range(batch_size)]\n",
        "    a_1hots = np.zeros((batch_size, action_size))\n",
        "    a_1hots[(range(batch_size), a)] = 1.0\n",
        "    return np.array(a), a_1hots, probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class RandomDirectionPlayer():\n",
        "  \"\"\"\n",
        "  Instantiate random player for GridWorld\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, game, critter_index=1):\n",
        "    self.game = game\n",
        "    self.critter_index = critter_index\n",
        "    assert (isinstance(critter_index, int) and\n",
        "        0 < critter_index <= game.num_critters), \"Value is not a positive integer or exceeds the upper limit.\"\n",
        "\n",
        "  def play(self, board):\n",
        "    \"\"\"\n",
        "    Simulates a batch of random game plays based on the given board state.\n",
        "\n",
        "    This function assigns a uniform probability to going up down left or right\n",
        "    independent of whether it is at an edge or cornor or not. Then because of\n",
        "    bouncing off edges it will have a higher probability of moving away from\n",
        "    edges as opposed to along them than the random valid move player.\n",
        "\n",
        "    Args:\n",
        "      board (dict): A dictionary representing the state of the game. It\n",
        "          contains:\n",
        "          - 'pieces': A (batch_size, x_size, y_size) numpy array indicating\n",
        "                      the pieces on the board.\n",
        "          - 'scores' (not used directly in this function, but expected in dict)\n",
        "          - 'rounds_left' (not used directly in this function, but expected in dict)\n",
        "\n",
        "    Returns:\n",
        "      tuple:\n",
        "      - a (numpy array): An array of shape (batch_size,) containing randomly\n",
        "                         chosen actions for each game in the batch.\n",
        "      - a_1hots (numpy array): An array of shape (batch_size, action_size)\n",
        "                               with one-hot encoded actions.\n",
        "      - probs (numpy array): An array of the same shape as 'valids' containing\n",
        "                             the probability of each move being played.\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    action_probs = {'up': 0.25, 'down': 0.25, 'left': 0.25, 'right': 0.25}\n",
        "\n",
        "    critter_oriented_moves = self.game.rng.choice(list(action_probs.keys()),\n",
        "                                                  size=(batch_size))\n",
        "    direction_probs = [action_probs] * batch_size\n",
        "    moves = self.game.critter_direction_to_move(board, critter_oriented_moves,\n",
        "                                                self.critter_index)\n",
        "    probs = self.game.direction_probs_to_flat_probs(board, direction_probs,\n",
        "                                                    self.critter_index)\n",
        "    sampled_actions = self.game.moves_to_actions(moves)\n",
        "    a_1hots = np.zeros((batch_size, n_rows*n_cols))\n",
        "    a_1hots[(range(batch_size), sampled_actions)] = 1.0\n",
        "\n",
        "    return sampled_actions, a_1hots, probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MonteCarloBasedPlayer():\n",
        "  \"\"\"\n",
        "  Simulate Player based on Monte Carlo Algorithm\n",
        "\n",
        "  Note: Has dependencies in the gw_NN_RL.py util, namely a policy/value\n",
        "  network and the Monte Carlo class.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, game, nnet,\n",
        "               critter_index=1,\n",
        "               default_depth=1,\n",
        "               default_rollouts=1,\n",
        "               default_K=4,\n",
        "               default_temp=1.0,\n",
        "               random_seed=None):\n",
        "    \"\"\"\n",
        "    Initialize Monte Carlo Parameters\n",
        "\n",
        "    Args:\n",
        "      game: Gridworld Game instance\n",
        "        Instance of the gridworldGame class above;\n",
        "      nnet: gridworldNet instance\n",
        "        Instance of the gridworldNNet class above;\n",
        "      args: dictionary\n",
        "        Instantiates number of iterations and episodes, controls temperature threshold, queue length,\n",
        "        arena, checkpointing, and neural network parameters:\n",
        "        learning-rate: 0.001, dropout: 0.3, epochs: 10, batch_size: 64,\n",
        "        num_channels: 512\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    self.game = game\n",
        "    self.critter_index = critter_index\n",
        "    assert (isinstance(critter_index, int) and\n",
        "        0 < critter_index <= game.num_critters), \"Value is not a positive integer or exceeds the upper limit.\"\n",
        "    self.nnet = nnet\n",
        "    self.default_depth = default_depth\n",
        "    self.default_rollouts = default_rollouts\n",
        "    self.mc = MonteCarlo(self.game, self.nnet, self.default_depth)\n",
        "    self.default_K = default_K\n",
        "    self.default_temp = default_temp\n",
        "    self.rng = np.random.default_rng(seed=random_seed)\n",
        "\n",
        "\n",
        "  def play(self, board,\n",
        "           num_rollouts=None,\n",
        "           rollout_depth=None,\n",
        "           K=None,\n",
        "           softmax_temp=None):\n",
        "    \"\"\"\n",
        "    Simulates a batch Monte Carlo based plays on the given board state.\n",
        "\n",
        "    Computes the probability of each valid move being played using a softmax\n",
        "    activation on the Monte Carlo based value (Q) of each action then selects a\n",
        "    move randomly for each game in the batch based on those probabilities.\n",
        "\n",
        "    Args:\n",
        "      board (dict): A dictionary representing the state of the game. It\n",
        "          contains:\n",
        "          - 'pieces': A (batch_size, x_size, y_size) numpy array indicating\n",
        "                      the pieces on the board.\n",
        "          - 'scores' (not used directly in this function, but expected in dict)\n",
        "          - 'rounds_left' (not used directly in this function, but expected in dict)\n",
        "\n",
        "    Returns:\n",
        "      tuple:\n",
        "      - a (numpy array): An array of shape (batch_size,) containing randomly\n",
        "                         chosen actions for each game in the batch.\n",
        "      - a_1hots (numpy array): An array of shape (batch_size, action_size)\n",
        "                               with one-hot encoded actions.\n",
        "      - probs (numpy array): An array of the same shape as 'valids' containing\n",
        "                             the probability of each move being played.\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    if num_rollouts is None:\n",
        "      num_rollouts = self.default_rollouts\n",
        "    if rollout_depth is None:\n",
        "      rollout_depth = self.default_depth\n",
        "    if K is None:\n",
        "      K = self.default_K\n",
        "    if softmax_temp is None:\n",
        "      softmax_temp = self.default_temp\n",
        "\n",
        "    # figure out top k actions according to normalize action probability\n",
        "    # given by our policy network prediction\n",
        "    #co_pieces = board['pieces'].copy()\n",
        "    #this_critter_locs = np.where(co_pieces == self.critter_index+1)\n",
        "    #all_critter_locs = np.where(co_pieces >= 1)\n",
        "    # other critters are invisible to this player\n",
        "    #co_pieces[all_critter_locs] = 0\n",
        "    # nnet trained to see self as 1\n",
        "    #co_pieces[this_critter_locs] = 1\n",
        "    #scalar_rounds_left = board['rounds_left'][0]\n",
        "    #co_rounds_left = scalar_rounds_left // self.game.num_critters\n",
        "    #if self.critter_index-1 < scalar_rounds_left % self.game.num_critters:\n",
        "       # add an extra if we haven't had this players turn yet in the round cycle\n",
        "    #   co_rounds_left = co_rounds_left + 1\n",
        "    #co_rounds_left = np.array([co_rounds_left]*batch_size)\n",
        "    #pis, vs = self.nnet.predict(co_pieces,\n",
        "    #                            board['scores'][:,self.critter_index-1],\n",
        "    #                            co_rounds_left)\n",
        "    pis, vs = self.mc.pis_vs_from_board(board, self.critter_index)\n",
        "    valids = self.game.get_valid_actions(board, self.critter_index)\n",
        "    masked_pis = pis * valids  # Masking invalid moves\n",
        "    sum_pis = np.sum(masked_pis, axis=1)\n",
        "    num_valid_actions = np.sum(valids, axis=1)\n",
        "    effective_topk = np.array(np.minimum(num_valid_actions, K), dtype= int)\n",
        "    probs = np.array([masked_pi / masked_pi.sum() if masked_pi.sum() > 0\n",
        "                      else valid / valid.sum()\n",
        "                      for valid, masked_pi in zip(valids, masked_pis)])\n",
        "    partioned = np.argpartition(probs,-effective_topk)\n",
        "    topk_actions = [partioned[g,-(ii+1)]\n",
        "                      for g in range(batch_size)\n",
        "                        for ii in range(effective_topk[g])]\n",
        "    topk_actions_index = [ii\n",
        "                            for ii, etk in enumerate(effective_topk)\n",
        "                              for _ in range(etk)]\n",
        "    values = np.zeros(len(topk_actions))\n",
        "    # Do some rollouts\n",
        "    for _ in range(num_rollouts):\n",
        "      values = values + self.mc.simulate(board, topk_actions,\n",
        "                                         topk_actions_index,\n",
        "                                         critter=self.critter_index,\n",
        "                                         depth=rollout_depth)\n",
        "    values = values / num_rollouts\n",
        "\n",
        "    value_expand = np.zeros((batch_size, n_rows*n_cols))\n",
        "    value_expand[(topk_actions_index, topk_actions)] = values\n",
        "    value_expand_shift = value_expand - np.max(value_expand, axis=1, keepdims=True)\n",
        "    value_expand_scale = value_expand_shift/softmax_temp\n",
        "    v_probs = np.exp(value_expand_scale) / np.sum(\n",
        "        np.exp(value_expand_scale), axis=1, keepdims=True)\n",
        "    v_probs = v_probs * valids\n",
        "    v_probs = v_probs / np.sum(v_probs, axis=1, keepdims=True)\n",
        "    samp = self.rng.uniform(size = batch_size).reshape((batch_size,1))\n",
        "    sampled_actions = np.argmax(v_probs.cumsum(axis=1) > samp, axis=1)\n",
        "    a_1Hots = np.zeros((batch_size, n_rows*n_cols))\n",
        "    a_1Hots[(range(batch_size), sampled_actions)] = 1.0\n",
        "    return sampled_actions, a_1Hots, v_probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class SimpleRulePlayer():\n",
        "  \"\"\"\n",
        "  A Player based on the following simple policy:\n",
        "  If there is any food immediately nearby move towards it,\n",
        "  otherwise it move randomly.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, game, fov_radius=2, critter_index=1):\n",
        "    \"\"\"\n",
        "\n",
        "    \"\"\"\n",
        "    self.game = game\n",
        "    self.critter_index = critter_index\n",
        "    assert (isinstance(critter_index, int) and\n",
        "        0 < critter_index <= game.num_critters), \"Value is not a positive integer or exceeds the upper limit.\"\n",
        "    self.fov_radius = fov_radius\n",
        "\n",
        "\n",
        "  def simple_action_from_percept(self, percept):\n",
        "    \"\"\"\n",
        "    Determine an action based on perception.\n",
        "\n",
        "    Args:\n",
        "      percept: A 1D array (len 12 if fov_radius = 2)representing the perception\n",
        "        of the organism. Indices correspond to spaces around the organism. The\n",
        "        values in the array can be -2 (out-of-bounds), 0 (empty space), or\n",
        "        -1 (food).\n",
        "\n",
        "    Returns:\n",
        "      action: a str, one of 'up', 'down', 'left', 'right'. If food in one or\n",
        "        more of the spaces immediately beside the organism, the function will\n",
        "        return a random choice among these directions. If there is no food\n",
        "        nearby, the function will return a random direction.\n",
        "    \"\"\"\n",
        "    # a human interpretable overview of the percept structure\n",
        "    percept_struct = [\n",
        "      'far up', 'left up', 'near up', 'right up',\n",
        "      'far left', 'near left', 'near right', 'far right',\n",
        "      'left down', 'near down', 'right down', 'far down']\n",
        "    # Defines directions corresponding to different perception indices\n",
        "    direction_struct = [\n",
        "      'None', 'None', 'up', 'None',\n",
        "      'None', 'left', 'right', 'None',\n",
        "      'None', 'down', 'None', 'None']\n",
        "    # these are what count as nearby in the percept\n",
        "    nearby_directions = ['near up', 'near left', 'near right', 'near down']\n",
        "    # Get the corresponding indices in the percept array\n",
        "    nearby_indices = [percept_struct.index(dir_) for dir_ in nearby_directions]\n",
        "    # Identify the directions where food is located\n",
        "    food_indices = [index for index in nearby_indices if percept[index] == -1]\n",
        "    food_directions = [direction_struct[index] for index in food_indices]\n",
        "\n",
        "    action_probs = {'up': 0.0, 'down': 0.0, 'left': 0.0, 'right': 0.0}\n",
        "    if len(food_directions) > 0:  # If there is any food nearby\n",
        "      # If there is any food nearby randomly choose a direction with food\n",
        "      action = self.game.rng.choice(food_directions)  # Move towards a random one\n",
        "      for direction in food_directions:\n",
        "        action_probs[direction] = 1.0 /len(food_directions)\n",
        "    else:\n",
        "      # If there is no food nearby, move randomly\n",
        "      action = self.game.rng.choice(['up', 'down', 'left', 'right'])\n",
        "      for direction in ['up', 'down', 'left', 'right']:\n",
        "        action_probs[direction] = 0.25\n",
        "\n",
        "    return action, action_probs\n",
        "\n",
        "\n",
        "  def play(self, board):\n",
        "    \"\"\"\n",
        "    Simulate Play on a Board\n",
        "\n",
        "    Args:\n",
        "      board: dict {'pieces':\n",
        "      (batch x num_rows x num_cols) np.ndarray of board position,\n",
        "                  'scores': batch len array of current scores,\n",
        "                  'rounds_left': batch len array of rounds left\n",
        "\n",
        "    Returns:\n",
        "      sampled_actions: a batch, row, col index of the move taken\n",
        "      by each player on each board\n",
        "      a_1hots: a batch nrow*ncol array of 1hot indices of those same moves\n",
        "      probs: sampling probabilities for those 1hots (If the policy\n",
        "      is deterministic a_1hots is returned here as well... or if getting the\n",
        "      probs is an un-needed fuss to compute)\n",
        "\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    perceptions = self.game.get_perceptions(board, self.fov_radius,\n",
        "                                            self.critter_index)\n",
        "\n",
        "    critter_oriented_moves = []\n",
        "    direction_probs = []\n",
        "    for g in range(batch_size):\n",
        "      action, action_probs = self.simple_action_from_percept(perceptions[g])\n",
        "      critter_oriented_moves.append(action)\n",
        "      direction_probs.append(action_probs)\n",
        "    moves = self.game.critter_direction_to_move(board, critter_oriented_moves,\n",
        "                                                direction_probs,\n",
        "                                                self.critter_index)\n",
        "    probs = self.game.direction_probs_to_flat_probs(board, direction_probs)\n",
        "    sampled_actions = self.game.moves_to_actions(moves)\n",
        "    a_1hots = np.zeros((batch_size, n_rows*n_cols))\n",
        "    a_1hots[(range(batch_size), sampled_actions)] = 1.0\n",
        "\n",
        "    return sampled_actions, a_1hots, probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PerceptParamPlayer():\n",
        "  \"\"\"\n",
        "  A Player playing a parameterized policy defined by the given weights\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, game, weights=None, fov_radius=2, critter_index=1):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      game: Gridworld Game instance\n",
        "        Instance of the gridworldGame class above;\n",
        "      weights: 4 x 12 numpy array (assumes fov_radius = 2), that gives the\n",
        "        connection strengths between the 'perception' neurons and the direction\n",
        "        'neurons'\n",
        "      fov_radius: int how far around itself the critter perceives, weights is\n",
        "        expecting fov_radius = 2\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    self.game = game\n",
        "    self.critter_index = critter_index\n",
        "    assert (isinstance(critter_index, int) and\n",
        "        0 < critter_index <= game.num_critters), \"Value is not a positive integer or exceeds the upper limit.\"\n",
        "    if weights is None:\n",
        "      self.W = np.array(\n",
        "      [[1., 1., 4., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 4., 1., 1.],\n",
        "       [0., 1., 0., 0., 1., 4., 0., 0., 1., 0., 0., 0.],\n",
        "       [0., 0., 0., 1., 0., 0., 4., 1., 0., 0., 1., 0.]])\n",
        "    else:\n",
        "      self.W = weights\n",
        "    self.fov_radius = fov_radius\n",
        "    self.default_softmax_temp = 0.05\n",
        "\n",
        "\n",
        "  def param_action_from_percept(self, percept, valid_directions, W,\n",
        "                                softmax_temp=None):\n",
        "    \"\"\"\n",
        "    Determine an action based on perception.\n",
        "\n",
        "    Args:\n",
        "      percept: A 1D len 12 array representing the perception of the organism.\n",
        "        Indices correspond to spaces around the organism. The values in the\n",
        "        array can be -2 (out-of-bounds), 0 (empty space), or -1 (food).\n",
        "      W: a 4 x 12 weight matrix parameter representing the connection strengths\n",
        "        between the 12 perceptions inputs and the 4 possible output actions.\n",
        "\n",
        "    Returns:\n",
        "      direction: a str, one of 'up', 'down', 'left', 'right'. If food in one or\n",
        "        more of the spaces immediately beside the organism, the function will\n",
        "        return a random choice among these directions. If there is no food\n",
        "        nearby, the function will return a random direction.\n",
        "      direction_probs: dictionary with probabilities of taking each action.\n",
        "    \"\"\"\n",
        "    if len(valid_directions) == 0:\n",
        "      # if there is no where legit to move, stay put\n",
        "      return 'still', {direction: 0 for direction in output_struct}\n",
        "\n",
        "    if softmax_temp is None:\n",
        "      # very low temp, basically deterministic for this range of values\n",
        "      softmax_temp = self.default_softmax_temp\n",
        "    # a human interpretable overview of the percept structure\n",
        "    percept_struct = [\n",
        "      'far up', 'left up', 'near up', 'right up',\n",
        "      'far left', 'near left', 'near right', 'far right',\n",
        "      'left down', 'near down', 'right down', 'far down']\n",
        "    # a human interpretable overview of the out structure\n",
        "    output_struct = ['up', 'down', 'left', 'right']\n",
        "    # boolean representation of percept, no edges, just 1's where food is,\n",
        "    # zero otherwise, also means other organisms are invisible\n",
        "    x = np.asarray(percept == -1, int)\n",
        "    output_activations = W @ x\n",
        "\n",
        "    # softmax shift by max, scale by temp\n",
        "    shift_scale_ex = np.exp((output_activations -\n",
        "                             np.max(output_activations))/softmax_temp)\n",
        "    # set invalid direction activations to zero\n",
        "    invalid_directions = [direction for direction in output_struct\n",
        "                           if direction not in valid_directions]\n",
        "    invalid_indices = [output_struct.index(direction)\n",
        "                        for direction in valid_directions]\n",
        "    sm = shift_scale_ex / shift_scale_ex.sum() #normalized\n",
        "    # set invalid direction probabilities to zero\n",
        "    invalid_directions = [direction for direction in output_struct\n",
        "                           if direction not in valid_directions]\n",
        "    invalid_indices = [output_struct.index(direction)\n",
        "                        for direction in invalid_directions]\n",
        "    sm[invalid_indices] = 0\n",
        "    probs_sm = sm / sm.sum(axis=0) #re-normalized again for fp issues\n",
        "    direction = self.game.rng.choice(output_struct, p=probs_sm)\n",
        "    direction_probs = {direction: prob\n",
        "                        for direction, prob in zip(output_struct, probs_sm)}\n",
        "    return direction, direction_probs\n",
        "\n",
        "\n",
        "  def play(self, board, temp=None):\n",
        "    \"\"\"\n",
        "    Simulate Play on a Board\n",
        "\n",
        "    Args:\n",
        "      board: dict {'pieces':\n",
        "      (batch x num_rows x num_cols) np.ndarray of board position,\n",
        "                  'scores': batch len array of current scores,\n",
        "                  'rounds_left': batch len array of rounds left\n",
        "\n",
        "    Returns:\n",
        "      sampled_actions: a batch, row, col index of the move taken\n",
        "      by each player on each board\n",
        "      a_1hots: a batch nrow*ncol array of 1hot indices of those same moves\n",
        "      v_probs: sampling probabilities for those 1hots (If the policy\n",
        "      is deterministic a_1hots is returned here as well... or if getting the\n",
        "      probs is an un-needed fuss to compute)\n",
        "    \"\"\"\n",
        "    if temp is None:\n",
        "      temp = self.default_softmax_temp\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    perceptions = self.game.get_perceptions(board, self.fov_radius,\n",
        "                                            self.critter_index)\n",
        "    critter_oriented_moves = []\n",
        "    direction_probs = []\n",
        "\n",
        "    # Get valid actions for each game in the batch\n",
        "    valid_directions = self.game.get_valid_directions(board, self.critter_index)\n",
        "    for g in range(batch_size):\n",
        "      direction, batch_direction_probs = self.param_action_from_percept(\n",
        "        perceptions[g], valid_directions[g], self.W, softmax_temp=temp)\n",
        "      critter_oriented_moves.append(direction)\n",
        "      direction_probs.append(batch_direction_probs)\n",
        "    moves = self.game.critter_direction_to_move(board, critter_oriented_moves,\n",
        "                                                self.critter_index)\n",
        "    probs = self.game.direction_probs_to_flat_probs(board, direction_probs, self.critter_index)\n",
        "    sampled_actions = self.game.moves_to_actions(moves)\n",
        "    a_1hots = np.zeros((batch_size, n_rows*n_cols))\n",
        "    a_1hots[(range(batch_size), sampled_actions)] = 1.0\n",
        "\n",
        "    return sampled_actions, a_1hots, probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class BatchOptPerceptParamPlayer():\n",
        "  \"\"\"\n",
        "  A Player playing a parameterized policy defined by the given weights\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, game, weights=None, fov_radius=2, critter_index=1,\n",
        "               get_probs=False, deterministic=False):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      game: Gridworld Game instance\n",
        "        Instance of the gridworldGame class above;\n",
        "      weights: 4 x 12 numpy array (assumes fov_radius = 2), that gives the\n",
        "        connection strengths between the 'perception' neurons and the direction\n",
        "        'neurons'\n",
        "      fov_radius: int how far around itself the critter percieves, weights is\n",
        "        expecting fov_radius = 2\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    # all critters need these things\n",
        "    self.game = game\n",
        "    self.critter_index = critter_index\n",
        "    assert (isinstance(critter_index, int) and\n",
        "        0 < critter_index <= game.num_critters), \"Value is not a positive integer or exceeds the upper limit.\"\n",
        "    self.get_probs = get_probs\n",
        "    # these things are specfic to this kind of critter\n",
        "    self.deterministic = deterministic\n",
        "    if weights is None:\n",
        "      self.W = np.array(\n",
        "      [[1., 1., 4., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 4., 1., 1.],\n",
        "       [0., 1., 0., 0., 1., 4., 0., 0., 1., 0., 0., 0.],\n",
        "       [0., 0., 0., 1., 0., 0., 4., 1., 0., 0., 1., 0.]])\n",
        "    else:\n",
        "      self.W = weights\n",
        "    self.fov_radius = fov_radius\n",
        "    self.default_softmax_temp = 0.05\n",
        "\n",
        "\n",
        "  def direction_value_from_percept(self, percepts, W):\n",
        "    \"\"\"\n",
        "    Determine an action based on perception.\n",
        "\n",
        "    Args:\n",
        "      percept: A batch by 1D len 12 array representing the perceptions of the\n",
        "      organism. Indices correspond to spaces around the organism. The values in\n",
        "      the array can be -2 (out-of-bounds), 0 (empty space), or -1 (food).\n",
        "      W: a 4 x 12 weight matrix parameter representing the connection strengths\n",
        "        between the 12 perceptions inputs and the 4 possible output actions.\n",
        "\n",
        "    Returns:\n",
        "      direction_probs: array of probabilities of taking each action.\n",
        "    \"\"\"\n",
        "    # a human interpretable overview of the percept structure\n",
        "    #percept_struct = [\n",
        "    #  'far up', 'left up', 'near up', 'right up',\n",
        "    #  'far left', 'near left', 'near right', 'far right',\n",
        "    #  'left down', 'near down', 'right down', 'far down']\n",
        "    # a human interpretable overview of the out structure\n",
        "    #output_struct = ['up', 'down', 'left', 'right']\n",
        "    # boolean representation of percept, no edges, just 1's where food is,\n",
        "    # zero otherwise, also means other organisms are invisible\n",
        "    # x is batch x 12\n",
        "    x = np.asarray(percepts == -1, int)\n",
        "    # W is 4 x 12\n",
        "    # this does the broadcasting we want\n",
        "    output_activations = (W @ x.T).T\n",
        "    # output activations is batch by 4\n",
        "    return output_activations\n",
        "\n",
        "\n",
        "  def play(self, board, temp=None, W=None):\n",
        "    \"\"\"\n",
        "    Simulate Play on a Board\n",
        "\n",
        "    Args:\n",
        "      board: dict {'pieces':\n",
        "      (batch x num_rows x num_cols) np.ndarray of board position,\n",
        "                  'scores': batch len array of current scores,\n",
        "                  'rounds_left': batch len array of rounds left\n",
        "\n",
        "    Returns:\n",
        "      sampled_actions: a batch, row, col index of the move taken\n",
        "      by each player on each board\n",
        "      a_1hots: a batch nrow*ncol array of 1hot indices of those same moves\n",
        "      v_probs: sampling probabilities for those 1hots (If the policy\n",
        "      is deterministic a_1hots is returned here as well... or if getting the\n",
        "      probs is an un-needed fuss to compute)\n",
        "    \"\"\"\n",
        "    if temp is None:\n",
        "      temp = self.default_softmax_temp\n",
        "    if W is None:\n",
        "      W = self.W\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    perceptions = self.game.get_perceptions(board, self.fov_radius,\n",
        "                                            self.critter_index)\n",
        "    # note the fragile order based dependency on how legal offsets is written,\n",
        "    # and how output activations are interpreted\n",
        "    direction_v = self.direction_value_from_percept(perceptions, W)\n",
        "    flat_ds = direction_v.T.ravel()\n",
        "\n",
        "    critter_locs = np.array(np.where(board['pieces'] == self.critter_index))\n",
        "    legal_offsets = np.stack([\n",
        "    critter_locs + np.array([np.array([0, -1,  0])]*batch_size).T, # up\n",
        "    critter_locs + np.array([np.array([0,  1,  0])]*batch_size).T, # down\n",
        "    critter_locs + np.array([np.array([0,  0, -1])]*batch_size).T, # left\n",
        "    critter_locs + np.array([np.array([0,  0,  1])]*batch_size).T]) #right\n",
        "    legal_offsets = np.vstack(np.transpose(legal_offsets, (0, 2, 1)))\n",
        "\n",
        "    # conditions for offsets on the board\n",
        "    c1 = legal_offsets[:,1] >= 0\n",
        "    c2 = legal_offsets[:,1] <= n_rows-1\n",
        "    c3 = legal_offsets[:,2] >= 0\n",
        "    c4 = legal_offsets[:,2] <= n_cols-1\n",
        "    all_c = np.logical_and.reduce([c1, c2, c3, c4])\n",
        "\n",
        "    batch_indexes = legal_offsets[:,0][all_c]\n",
        "    action_indexes = legal_offsets[:,1][all_c] * n_cols + legal_offsets[:,2][all_c]\n",
        "    direction_values = flat_ds[all_c]\n",
        "    value_expand = np.zeros((batch_size, n_rows*n_cols))\n",
        "    value_expand[(batch_indexes, action_indexes)] = direction_values\n",
        "    valids = gwg.get_valid_actions(board, self.critter_index)\n",
        "    # Set invalid positions to -inf\n",
        "    valid_value_expand = np.where(valids == 1, value_expand, -np.inf)\n",
        "    if self.deterministic:\n",
        "      sampled_actions = np.argmax(valid_value_expand, axis=1)\n",
        "      a_1Hots = np.zeros((batch_size, n_rows * n_cols))\n",
        "      a_1Hots[np.arange(batch_size), sampled_actions] = 1.0\n",
        "      v_probs = a_1Hots\n",
        "    else:\n",
        "      # Subtract max for numerical stability\n",
        "      value_expand_shift = valid_value_expand - np.max(valid_value_expand,\n",
        "                                                       axis=1, keepdims=True)\n",
        "      # softmax temp scaling\n",
        "      value_expand_scale = value_expand_shift/temp\n",
        "      exp_value = np.exp(value_expand_scale)\n",
        "      # Normalize by the sum of the exponentiated values for each row\n",
        "      v_probs = exp_value / np.sum(exp_value, axis=1, keepdims=True)\n",
        "      v_probs = v_probs / np.sum(v_probs, axis=1, keepdims=True)\n",
        "      samp = self.game.rng.uniform(size = batch_size).reshape((batch_size,1))\n",
        "      sampled_actions = np.argmax(v_probs.cumsum(axis=1) > samp, axis=1)\n",
        "      a_1Hots = np.zeros((batch_size, n_rows*n_cols))\n",
        "      a_1Hots[(range(batch_size), sampled_actions)] = 1.0\n",
        "    return sampled_actions, a_1Hots, v_probs"
      ],
      "metadata": {
        "id": "tBF1N1i5L0dP",
        "cellView": "form"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title interactive gridworld widgets\n",
        "\n",
        "########################################\n",
        "# widgets refactor for multi-critter\n",
        "#########################################\n",
        "# Interactive Gridworld Game Widgets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class InteractiveGridworld():\n",
        "  \"\"\"\n",
        "  A widget based object for interacting with a gridworld game\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, gridworld_game, init_board=None, has_fov=False,\n",
        "               radius=2, collect_fov_data=False,\n",
        "               figsize=(6,5), critter_names=['Critter'], players=['human']):\n",
        "    \"\"\"\n",
        "    Initializes a widget based object for interacting with a gridworld game\n",
        "\n",
        "    Args:\n",
        "      gridworld_game: an instance of GridworldGame object\n",
        "        expects this to have batchsize 1\n",
        "      init_board: (optional) a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "        if left out will initialize with a random board state\n",
        "      has_fov: bool, whether or not to display fog of war around the critter\n",
        "      radius: int, number of squares the critter can \"see\" around it\n",
        "      figsize: tuple (int, int), size of the figure\n",
        "      critter_names: a list of strings that determines what the critter is called\n",
        "        in the plot legend, order should align with players\n",
        "      player: a list of either 'human', None, or a player object with a play\n",
        "        method and a critter_index attribute. If 'human' use buttons,  if None\n",
        "        default to making a RandomValidPlayer object, otherwise use the\n",
        "        player class provided to make the player objects and use a start button.\n",
        "        The list needs to be as long as the gridworld_game.num_critters\n",
        "        attribute. Order should align with critter_name.\n",
        "\n",
        "      Note: fov is going to look pretty janky with more than one player, maybe\n",
        "      we get fov to only turn on for the 'active' player?\n",
        "    \"\"\"\n",
        "\n",
        "    # Set GridworldGame object and initialize the board state\n",
        "    self.gwg = gridworld_game\n",
        "    self.has_fov = has_fov\n",
        "    self.radius = radius\n",
        "    self.percept_len = 2*self.radius*(self.radius+1)\n",
        "    self.collect_fov_data = collect_fov_data\n",
        "    self.figsize = figsize\n",
        "    # initialize players and plotting specs together to ensure alignment\n",
        "    self.players = []\n",
        "    self.any_human_players = False\n",
        "    self.crit_specs = []\n",
        "    markers = ['h', 'd']  # hexagon and diamond\n",
        "    colors = sns.color_palette(\"colorblind\")\n",
        "    for i in range(self.gwg.num_critters):\n",
        "      spec = {'marker': markers[i % len(markers)],\n",
        "              'color': colors[i // len(markers) % len(colors)],\n",
        "              'name': critter_names[i],\n",
        "              'int_id': i+1}\n",
        "      self.crit_specs.append(spec)\n",
        "      player = players[i] #implict check that players is at least long enough\n",
        "      if player is None:\n",
        "        self.players.append(RandomValidPlayer(self.gwg, critter_index=i+1))\n",
        "      elif player == 'human':\n",
        "        self.players.append('human')\n",
        "        # right now only ever have on human player with index 1\n",
        "        self.any_human_players = True\n",
        "      else:\n",
        "        player.critter_index = i+1\n",
        "        self.players.append(player)\n",
        "    self.final_scores = []\n",
        "    if init_board is None:\n",
        "      self.board_state = self.gwg.get_init_board()\n",
        "    else:\n",
        "      self.board_state = init_board\n",
        "    if self.collect_fov_data is True:\n",
        "      # keep raw records of percept and eating for manipulation later\n",
        "      self.percept_eat_records = []\n",
        "      # keep data in contingency table of how many food items were in\n",
        "      # the percept, and whether or not food was eaten\n",
        "      self.fov_eat_table_data = np.zeros((2, self.percept_len+1))\n",
        "    # Initialize widgets and buttons\n",
        "    self.output = widgets.Output(layout=widgets.Layout(\n",
        "      width = '20.0em', min_width='20.0em', max_width='21.0em',\n",
        "      min_height='10.0em', overflow='auto'))\n",
        "    self.scoreboard = widgets.Output(layout=widgets.Layout(\n",
        "      min_width='12.5em', max_width='18.8em',\n",
        "      min_height='6.3em', overflow='auto'))\n",
        "    self.fov_eat_table_display = widgets.Output(layout=widgets.Layout(\n",
        "      min_width='25.0em', min_height='18.8em', overflow='auto'))\n",
        "    self.up_button = widgets.Button(description=\"Up\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.down_button = widgets.Button(description=\"Down\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.left_button = widgets.Button(description=\"Left\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.right_button = widgets.Button(description=\"Right\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.start_button = widgets.Button(description=\"Start\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "\n",
        "    # get plot canvas widgets and other plotting objects\n",
        "    plt.ioff()\n",
        "    if self.collect_fov_data and self.any_human_players:\n",
        "      self.legend_type = None # don't keep regenerating the legend\n",
        "      # do legend separately if showing observations and no human player\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov,\n",
        "       self.b_fig_legend, self.b_ax_legend) = self.gwg.plot_board(\n",
        "          self.board_state, g=0, critter_specs=self.crit_specs,\n",
        "          legend_type='separate', figsize=self.figsize, has_fov=self.has_fov,\n",
        "          radius=self.radius)\n",
        "    elif len(self.players) > 1:\n",
        "      self.legend_type=None # don't keep regenerating the legend\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov,\n",
        "       self.b_fig_legend, self.b_ax_legend) = self.gwg.plot_board(\n",
        "          self.board_state, g=0, critter_specs=self.crit_specs,\n",
        "          has_fov=self.has_fov, legend_type='separate',\n",
        "          radius=self.radius, figsize=self.figsize)\n",
        "    else:\n",
        "      self.legend_type = 'included'\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov\n",
        "        ) = self.gwg.plot_board(self.board_state, g=0,\n",
        "                                critter_specs=self.crit_specs,\n",
        "                                has_fov=self.has_fov,\n",
        "                                radius=self.radius, figsize=self.figsize)\n",
        "    # lump buttons together\n",
        "    self.buttons = widgets.HBox([self.left_button,\n",
        "                               widgets.VBox([self.up_button, self.down_button]),\n",
        "                               self.right_button])\n",
        "    # automatically pick different layouts for different situations\n",
        "    if self.any_human_players:\n",
        "      self.board_and_buttons = widgets.VBox([self.b_fig.canvas,\n",
        "                                             self.buttons])\n",
        "      if len(self.players) == 1:\n",
        "        #one human player\n",
        "        self.output_and_score = widgets.HBox([self.scoreboard, self.output])\n",
        "        self.no_table_final_display = widgets.VBox([self.board_and_buttons,\n",
        "                                                  self.output_and_score])\n",
        "        if self.collect_fov_data == True:\n",
        "          # a single human player collecting data\n",
        "          self.final_display = widgets.HBox([self.no_table_final_display,\n",
        "                                           self.fov_eat_table_display])\n",
        "        else: # self.collect_fov_data == False:\n",
        "          # a single human player not collecting data\n",
        "          self.final_display = self.no_table_final_display\n",
        "      else:\n",
        "        # more than one player, one of them human\n",
        "        self.V_board_outbput = widgets.VBox([self.board_and_buttons,\n",
        "                                             self.output])\n",
        "        self.V_scoreboard_start_legend = widgets.VBox([\n",
        "        self.scoreboard, self.start_button, self.b_fig_legend.canvas])\n",
        "        self.final_display = widgets.HBox([self.V_board_outbput,\n",
        "                                             self.V_scoreboard_start_legend])\n",
        "    else: # player is some kind of ai\n",
        "      if self.collect_fov_data == True:\n",
        "        # an ai player with recording\n",
        "        # in this case legend is separate\n",
        "        self.V_score_start_output_legend = widgets.VBox([self.scoreboard,\n",
        "          self.start_button,  self.output, self.b_fig_legend.canvas])\n",
        "        self.V_board_table = widgets.VBox([self.b_fig.canvas,\n",
        "                                           self.fov_eat_table_display])\n",
        "        self.final_display = widgets.HBox([self.V_board_table,\n",
        "                                           self.V_score_start_output_legend])\n",
        "      else:\n",
        "        if len(self.players) == 1:\n",
        "          # an ai player without recording\n",
        "          self.H_score_output_start = widgets.HBox([\n",
        "            self.scoreboard, self.output, self.start_button])\n",
        "          self.final_display = widgets.VBox([\n",
        "            self.b_fig.canvas, self.H_score_output_start])\n",
        "        else:\n",
        "          # more than one ai player\n",
        "          self.V_board_outbput = widgets.VBox([self.b_fig.canvas, self.output])\n",
        "          self.V_scoreboard_start_legend = widgets.VBox([\n",
        "              self.scoreboard, self.start_button, self.b_fig_legend.canvas])\n",
        "          self.final_display = widgets.HBox([self.V_board_outbput,\n",
        "                                             self.V_scoreboard_start_legend])\n",
        "\n",
        "    # initialize text outputs\n",
        "    with self.scoreboard:\n",
        "      table = [['High Score:'] + ['--'] * self.gwg.num_critters,\n",
        "               ['Last Score:'] + ['--'] * self.gwg.num_critters,\n",
        "               ['Average Score:'] + ['--'] * self.gwg.num_critters,]\n",
        "      if len(self.players) > 1:\n",
        "        headers = [''] + [f'P{i+1}' for i in range(self.gwg.num_critters)]\n",
        "        print(tabulate(table, headers=headers))\n",
        "      else: # len(self.players) == 1\n",
        "        print(tabulate(table))\n",
        "    with self.output:\n",
        "      if self.any_human_players:\n",
        "        print('Click a button to start playing')\n",
        "      else:\n",
        "        print('Click the start button to run the simulation')\n",
        "    with self.fov_eat_table_display:\n",
        "      printmd(\"**Observations**\")\n",
        "      table_data = [[str(ii),\n",
        "                     str(self.fov_eat_table_data[0,ii]),\n",
        "                     str(self.fov_eat_table_data[1,ii])] for ii in range(11)]\n",
        "      table = ([['Food in Percept', 'Food Not Eaten', 'Food Eaten']] +\n",
        "               table_data)\n",
        "      print(tabulate(table))\n",
        "\n",
        "    # Connect the buttons to functions that do something\n",
        "    self.up_button.on_click(self.on_up_button_clicked)\n",
        "    self.down_button.on_click(self.on_down_button_clicked)\n",
        "    self.left_button.on_click(self.on_left_button_clicked)\n",
        "    self.right_button.on_click(self.on_right_button_clicked)\n",
        "    self.start_button.on_click(self.on_start_button_clicked)\n",
        "\n",
        "\n",
        "  def button_output_update(self, which_button):\n",
        "    old_board = self.board_state.copy()\n",
        "    # index is 0 through num_critter-1, critter value in pieces is\n",
        "    # index + 1\n",
        "    active_player_index = old_board['active_player']\n",
        "    old_scores = old_board['scores'][0]\n",
        "    if self.collect_fov_data is True:\n",
        "      batch_size, n_rows, n_cols = old_board['pieces'].shape\n",
        "      b = GridworldBoard(batch_size, n_rows, n_cols,\n",
        "                         self.gwg.num_food, self.gwg.lifetime,\n",
        "                         rng=self.gwg.rng)\n",
        "      b.set_state(old_board)\n",
        "      percept = b.get_perceptions(self.radius)[0]\n",
        "\n",
        "    #print(self.players[active_player_index])\n",
        "    #print(active_player_index)\n",
        "    #if not self.players[active_player_index] == 'human':\n",
        "    #  print(self.players[active_player_index].critter_index)\n",
        "    #else:\n",
        "    #  print('human has no critter_index attribute')\n",
        "\n",
        "    if (isinstance(self.players[active_player_index], str) and\n",
        "        'human' in self.players[active_player_index]):\n",
        "      direction = which_button\n",
        "    else:\n",
        "      a_player, _, _ = self.players[active_player_index].play(old_board)\n",
        "      # print(a_player)\n",
        "      a_player = self.gwg.action_to_critter_direction(old_board,\n",
        "                                                      active_player_index+1,\n",
        "                                                      a_player)\n",
        "      # but we only want to apply their move to the appropriate board\n",
        "      direction = a_player[0]\n",
        "\n",
        "    self.board_state = self.gwg.critter_oriented_get_next_state(\n",
        "          self.board_state, active_player_index+1, [direction])\n",
        "    new_scores = self.board_state['scores'][0] #first batch first critter type\n",
        "    rounds_left = self.board_state['rounds_left'][0]\n",
        "    num_moves = np.floor(self.gwg.lifetime -\n",
        "                         rounds_left / self.gwg.num_critters)\n",
        "    if new_scores[active_player_index] > old_scores[active_player_index]:\n",
        "      #eating happened\n",
        "      eating_string = \"They ate the food there!\"\n",
        "      did_eat = 1\n",
        "    else: #eating didn't happen\n",
        "      eating_string = \"There's no food there.\"\n",
        "      did_eat = 0\n",
        "    row, col = self.gwg.get_critter_rc(self.board_state, 0,\n",
        "                                       active_player_index+1)\n",
        "    (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov\n",
        "     ) = self.gwg.plot_board(self.board_state, g=0,\n",
        "                             fig=self.b_fig, ax=self.b_ax,\n",
        "                             critter_specs=self.b_crit_specs, food=self.b_food,\n",
        "                             fov=self.b_fov, has_fov=self.has_fov,\n",
        "                             radius=self.radius, legend_type=self.legend_type)\n",
        "    if self.collect_fov_data is True:\n",
        "      p_e_data = {'perception': percept.copy(),\n",
        "                  'state': old_board,\n",
        "                  'did_eat': bool(did_eat)}\n",
        "      self.percept_eat_records.append(p_e_data)\n",
        "      percept_int = np.sum(percept==-1) # number of food items in FoV\n",
        "      self.fov_eat_table_data[did_eat, percept_int] += 1\n",
        "\n",
        "    with self.output:\n",
        "      clear_output()\n",
        "      if len(self.players) == 1:\n",
        "        print(\"The critter (tried) to move \" + direction +\n",
        "              \" and is now at ({}, {}).\".format(row,col))\n",
        "        print(eating_string)\n",
        "        print(\"Rounds Left: {}\\nFood Eaten: {}\\nFood Per Move: {:.2f}\".format(\n",
        "            rounds_left, new_scores[active_player_index],\n",
        "            new_scores[active_player_index] / num_moves))\n",
        "      else: # more than one players\n",
        "        print(\"Critter {} (tried) to move \".format(active_player_index+1) +\n",
        "              direction +\n",
        "              \" and is now at ({}, {}).\".format(row, col))\n",
        "        print(eating_string)\n",
        "        print(\"Rounds Left: {}\\nFood Eaten: {}\".format(\n",
        "            rounds_left, new_scores))\n",
        "    if rounds_left == 0:\n",
        "      self.final_scores.append(new_scores)\n",
        "      with self.output:\n",
        "        clear_output\n",
        "        print('Game Over. Final Score {}'.format(new_scores))\n",
        "        print('Resetting the board for another game')\n",
        "        self.board_state = self.gwg.get_init_board()\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov\n",
        "       ) = self.gwg.plot_board(self.board_state, 0, self.b_fig, self.b_ax,\n",
        "                               self.b_crit_specs, self.b_food, self.b_fov,\n",
        "                               has_fov=self.has_fov, radius=self.radius,\n",
        "                               legend_type=self.legend_type)\n",
        "    with self.scoreboard:\n",
        "        clear_output()\n",
        "        print('Games Played: ' + str(len(self.final_scores)))\n",
        "        if len(self.players) == 1:\n",
        "          if len(self.final_scores) > 0:\n",
        "            table = [\n",
        "              ['High Score:', str(np.max(np.array(self.final_scores)))],\n",
        "              ['Last Score:', str(self.final_scores[-1])],\n",
        "              ['Average Score',\n",
        "              '{:.2f}'.format(np.mean(np.array(self.final_scores)))]]\n",
        "          else:\n",
        "            table = [['High Score:', '--'],\n",
        "                     ['Last Score:', '--'],\n",
        "                     ['Average Score:', '--']]\n",
        "          print(tabulate(table))\n",
        "        else: # len(self.players) > 1\n",
        "          headers = [''] + [f'P{i+1}' for i in range(self.gwg.num_critters)]\n",
        "          if len(self.final_scores) > 0:\n",
        "            table = []\n",
        "            # Assuming the batch size is 1 for now\n",
        "            current_scores = self.final_scores[-1]\n",
        "            max_scores = np.max(np.array(self.final_scores), axis=0)\n",
        "            average_scores = np.mean(np.array(self.final_scores), axis=0)\n",
        "            table.append(['High Scores:'] +\n",
        "              [str(score) for score in max_scores])\n",
        "            table.append(['Last Scores:'] +\n",
        "              [str(score) for score in current_scores])\n",
        "            table.append(['Average Scores:'] +\n",
        "              ['{:.2f}'.format(score) for score in average_scores])\n",
        "          else:\n",
        "            table = [\n",
        "              ['High Score:'] + ['--'] * self.gwg.num_critters,\n",
        "              ['Last Score:'] + ['--'] * self.gwg.num_critters,\n",
        "              ['Average Score:'] + ['--'] * self.gwg.num_critters,]\n",
        "          print(tabulate(table, headers=headers))\n",
        "\n",
        "    with self.fov_eat_table_display:\n",
        "      clear_output()\n",
        "      printmd(\"**Observations**\")\n",
        "      table_data = [[str(ii),\n",
        "                     str(self.fov_eat_table_data[0,ii]),\n",
        "                     str(self.fov_eat_table_data[1,ii])] for ii in range(11)]\n",
        "      table = ([['Food in Percept', 'Food Not Eaten', 'Food Eaten']] +\n",
        "               table_data)\n",
        "      print(tabulate(table))\n",
        "\n",
        "  def disable_direction_buttons(self):\n",
        "    self.up_button.disabled = True\n",
        "    self.down_button.disabled = True\n",
        "    self.left_button.disabled = True\n",
        "    self.right_button.disabled = True\n",
        "\n",
        "  def enable_direction_buttons(self):\n",
        "    self.up_button.disabled = False\n",
        "    self.down_button.disabled = False\n",
        "    self.left_button.disabled = False\n",
        "    self.right_button.disabled = False\n",
        "\n",
        "  def human_ai_player_loop(self, direction):\n",
        "    self.disable_direction_buttons()\n",
        "    for player in self.players:\n",
        "      if player == 'human':\n",
        "        self.button_output_update(direction)\n",
        "      else:\n",
        "        self.button_output_update('tbd')\n",
        "    self.enable_direction_buttons()\n",
        "\n",
        "  def on_up_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('up')\n",
        "\n",
        "  def on_down_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('down')\n",
        "\n",
        "  def on_left_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('left')\n",
        "\n",
        "  def on_right_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('right')\n",
        "\n",
        "  def on_start_button_clicked(self, *args):\n",
        "    self.start_button.disabled = True\n",
        "    for ii in range(self.gwg.lifetime*self.gwg.num_critters):\n",
        "      self.button_output_update('tbd')\n",
        "      time.sleep(0.2)\n",
        "    self.start_button.disabled = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Head2HeadGridworld():\n",
        "  \"\"\"\n",
        "  A widget for interacting with a gridworld game while an artificial player\n",
        "  plays on an identical board or watching two artificial players play, again\n",
        "  with identical starting positions (though RNG not synched between the two\n",
        "  boards, so not like duplicate bridge). We are not going to worry about having\n",
        "  more than 1 critter type playing in head to head, (maybe we will to talk\n",
        "  about cooperation... maybe).\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, gridworld_game, init_board=None,\n",
        "               player0='human', p0_short_name='YOU', p0_long_name=None,\n",
        "               player1=None, p1_short_name='THEM', p1_long_name=None,\n",
        "               has_fov=False, radius=2, collect_fov_data=False,\n",
        "               critter_name='Critter', figsize=(5,4.5),\n",
        "               has_temp_slider=False):\n",
        "    \"\"\"\n",
        "    Initializes a widget based object for interacting with a gridworld game\n",
        "\n",
        "    Args:\n",
        "      gridworld_game: an instance of GridworldGame object\n",
        "        expects this to have batch_size of 2\n",
        "      init_board: (optional) a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "        if left out will initialize with a random board state\n",
        "      player0: object with a play method that takes a board state\n",
        "        as an argument and returns a move. If none will use a random player\n",
        "        if the special string 'human' is passed make arrow keys for that player\n",
        "      player1: same deal as player0, never more than 1 human player\n",
        "      has_fov: bool, whether or not to display field of view around the critter\n",
        "      radius: int, number of squares the critter can \"see\" around it\n",
        "    \"\"\"\n",
        "    # Set GridworldGame object and initialize the board state\n",
        "    self.gwg = gridworld_game\n",
        "    self.final_scores = []\n",
        "    self.player0 = player0\n",
        "    self.p0_short_name = p0_short_name\n",
        "    self.p0_long_name = p0_long_name\n",
        "    self.player1 = player1\n",
        "    self.p1_short_name = p1_short_name\n",
        "    self.p1_long_name = p1_long_name\n",
        "    self.no_human = True\n",
        "    if self.player0 == 'human':\n",
        "      assert self.player1 != 'human'\n",
        "      self.no_human = False\n",
        "    if self.player1 == 'human':\n",
        "      assert self.player0 != 'human'\n",
        "      self.no_human = False\n",
        "    self.p0_next_move = None\n",
        "    self.p1_next_move = None\n",
        "    self.has_fov = has_fov\n",
        "    self.radius = radius\n",
        "    self.percept_len = 2*self.radius*(self.radius+1)\n",
        "    self.collect_fov_data = collect_fov_data\n",
        "    self.critter_name = critter_name\n",
        "    self.figsize = figsize\n",
        "    if player0 is None:\n",
        "      self.player0 = RandomValidPlayer(self.gwg)\n",
        "    else:\n",
        "      self.player0 = player0\n",
        "    if player1 is None:\n",
        "      self.player1 = RandomValidPlayer(self.gwg)\n",
        "    else:\n",
        "      self.player1 = player1\n",
        "    self.has_temp_slider = has_temp_slider\n",
        "\n",
        "    if self.collect_fov_data is True:\n",
        "      self.percept_eat_records = []\n",
        "      self.fov_eat_table_data = np.zeros((2, self.percept_len+1))\n",
        "    if init_board is None:\n",
        "      self.board_state = self.gwg.get_init_board()\n",
        "    else:\n",
        "      self.board_state = init_board\n",
        "    #print(self.board_state)\n",
        "\n",
        "    # both players have same starting board\n",
        "    self.board_state['pieces'][1] = self.board_state['pieces'][0].copy()\n",
        "\n",
        "    # Initialize widgets and buttons\n",
        "    if self.has_temp_slider:\n",
        "      self.sft_slider_label = widgets.Label(value='Softmax Temperature')\n",
        "      self.sft_slider = widgets.FloatSlider(value=1.0, min=0.05,\n",
        "                                            max=5.0, step=0.05)\n",
        "      self.softmax_temp_slider = widgets.VBox([self.sft_slider_label,\n",
        "                                               self.sft_slider])\n",
        "    self.output0 = widgets.Output(layout=widgets.Layout(\n",
        "      width = '20.0em', min_width='20.0em', max_width='21.0em',\n",
        "      min_height='10.0em', overflow='auto'))\n",
        "    self.output1 = widgets.Output(layout=widgets.Layout(\n",
        "      width = '20.0em', min_width='20.0em', max_width='21.0em',\n",
        "      min_height='10.0em', overflow='auto'))\n",
        "    self.scoreboard = widgets.Output(layout=widgets.Layout(\n",
        "      min_width='20em', max_width='21em', min_height='6.3em', overflow='auto'))\n",
        "    self.up_button = widgets.Button(description=\"Up\",\n",
        "                                    layout=widgets.Layout(width='6.3em'))\n",
        "    self.down_button = widgets.Button(description=\"Down\",\n",
        "                                      layout=widgets.Layout(width='6.3em'))\n",
        "    self.left_button = widgets.Button(description=\"Left\",\n",
        "                                      layout=widgets.Layout(width='6.3em'))\n",
        "    self.right_button = widgets.Button(description=\"Right\",\n",
        "                                       layout=widgets.Layout(width='6.3em'))\n",
        "    self.start_button = widgets.Button(description=\"Start\",\n",
        "      layout=widgets.Layout(width='6.3em', margin='0.6em 0 0 0'))  # 0.6em top margin\n",
        "\n",
        "    #set up buttons and outputs and layouts\n",
        "    self.buttons = widgets.HBox([self.left_button,\n",
        "                               widgets.VBox([self.up_button, self.down_button]),\n",
        "                               self.right_button])\n",
        "    plt.ioff()\n",
        "    (self.b_fig0, self.b_ax0, self.b_crit_specs0, self.b_food0, self.b_fov0,\n",
        "     self.b_fig_legend, self.b_ax_legend) = self.gwg.plot_board(\n",
        "        self.board_state, g=0, legend_type='separate', figsize=self.figsize,\n",
        "        has_fov=self.has_fov, radius=self.radius,\n",
        "        name=self.critter_name, title=self.p0_long_name)\n",
        "    (self.b_fig1, self.b_ax1, self.b_crit_specs1, self.b_food1, self.b_fov1\n",
        "     ) = self.gwg.plot_board(self.board_state, g=1, legend_type=None,\n",
        "                             figsize=self.figsize, has_fov=self.has_fov,\n",
        "                             radius=self.radius, title=self.p1_long_name)\n",
        "    # player 0 is human\n",
        "    self.board_buttons_and_output0 = widgets.VBox(\n",
        "      [self.b_fig0.canvas, self.buttons, self.output0])\n",
        "    # player 1 is human\n",
        "    self.board_buttons_and_output1 = widgets.VBox(\n",
        "      [self.b_fig1.canvas, self.buttons, self.output1])\n",
        "    # non human players\n",
        "    self.board_and_output0 = widgets.VBox([self.b_fig0.canvas, self.output0])\n",
        "    self.board_and_output1 = widgets.VBox([self.b_fig1.canvas, self.output1])\n",
        "\n",
        "    self.legend_and_scores = widgets.VBox([self.b_fig_legend.canvas,\n",
        "                                           self.scoreboard])\n",
        "    if self.has_temp_slider:\n",
        "      self.legend_scores_start = widgets.VBox([self.b_fig_legend.canvas,\n",
        "                                               self.scoreboard,\n",
        "                                               self.softmax_temp_slider,\n",
        "                                               self.start_button])\n",
        "    else:\n",
        "      self.legend_scores_start = widgets.VBox([self.b_fig_legend.canvas,\n",
        "                                               self.scoreboard,\n",
        "                                               self.start_button])\n",
        "    if self.player0 == 'human':\n",
        "      self.final_display = widgets.HBox([self.board_buttons_and_output0,\n",
        "                                         self.legend_and_scores,\n",
        "                                         self.board_and_output1])\n",
        "    elif self.player1 == 'human':\n",
        "      self.final_display = widgets.HBox([self.board_and_output0,\n",
        "                                         self.legend_and_scores,\n",
        "                                         self.board_buttons_and_output1])\n",
        "    else: # no human player\n",
        "      self.final_display = widgets.HBox([self.board_and_output0,\n",
        "                                          self.legend_scores_start,\n",
        "                                          self.board_and_output1])\n",
        "    # initial text outputs\n",
        "    # if there's a temp slider check who, if anyone uses it\n",
        "    self.p0_uses_temp = False\n",
        "    self.p1_uses_temp = False\n",
        "    if self.has_temp_slider:\n",
        "      if self.player0=='human':\n",
        "        pass\n",
        "      else:\n",
        "        try:\n",
        "          _ = self.player0.play(self.board_state, temp=1.0)\n",
        "          self.p0_uses_temp = True\n",
        "        except TypeError: pass\n",
        "      if self.player1 == 'human':\n",
        "        pass\n",
        "      else:\n",
        "        try:\n",
        "          _ = self.player1.play(self.board_state, temp=1.0)\n",
        "          self.p1_uses_temp = True\n",
        "        except TypeError: pass\n",
        "      if not self.p0_uses_temp and not self.p1_uses_temp:\n",
        "        with self.output0:\n",
        "          print(\"Warning: neither player supports temperature adjustment. \"\n",
        "                \"The slider will have no effect.\")\n",
        "    with self.output0:\n",
        "      if self.no_human == False:\n",
        "        print('Click a button to start.')\n",
        "      else:\n",
        "        print('Click the start button to run the simulation')\n",
        "    with self.scoreboard:\n",
        "      print('Games Played: ' + str(len(self.final_scores)))\n",
        "      table = [['', self.p0_short_name, self.p1_short_name],\n",
        "          ['High Score:', '--', '--'],\n",
        "          ['Last Score:', '--', '--'],\n",
        "          ['Avg. Score:', '--', '--']]\n",
        "      print(tabulate(table))\n",
        "\n",
        "    # Connect the buttons to functions that do something\n",
        "    self.up_button.on_click(self.on_up_button_clicked)\n",
        "    self.down_button.on_click(self.on_down_button_clicked)\n",
        "    self.left_button.on_click(self.on_left_button_clicked)\n",
        "    self.right_button.on_click(self.on_right_button_clicked)\n",
        "    self.start_button.on_click(self.on_start_button_clicked)\n",
        "\n",
        "\n",
        "  def button_output_update(self, which_button):\n",
        "    old_board = self.board_state.copy()\n",
        "    old_scores = old_board['scores'][:,0] #both batches only one critter type\n",
        "    active_player_index = old_board['active_player']\n",
        "    self.disable_buttons()\n",
        "    if self.player0 == 'human':\n",
        "      a_player0 = which_button\n",
        "    else:\n",
        "      if self.p0_next_move is not None:\n",
        "        a_player0_ = self.p0_next_move\n",
        "        self.p0_next_move = None\n",
        "      else:\n",
        "        with self.output0:\n",
        "          print(\"AI is thinking...\")\n",
        "        if self.p0_uses_temp:\n",
        "          a_player0_, _, _ = self.player0.play(old_board,\n",
        "                                               temp=self.sft_slider.value)\n",
        "        else:\n",
        "          a_player0_, _, _ = self.player0.play(old_board)\n",
        "      a_player0_ = self.gwg.action_to_critter_direction(old_board,\n",
        "                                                        active_player_index+1,\n",
        "                                                        a_player0_)\n",
        "      a_player0 = a_player0_[0]\n",
        "    if self.player1 == 'human':\n",
        "      a_player1 = which_button\n",
        "    else:\n",
        "      if self.p1_next_move is not None:\n",
        "        a_player1_ = self.p1_next_move\n",
        "        self.p1_next_move = None\n",
        "      else:\n",
        "        with self.output1:\n",
        "          print(\"AI is thinking...\")\n",
        "        if self.p1_uses_temp:\n",
        "          a_player1_, _, _ = self.player1.play(old_board,\n",
        "                                               temp=self.sft_slider.value)\n",
        "        else:\n",
        "          a_player1_, _, _ = self.player1.play(old_board)\n",
        "      a_player1_ = self.gwg.action_to_critter_direction(old_board,\n",
        "                                                        active_player_index+1,\n",
        "                                                        a_player1_)\n",
        "      a_player1 = a_player1_[1]\n",
        "    self.enable_buttons()\n",
        "\n",
        "    self.board_state = self.gwg.critter_oriented_get_next_state(\n",
        "        self.board_state, active_player_index+1, [a_player0, a_player1])\n",
        "\n",
        "    # Try to precompute next AI player move(s) if there are any rounds left\n",
        "    if self.board_state['rounds_left'][0] > 0:\n",
        "      if self.player0 != 'human':\n",
        "        if self.p0_uses_temp:\n",
        "          self.p0_next_move, _, _ = self.player0.play(\n",
        "            self.board_state, temp=self.sft_slider.value)\n",
        "        else:\n",
        "          self.p0_next_move, _, _ = self.player0.play(self.board_state)\n",
        "      if self.player1 != 'human':\n",
        "        if self.p1_uses_temp:\n",
        "          self.p1_next_move, _, _ = self.player1.play(\n",
        "            self.board_state, temp=self.sft_slider.value)\n",
        "        else:\n",
        "          self.p1_next_move, _, _ = self.player1.play(self.board_state)\n",
        "\n",
        "    if self.collect_fov_data is True:\n",
        "      batch_size, n_rows, n_cols = old_board['pieces'].shape\n",
        "      b = GridworldBoard(batch_size, n_rows, n_cols,\n",
        "                         self.gwg.num_food, self.gwg.lifetime,\n",
        "                         rng=self.gwg.rng)\n",
        "      b.set_state(old_board)\n",
        "      percept = b.get_perceptions(self.radius)\n",
        "\n",
        "    new_scores = self.board_state['scores'][:,0] #both batches one critter type\n",
        "    rounds_left = self.board_state['rounds_left'][0]\n",
        "    num_moves = self.gwg.lifetime - rounds_left\n",
        "\n",
        "    if new_scores[0] > old_scores[0]:\n",
        "      eating_string0 = \"They ate the food there!\"\n",
        "    else:\n",
        "      eating_string0 = \"There's no food there.\"\n",
        "    if new_scores[1] > old_scores[1]:\n",
        "      eating_string1 = \"They ate the food there!\"\n",
        "    else:\n",
        "      eating_string1 = \"There's no food there.\"\n",
        "    did_eat = int(new_scores[0] > old_scores[0])\n",
        "\n",
        "    row0, col0 = self.gwg.get_critter_rc(self.board_state, 0, 1)\n",
        "    (self.b_fig0, self.b_ax0, self.b_crit_specs0, self.b_food0, self.b_fov0\n",
        "     ) = self.gwg.plot_board(self.board_state, 0, self.b_fig0, self.b_ax0,\n",
        "                             self.b_crit_specs0, self.b_food0, self.b_fov0,\n",
        "                             has_fov=self.has_fov, radius=self.radius,\n",
        "                             legend_type=None)\n",
        "    row1, col1 = self.gwg.get_critter_rc(self.board_state, 1, 1)\n",
        "    (self.b_fig1, self.b_ax1, self.b_crit_specs1, self.b_food1, self.b_fov1\n",
        "     ) = self.gwg.plot_board(self.board_state, 1, self.b_fig1, self.b_ax1,\n",
        "                             self.b_crit_specs1, self.b_food1, self.b_fov1,\n",
        "                             has_fov=self.has_fov, radius=self.radius,\n",
        "                             legend_type=None)\n",
        "\n",
        "    with self.output0:\n",
        "      clear_output()\n",
        "      if self.player0 == 'human':\n",
        "        print(\"You clicked the \" + which_button +\n",
        "              \" button and your critter is now at ({}, {}).\".format(row0,col0))\n",
        "      else:\n",
        "        print(\"This player (tried) to move \" + a_player0 +\n",
        "              \" and is now at ({}, {}).\".format(row0,col0))\n",
        "      print(eating_string0)\n",
        "      print(\"Rounds Left: {} \\nFood Eaten: {} \\nFood Per Move: {:.2f}\".format(\n",
        "          rounds_left, new_scores[0], new_scores[0] / num_moves))\n",
        "    with self.output1:\n",
        "      clear_output()\n",
        "      if self.player1 == 'human':\n",
        "        print(\"You clicked the \" + which_button +\n",
        "              \" button and your critter is now at ({}, {}).\".format(row1,col1))\n",
        "      else:\n",
        "        print(\"This player (tried) to move \" + a_player1 +\n",
        "              \" and is now at ({}, {}).\".format(row1,col1))\n",
        "      print(eating_string1)\n",
        "      print(\"Rounds Left: {} \\nFood Eaten: {} \\nFood Per Move: {:.2f}\".format(\n",
        "        rounds_left, new_scores[1], new_scores[1] / num_moves))\n",
        "\n",
        "    if self.collect_fov_data is True:\n",
        "      p_e_data = (percept.copy(), did_eat, old_board)\n",
        "      self.percept_eat_records.append(p_e_data)\n",
        "      percept_int = np.sum(percept==-1, axis=1)\n",
        "      self.fov_eat_table_data[did_eat, percept_int] += 1\n",
        "\n",
        "    if rounds_left == 0:\n",
        "      self.final_scores.append(new_scores)\n",
        "      self.board_state = self.gwg.get_init_board()\n",
        "      self.board_state['pieces'][1] = self.board_state['pieces'][0].copy()\n",
        "      (self.b_fig0, self.b_ax0, self.b_crit_specs0, self.b_food0, self.b_fov0\n",
        "       ) = self.gwg.plot_board(self.board_state, 0, self.b_fig0, self.b_ax0,\n",
        "                             self.b_crit_specs0, self.b_food0, self.b_fov0,\n",
        "                             has_fov=self.has_fov, radius=self.radius,\n",
        "                             legend_type=None)\n",
        "      (self.b_fig1, self.b_ax1, self.b_crit_specs1, self.b_food1, self.b_fov1\n",
        "       ) = self.gwg.plot_board(self.board_state, 1, self.b_fig1, self.b_ax1,\n",
        "                             self.b_crit_specs1, self.b_food1, self.b_fov1,\n",
        "                             has_fov=self.has_fov, radius=self.radius,\n",
        "                             legend_type=None)\n",
        "      with self.output0:\n",
        "        clear_output\n",
        "        print('Game Over. Final Score {}'.format(new_scores[0]))\n",
        "        print('Resetting the board for another game')\n",
        "      with self.output1:\n",
        "        clear_output\n",
        "        print('Game Over. Final Score {}'.format(new_scores[1]))\n",
        "        print('Resetting the board for another game')\n",
        "    with self.scoreboard:\n",
        "      clear_output()\n",
        "      self.b_fig_legend.canvas.draw()\n",
        "      print('Games Played: ' + str(len(self.final_scores)))\n",
        "      if len(self.final_scores) > 0:\n",
        "        table = [['', self.p0_short_name, self.p1_short_name],\n",
        "          ['High Score:', str(np.max(np.array(self.final_scores)[:,0])),\n",
        "                          str(np.max(np.array(self.final_scores)[:,1]))],\n",
        "          ['Last Score:', str(self.final_scores[-1][0]),\n",
        "                          str(self.final_scores[-1][1])],\n",
        "          ['Average Score',\n",
        "            '{:.2f}'.format(np.mean(np.array(self.final_scores)[:,0])),\n",
        "            '{:.2f}'.format(np.mean(np.array(self.final_scores)[:,1]))]]\n",
        "      else:\n",
        "        table = [['', self.p0_short_name, self.p1_short_name],\n",
        "          ['High Score:', '--', '--'],\n",
        "          ['Last Score:', '--', '--'],\n",
        "          ['Average Score:', '--', '--']]\n",
        "      print(tabulate(table))\n",
        "\n",
        "\n",
        "  def on_up_button_clicked(self, *args):\n",
        "    self.button_output_update('up')\n",
        "\n",
        "  def on_down_button_clicked(self, *args):\n",
        "    self.button_output_update('down')\n",
        "\n",
        "  def on_left_button_clicked(self, *args):\n",
        "    self.button_output_update('left')\n",
        "\n",
        "  def on_right_button_clicked(self, *args):\n",
        "    self.button_output_update('right')\n",
        "\n",
        "  def on_start_button_clicked(self, *args):\n",
        "    self.start_button.disabled = True\n",
        "    if self.has_temp_slider:\n",
        "      self.softmax_temp_slider.disabled = True\n",
        "    for ii in range(self.gwg.lifetime):\n",
        "      self.button_output_update('tbd')\n",
        "      time.sleep(0.2)\n",
        "    self.start_button.disabled = False\n",
        "    if self.has_temp_slider:\n",
        "      self.softmax_temp_slider.disabled = False\n",
        "\n",
        "  def disable_buttons(self):\n",
        "    self.up_button.disabled = True\n",
        "    self.down_button.disabled = True\n",
        "    self.left_button.disabled = True\n",
        "    self.right_button.disabled = True\n",
        "\n",
        "  def enable_buttons(self):\n",
        "    self.up_button.disabled = False\n",
        "    self.down_button.disabled = False\n",
        "    self.left_button.disabled = False\n",
        "    self.right_button.disabled = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ExploreWeightsWidget:\n",
        "  def __init__(self, game):\n",
        "    self.game = game\n",
        "    self.n_rows, self.n_cols = 4, 12  # four directions, twelve fov cells\n",
        "    self.row_labels = ['Up', 'Down', 'Left', 'Right']\n",
        "    self.col_labels = [\n",
        "      'Far<br>Up', 'Left<br>Up', 'Near<br>Up', 'Right<br>Up',\n",
        "      'Far<br>Left', 'Near<br>Left', 'Near<br>Right', 'Far<br>Right',\n",
        "      'Left<br>Down', 'Near<br>Down', 'Right<br>Down', 'Far<br>Down'\n",
        "      ]\n",
        "\n",
        "    # Create column headers\n",
        "    col_header = [widgets.Label(value='', layout=widgets.Layout(width='50px'))] + \\\n",
        "                 [widgets.HTML(value=label, layout=widgets.Layout(width='60px', min_height='60px')) for label in self.col_labels]\n",
        "\n",
        "    self.text_fields = [widgets.HBox(col_header)]\n",
        "\n",
        "    for label in self.row_labels:\n",
        "      row_fields = [widgets.FloatText(value=0.0, step=0.1, layout=widgets.Layout(width='60px'))\n",
        "                    for _ in range(self.n_cols)]\n",
        "      row_label = widgets.Label(value=f\"{label}:\", layout=widgets.Layout(width='50px'))\n",
        "      self.text_fields.append(widgets.HBox([row_label] + row_fields))\n",
        "\n",
        "    # Create a button to start the game\n",
        "    self.run_button = widgets.Button(description=\"Run Game\")\n",
        "    self.run_button.on_click(self.run_game)\n",
        "\n",
        "    # set up fig and create placeholders for vertical lines and histograms\n",
        "    colors = sns.color_palette(\"colorblind\")\n",
        "    self.current_color = colors[0]\n",
        "    self.best_color = colors[1]\n",
        "    self.prev_color = colors[2]\n",
        "    self.fig, self.ax = plt.subplots(figsize=(6,4))\n",
        "    self.ax.set_xlim([0,25])\n",
        "    self.ax.set_ylim([0,1])\n",
        "    remove_ip_clutter(self.fig)\n",
        "    self.current_avg_line = self.ax.axvline(-1, color=self.current_color,\n",
        "                                            linestyle='dashed', linewidth=3,\n",
        "                                            label='Current')\n",
        "    self.prev_avg_line = self.ax.axvline(-1, color=self.prev_color,\n",
        "                                         linestyle='dashed', linewidth=3,\n",
        "                                         label='Previous')\n",
        "    self.best_avg_line = self.ax.axvline(-1, color=self.best_color,\n",
        "                                         linestyle='dashed', linewidth=3,\n",
        "                                         label='Best')\n",
        "    if self.game.batch_size > 1:\n",
        "      #only do hist for batches\n",
        "      self.current_hist_bars = self.ax.bar([0]*10, [0]*10,\n",
        "                                           color=self.current_color,\n",
        "                                           label='Current Run')\n",
        "      self.prev_hist_bars = self.ax.bar([0]*10, [0]*10, color=self.prev_color,\n",
        "                                        label='Previous Run', alpha=0.5)\n",
        "    self.fig.legend(loc='outside right upper')\n",
        "    self.fig.canvas.draw()\n",
        "\n",
        "    # Output widget to display game output and any other information\n",
        "    self.out = widgets.Output()\n",
        "\n",
        "    # keep track of important values\n",
        "    self.best_avg_score = float('-inf')\n",
        "    self.best_params = None\n",
        "    self.prev_scores = []\n",
        "    self.scores = np.array([])\n",
        "\n",
        "    # Button to set the best weights\n",
        "    self.best_button = widgets.Button(description=\"Set Best Weights\")\n",
        "    self.best_button.on_click(self.set_best_weights)\n",
        "\n",
        "    # Add a ToggleButton for symmetry\n",
        "    self.symmetry_toggle = widgets.ToggleButton(value=False,\n",
        "                                                description='Enforce Symmetry',\n",
        "                                                disabled=False,\n",
        "                                                button_style='',\n",
        "                                                tooltip='Toggle symmetry enforcement',\n",
        "                                                icon='check')\n",
        "    self.symmetry_toggle.observe(self.toggle_symmetry, 'value')\n",
        "\n",
        "    self.final_display = widgets.VBox([\n",
        "      *self.text_fields,\n",
        "      widgets.HBox([self.run_button, self.best_button, self.symmetry_toggle]),\n",
        "      self.fig.canvas,\n",
        "      self.out])\n",
        "\n",
        "    self.links = []  # To keep track of the jslink objects\n",
        "\n",
        "\n",
        "  def run_game(self, *args):\n",
        "    weights = []\n",
        "    for hbox in self.text_fields[1:]:  # Skip the header row\n",
        "      row_weights = [field.value for field in hbox.children[1:]]  # Skip the label at the first position\n",
        "      weights.append(row_weights)\n",
        "    weights = np.array(weights)\n",
        "    ppp = PerceptParamPlayer(self.game, weights=weights)\n",
        "    # Run the game\n",
        "    final_board = self.game.play_game(players=[ppp], visualize=False)\n",
        "\n",
        "    self.scores = final_board['scores'].flatten()\n",
        "    avg_score = np.mean(self.scores)\n",
        "\n",
        "    if avg_score > self.best_avg_score:\n",
        "      self.best_avg_score = avg_score\n",
        "      self.best_params = weights\n",
        "\n",
        "    if self.game.batch_size > 1:\n",
        "      # Compute and update histogram data\n",
        "      counts, edges = np.histogram(self.scores, bins=10)\n",
        "      counts = counts/np.sum(counts)\n",
        "      prev_counts, prev_edges = np.histogram(self.prev_scores[-1], bins=10) if len(self.prev_scores) > 0 else ([0]*10, edges)\n",
        "      prev_sum = np.sum(prev_counts)\n",
        "      if prev_sum > 0:\n",
        "        prev_counts = prev_counts / np.sum(prev_counts)\n",
        "      # Update the height of bars for the current scores\n",
        "      for bar, height, left in zip(self.current_hist_bars, counts, edges[:-1]):\n",
        "          bar.set_height(height)\n",
        "          bar.set_x(left)\n",
        "          bar.set_width(edges[1] - edges[0])\n",
        "      # Update the height of bars for the previous scores\n",
        "      for bar, height, left in zip(self.prev_hist_bars, prev_counts, prev_edges[:-1]):\n",
        "          bar.set_height(height)\n",
        "          bar.set_x(left)\n",
        "          bar.set_width(prev_edges[1] - prev_edges[0])\n",
        "    # set vline data\n",
        "    self.current_avg_line.set_xdata([avg_score])\n",
        "    if len(self.prev_scores) > 0:\n",
        "        prev_avg_score = np.mean(self.prev_scores[-1])\n",
        "        self.prev_avg_line.set_xdata([prev_avg_score])\n",
        "    self.best_avg_line.set_xdata([self.best_avg_score])\n",
        "\n",
        "    #update the fig\n",
        "    self.fig.legend(loc='outside right upper')\n",
        "    self.fig.canvas.draw()\n",
        "    # Display the output\n",
        "    with self.out:\n",
        "      clear_output()\n",
        "\n",
        "      if self.game.batch_size > 1:\n",
        "        print(f\"Average Score This Time: {avg_score}\")\n",
        "        if len(self.prev_scores) > 0:\n",
        "          prev_avg_score = np.mean(self.prev_scores[-1])\n",
        "          print(f\"Average Score Last Time: {prev_avg_score}\")\n",
        "        print(f\"Best Ever Average Score: {self.best_avg_score}\")\n",
        "      else:\n",
        "        print(f\"Score This Run: {avg_score}\")\n",
        "        if len(self.prev_scores) > 0:\n",
        "          print(f\"Score Last Run: {prev_avg_score}\")\n",
        "        print(f\"Best Score: {self.best_avg_score}\")\n",
        "\n",
        "    self.prev_scores.append(self.scores.copy())\n",
        "\n",
        "\n",
        "  def link_symmetric_widgets(self, change):\n",
        "    # Each row's symmetry permutation indices\n",
        "    symmetry_indices = {\n",
        "      'Up':    [ 0,  1,  2,  1,  3,  4,  4,  3,  5,  6,  5,  7],\n",
        "      'Down':  [ 7,  5,  6,  5,  3,  4,  4,  3,  1,  2,  1,  0],\n",
        "      'Left':  [ 3,  1,  4,  5,  0,  2,  6,  7,  1,  4,  5,  3],\n",
        "      'Right': [ 3,  5,  4,  1,  7,  6,  2,  0,  5,  4,  1,  3]}\n",
        "\n",
        "    if change['new']:  # If the toggle button is activated\n",
        "      base_row = self.text_fields[1].children[1:]  # The 'Up' row\n",
        "      base_perm = np.array(symmetry_indices['Up'])  # Convert to a NumPy array for easier manipulation\n",
        "\n",
        "      for row_label, hbox in zip(self.row_labels, self.text_fields[1:]):  # Include all rows\n",
        "        link_row = hbox.children[1:]  # Skip the label\n",
        "        perm = np.array(symmetry_indices[row_label])  # Convert to a NumPy array for easier manipulation\n",
        "        for i, j in enumerate(perm):\n",
        "          base_index = np.flatnonzero(base_perm == j)[0]\n",
        "          if row_label != 'Up' or base_index != i:  # Skip self-links\n",
        "            link = widgets.jslink((base_row[base_index], 'value'), (link_row[i], 'value'))\n",
        "            self.links.append(link)\n",
        "\n",
        "\n",
        "  def unlink_symmetric_widgets(self):\n",
        "    for link in self.links:\n",
        "      link.unlink()\n",
        "    self.links.clear()\n",
        "\n",
        "\n",
        "  def toggle_symmetry(self, change):\n",
        "    if change.new:\n",
        "      self.link_symmetric_widgets(change)\n",
        "    else:\n",
        "      self.unlink_symmetric_widgets()\n",
        "\n",
        "\n",
        "  def set_best_weights(self, *args):\n",
        "    if self.best_params is not None:\n",
        "      for i, hbox in enumerate(self.text_fields[1:]):\n",
        "        for j, field in enumerate(hbox.children[1:]):\n",
        "          field.value = self.best_params[i][j]"
      ],
      "metadata": {
        "id": "Sz3HGM23H9_P"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "MZoYPSIM5MK4"
      },
      "source": [
        "# 1.2.2.1: A Dynamic Gridworld - Food Moves\n",
        "\n",
        "To add some (easily parameterized) variation to our environment we are going to further complicate Gridworld by allowing food to drift. Specifically, after an organism has made its move, each food item has some probability of drifting in each of the four directions. Different drift probabilities will create fundamentally different Gridworlds, each requiring a different strategy. Classic Gridworld can be thought of as this new version, but with all food drift direction probabilities set to zero. Let's look at how our 'parameterized weights' policy from last sequence, optimzed for classic Gridworld performs, both in classic Gridworld, and in this new dynamic Gridworld."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "execution": {},
        "id": "6Od7qki25MK6",
        "outputId": "5b36b9e4-d001-4821-f7ea-8d83efb32780",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565,
          "referenced_widgets": [
            "8072429271704bc48729851ebf0f9167",
            "935b3a5c58a043658ce7d3aff57ba4f6",
            "4c04ef351d4c426cacb84e84539ab00c",
            "d5fc625d94e94a30bedbdf85d02c2bd6",
            "ffadd62f640a4652813eda7ac187e240",
            "79d2d89f0d75473cb12d423820539ddf",
            "4d3b578b904246eeb62e69ac51cb4833",
            "33da9cdf611249c9b653946a1c63b648",
            "8ec34e3f178d42f9bab2ac292f8b3cd2",
            "bfe3d70feab94ae9a7f1c10b6795bdac",
            "b0176a5839d0436c917bd2fd7138b219",
            "539a7dfcfeee4f548957f78c790264a6",
            "5c2e61f5b5c44fd6982c5bb2512aaea9",
            "434e562d444947f48094742053fee60f",
            "c6b4aeabe8704852a8d006573c092409"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Canvas(footer_visible=False, header_visible=False, resizable=False, toolbar=Toolbar(toolitems=[â€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8072429271704bc48729851ebf0f9167"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "# @title Optimized Parameterized Weights in Classic Gridworld\n",
        "# @markdown Run this cell to see our optimized policy from last sequence in action!\n",
        "gwg = GridworldGame(batch_size=1, n_rows=7, n_cols=7,\n",
        "                    num_critters=1, num_food=10, lifetime=30)\n",
        "sym_weights = np.array([ 711.9256878,  -188.34681299,\n",
        "                        700.65707005,   397.25119332,\n",
        "                        -36.91700298,   -227.4452487,\n",
        "                        231.42719449,   367.63939442])\n",
        "def convert_symmetry_to_weights(symmetry_params):\n",
        "  # Initialize the weight matrix with zeros\n",
        "  weights = np.zeros((4,12))\n",
        "  symmetry_indices = {\n",
        "    'Up':    [0,  1,  2,  1,  3,  4,  4,  3,  5,  6,  5,  7],\n",
        "    'Down':  [7,  5,  6,  5,  3,  4,  4,  3,  1,  2,  1,  0],\n",
        "    'Left':  [3,  1,  4,  5,  0,  2,  6,  7,  1,  4,  5,  3],\n",
        "    'Right': [3,  5,  4,  1,  7,  6,  2,  0,  5,  4,  1,  3]}\n",
        "  # Use the symmetry indices to populate the 48-dimensional weight vector\n",
        "  for i, direction in enumerate(['Up', 'Down', 'Left', 'Right']):\n",
        "    for j, idx in enumerate(symmetry_indices[direction]):\n",
        "      weights[i, j] = symmetry_params[idx]\n",
        "  return weights\n",
        "\n",
        "weights = convert_symmetry_to_weights(sym_weights)\n",
        "#ppp = PerceptParamPlayer(gwg, weights=weights)\n",
        "boppp = BatchOptPerceptParamPlayer(gwg, weights=weights)\n",
        "classic_igwg = InteractiveGridworld(gwg, players=[boppp],\n",
        "                                    figsize=(5,4))\n",
        "display(classic_igwg.b_fig.canvas)\n",
        "clear_output()\n",
        "display(classic_igwg.final_display)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Optimized Parameterized Weights in Gridworld where Food Drifts\n",
        "# @markdown Run this cell to see our optimized policy from last sequence in an environment that they were not optimized for.\n",
        "gwg = GridworldGame(batch_size=1, n_rows=7, n_cols=7,\n",
        "                    num_critters=1, num_food=10, lifetime=30,\n",
        "                    drift_probs=np.array([0.0, 0.0, 1.0, 0.0, 0.0]),\n",
        "                    wrapping=True, drift_after_move=False)\n",
        "sym_weights = np.array([ 711.9256878,  -188.34681299,\n",
        "                        700.65707005,   397.25119332,\n",
        "                        -36.91700298,   -227.4452487,\n",
        "                        231.42719449,   367.63939442])\n",
        "def convert_symmetry_to_weights(symmetry_params):\n",
        "  # Initialize the weight matrix with zeros\n",
        "  weights = np.zeros((4,12))\n",
        "  symmetry_indices = {\n",
        "    'Up':    [0,  1,  2,  1,  3,  4,  4,  3,  5,  6,  5,  7],\n",
        "    'Down':  [7,  5,  6,  5,  3,  4,  4,  3,  1,  2,  1,  0],\n",
        "    'Left':  [3,  1,  4,  5,  0,  2,  6,  7,  1,  4,  5,  3],\n",
        "    'Right': [3,  5,  4,  1,  7,  6,  2,  0,  5,  4,  1,  3]}\n",
        "  # Use the symmetry indices to populate the 48-dimensional weight vector\n",
        "  for i, direction in enumerate(['Up', 'Down', 'Left', 'Right']):\n",
        "    for j, idx in enumerate(symmetry_indices[direction]):\n",
        "      weights[i, j] = symmetry_params[idx]\n",
        "  return weights\n",
        "\n",
        "weights = convert_symmetry_to_weights(sym_weights)\n",
        "#ppp = PerceptParamPlayer(gwg, weights=weights)\n",
        "boppp = BatchOptPerceptParamPlayer(gwg, weights=weights)\n",
        "drift_igwg = InteractiveGridworld(gwg, players=[boppp],\n",
        "                                  figsize=(5,4))\n",
        "display(drift_igwg.b_fig.canvas)\n",
        "clear_output()\n",
        "display(drift_igwg.final_display)"
      ],
      "metadata": {
        "id": "Rq2MHwe0nEMO",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 565,
          "referenced_widgets": [
            "84bbd23dfbcc4bdb9e8a154d979bbf30",
            "3ff6a25d1e424f8796e340ee0e24a4a8",
            "d7d51ed9f1774e4fa57cc299687c1e24",
            "f9e3f1e4b38b4e6381fdbc6a7946a092",
            "f97889b49f0d4df09c2c08ea4690c7b2",
            "f6386385609c40efba3c6c7d4af92acc",
            "e031ba48118d469da8044ed33fbb7b6c",
            "9ef4c40c1f264776b09f697d0f6af48b",
            "3007a753393d4a1e84573f57c0a3850b",
            "0df51975ae3741a295d25e56c579061e",
            "538e4f4e61cd4fd280bb233012c3dc25",
            "cc37692c29194f42a3fb456d57b8b4ab",
            "726fb8b5c9b84ac28b3e92a2d67150f0",
            "df928ea3756a4481a232d2964a5918c7",
            "b4a6ff41c2c34aa0bc7a70cf0ca53a76"
          ]
        },
        "outputId": "162c9be2-56eb-400d-838f-d87c4375de2a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(Canvas(footer_visible=False, header_visible=False, resizable=False, toolbar=Toolbar(toolitems=[â€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "84bbd23dfbcc4bdb9e8a154d979bbf30"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "In many ways this drifting food environment is very 'unfair' for our policy from last time. One particularly 'unfair' aspect is that in this Gridworld varient the organism determines it's move based on its perceptions, then the food drifts, and then the organism makes its move. This means that the organism might fruitlessly chase a piece of food across the board, never catching it. To be truly effective in this variant, the organism's actions must in some sense anticipate the possible movement. Another 'unfair' aspect of this drifting food environment is its asymetrry (food drifts to the left) but the organism (as optimized last sequence) is constrained to optimize to have symmetric weights. We enforced symmetry in the last sequence so that there would only be 8 parameters to optimize instead of 48 (12 inputs $\\times$ 4 output directions), but now to optimize a policy for this new environment we will need to relax this symmetry constraint. Is our simple propose and test algorithm from last time up to the task, run the cell below to find out?"
      ],
      "metadata": {
        "id": "QrNSWLMoAwm7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(flat_W, game):\n",
        "  # Run the game with the proposed weights\n",
        "  W = flat_W.reshape((4,12))\n",
        "  boppp = BatchOptPerceptParamPlayer(game, weights=W, deterministic=False)\n",
        "  final_board = game.play_game(players=[boppp], visualize=False)\n",
        "  # Evaluate the score\n",
        "  scores = final_board['scores'].flatten()\n",
        "  avg_score = np.mean(scores)\n",
        "  return(avg_score)\n",
        "\n",
        "# initialize with a 'good guess' for speed\n",
        "init_params = np.array([\n",
        "        39.30865292,   9.01760111,  80.38286295,  12.10480525,\n",
        "        -1.54035101, -12.62806362,  -9.31724702, -40.33851897,\n",
        "       -29.14361924, -42.22325768,  -2.70981836, -16.55625833,\n",
        "        15.39325135, -15.52997923, -31.71959468,  22.0902372 ,\n",
        "        11.89814249, -16.92870311, -52.21048477, -66.42899895,\n",
        "        16.91074232,  15.19381806,  -5.92085391,  51.12563735,\n",
        "        26.93871658, -34.21710862,   5.18250537,   6.80638903,\n",
        "        23.47074635,  42.21277965, -32.30035029, -31.47703595,\n",
        "         1.44918797, -28.95364066, -14.34993081,   5.90956138,\n",
        "        12.77977911, -15.82296614, -63.84035169,  22.54943483,\n",
        "        17.14026093, -39.08213296,  12.31602557,  30.9064372 ,\n",
        "        -8.27488813,  -7.43353598,  15.57508677,  40.78037226])\n",
        "\n",
        "\n",
        "def propose_and_test(batch_size=25, high_batch_size=900,\n",
        "                     initial_params=None,\n",
        "                     max_rejected=500,\n",
        "                     step_scale=10.0,\n",
        "                     verbose=True):\n",
        "\n",
        "  game = GridworldGame(batch_size=batch_size, n_rows=7, n_cols=7,\n",
        "                       num_critters=1, num_food=10, lifetime=30,\n",
        "                       rng=np.random.default_rng(48))\n",
        "  high_batch_game = GridworldGame(batch_size=high_batch_size, n_rows=7, n_cols=7,\n",
        "                                  num_critters=1, num_food=10, lifetime=30,\n",
        "                                  rng=np.random.default_rng(48))\n",
        "  # Initialize parameters\n",
        "  if initial_params is None:\n",
        "    initial_params = np.zeros(48)\n",
        "  best_params = initial_params\n",
        "  best_avg_score = evaluate(best_params, high_batch_game)\n",
        "  print(f\"Initial score: {best_avg_score}\")\n",
        "  rejected_count = 0\n",
        "  total_tests = 0  # Number of iterations\n",
        "  std_dev = step_scale  # Standard deviation for Gaussian proposal\n",
        "\n",
        "  # Propose-and-test loop\n",
        "  start_time = time.time()\n",
        "  while rejected_count < max_rejected:\n",
        "    # Propose new parameters: sample from Gaussian centered at best_params\n",
        "    delta_params = np.random.normal(0, std_dev, best_params.shape)\n",
        "    proposal_params = best_params + delta_params\n",
        "    avg_score = evaluate(proposal_params, game)\n",
        "    # If a promising candidate is found, validate it with a high batch size evaluation\n",
        "    if avg_score > best_avg_score:\n",
        "      avg_score_high_batch = evaluate(proposal_params, high_batch_game)\n",
        "      # Only update best parameters if the candidate also performs well in the\n",
        "      # high batch size evaluation to avoid choosing parameters based on 'luck'\n",
        "      # i.e. from a really exceptional batch of simulations\n",
        "      if avg_score_high_batch > best_avg_score:\n",
        "        best_avg_score = avg_score\n",
        "        best_params = proposal_params\n",
        "        if verbose:\n",
        "          #print('best params so far:')\n",
        "          #display(best_params)\n",
        "          print(f\"Best score so far: {best_avg_score}\")\n",
        "          print(f\"Found after {rejected_count} tests and {time.time() - start_time} seconds\")\n",
        "        rejected_count = 0\n",
        "      else:\n",
        "        rejected_count += 1\n",
        "    else:\n",
        "      rejected_count += 1\n",
        "    total_tests +=1\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "\n",
        "  if verbose:\n",
        "    # Print the best found parameters and score\n",
        "    print(\"Best Parameters:\", best_params)\n",
        "    print(\"Best Average Score:\", best_avg_score)\n",
        "    print(\"Parameter combinations tested:\", total_tests)\n",
        "    print(f\"Time taken for the optimization loop: {elapsed_time:.2f} seconds\")\n",
        "  return best_params, best_avg_score\n",
        "\n",
        "best_params, best_avg_score = propose_and_test(initial_params=init_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2OTGtVbZCR17",
        "outputId": "8348f8e8-ff90-4d85-f36c-2d4a0b3c9552"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial score: 14.527777777777779\n",
            "Best score so far: 15.0\n",
            "Found after 305 tests and 34.75087642669678 seconds\n",
            "Best Parameters: [ 43.92549298   9.65150574  79.63376762  10.69954994  -8.07436766\n",
            " -31.84851018  -7.59684915 -31.29091036 -21.87717318 -59.35659086\n",
            "  11.60930361 -30.53345148   5.80758298 -10.41824956 -43.69926561\n",
            "  18.41467569  10.59950108 -27.84396476 -69.81655222 -65.05792288\n",
            "  15.34261975  22.19927146   1.14359273  64.48744075  10.34109243\n",
            " -34.87869484   9.42669213   3.81917279  28.63064748  43.05201715\n",
            " -34.21685507 -47.36547275   3.08875511 -23.45633306 -12.7610816\n",
            "  -5.62226547  21.33379826 -19.41869257 -59.78289688  24.99114032\n",
            "  18.07254983 -60.84647228  19.22953291  14.56102517  -0.5010634\n",
            " -13.98649011  25.09604283  45.90696478]\n",
            "Best Average Score: 15.0\n",
            "Parameter combinations tested: 806\n",
            "Time taken for the optimization loop: 92.19 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We cheated a bit in the cell above, setting our initial guess to something that we knew (from previous optimization runs) would be pretty good. If we start with zero weights it takes a bit longer, but not impossibly long (about 5 minutes)."
      ],
      "metadata": {
        "id": "DtKqi27o_vgJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_params, best_avg_score = propose_and_test(max_rejected=1000, initial_params=None)"
      ],
      "metadata": {
        "id": "FtmZbkWIpI2w",
        "outputId": "946ffba6-e9ba-4a0d-9706-fa9c749d9257",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial score: 3.6455555555555557\n",
            "Best score so far: 5.12\n",
            "Found after 305 tests and 21.77837610244751 seconds\n",
            "Best score so far: 6.6\n",
            "Found after 43 tests and 26.46452832221985 seconds\n",
            "Best score so far: 7.64\n",
            "Found after 162 tests and 40.86678647994995 seconds\n",
            "Best score so far: 8.08\n",
            "Found after 65 tests and 51.22782826423645 seconds\n",
            "Best score so far: 10.92\n",
            "Found after 8 tests and 53.35298037528992 seconds\n",
            "Best score so far: 13.4\n",
            "Found after 18 tests and 56.218074321746826 seconds\n",
            "Best score so far: 14.04\n",
            "Found after 108 tests and 67.63145041465759 seconds\n",
            "Best score so far: 14.8\n",
            "Found after 443 tests and 108.82835054397583 seconds\n",
            "Best Parameters: [ 19.46987252 -12.83893423  98.85704806 -25.56818574  -6.67245011\n",
            " -17.30043767   2.13019639  -1.42346418  10.50147342  -3.19503848\n",
            " -24.92801141  14.43047927 -36.67714186 -19.79147367  31.30586204\n",
            " -26.33052996 -25.36571567 -41.17726055  24.78322079 -41.64268951\n",
            "  48.80130088  60.1108176   13.57002293  67.47265445 -27.97774069\n",
            " -55.17779379   8.01190042  -2.65126416  -0.52818062  32.86080255\n",
            "  -3.13890961  -5.31484209   5.10134301 -50.03950957 -25.01103828\n",
            "  44.60870819  -2.95590791 -14.42094904  35.52902642  -0.63733344\n",
            " -23.16382929 -27.21637141  63.19225003  12.08204811  26.39252988\n",
            " -65.63012734  -0.51705844 -21.82995606]\n",
            "Best Average Score: 14.8\n",
            "Parameter combinations tested: 2160\n",
            "Time taken for the optimization loop: 185.65 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2.2.2 Optimizing for Drifting Food\n",
        "Finding a good set of prameters in an 8 dimensional space was much easier than finding a good set of parameters in a 48 dimensional space, but given enough time and good hyper-parameter settings, our simple propose and reject algorithm is still up to the task. Now that we know that this optimization process is feasible for this problem, let's see if we can optimize a policy for the evironment when food drifts."
      ],
      "metadata": {
        "id": "0KL4cwrgFoJu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# initialize the policy that was good with no drift 'good guess'\n",
        "init_params = np.array([\n",
        "        39.30865292,   9.01760111,  80.38286295,  12.10480525,\n",
        "        -1.54035101, -12.62806362,  -9.31724702, -40.33851897,\n",
        "       -29.14361924, -42.22325768,  -2.70981836, -16.55625833,\n",
        "        15.39325135, -15.52997923, -31.71959468,  22.0902372 ,\n",
        "        11.89814249, -16.92870311, -52.21048477, -66.42899895,\n",
        "        16.91074232,  15.19381806,  -5.92085391,  51.12563735,\n",
        "        26.93871658, -34.21710862,   5.18250537,   6.80638903,\n",
        "        23.47074635,  42.21277965, -32.30035029, -31.47703595,\n",
        "         1.44918797, -28.95364066, -14.34993081,   5.90956138,\n",
        "        12.77977911, -15.82296614, -63.84035169,  22.54943483,\n",
        "        17.14026093, -39.08213296,  12.31602557,  30.9064372 ,\n",
        "        -8.27488813,  -7.43353598,  15.57508677,  40.78037226])\n",
        "\n",
        "\n",
        "def drift_propose_and_test(batch_size=25, high_batch_size=900,\n",
        "                           initial_params=None,\n",
        "                           max_rejected=500,\n",
        "                           step_scale=10.0,\n",
        "                           verbose=True):\n",
        "\n",
        "  game = GridworldGame(batch_size=batch_size, n_rows=7, n_cols=7,\n",
        "                       num_critters=1, num_food=10, lifetime=30,\n",
        "                       rng=np.random.default_rng(48),\n",
        "                       drift_probs=[0, 0, 1.0, 0, 0.0],\n",
        "                       wrapping=True, drift_after_move=False)\n",
        "  high_batch_game = GridworldGame(batch_size=high_batch_size, n_rows=7, n_cols=7,\n",
        "                                  num_critters=1, num_food=10, lifetime=30,\n",
        "                                  rng=np.random.default_rng(48),\n",
        "                                  drift_probs=[0, 0, 1.0, 0, 0.0],\n",
        "                                  wrapping=True, drift_after_move=False)\n",
        "  # Initialize parameters\n",
        "  if initial_params is None:\n",
        "    initial_params = np.zeros(48)\n",
        "  best_params = initial_params\n",
        "  best_avg_score = evaluate(best_params, high_batch_game)\n",
        "  print(f\"Initial score: {best_avg_score}\")\n",
        "  rejected_count = 0\n",
        "  total_tests = 0  # Number of iterations\n",
        "  std_dev = step_scale  # Standard deviation for Gaussian proposal\n",
        "\n",
        "  # Propose-and-test loop\n",
        "  start_time = time.time()\n",
        "  while rejected_count < max_rejected:\n",
        "    # Propose new parameters: sample from Gaussian centered at best_params\n",
        "    delta_params = np.random.normal(0, std_dev, best_params.shape)\n",
        "    proposal_params = best_params + delta_params\n",
        "    avg_score = evaluate(proposal_params, game)\n",
        "    # If a promising candidate is found, validate it with a high batch size evaluation\n",
        "    if avg_score > best_avg_score:\n",
        "      avg_score_high_batch = evaluate(proposal_params, high_batch_game)\n",
        "      # Only update best parameters if the candidate also performs well in the\n",
        "      # high batch size evaluation to avoid choosing parameters based on 'luck'\n",
        "      # i.e. from a really exceptional batch of simulations\n",
        "      if avg_score_high_batch > best_avg_score:\n",
        "        best_avg_score = avg_score\n",
        "        best_params = proposal_params\n",
        "        if verbose:\n",
        "          #print('best params so far:')\n",
        "          #display(best_params)\n",
        "          print(f\"Best score so far: {best_avg_score}\")\n",
        "          print(f\"Found after {rejected_count} tests and {time.time() - start_time} seconds\")\n",
        "        rejected_count = 0\n",
        "      else:\n",
        "        rejected_count += 1\n",
        "    else:\n",
        "      rejected_count += 1\n",
        "    total_tests +=1\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "\n",
        "  if verbose:\n",
        "    # Print the best found parameters and score\n",
        "    print(\"Best Parameters:\", best_params)\n",
        "    print(\"Best Average Score:\", best_avg_score)\n",
        "    print(\"Parameter combinations tested:\", total_tests)\n",
        "    print(f\"Time taken for the optimization loop: {elapsed_time:.2f} seconds\")\n",
        "  return best_params, best_avg_score\n",
        "\n",
        "best_drift_params, best_avg_drift_score = drift_propose_and_test(initial_params=init_params)"
      ],
      "metadata": {
        "id": "fsj6K42xrdVT",
        "outputId": "19252861-b075-4dcf-8a45-bd650ecb48cb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Initial score: 8.956666666666667\n",
            "Best score so far: 9.08\n",
            "Found after 0 tests and 2.890016794204712 seconds\n",
            "Best score so far: 9.2\n",
            "Found after 1 tests and 5.889010667800903 seconds\n",
            "Best score so far: 10.48\n",
            "Found after 0 tests and 8.860782861709595 seconds\n",
            "Best score so far: 11.4\n",
            "Found after 21 tests and 28.12005639076233 seconds\n",
            "Best score so far: 12.36\n",
            "Found after 18 tests and 32.8866126537323 seconds\n",
            "Best score so far: 12.72\n",
            "Found after 49 tests and 46.70574975013733 seconds\n",
            "Best score so far: 12.8\n",
            "Found after 4 tests and 52.76562762260437 seconds\n",
            "Best score so far: 13.48\n",
            "Found after 0 tests and 55.713730812072754 seconds\n",
            "Best score so far: 13.96\n",
            "Found after 5 tests and 59.258217573165894 seconds\n",
            "Best score so far: 14.0\n",
            "Found after 16 tests and 76.1360216140747 seconds\n",
            "Best score so far: 14.84\n",
            "Found after 0 tests and 79.22946071624756 seconds\n",
            "Best Parameters: [ 66.84683923 -31.14037535  35.72160555  75.88710233 -14.52362157\n",
            "  -0.35951824  14.73964635 -22.9651928   23.40167114  -5.13438758\n",
            "   1.68196833 -36.29577184  15.61269478 -34.0530641   -9.99446513\n",
            "  61.16594299  -6.68703432 -23.43489111  11.62657541 -22.25216803\n",
            "  50.03945972   0.66944131  76.36765152  70.97772887  20.04880876\n",
            " -40.64861642 -63.20632135 -16.15671423  48.12461276  59.46140827\n",
            " -30.5511899    3.22998332  37.01074072 -46.36414271 -13.90466665\n",
            "  41.78343265 -22.02720312 -18.08082796 -57.60174968 -15.54073006\n",
            " -45.96275769  -6.34720342  26.57475296  17.10038933  20.49030444\n",
            " -20.13110637 -22.82172666  70.8456051 ]\n",
            "Best Average Score: 14.84\n",
            "Parameter combinations tested: 625\n",
            "Time taken for the optimization loop: 180.11 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title In a Gridworld where Food Drifts, optimized for a Gridworld where food drifts\n",
        "# @markdown Run this cell to see an optimized policy for this drifting environment.\n",
        "gwg = GridworldGame(batch_size=2, n_rows=7, n_cols=7,\n",
        "                    num_critters=1, num_food=10, lifetime=30,\n",
        "                    drift_probs=np.array([0.0, 0.0, 1.0, 0.0, 0.0]),\n",
        "                    wrapping=True, drift_after_move=False)\n",
        "\n",
        "try:\n",
        "  flat_classic_weights = best_params\n",
        "except NameError:\n",
        "  flat_classic_weights = np.array([\n",
        "    72.44502999, -10.1196398,   75.58460857,   6.30015161,  22.72267252,\n",
        "   -21.87763734, -25.29124192, -37.70261395, -32.06002976, -37.55333989,\n",
        "     3.05150248, -10.64373529,  -6.70861488, -25.30559016, -56.576501,\n",
        "    16.30638079,  10.80652839,  -0.85537565, -61.01324566, -37.03868886,\n",
        "    21.13524191,  18.40083665, -25.36843063,  43.14481738,  29.39306285,\n",
        "   -24.54420009,  -2.0335233,   -0.31976222,  40.61494124,  57.30685941,\n",
        "   -34.73713881, -30.63781385,   8.45863857, -32.02285974,  -9.81967995,\n",
        "    19.31799882,  -5.87473403, -10.68178413, -54.75878878,  21.34389051,\n",
        "     6.64222051, -71.77728684,  11.06174306,  12.94640783, -13.26093112,\n",
        "   -23.2402532,    9.96075751,  25.32552931])\n",
        "\n",
        "try:\n",
        "  flat_drift_weights = best_drift_params\n",
        "except NameError:\n",
        "  flat_drift_weights = np.array([\n",
        "         37.89629402,  -48.2903797 ,  104.57227396,   82.96216298,\n",
        "        -33.72075405,  -11.60406537,  -13.81356909,  -51.3297726 ,\n",
        "        -88.41182722,  -40.9836382 ,  -11.69845196,   26.95174635,\n",
        "         14.99113154,  -42.84500512,  -31.22642526,    0.8173807 ,\n",
        "         14.84325766,    5.03038252, -103.05269519,  -28.56967293,\n",
        "         51.6487887 ,   73.90697663,   18.44399746,   76.73473352,\n",
        "         40.74093128,  -42.35290311,   45.31994088,  -31.84604343,\n",
        "          8.83368266,   81.59865548,   -5.40502478,  -72.75935279,\n",
        "         46.0222178 ,  -64.32899446,   -1.39618574,   45.16903944,\n",
        "          2.57398304,  -65.45567314,  -24.56553091,    0.86333044,\n",
        "         45.63555023,  -56.93741837,   10.23266167,  -13.28302046,\n",
        "         29.150387  ,  -39.25495485,  -31.43520672,   31.85720807])\n",
        "\n",
        "#ppp = PerceptParamPlayer(gwg, weights=weights)\n",
        "drift_boppp = BatchOptPerceptParamPlayer(\n",
        "    gwg, weights=flat_drift_weights.reshape(4,12))\n",
        "classic_boppp = BatchOptPerceptParamPlayer(\n",
        "    gwg, weights=flat_classic_weights.reshape(4,12))\n",
        "h2hgw = Head2HeadGridworld(\n",
        "    gwg, player0=drift_boppp, p0_short_name='Drift',\n",
        "    player1=classic_boppp, p1_short_name='Classic',\n",
        "    p0_long_name='Optimized for Drift',\n",
        "    p1_long_name='Optimized for No Drift',\n",
        "    figsize=(4,4))\n",
        "display(h2hgw.b_fig0.canvas)\n",
        "display(h2hgw.b_fig1.canvas)\n",
        "clear_output()\n",
        "display(h2hgw.final_display)"
      ],
      "metadata": {
        "cellView": "form",
        "id": "6y7ZnD4nWapG",
        "outputId": "ff16f79a-e097-4b65-9cce-95934b2e44d5",
        "colab": {
          "resources": {
            "http://localhost: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": {
              "data": "CjwhRE9DVFlQRSBodG1sPgo8aHRtbCBsYW5nPWVuPgogIDxtZXRhIGNoYXJzZXQ9dXRmLTg+CiAgPG1ldGEgbmFtZT12aWV3cG9ydCBjb250ZW50PSJpbml0aWFsLXNjYWxlPTEsIG1pbmltdW0tc2NhbGU9MSwgd2lkdGg9ZGV2aWNlLXdpZHRoIj4KICA8dGl0bGU+RXJyb3IgNDA0IChOb3QgRm91bmQpISExPC90aXRsZT4KICA8c3R5bGU+CiAgICAqe21hcmdpbjowO3BhZGRpbmc6MH1odG1sLGNvZGV7Zm9udDoxNXB4LzIycHggYXJpYWwsc2Fucy1zZXJpZn1odG1se2JhY2tncm91bmQ6I2ZmZjtjb2xvcjojMjIyO3BhZGRpbmc6MTVweH1ib2R5e21hcmdpbjo3JSBhdXRvIDA7bWF4LXdpZHRoOjM5MHB4O21pbi1oZWlnaHQ6MTgwcHg7cGFkZGluZzozMHB4IDAgMTVweH0qID4gYm9keXtiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9lcnJvcnMvcm9ib3QucG5nKSAxMDAlIDVweCBuby1yZXBlYXQ7cGFkZGluZy1yaWdodDoyMDVweH1we21hcmdpbjoxMXB4IDAgMjJweDtvdmVyZmxvdzpoaWRkZW59aW5ze2NvbG9yOiM3Nzc7dGV4dC1kZWNvcmF0aW9uOm5vbmV9YSBpbWd7Ym9yZGVyOjB9QG1lZGlhIHNjcmVlbiBhbmQgKG1heC13aWR0aDo3NzJweCl7Ym9keXtiYWNrZ3JvdW5kOm5vbmU7bWFyZ2luLXRvcDowO21heC13aWR0aDpub25lO3BhZGRpbmctcmlnaHQ6MH19I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LnBuZykgbm8tcmVwZWF0O21hcmdpbi1sZWZ0Oi01cHh9QG1lZGlhIG9ubHkgc2NyZWVuIGFuZCAobWluLXJlc29sdXRpb246MTkyZHBpKXsjbG9nb3tiYWNrZ3JvdW5kOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSBuby1yZXBlYXQgMCUgMCUvMTAwJSAxMDAlOy1tb3otYm9yZGVyLWltYWdlOnVybCgvL3d3dy5nb29nbGUuY29tL2ltYWdlcy9sb2dvcy9lcnJvcnBhZ2UvZXJyb3JfbG9nby0xNTB4NTQtMngucG5nKSAwfX1AbWVkaWEgb25seSBzY3JlZW4gYW5kICgtd2Via2l0LW1pbi1kZXZpY2UtcGl4ZWwtcmF0aW86Mil7I2xvZ297YmFja2dyb3VuZDp1cmwoLy93d3cuZ29vZ2xlLmNvbS9pbWFnZXMvbG9nb3MvZXJyb3JwYWdlL2Vycm9yX2xvZ28tMTUweDU0LTJ4LnBuZykgbm8tcmVwZWF0Oy13ZWJraXQtYmFja2dyb3VuZC1zaXplOjEwMCUgMTAwJX19I2xvZ297ZGlzcGxheTppbmxpbmUtYmxvY2s7aGVpZ2h0OjU0cHg7d2lkdGg6MTUwcHh9CiAgPC9zdHlsZT4KICA8YSBocmVmPS8vd3d3Lmdvb2dsZS5jb20vPjxzcGFuIGlkPWxvZ28gYXJpYS1sYWJlbD1Hb29nbGU+PC9zcGFuPjwvYT4KICA8cD48Yj40MDQuPC9iPiA8aW5zPlRoYXTigJlzIGFuIGVycm9yLjwvaW5zPgogIDxwPiAgPGlucz5UaGF04oCZcyBhbGwgd2Uga25vdy48L2lucz4K",
              "ok": false,
              "headers": [
                [
                  "content-length",
                  "1449"
                ],
                [
                  "content-type",
                  "text/html; charset=utf-8"
                ]
              ],
              "status": 404,
              "status_text": "Not Found"
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 581,
          "referenced_widgets": [
            "c21c438aab2642979828c1aaa5fd0c86",
            "2b1f74e6b202479ca5d04f3e9688135c",
            "26df0b28f2854eccba441ffa4afbb401",
            "3566380572174dc2b412de5f30de051f",
            "c3a09656c1844f928d7b9835891f924e",
            "4a145b66e71e44bdbbbcdc1a56599243",
            "579acb6f014c4fc4bd45faf7110a221c",
            "eb61094ebb39489796d1fdf44d0072e1",
            "04fb80756bb84f228d39bbef242261ad",
            "6fa43bd2ced54a04b8f3d6085d021879",
            "b9b167d9de52414799696ed53df35687",
            "f7346819dfb44fd9b5f5d4e9aa2424cb",
            "413bbc1b44004efba70af502e1c376f9",
            "e7c68b8e91f24279b9b91bef0a339412",
            "10fd13ce8c8749e289b32bf5f375cdb6",
            "8f7e6382af5e47598e16f8905e89f305",
            "12c8e530025046d1b6144c62fad17097",
            "9b357f33032846b193bb334e00c85e6f",
            "994120fe25304eb5bb799da03dede0da",
            "72b136e3c2a941f5989d63fc1b56f4b8",
            "0d4b7047c6ea482fb4af0d4616eabe89",
            "e33f8e159b6b40d68d89338366df820f",
            "f6d77bacfb71472fac0530163a76588a",
            "07acb513f68142bd9a099bfcd302470a",
            "430b871d23ea4e99a9eb214a17639b1c",
            "3a92abec75fd4e5f8eeb6b38d99a91f3",
            "ad4eccde96fc467988052534199e1543",
            "29b234dde22b45e48df9db030157fa38",
            "4c7813fd5acd49e581d739ade1e57c9c"
          ]
        }
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "HBox(children=(VBox(children=(Canvas(footer_visible=False, header_visible=False, resizable=False, toolbar=Toolâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c21c438aab2642979828c1aaa5fd0c86"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/b3e629b1971e1542/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maybe this is an obvious point, but still one worth emphasizing. The good parameters for the environment with drift are differentr from the the good parameters for the environment without drift, and vice-vera."
      ],
      "metadata": {
        "id": "QGVj4IUnOVqy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @markdown Run this cell to see a contingency table showing how the different policies perform in the different environments.\n",
        "\n",
        "classic_game = GridworldGame(batch_size=900, n_rows=7, n_cols=7,\n",
        "                             num_critters=1, num_food=10, lifetime=30,\n",
        "                             rng=np.random.default_rng(48))\n",
        "drift_game = GridworldGame(batch_size=900, n_rows=7, n_cols=7,\n",
        "                           num_critters=1, num_food=10, lifetime=30,\n",
        "                           rng=np.random.default_rng(48),\n",
        "                           drift_probs=[0, 0, 1.0, 0, 0.0],\n",
        "                           wrapping=True, drift_after_move=False)\n",
        "\n",
        "try:\n",
        "  good_classic_params = best_params\n",
        "except NameError:\n",
        "  good_classic_params = np.array([\n",
        "    72.44502999, -10.1196398,   75.58460857,   6.30015161,  22.72267252,\n",
        "   -21.87763734, -25.29124192, -37.70261395, -32.06002976, -37.55333989,\n",
        "     3.05150248, -10.64373529,  -6.70861488, -25.30559016, -56.576501,\n",
        "    16.30638079,  10.80652839,  -0.85537565, -61.01324566, -37.03868886,\n",
        "    21.13524191,  18.40083665, -25.36843063,  43.14481738,  29.39306285,\n",
        "   -24.54420009,  -2.0335233,   -0.31976222,  40.61494124,  57.30685941,\n",
        "   -34.73713881, -30.63781385,   8.45863857, -32.02285974,  -9.81967995,\n",
        "    19.31799882,  -5.87473403, -10.68178413, -54.75878878,  21.34389051,\n",
        "     6.64222051, -71.77728684,  11.06174306,  12.94640783, -13.26093112,\n",
        "   -23.2402532,    9.96075751,  25.32552931])\n",
        "\n",
        "try:\n",
        "  good_drift_params = best_drift_params\n",
        "except NameError:\n",
        "  good_drift_params = np.array([\n",
        "         37.89629402,  -48.2903797 ,  104.57227396,   82.96216298,\n",
        "        -33.72075405,  -11.60406537,  -13.81356909,  -51.3297726 ,\n",
        "        -88.41182722,  -40.9836382 ,  -11.69845196,   26.95174635,\n",
        "         14.99113154,  -42.84500512,  -31.22642526,    0.8173807 ,\n",
        "         14.84325766,    5.03038252, -103.05269519,  -28.56967293,\n",
        "         51.6487887 ,   73.90697663,   18.44399746,   76.73473352,\n",
        "         40.74093128,  -42.35290311,   45.31994088,  -31.84604343,\n",
        "          8.83368266,   81.59865548,   -5.40502478,  -72.75935279,\n",
        "         46.0222178 ,  -64.32899446,   -1.39618574,   45.16903944,\n",
        "          2.57398304,  -65.45567314,  -24.56553091,    0.86333044,\n",
        "         45.63555023,  -56.93741837,   10.23266167,  -13.28302046,\n",
        "         29.150387  ,  -39.25495485,  -31.43520672,   31.85720807])\n",
        "data = {\n",
        "  \"classic_game\": [evaluate(good_classic_params, classic_game),\n",
        "                   evaluate(good_drift_params, classic_game)],\n",
        "  \"drift_game\": [evaluate(good_classic_params, drift_game),\n",
        "                   evaluate(good_drift_params, drift_game)]\n",
        "}\n",
        "df = pd.DataFrame.from_dict(data, orient='index', columns=[\"good_classic_params\", \"good_drift_params\"])\n",
        "display(df)\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "SBD3OUFqCth0",
        "outputId": "16ce870b-9d84-4a8f-da2c-ff5f81bfa0db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        }
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "              good_classic_params  good_drift_params\n",
              "classic_game            14.395556           4.922222\n",
              "drift_game               8.755556          14.160000"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-add507e4-87ac-47d9-9cea-2e2fac663f12\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>good_classic_params</th>\n",
              "      <th>good_drift_params</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>classic_game</th>\n",
              "      <td>14.395556</td>\n",
              "      <td>4.922222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>drift_game</th>\n",
              "      <td>8.755556</td>\n",
              "      <td>14.160000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-add507e4-87ac-47d9-9cea-2e2fac663f12')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-add507e4-87ac-47d9-9cea-2e2fac663f12 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-add507e4-87ac-47d9-9cea-2e2fac663f12');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-147ff584-12c6-4164-a0d4-d1efdac3fb03\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-147ff584-12c6-4164-a0d4-d1efdac3fb03')\"\n",
              "            title=\"Suggest charts.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-147ff584-12c6-4164-a0d4-d1efdac3fb03 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.2.2.3 Optimization in a constantly changing environment"
      ],
      "metadata": {
        "id": "YN0N5gMgUfcw"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This simple observation, that the policy which is well suited to one environment may not be well suited to another is somewhat trivial. As is the seemingly trite obervation that any environment is in a constant state of change (change is the only constant!). However, considering these two somewhat banal observations together hints at the difficulty of producing adaptive behaviour and phenotypes, i.e. the grand optimization problem evolution and learning processes attempt to solve."
      ],
      "metadata": {
        "id": "kVMGCojVco0p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The following simulation helps to demonstrate the issue."
      ],
      "metadata": {
        "id": "dGSnTKJ4rWyN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Adjusting the order of directions for clockwise transition while maintaining the output order\n",
        "clockwise_order = ['left', 'up', 'right', 'down']\n",
        "output_order = ['up', 'down', 'left', 'right', 'still']\n",
        "\n",
        "# Mapping the direction_order to the desired output_order\n",
        "mapping = [output_order.index(direction) for direction in clockwise_order]\n",
        "\n",
        "# Generating combinations in the specified order\n",
        "combinations = []\n",
        "\n",
        "# Iterate over pairs of directions\n",
        "for idx in range(len(clockwise_order)):\n",
        "  current_direction = mapping[idx]\n",
        "  next_direction = mapping[(idx + 1) % len(clockwise_order)]  # Using modulo to wrap around to the start\n",
        "  for i in range(11):\n",
        "    probs = [0.0, 0.0, 0.0, 0.0, 0.0]\n",
        "    probs[current_direction] = 1.0 - i * 0.1\n",
        "    probs[next_direction] = i * 0.1\n",
        "    combinations.append(probs)\n",
        "\n",
        "print(len(combinations))\n"
      ],
      "metadata": {
        "id": "AX7_L9a-3xkk",
        "outputId": "8a35f35c-d5b5-42c1-9355-6a71ecc0035b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for env_ in combinations:\n",
        "  game = GridworldGame"
      ],
      "metadata": {
        "id": "agCuKV2A4jlH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "In that lower dimensional space it was sufficient to just try random parameters values in the neighbourhood of the best known parameter values, but in this higher dimensional space, such an approach will not reliably find good parameters. In this higher dimensional optimization problem there are just so many more bad directions to go in that an algorithm that relys soley on luck to pick a new, better set of parameters can't always find good parameters in a reasonable amount of time. Specifically, in the last sequence, taking advantage of symmetry, a good set of parameter values could be found in 1-3 minutes setting `max_rejected`=100. In contrast, `max_reject` must be set higher in this problem for reliable convergence to a good result (and we only know what a good or bad result is from our previous experience with this problem). With this higher `max_rejected` the time to converge is much longer for the version of the problem without symmetry. Run the cell below to execute a more sophisticated optimization algorithm (Nelder-Mead). We won't get into any of the details of this algorithm, other than to mention that it keeps track of the best points it has tested, and uses these to inform a guess about which parameters to investigate next."
      ],
      "metadata": {
        "id": "NiHdvcL5rd9H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "id": "_LDV7bLpqwA8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(flat_W, game):\n",
        "  # Run the game with the proposed weights\n",
        "  W = flat_W.reshape((4,12))\n",
        "  boppp = BatchOptPerceptParamPlayer(game, weights=W, deterministic=False)\n",
        "  final_board = game.play_game(players=[boppp], visualize=False)\n",
        "  # Evaluate the score\n",
        "  scores = final_board['scores'].flatten()\n",
        "  avg_score = np.mean(scores)\n",
        "  return(avg_score)\n",
        "\n",
        "\n",
        "def memory_propose_and_test(batch_size=25, high_batch_size=400,\n",
        "                            N = 100, # number of test points to remember\n",
        "                            dim = 48, # depends on evaluated function\n",
        "                            max_rejected=100,\n",
        "                            grad_scale=0.2,\n",
        "                            noise_scale = 0.1,\n",
        "                            verbose=True):\n",
        "\n",
        "  game = GridworldGame(batch_size=batch_size, n_rows=7, n_cols=7,\n",
        "                       num_critters=1, num_food=10, lifetime=30,\n",
        "                       rng=np.random.default_rng(48))\n",
        "  high_batch_game = GridworldGame(batch_size=high_batch_size, n_rows=7, n_cols=7,\n",
        "                                  num_critters=1, num_food=10, lifetime=30,\n",
        "                                  rng=np.random.default_rng(48))\n",
        "  # Initialization\n",
        "  test_points = np.random.uniform(-1, 1, (N, dim))\n",
        "  test_values = np.zeros(len(test_points))\n",
        "  start_time = time.time()\n",
        "  print(f\"Initializing {N} test points\")\n",
        "  for i, tp in enumerate(tqdm(test_points)):\n",
        "    test_values[i] = evaluate(tp, game)\n",
        "  rejected_count = 0\n",
        "  tests_to_new_best = 0\n",
        "  total_tests = 0  # Number of iterations\n",
        "\n",
        "  print('Starting propose and test loop')\n",
        "  # Propose-and-test loop\n",
        "  while rejected_count < max_rejected:\n",
        "    model = LinearRegression().fit(test_points, test_values)\n",
        "    # Identify the best point\n",
        "    best_idx = np.argmax(test_values)\n",
        "    best_point = test_points[best_idx]\n",
        "\n",
        "    # Proposal based on model gradient\n",
        "    gradient = model.coef_\n",
        "    #print(np.linalg.norm(gradient))\n",
        "    # to maximize score go in the grad direction, to min go neg grad\n",
        "    delta = np.random.normal(0, noise_scale, dim) + grad_scale * gradient\n",
        "    proposed_point = best_point + delta\n",
        "    proposed_value = evaluate(proposed_point, game)\n",
        "\n",
        "    worst_test_value = np.min(test_values)\n",
        "    if proposed_value > worst_test_value:\n",
        "      lower_var_proposed_value = evaluate(proposed_point, high_batch_game)\n",
        "      if lower_var_proposed_value > worst_test_value:\n",
        "        print(f\"Added new test point after {rejected_count} tests and {time.time() - start_time} seconds\")\n",
        "        worst_idx = np.argmin(test_values)\n",
        "        old_best = np.max(test_values)\n",
        "        best_idx = np.argmax(test_values)\n",
        "        best_params = test_points[best_idx]\n",
        "        test_points[worst_idx] = proposed_point\n",
        "        test_values[worst_idx] = lower_var_proposed_value\n",
        "        if old_best < lower_var_proposed_value:\n",
        "          if verbose:\n",
        "            print(f\"New best test score now: {np.max(test_values)}\")\n",
        "            print(f\"Found after {tests_to_new_best} tests\")\n",
        "            #print(f\"Best params now: {best_params}\")\n",
        "            #print(f\"Params just added: {proposed_point}\")\n",
        "          tests_to_new_best = 0\n",
        "        rejected_count = 0\n",
        "      else:\n",
        "        rejected_count += 1\n",
        "    else:\n",
        "      rejected_count += 1\n",
        "    tests_to_new_best += 1\n",
        "    total_tests +=1\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "  best_score = np.max(test_values)\n",
        "  best_idx = np.argmax(test_values)\n",
        "  best_params = test_points[best_idx]\n",
        "\n",
        "  if verbose:\n",
        "    # Print the best found parameters and score\n",
        "    print(\"Best Parameters:\", best_params)\n",
        "    print(\"Best Average Score:\", best_score)\n",
        "    print(\"Parameter combinations tested:\", total_tests)\n",
        "    print(f\"Time taken for the optimization loop: {elapsed_time:.2f} seconds\")\n",
        "  return best_params, best_score\n",
        "best_params, best_avg_score = memory_propose_and_test()\n"
      ],
      "metadata": {
        "id": "QEXcNLzH8U-0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now we have a an optimization process that can find good parameters in a moderately high dimensional space (48) and we know it works pretty well since it is finding parameters that perform abou as well as the one we found in the symmetric case. Now that we have this process in place, let's see if this memory augmented propose and"
      ],
      "metadata": {
        "id": "GrLzo8S0et_V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_params"
      ],
      "metadata": {
        "id": "fOh4qwvC_LMX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "game = GridworldGame(batch_size=400, n_rows=7, n_cols=7,\n",
        "                     num_critters=1, num_food=10, lifetime=30,\n",
        "                     rng=np.random.default_rng(48))\n",
        "def evaluate(flat_W):\n",
        "  # Run the game with the proposed weights\n",
        "  W = flat_W.reshape((4,12))\n",
        "  boppp = BatchOptPerceptParamPlayer(game, weights=W, deterministic=False)\n",
        "  final_board = game.play_game(players=[boppp], visualize=False)\n",
        "  # Evaluate the score\n",
        "  scores = final_board['scores'].flatten()\n",
        "  avg_score = np.mean(scores)\n",
        "  return(-avg_score)\n",
        "\n",
        "bounds = [(-10.0, 20.0) for _ in range(48)]\n",
        "\n",
        "# Generate an initial guess within the bounds\n",
        "flat_W_init = np.array([np.random.uniform(low, high) for low, high in bounds])\n",
        "\n",
        "def callback(intermediate_result):\n",
        "    current_cost = intermediate_result.fun\n",
        "    if np.mod(callback.iter_count, 3) == 0:\n",
        "      print(f\"Iteration {callback.iter_count}: Cost = {current_cost}\")\n",
        "    callback.iter_count += 1\n",
        "# Initialize attributes for the callback function\n",
        "callback.prev_cost = float('inf')\n",
        "callback.iter_count = 1\n",
        "\n",
        "# Optimize using Nelder-Mead with bounds\n",
        "result = minimize(evaluate, flat_W_init,\n",
        "                  method='Nelder-Mead',\n",
        "                  bounds=bounds, options={'disp':True, 'maxiter':500000,\n",
        "                                          'adaptive':True},\n",
        "                  callback=callback)\n",
        "\n",
        "print(result.fun, result.success)"
      ],
      "metadata": {
        "id": "tL2042K01bjL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from scipy.optimize import minimize\n",
        "\n",
        "# Define the dimensions\n",
        "n, m = 7, 7\n",
        "\n",
        "# Sample W_targ from a uniform distribution\n",
        "W_targ = np.random.uniform(-1, 1, (n, m))\n",
        "\n",
        "# Create a random positive vector x\n",
        "x = np.abs(np.random.randn(n))\n",
        "\n",
        "# Define the cost function\n",
        "def cost_function(W_params_flat):\n",
        "    W_params = W_params_flat.reshape(n, m)\n",
        "    diff = W_targ - W_params\n",
        "    return x.T @ (diff**2) @ x\n",
        "\n",
        "# Define bounds based on W_targ values\n",
        "bounds = [(-1.0, 1.0) for _ in W_targ.flatten()]\n",
        "\n",
        "# Generate an initial guess within the bounds\n",
        "W_params_init_within_bounds = np.array([np.random.uniform(low, high) for low, high in bounds])\n",
        "\n",
        "\n",
        "def callback(intermediate_result):\n",
        "    current_cost = intermediate_result.fun\n",
        "    if np.mod(callback.iter_count, 10000) == 0:\n",
        "      print(f\"Iteration {callback.iter_count}: Cost = {current_cost}\")\n",
        "    callback.iter_count += 1\n",
        "\n",
        "# Initialize attributes for the callback function\n",
        "callback.prev_cost = None\n",
        "callback.iter_count = 1\n",
        "\n",
        "# Initialize attributes for the callback function\n",
        "callback.prev_cost = float('inf')\n",
        "callback.iter_count = 1\n",
        "\n",
        "# Optimize using Nelder-Mead with bounds\n",
        "result = minimize(cost_function, W_params_init_within_bounds,\n",
        "                  method='Nelder-Mead',\n",
        "                  bounds=bounds, options={'disp':True, 'maxiter':500000,\n",
        "                                          'adaptive':True},\n",
        "                  callback=callback)\n",
        "\n",
        "print(result.fun, result.success)\n"
      ],
      "metadata": {
        "id": "dXqV0tvvwS1k"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Yv2oBtoA1TPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Squared Exponential Kernel\n",
        "def se_kernel(x, y, l=1.0, sigma_f=1.0):\n",
        "  \"\"\"Squared Exponential kernel.\"\"\"\n",
        "  sqdist = np.sum(x**2, 1).reshape(-1, 1) + np.sum(y**2, 1) - 2 * np.dot(x, y.T)\n",
        "  return sigma_f**2 * np.exp(-0.5 / l**2 * sqdist)\n",
        "\n",
        "\n",
        "def gp_posterior(X_train, Y_train, X_new,\n",
        "                 l=1.0, sigma_f=1.0, sigma_y=1e-8,\n",
        "                 K_inv=None):\n",
        "  \"\"\"Compute the posterior mean and covariance for new data X_new given training data X_train and Y_train.\"\"\"\n",
        "  K = se_kernel(X_train, X_train, l, sigma_f) + sigma_y**2 * np.eye(len(X_train))\n",
        "  K_s = se_kernel(X_train, X_new, l, sigma_f)\n",
        "  K_ss = se_kernel(X_new, X_new, l, sigma_f) + 1e-8 * np.eye(len(X_new))\n",
        "  # Compute the inverse of K if not provided\n",
        "  if K_inv is None:\n",
        "    K_inv = np.linalg.inv(K)\n",
        "  # Posterior mean\n",
        "  mu_s = K_s.T.dot(K_inv).dot(Y_train)\n",
        "  # Posterior covariance\n",
        "  cov_s = K_ss - K_s.T.dot(K_inv).dot(K_s)\n",
        "  return mu_s, cov_s\n",
        "\n",
        "\n",
        "def expected_improvement(X_new, X_train, Y_train,\n",
        "                         l=1.0, sigma_f=1.0, xi=0.01,\n",
        "                         K_inv=None):\n",
        "  \"\"\"Compute the expected improvement at X_new.\"\"\"\n",
        "  mu_s, cov_s = gp_posterior(X_train, Y_train, X_new, l, sigma_f, K_inv=K_inv)\n",
        "  sigma_s = np.sqrt(np.diag(cov_s))\n",
        "  mu_sample_opt = np.max(Y_train)\n",
        "  with np.errstate(divide='warn'):\n",
        "    imp = mu_s - mu_sample_opt - xi\n",
        "    Z = imp / sigma_s\n",
        "    ei = imp * norm.cdf(Z) + sigma_s * norm.pdf(Z)\n",
        "    ei[sigma_s == 0.0] = 0.0\n",
        "  return np.sum(ei)\n",
        "\n",
        "\n",
        "def propose_next_sample(acquisition, X_train, Y_train,\n",
        "                        l=1.0, sigma_f=1.0, bounds=None,\n",
        "                        n_restarts=25, K_inv=None):\n",
        "  \"\"\"Propose the next sampling point by optimizing the acquisition function.\"\"\"\n",
        "  dim = X_train.shape[1]\n",
        "  min_val = 1\n",
        "  x_next = None\n",
        "  # Randomly sample possible starting points for optimizer\n",
        "  starting_points = np.random.uniform(bounds[:, 0], bounds[:, 1], size=(n_restarts, dim))\n",
        "  for x_try in starting_points:\n",
        "    res = minimize(lambda x: -acquisition(x.reshape(1, -1),\n",
        "                                          X_train, Y_train,\n",
        "                                          l, sigma_f, K_inv=K_inv),\n",
        "                    x_try,\n",
        "                    bounds=bounds,\n",
        "                    method='Nelder-Mead')\n",
        "\n",
        "    if res.fun < min_val:\n",
        "      min_val = res.fun\n",
        "      x_next = res.x\n",
        "  return x_next.reshape(1, -1)\n",
        "\n",
        "\n",
        "def gp_optimization(initial_params, n_iterations, bounds):\n",
        "  \"\"\"\n",
        "  Use Gaussian Process to optimize the function evaluate by selecting the best parameters.\n",
        "  \"\"\"\n",
        "  # Initial data\n",
        "  X_train = initial_params.reshape(1, -1)\n",
        "  weights = np.reshape(X_train[0], (4,12))\n",
        "  scores = evaluate(weights)\n",
        "  Y_train = np.array([[np.mean(scores)]])  # Ensure Y_train is 2D\n",
        "\n",
        "  best_params = X_train[0]\n",
        "  best_avg_score = Y_train[0, 0]\n",
        "\n",
        "  # Cache the inverse of K\n",
        "  K = se_kernel(X_train, X_train) + 1e-8 * np.eye(len(X_train))\n",
        "  K_inv = np.linalg.inv(K)\n",
        "\n",
        "  for iteration in tqdm(range(n_iterations)):\n",
        "    # Propose next sample\n",
        "    X_new = propose_next_sample(expected_improvement, X_train, Y_train,\n",
        "                                bounds=bounds, K_inv=K_inv)\n",
        "    # Evaluate the new sample\n",
        "    weights_new = np.reshape(X_new[0], (4,12))\n",
        "    scores_new = evaluate(weights_new)\n",
        "    avg_score_new = np.mean(scores_new)\n",
        "\n",
        "    # Add new data to training set\n",
        "    X_train = np.vstack((X_train, X_new))\n",
        "    Y_train = np.vstack((Y_train, avg_score_new))\n",
        "\n",
        "    # Update the inverse of K\n",
        "    K = se_kernel(X_train, X_train) + 1e-8 * np.eye(len(X_train))\n",
        "    K_inv = np.linalg.inv(K)\n",
        "\n",
        "    # Update best parameters if needed\n",
        "    if avg_score_new > best_avg_score:\n",
        "      best_avg_score = avg_score_new\n",
        "      best_params = X_new[0]\n",
        "\n",
        "    print(f\"Iteration {iteration + 1}:\")\n",
        "    print('Best params so far:', best_params)\n",
        "    print('Best score so far:', best_avg_score)\n",
        "    print('Parms just tested:', X_new[0])\n",
        "    print('Score of latest params:', avg_score_new)\n",
        "\n",
        "  return best_params, best_avg_score\n",
        "\n",
        "\n",
        "def evaluate(W):\n",
        "  game = GridworldGame(batch_size=400, n_rows=7, n_cols=7,\n",
        "                     num_critters=1, num_food=10, lifetime=30,\n",
        "                     rng=np.random.default_rng(48))\n",
        "  # Run the game with the proposed weights\n",
        "  boppp = BatchOptPerceptParamPlayer(game, weights=W, deterministic=False)\n",
        "  final_board = game.play_game(players=[boppp], visualize=False)\n",
        "  # Evaluate the score\n",
        "  scores = final_board['scores'].flatten()\n",
        "  avg_score = np.mean(scores)\n",
        "  return(avg_score)\n",
        "\n",
        "\n",
        "# Let's assume some bounds for your parameters. You might need to adjust these.\n",
        "bounds = np.array([[-10, 20] for _ in range(48)])\n",
        "# For simplicity, assuming all parameters are bounded between -1 and 2.\n",
        "\n",
        "# Rerun the GP optimization\n",
        "best_params_gp, best_avg_score_gp = gp_optimization(np.zeros(48),\n",
        "                                                    n_iterations=200,\n",
        "                                                    bounds=bounds)\n",
        "best_params_gp, best_avg_score_gp"
      ],
      "metadata": {
        "id": "lTp9TDcEFnd6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VGJbySUBFkfP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "gwg.drift_probs"
      ],
      "metadata": {
        "id": "AHYOSs7G-4G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "j8ey-3j55MK8"
      },
      "source": [
        "Okay, so it will probably take a long time to optimize if we can only get feedback on one stochastic simulation at a time. Also what are we even trying to optimize for? Our best score out of 10 simulation runs? The highest low score out of 100 simulation runs? The highest average score over 10, 100, 1000 simulation runs? The policy that achieves one of these goals might not be the same as the policy that achieves another of these goals, so we need to choose. A well defined evolutionary process often implies a specific goal, but we don't have a well defined evolutionary process just yet so instead we're going to have to just pick something. For now we're going to go with maximizing the ***Expected*** score, i.e. the goal is to have a policy with a [high average score over many simulations](## \"The expectation of a random variable is connected to the mean of a set of samples of that variable by an important theorem in probability theory called the Law of Large Numbers. Specifically, the sample mean can be made arbitrarily close to the expected value of the random variable by making the sample size larger and larger. Imagine flipping a fair coin. Even though the chance of getting heads is 50%, in just 10 flips, there could easily be 7 heads and 3 tails just due to randomness, and 70% heads is very different from the true expected value of 50%. But flip that same coin a million times and the proportion of heads will be much closer to 50%. The Law of Large Numbers essentially says: the more flips, the closer to that true 50% mark.\").  We can get better feedback on how well we are doing on this goal, despite the stochaticity of the environment and the policy, by averaging the score over many runs. Run the cell below to continue exploring the impact of weight changes on score, but now getting feedback from 400 simulations run in parallel."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "rhsmkZeW5MK9"
      },
      "outputs": [],
      "source": [
        "# @title Twiddle the Weights Again\n",
        "# @markdown Run this cell to play with the weights for our 'Parameterized Weights' policy. This time getting feedback on 400 simulation runs instead of just one. It may take a few seconds to run the simulations.\n",
        "gwg = GridworldGame(batch_size=400, n_rows=7, n_cols=7,\n",
        "                    num_critters=1, num_food=10, lifetime=30)\n",
        "eww = ExploreWeightsWidget(gwg)\n",
        "display(eww.fig.canvas)\n",
        "clear_output()\n",
        "display(eww.final_display)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "KhOvouJo5MLB"
      },
      "source": [
        "How well did you do? What differences did you notice between evaluating weights based on 400 simulations versus one?\n",
        "[Answer](## \"The simulations take longer to run, but the feedback is more consistent. This is due to an important theorem in statistics called the Central Limit Theorem. It states that, for large sample sizes, the average (or mean) of the sample values will follow a normal distribution, centered around the true average of the entire population. Furthermore the variability (or spread) of these averages decreases as you increase the sample size. Specifically, the standard deviation of the sample mean distribution is close to the standard deviation of the population divided by the square root of the sample size. These means that with a sample size of 400 we expect the standard deviation in the feedback to be 20 times smaller than in the single simulation case.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "HC-qD37p5MLC"
      },
      "source": [
        "You may now be wondering if there are ways of choosing parameter weights that are less tedious than dialing them in by hand and looking at the feedback. You may even be imagining what they might be, and how to implement them. There are ***many*** ways of setting parameter values to improve an objective function and we are going to start implementing and thinking about some of the simplest and most foundational ones. We start with grid search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "WFMJz0At5MLD"
      },
      "outputs": [],
      "source": [
        "# @markdown Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_M1\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "pfXnoFQC5MLE"
      },
      "source": [
        "# 1.2.1.2 Grid Search Parameter Tuning\n",
        "Grid search is both simple and computationally intensive, and so is often reffered to as a 'Brute Force' method. The basic idea, in our case, is to think of the parameters of the policy as sitting in a 48 dimensional, real valued, vector space (one for each element of the weights matrix). In math symbols this is $\\theta \\in \\mathbb{R}^{48}$. We can make a grid over a plausible set of parameters in this vector space, and evaluate the performance of a policy with weights corresponding to each point on the grid. Grids of evenly spaced numbers in vector spaces of arbitrary dimension come up frequently in many applications, so there are nice libraries and functions to help us make such grids. Let's start by only allowing parameters to be one of three values, $0$, $0.5$, or $1$."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "acH5ob4W5MLE"
      },
      "outputs": [],
      "source": [
        "# numpy's linspace makes an array of evenly spaced points on a line,\n",
        "# we need 48 of those\n",
        "dimensions = [np.linspace(0, 1, 3) for _ in range(48)]\n",
        "print(\"'dimensions' is a: \" + type(dimensions).__name__)\n",
        "print('It has a length of ' + str(len(dimensions)))\n",
        "print('Each element of dimensions looks like:')\n",
        "display(dimensions[0])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "SP_VX9n05MLE"
      },
      "source": [
        "Now let's make a grid of all those dimensions to evaluate our policy at."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "S_q69qSV5MLF"
      },
      "outputs": [],
      "source": [
        "# numpy.meshgrid or itertools.product can be used to enumerate every possible\n",
        "# combination of values in each of those parameter dimension.\n",
        "try:\n",
        "  grid = np.meshgrid(*dimensions, indexing='ij')\n",
        "except ValueError as e:\n",
        "  display(f\"Caught an error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "0rxlWerU5MLF"
      },
      "source": [
        "This should throw an error. The reason that the meshgrid function is throwing an error is because we are asking it to make a grid with $3^{48} \\approx 7.9766 \\times 10^{22}$ points in it. For context this is many orders of magnitude greater than the number of synapses in a human brain or the number of grains of sand on all the earth's beaches. More directly relevant, this is also much larger than the maximum number of float64's ($6.85 \\times 10^9$) that could theoretically be stored in 51 GB of memory (The memory provision of a 'High-Ram' Colab instance circa September 2023). It is simply not feasible for us to iterate through all of those grid-points. We can reduce our problem to something more tractable by enforcing symmetry (though maybe the optimal strategy isn't symmetric). Because Gridworld is symmetric and the organism is symmetric, it is plausible that a good weight strength between the 'near right' perceptive cell and the 'right direction' output neuron should be the same as the weight strength between the 'near left' perceptive cell and the 'left direction' output neuron, which should also be the same as between 'near up' and 'up direction' and the same as between 'near down' and 'down direction'. Generalizing this thinking we can apply rotational symmetry to reduce the parameters by a factor of 4, down to 12 and then apply flip symmetries (e.g. down and up perceptions should be treated the same for purposes of deciding to move left or right) to further reduce from 12 parameters to 8. In contrast $3^8=6561$ is not [such a big number](## \"From a practical perspective thinking about data set sizes, model sizes, and algorithm memory use three distinct order of magnitude categories should be considered. 1) Fits in memory life is great. 2) Fits on disk but not on memory, need to use a database to manage io between disk and memory but life is okay. 3) Does not fit on disk, need to set up a cluster and coordinate computation between different hardware, life is complicated\"). This scale of grid easily fits in a (modern) computer's memory, we can readily work with it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "2hrQQYc55MLH"
      },
      "outputs": [],
      "source": [
        "sym_dimensions = [np.linspace(0, 1, 3) for _ in range(8)]\n",
        "try:\n",
        "  # Generate all possible combinations of symmetry parameters\n",
        "  param_combinations = list(itertools.product(*sym_dimensions))\n",
        "except ValueError as e:\n",
        "  display(f\"Caught an error: {e}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "8UsJb2Hn5MLI"
      },
      "source": [
        "Okay, now that we have a tractable set of parameters to iterate through, let's implement grid search."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "3sssfZww5MLI"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# TODO for students: Complete the lines with ...  to correctly map the symmetric\n",
        "# parameters to the expanded weight matrix, and to update the best params and\n",
        "# average score based on each evaluation of the params. Then comment out the\n",
        "# line below.\n",
        "raise NotImplementedError(\"Exercise: implement symmetry, and param updates\")\n",
        "################################################################################\n",
        "\n",
        "game = GridworldGame(batch_size=9, n_rows=7, n_cols=7,\n",
        "                     num_critters=1, num_food=10, lifetime=30,\n",
        "                     rng=np.random.default_rng(48))\n",
        "best_avg_score = float('-inf')\n",
        "best_params = None\n",
        "\n",
        "def convert_symmetry_to_weights(symmetry_params):\n",
        "  # Initialize the weight matrix with zeros\n",
        "  weights = np.zeros((4,12))\n",
        "  symmetry_indices = {\n",
        "    'Up':    [0,  1,  2,  1,  3,  4,  4,  3,  5,  6,  5,  7],\n",
        "    'Down':  [7,  5,  6,  5,  3,  4,  4,  3,  1,  2,  1,  0],\n",
        "    'Left':  [3,  1,  4,  5,  0,  2,  6,  7,  1,  4,  5,  3],\n",
        "    'Right': [3,  5,  4,  1,  7,  6,  2,  0,  5,  4,  1,  3]}\n",
        "  # Use the symmetry indices to populate the 48-dimensional weight vector\n",
        "  for i, direction in enumerate(['Up', 'Down', 'Left', 'Right']):\n",
        "    for j, idx in enumerate(symmetry_indices[direction]):\n",
        "      weights[..., ...] = symmetry_params[...]\n",
        "    return weights\n",
        "\n",
        "# Loop through each combination\n",
        "for params in tqdm(param_combinations):\n",
        "  # Convert symmetry parameters to the actual weights\n",
        "  weights = convert_symmetry_to_weights(params)\n",
        "\n",
        "  # Run the game with the weights\n",
        "  boppp = BatchOptPerceptParamPlayer(game, weights=weights, deterministic=True)\n",
        "  final_board = game.play_game(players=[boppp], visualize=False)\n",
        "\n",
        "  # Evaluate the score\n",
        "  scores = final_board['scores'].flatten()\n",
        "  avg_score = np.mean(scores)\n",
        "\n",
        "  # Update best parameters if needed\n",
        "  if avg_score > ...:\n",
        "    best_avg_score = ...\n",
        "    best_params = ...\n",
        "\n",
        "print(best_params)\n",
        "print(best_avg_score)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "yGPPd4zt5MLJ"
      },
      "outputs": [],
      "source": [
        "# to_remove solution\n",
        "game = GridworldGame(batch_size=9, n_rows=7, n_cols=7,\n",
        "                     num_critters=1, num_food=10, lifetime=30,\n",
        "                     rng=np.random.default_rng(48))\n",
        "best_avg_score = float('-inf')\n",
        "best_params = None\n",
        "\n",
        "def convert_symmetry_to_weights(symmetry_params):\n",
        "  # Initialize the weight matrix with zeros\n",
        "  weights = np.zeros((4,12))\n",
        "  symmetry_indices = {\n",
        "    'Up':    [0,  1,  2,  1,  3,  4,  4,  3,  5,  6,  5,  7],\n",
        "    'Down':  [7,  5,  6,  5,  3,  4,  4,  3,  1,  2,  1,  0],\n",
        "    'Left':  [3,  1,  4,  5,  0,  2,  6,  7,  1,  4,  5,  3],\n",
        "    'Right': [3,  5,  4,  1,  7,  6,  2,  0,  5,  4,  1,  3]}\n",
        "  # Use the symmetry indices to populate the 48-dimensional weight vector\n",
        "  for i, direction in enumerate(['Up', 'Down', 'Left', 'Right']):\n",
        "    for j, idx in enumerate(symmetry_indices[direction]):\n",
        "      weights[i, j] = symmetry_params[idx]\n",
        "    return weights\n",
        "\n",
        "# Loop through each combination\n",
        "for params in tqdm(param_combinations):\n",
        "  # Convert symmetry parameters to the actual weights\n",
        "  weights = convert_symmetry_to_weights(params)\n",
        "\n",
        "  # Run the game with the weights\n",
        "  boppp = BatchOptPerceptParamPlayer(game, weights=weights, deterministic=True)\n",
        "  final_board = game.play_game(players=[boppp], visualize=False)\n",
        "\n",
        "  # Evaluate the score\n",
        "  scores = final_board['scores'].flatten()\n",
        "  avg_score = np.mean(scores)\n",
        "\n",
        "  # Update best parameters if needed\n",
        "  if avg_score > best_avg_score:\n",
        "    best_avg_score = avg_score\n",
        "    best_params = params\n",
        "\n",
        "print(best_params)\n",
        "print(best_avg_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "6usTPFkt5MLK"
      },
      "source": [
        "Even just considering three points per dimension, and only evaluating each grid point using nine simulation runs, this looks like it is going to take about three minutes (on a default Colab instance circa September 2023). If we want to get a better result from this grid search approach we are going to have to both increase the resolution of the grid, and do a better evaluation of each grid point. Edit your solution and the grid definition cell above to increase the grid resolution to 5 points ranging from -1 to 1, and to evaluate each grid point with 25 simulations runs (hint edit batch_size). What does this do to the expected time to complete? This could take awhile so keep reading while you wait for this grid search to complete. You can also cancel the execution of this cell by clicking the square 'stop' symbol to the upper right of the code cell (Colab) or going to the `Runtime` drop-down and selecting `Interrupt execution`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "BeJCerp85MLK"
      },
      "source": [
        "Even though the grid search idea is simple, 'evaluate all the possible options and pick the best one', from a practical perspective it suffers from what is called the **Curse of Dimensionality**. When 'all possible options' are derived from a combination of parameters in different dimensions, even if we consider only a very small number of possible values in each dimension, the total number of combinations to be explored is the product of the number of parameters to be considered in each dimension. This number of all possible combinations can thus grow very quickly as the number of points per dimension increases, so much so, that it is often referred to as a **combinatorial explosion**. As a result, approaches to finding good parameters using grid search can only ever be effective if the number of dimensions being considered is very low (or if selecting parameters before the heat-death of the universe is not a concern)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "gUgA9U0c5MLL"
      },
      "source": [
        "**Memory Awareness Exercise**: If you are running this notebook in a Colab instance pop open the resources tab and watch what happens to System RAM when you run the next cell. (If you're running this notebook locally you can use 'top' or similar in a linux environment, or the task manager in windows). Next increase the number of points considered from $3$ to $10$, and run the cell again, still observing the memory usage. This is the combinatorial explosion in action! What number do you need to go to crash your Colab instance (or start using [swap](## \"Swap is when your computer runs out space in memory (RAM) and starts to use the disk as 'fake' RAM, which is usually an order of magnitude slower to read an write from, and will considerably slow most processes.\") on you local machine?). Warning, save your work before trying this, you might also crash your local machine!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "vrb3GPdt5MLM"
      },
      "outputs": [],
      "source": [
        "sym_dimensions = [np.linspace(0, 1, 3) for _ in range(8)]\n",
        "try:\n",
        "  # Generate all possible combinations of symmetry parameters\n",
        "  param_combinations = list(itertools.product(*sym_dimensions))\n",
        "except ValueError as e:\n",
        "  display(f\"Caught an error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "YgTnUARA5MLN"
      },
      "outputs": [],
      "source": [
        "# @markdown Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_M2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "b4SPstXJ5MLN"
      },
      "source": [
        "# 1.2.1.3 Propose and Test Parameter Tuning\n",
        "This scaling issue with grid search motivates us to come up with a parameter selection process that does not depend on iterating through an excessively long list of possible values. So, instead of labouriously iterating through a vast array of combinations, we'll 'test' parameter combinations (one at a time) that are close to the best known set of parameter values. If these test parameters outperform relative to the current best parameters they are 'accepted' and become the new best parameters. If the test parameters underperform relative to the current best parameters they are rejected and forgotten. After some fixed number of tests are rejected in a row we will say that the process has 'converged'. Let's make this."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "AYAUtKmv5MLN"
      },
      "outputs": [],
      "source": [
        "################################################################################\n",
        "# TODO for students: Complete the lines with ...  to set the stopping criterion\n",
        "# for the while loop, and to update the best params and average score based on\n",
        "# each evaluation of the params. Then comment out the line below.\n",
        "# This optimization may take some a few minutes to complete.\n",
        "raise NotImplementedError(\"Exercise: implement stopping criteria and param updates\")\n",
        "################################################################################\n",
        "\n",
        "def propose_and_test(batch_size=25, high_batch_size=400,\n",
        "                     max_rejected=100,\n",
        "                     step_scale=1.0,\n",
        "                     verbose=True):\n",
        "\n",
        "  game = GridworldGame(batch_size=batch_size, n_rows=7, n_cols=7,\n",
        "                       num_critters=1, num_food=10, lifetime=30,\n",
        "                       rng=np.random.default_rng(48))\n",
        "  high_batch_game = GridworldGame(batch_size=high_batch_size, n_rows=7, n_cols=7,\n",
        "                                  num_critters=1, num_food=10, lifetime=30,\n",
        "                                  rng=np.random.default_rng(48))\n",
        "  # Initialize parameters\n",
        "  initial_params = np.zeros(8)\n",
        "  best_params = initial_params\n",
        "  best_avg_score = float('-inf')\n",
        "  rejected_count = 0\n",
        "  total_tests = 0  # Number of iterations\n",
        "  std_dev = step_scale  # Standard deviation for Gaussian proposal\n",
        "\n",
        "  # Propose-and-test loop\n",
        "  start_time = time.time()\n",
        "  while rejected_count < ...:\n",
        "    # Propose new parameters: sample from Gaussian centered at best_params\n",
        "    delta_params = np.random.normal(0, std_dev, best_params.shape)\n",
        "    proposal_params = best_params + delta_params\n",
        "    # Convert symmetry parameters to actual weights\n",
        "    weights = convert_symmetry_to_weights(proposal_params)\n",
        "    # Run the game with the proposed weights\n",
        "    boppp = BatchOptPerceptParamPlayer(game, weights=weights, deterministic=False)\n",
        "    final_board = game.play_game(players=[boppp], visualize=False)\n",
        "    # Evaluate the score\n",
        "    scores = final_board['scores'].flatten()\n",
        "    avg_score = np.mean(scores)\n",
        "\n",
        "    # If a promising candidate is found, validate it with a high batch size evaluation\n",
        "    if avg_score > best_avg_score:\n",
        "      boppp_high_batch = BatchOptPerceptParamPlayer(high_batch_game, weights=weights, deterministic=False)\n",
        "      final_board_high_batch = high_batch_game.play_game(players=[boppp_high_batch], visualize=False)\n",
        "      scores_high_batch = final_board_high_batch['scores'].flatten()\n",
        "      avg_score_high_batch = np.mean(scores_high_batch)\n",
        "      # Only update best parameters if the candidate also performs well in the\n",
        "      # high batch size evaluation to avoid choosing parameters based on 'luck'\n",
        "      # i.e. from a really exceptional batch of simulations\n",
        "      if avg_score_high_batch > ...:\n",
        "        best_avg_score = ...\n",
        "        best_params = ...\n",
        "        if verbose:\n",
        "          #print('best params so far:')\n",
        "          #display(best_params)\n",
        "          print(f\"Best score so far: {best_avg_score}\")\n",
        "          print(f\"Found after {rejected_count} tests\")\n",
        "        rejected_count = 0\n",
        "      else:\n",
        "        rejected_count += 1\n",
        "    else:\n",
        "      rejected_count += 1\n",
        "    total_tests +=1\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "\n",
        "  if verbose:\n",
        "    # Print the best found parameters and score\n",
        "    print(\"Best Parameters:\", best_params)\n",
        "    print(\"Best Average Score:\", best_avg_score)\n",
        "    print(\"Parameter combinations tested:\", total_tests)\n",
        "    print(f\"Time taken for the optimization loop: {elapsed_time:.2f} seconds\")\n",
        "  return best_params, best_avg_score\n",
        "\n",
        "best_params, best_avg_score = propose_and_test()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "7iGFwGj25MLO"
      },
      "outputs": [],
      "source": [
        "# to_remove solution\n",
        "\n",
        "def propose_and_test(batch_size=25, high_batch_size=400,\n",
        "                     max_rejected=100,\n",
        "                     step_scale=1.0,\n",
        "                     verbose=True):\n",
        "\n",
        "  game = GridworldGame(batch_size=batch_size, n_rows=7, n_cols=7,\n",
        "                       num_critters=1, num_food=10, lifetime=30,\n",
        "                       rng=np.random.default_rng(48))\n",
        "  high_batch_game = GridworldGame(batch_size=high_batch_size, n_rows=7, n_cols=7,\n",
        "                                  num_critters=1, num_food=10, lifetime=30,\n",
        "                                  rng=np.random.default_rng(48))\n",
        "  # Initialize parameters\n",
        "  initial_params = np.zeros(8)\n",
        "  best_params = initial_params\n",
        "  best_avg_score = float('-inf')\n",
        "  rejected_count = 0\n",
        "  total_tests = 0  # Number of iterations\n",
        "  std_dev = step_scale  # Standard deviation for Gaussian proposal\n",
        "\n",
        "  # Propose-and-test loop\n",
        "  start_time = time.time()\n",
        "  while rejected_count < max_rejected:\n",
        "    # Propose new parameters: sample from Gaussian centered at best_params\n",
        "    delta_params = np.random.normal(0, std_dev, best_params.shape)\n",
        "    proposal_params = best_params + delta_params\n",
        "    # Convert symmetry parameters to actual weights\n",
        "    weights = convert_symmetry_to_weights(proposal_params)\n",
        "    # Run the game with the proposed weights\n",
        "    boppp = BatchOptPerceptParamPlayer(game, weights=weights, deterministic=False)\n",
        "    final_board = game.play_game(players=[boppp], visualize=False)\n",
        "    # Evaluate the score\n",
        "    scores = final_board['scores'].flatten()\n",
        "    avg_score = np.mean(scores)\n",
        "\n",
        "    # If a promising candidate is found, validate it with a high batch size evaluation\n",
        "    if avg_score > best_avg_score:\n",
        "      boppp_high_batch = BatchOptPerceptParamPlayer(high_batch_game, weights=weights, deterministic=False)\n",
        "      final_board_high_batch = high_batch_game.play_game(players=[boppp_high_batch], visualize=False)\n",
        "      scores_high_batch = final_board_high_batch['scores'].flatten()\n",
        "      avg_score_high_batch = np.mean(scores_high_batch)\n",
        "      # Only update best parameters if the candidate also performs well in the\n",
        "      # high batch size evaluation to avoid choosing parameters based on 'luck'\n",
        "      # i.e. from a really exceptional batch of simulations\n",
        "      if avg_score_high_batch > best_avg_score:\n",
        "        best_avg_score = avg_score_high_batch\n",
        "        best_params = proposal_params\n",
        "        if verbose:\n",
        "          #print('best params so far:')\n",
        "          #display(best_params)\n",
        "          print(f\"Best score so far: {best_avg_score}\")\n",
        "          print(f\"Found after {rejected_count} tests\")\n",
        "        rejected_count = 0\n",
        "      else:\n",
        "        rejected_count += 1\n",
        "    else:\n",
        "      rejected_count += 1\n",
        "    total_tests +=1\n",
        "  end_time = time.time()\n",
        "  elapsed_time = end_time - start_time\n",
        "\n",
        "  if verbose:\n",
        "    # Print the best found parameters and score\n",
        "    print(\"Best Parameters:\", best_params)\n",
        "    print(\"Best Average Score:\", best_avg_score)\n",
        "    print(\"Parameter combinations tested:\", total_tests)\n",
        "    print(f\"Time taken for the optimization loop: {elapsed_time:.2f} seconds\")\n",
        "  return best_params, best_avg_score\n",
        "\n",
        "best_params, best_avg_score = propose_and_test()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "klRGlqUp5MLO"
      },
      "source": [
        "Okay that took less time than grid search and deliverd a way better result. Now that we have this optimization process in place we can play with and think a bit about the 'hyperparameters' of the optimization process, i.e. the *parameters of the process* that we use to select the *parameters for our policy*. Run the code cells below. In each cell the values assigned to `max_rejected` or `step_scale` have been changed from the defaults above. As these cells execute, consider:\n",
        "* What will happen when `max_rejected` is very low? [Answer](## \"`max_rejected` determines how persistent the algorithm is in testing for better parameters before 'giving up' and accepting an answer. If `max_rejected` is too high the algorithm will take additional time to stop. On the other hand if `max_rejected` is too low, the algorithm might not search adequately for improvements and could stop prematurely, settling for a suboptimal solution.\")\n",
        "* How will a very small or a very large `step_scale` affect results? [Answer](## \"The value of step_scale influences the speed of convergence towards optimal parameters. If it's too small, the algorithm will inch towards a solution very slowly. Additionally, if the evaluation function is stochastic then the inherent variation in the evaluation function will overwhelm any changes in performance due to very small parameter changes, which will make improvement impossible. An excessively large step_scale can make the method act like it's randomly sampling the parameter space since the guidance from the current best parameters becomes less relevant. A large `step_scale` is less of an issue in this context since the soft-max normalization means that good solutions are possible at many different scales of parameters, i.e. the relative proportions of the weights far more important than the order of magnitude of the weights\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "KEUKrl5-5MLP"
      },
      "outputs": [],
      "source": [
        "best_params, best_avg_score = propose_and_test(max_rejected=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "WouzIcGD5MLP"
      },
      "outputs": [],
      "source": [
        "best_params, best_avg_score = propose_and_test(step_scale=0.0001, max_rejected=200)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "mWM4GI5Z5MLP"
      },
      "outputs": [],
      "source": [
        "best_params, best_avg_score = propose_and_test(step_scale=200, max_rejected=200)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "3n6dvHpr5MLQ"
      },
      "source": [
        "In this particular problem, we observed that setting `max_rejected` too low can lead to catastrophic failure, i.e., a good solution is never be found. In contrast, setting `max_rejected` too high only results in taking longer to identify a solution. So, in this kind of problem, it's better err on the side of setting `max_rejected` too high. Similarly, we can see that setting `step_scale` too small might can lead to failure. This could be because the stochasticity of the feedback function is overwhelming the signal from parameter changes, or because the process is caught in a local minima, and small step sizes do not allow it to escape. On the other hand, due to softmax normalization, setting high `step_scale` values doesn't seem too problematic, though with very large step sizes it may be difficult to really 'dial in' a good solution, i.e. the parameters will be close to optimal but unable to settle in on a precise peak due to the large step scale. Therefore, in a problem like this, where the parameter scale can roughly adapt to the step scale, it's better to err on the side of setting `step_scale` higher."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "jfU1pyCY5MLQ"
      },
      "outputs": [],
      "source": [
        "# @markdown Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_M3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "I1X39odb5MLQ"
      },
      "source": [
        "# 1.2.1.4 Reflections on Symmetry\n",
        "\n",
        "In this sequence, symmetry emerged as a powerful tool for reducing the complexity of our problem. Evolutionary processes are also able to take advantage of symmetry. Many organisms, such as humans and most other vertebrates, exhibit bilateral symmetry, where one half of an organism (roughly) mirrors the other. Plants, too, display varied symmetries, from the radial symmetry of flowers to the repetitive patterns of leaves and branches. However, within these symmetrical development regimes, localized adaptivity breaks perfect symmetry. Take an oak tree, for instance. Each leaf follows the same developmental program encoded in its DNA. Yet, due to local conditions such as sunlight, moisture, and space, some leaves grow large, while others remain small. The developmental program for each leaf might be identical, but diverse outcomes can still arise from localized conditions.\n",
        "\n",
        "This widespread symmetry in morphology is possible because cell structures in distal parts of the body can be intrinsically 'linked' by executing the same (or similar) developmental programs encoded in identical copies of DNA. Yet, just as with oak tree leaves, localized conditions and adaptions can lead to deviations from symmetry. As another example consider a person doing bicep curls with just one arm - over time, one arm becomes more muscular, breaking the bilateral symmetry typical in human bodies.\n",
        "\n",
        "In neural systems, the applicability of symmetry is even more nuanced. On the surface, mammalian nervous systems, with their two brain hemispheres, might suggest that symmetry also governs neural systems. But, beyond the macro morphology and into the functional intricacies of the brain, the symmetry appears to break down. At a functional level, neural structures arise not just from pre-programmed ontogenetic processes but alsoâ€”and often predominantlyâ€”from adaptive learning processes. These learning processes, dynamic adaptive adjustments in synaptic connections made in response to experience and environmental inputs, are inherently localized. Consider, does mastering writing with the right hand automatically confer equal proficiency to the left? Not really. Yet, does this deviation from symmetry imply its complete absence? Not quite. While the neural structures in the motor cortex governing the left and right hands will have followed different learning trajectories, the rules of neural plasticity guiding these trajectories are likely consistent. So, at this level of neural functionality, while we may not see direct physiological symmetry, shared plasticity rules between structures can be thought of as another, albeit more abstract, form of symmetry."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "aTqDJNxp5MLR"
      },
      "source": [
        "This concludes our introductory sequence on optimization. We learned about a few very basic optimization methods, and saw that while grid search was not powerful enough to solve our problem, a simple propose and test method was. We also looked into the importance of hyper-parameters in optimization processes. In the next sequence we will see just how robust this propose and test method is, looking at how it can be used to optimize a policy (behaviour) across of variety of environments, each with its own challenges."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "oYlX_N1G5MLR"
      },
      "outputs": [],
      "source": [
        "# @markdown Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_M4\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "14XUAa6o5MLS"
      },
      "source": [
        "# Quiz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "VIr2OG5H5MLS"
      },
      "outputs": [],
      "source": [
        "# @markdown **Run this cell** to take the quiz\n",
        "comprehension_quiz = [\n",
        "  {\"question\": \"Which of the following best describes the term 'combinatorial explosion'?\",\n",
        "   \"type\": \"multiple_choice\",\n",
        "   \"answers\": [\n",
        "      {\"answer\": \"The rapid growth of combinations when considering multiple parameters, often making brute-force searches infeasible.\",\n",
        "       \"correct\": True,\n",
        "       \"feedback\": \"Correct! The number of combinations grows exponentially with each added parameter.\"},\n",
        "      {\"answer\": \"An unexpected surge in the number of possible combinations due to a system error.\",\n",
        "       \"correct\": False,\n",
        "       \"feedback\": \"False. The increase is expected, not due to an error.\"},\n",
        "      {\"answer\": \"The explosion of data points in a database due to redundant entries.\",\n",
        "       \"correct\": False,\n",
        "       \"feedback\": \"False. This is not the primary meaning of combinatorial explosion.\"},\n",
        "      {\"answer\": \"The branching out of possibilities in a decision tree.\",\n",
        "       \"correct\": False,\n",
        "       \"feedback\": \"False. While decision trees can grow, this is not what's meant by combinatorial explosion.\"}\n",
        "    ]\n",
        "  },\n",
        "  {\"question\": \"When conducting a larger number of simulation runs, which of the following statements is true in the context of the Central Limit Theorem and the Law of Large Numbers?\",\n",
        "   \"type\": \"multiple_choice\",\n",
        "   \"answers\": [\n",
        "      {\"answer\": \"The sample mean will diverge from the expected value of the random variable.\",\n",
        "       \"correct\": False,\n",
        "       \"feedback\": \"False. The law ensures convergence, not divergence.\"},\n",
        "      {\"answer\": \"Only the Central Limit Theorem assures that the sample mean will be closer to the expected value.\",\n",
        "       \"correct\": False,\n",
        "       \"feedback\": \"False. Both the CLT and LLN play roles in this context.\"},\n",
        "      {\"answer\": \"The distribution of the sample mean will be normally distributed regardless of the original distribution, and as the sample size increases, the sample mean will get closer to the expected value.\",\n",
        "       \"correct\": True,\n",
        "       \"feedback\": \"Correct! This captures the essence of both the Central Limit Theorem and the Law of Large Numbers.\"},\n",
        "      {\"answer\": \"The Law of Large Numbers and the Central Limit Theorem both state that larger samples guarantee a narrower distribution.\",\n",
        "       \"correct\": False,\n",
        "       \"feedback\": \"False. Only the CLT speaks about the distribution's shape; LLN focuses on the convergence of the sample mean.\"}\n",
        "    ]\n",
        "  },\n",
        "  {\"question\": \"Which statement best describes the role of symmetry in neural systems compared to morphological structures?\",\n",
        "   \"type\": \"multiple_choice\",\n",
        "   \"answers\": [\n",
        "      {\"answer\": \"Both morphological and neural systems in organisms are governed by perfect bilateral symmetry.\",\n",
        "       \"correct\": False,\n",
        "       \"feedback\": \"False. While morphological systems often display symmetry, neural systems have more nuanced symmetry.\"},\n",
        "      {\"answer\": \"While morphological structures like body shape often exhibit symmetry due to identical DNA instructions, neural systems show localized adaptivity and learning, making their symmetry more nuanced.\",\n",
        "       \"correct\": True,\n",
        "       \"feedback\": \"Correct! Neural systems have functional adaptivity based on learning and environment.\"},\n",
        "      {\"answer\": \"Neural systems are always symmetric, and any deviation from symmetry indicates a neural malfunction.\",\n",
        "       \"correct\": False,\n",
        "       \"feedback\": \"False. Neural systems can deviate from perfect symmetry based on learning and localized adaptivity.\"},\n",
        "      {\"answer\": \"Symmetry in neural systems is only a byproduct of the symmetry seen in morphological structures.\",\n",
        "       \"correct\": False,\n",
        "       \"feedback\": \"False. Symmetry in neural systems, while influenced by morphology, has its own complexities due to learning and adaptivity.\"}\n",
        "    ]\n",
        "  }\n",
        "]\n",
        "\n",
        "display_quiz(comprehension_quiz)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "P1C2_Sequence2",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "8072429271704bc48729851ebf0f9167": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_935b3a5c58a043658ce7d3aff57ba4f6",
              "IPY_MODEL_4c04ef351d4c426cacb84e84539ab00c"
            ],
            "layout": "IPY_MODEL_d5fc625d94e94a30bedbdf85d02c2bd6"
          }
        },
        "935b3a5c58a043658ce7d3aff57ba4f6": {
          "model_module": "jupyter-matplotlib",
          "model_name": "MPLCanvasModel",
          "model_module_version": "^0.11",
          "state": {
            "_cursor": "default",
            "_data_url": "data:image/png;base64,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",
            "_dom_classes": [],
            "_figure_label": "Figure 1",
            "_image_mode": "full",
            "_message": "",
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "MPLCanvasModel",
            "_rubberband_height": 0,
            "_rubberband_width": 0,
            "_rubberband_x": 0,
            "_rubberband_y": 0,
            "_size": [
              500,
              400
            ],
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "MPLCanvasView",
            "capture_scroll": false,
            "footer_visible": false,
            "header_visible": false,
            "layout": "IPY_MODEL_5c2e61f5b5c44fd6982c5bb2512aaea9",
            "pan_zoom_throttle": 33,
            "resizable": false,
            "toolbar": "IPY_MODEL_434e562d444947f48094742053fee60f",
            "toolbar_position": "left",
            "toolbar_visible": false
          }
        },
        "4c04ef351d4c426cacb84e84539ab00c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ffadd62f640a4652813eda7ac187e240",
              "IPY_MODEL_79d2d89f0d75473cb12d423820539ddf",
              "IPY_MODEL_4d3b578b904246eeb62e69ac51cb4833"
            ],
            "layout": "IPY_MODEL_33da9cdf611249c9b653946a1c63b648"
          }
        },
        "d5fc625d94e94a30bedbdf85d02c2bd6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ffadd62f640a4652813eda7ac187e240": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_8ec34e3f178d42f9bab2ac292f8b3cd2",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "--------------  --\n",
                  "High Score:     --\n",
                  "Last Score:     --\n",
                  "Average Score:  --\n",
                  "--------------  --\n"
                ]
              }
            ]
          }
        },
        "79d2d89f0d75473cb12d423820539ddf": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_bfe3d70feab94ae9a7f1c10b6795bdac",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Click the start button to run the simulation\n"
                ]
              }
            ]
          }
        },
        "4d3b578b904246eeb62e69ac51cb4833": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Start",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_b0176a5839d0436c917bd2fd7138b219",
            "style": "IPY_MODEL_539a7dfcfeee4f548957f78c790264a6",
            "tooltip": ""
          }
        },
        "33da9cdf611249c9b653946a1c63b648": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8ec34e3f178d42f9bab2ac292f8b3cd2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": "18.8em",
            "min_height": "6.3em",
            "min_width": "12.5em",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": "auto",
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bfe3d70feab94ae9a7f1c10b6795bdac": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": "21.0em",
            "min_height": "10.0em",
            "min_width": "20.0em",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": "auto",
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20.0em"
          }
        },
        "b0176a5839d0436c917bd2fd7138b219": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "6.3em"
          }
        },
        "539a7dfcfeee4f548957f78c790264a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "5c2e61f5b5c44fd6982c5bb2512aaea9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "434e562d444947f48094742053fee60f": {
          "model_module": "jupyter-matplotlib",
          "model_name": "ToolbarModel",
          "model_module_version": "^0.11",
          "state": {
            "_current_action": "",
            "_dom_classes": [],
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "ToolbarModel",
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "ToolbarView",
            "button_style": "",
            "collapsed": true,
            "layout": "IPY_MODEL_c6b4aeabe8704852a8d006573c092409",
            "orientation": "vertical",
            "toolitems": [
              [
                "Home",
                "Reset original view",
                "home",
                "home"
              ],
              [
                "Back",
                "Back to previous view",
                "arrow-left",
                "back"
              ],
              [
                "Forward",
                "Forward to next view",
                "arrow-right",
                "forward"
              ],
              [
                "Pan",
                "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
                "arrows",
                "pan"
              ],
              [
                "Zoom",
                "Zoom to rectangle\nx/y fixes axis",
                "square-o",
                "zoom"
              ],
              [
                "Download",
                "Download plot",
                "floppy-o",
                "save_figure"
              ]
            ]
          }
        },
        "c6b4aeabe8704852a8d006573c092409": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "84bbd23dfbcc4bdb9e8a154d979bbf30": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3ff6a25d1e424f8796e340ee0e24a4a8",
              "IPY_MODEL_d7d51ed9f1774e4fa57cc299687c1e24"
            ],
            "layout": "IPY_MODEL_f9e3f1e4b38b4e6381fdbc6a7946a092"
          }
        },
        "3ff6a25d1e424f8796e340ee0e24a4a8": {
          "model_module": "jupyter-matplotlib",
          "model_name": "MPLCanvasModel",
          "model_module_version": "^0.11",
          "state": {
            "_cursor": "default",
            "_data_url": "data:image/png;base64,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",
            "_dom_classes": [],
            "_figure_label": "Figure 2",
            "_image_mode": "full",
            "_message": "",
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "MPLCanvasModel",
            "_rubberband_height": 0,
            "_rubberband_width": 0,
            "_rubberband_x": 0,
            "_rubberband_y": 0,
            "_size": [
              500,
              400
            ],
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "MPLCanvasView",
            "capture_scroll": false,
            "footer_visible": false,
            "header_visible": false,
            "layout": "IPY_MODEL_726fb8b5c9b84ac28b3e92a2d67150f0",
            "pan_zoom_throttle": 33,
            "resizable": false,
            "toolbar": "IPY_MODEL_df928ea3756a4481a232d2964a5918c7",
            "toolbar_position": "left",
            "toolbar_visible": false
          }
        },
        "d7d51ed9f1774e4fa57cc299687c1e24": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f97889b49f0d4df09c2c08ea4690c7b2",
              "IPY_MODEL_f6386385609c40efba3c6c7d4af92acc",
              "IPY_MODEL_e031ba48118d469da8044ed33fbb7b6c"
            ],
            "layout": "IPY_MODEL_9ef4c40c1f264776b09f697d0f6af48b"
          }
        },
        "f9e3f1e4b38b4e6381fdbc6a7946a092": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f97889b49f0d4df09c2c08ea4690c7b2": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_3007a753393d4a1e84573f57c0a3850b",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "--------------  --\n",
                  "High Score:     --\n",
                  "Last Score:     --\n",
                  "Average Score:  --\n",
                  "--------------  --\n"
                ]
              }
            ]
          }
        },
        "f6386385609c40efba3c6c7d4af92acc": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_0df51975ae3741a295d25e56c579061e",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Click the start button to run the simulation\n"
                ]
              }
            ]
          }
        },
        "e031ba48118d469da8044ed33fbb7b6c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Start",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_538e4f4e61cd4fd280bb233012c3dc25",
            "style": "IPY_MODEL_cc37692c29194f42a3fb456d57b8b4ab",
            "tooltip": ""
          }
        },
        "9ef4c40c1f264776b09f697d0f6af48b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3007a753393d4a1e84573f57c0a3850b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": "18.8em",
            "min_height": "6.3em",
            "min_width": "12.5em",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": "auto",
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0df51975ae3741a295d25e56c579061e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": "21.0em",
            "min_height": "10.0em",
            "min_width": "20.0em",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": "auto",
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20.0em"
          }
        },
        "538e4f4e61cd4fd280bb233012c3dc25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "6.3em"
          }
        },
        "cc37692c29194f42a3fb456d57b8b4ab": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "726fb8b5c9b84ac28b3e92a2d67150f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "df928ea3756a4481a232d2964a5918c7": {
          "model_module": "jupyter-matplotlib",
          "model_name": "ToolbarModel",
          "model_module_version": "^0.11",
          "state": {
            "_current_action": "",
            "_dom_classes": [],
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "ToolbarModel",
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "ToolbarView",
            "button_style": "",
            "collapsed": true,
            "layout": "IPY_MODEL_b4a6ff41c2c34aa0bc7a70cf0ca53a76",
            "orientation": "vertical",
            "toolitems": [
              [
                "Home",
                "Reset original view",
                "home",
                "home"
              ],
              [
                "Back",
                "Back to previous view",
                "arrow-left",
                "back"
              ],
              [
                "Forward",
                "Forward to next view",
                "arrow-right",
                "forward"
              ],
              [
                "Pan",
                "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
                "arrows",
                "pan"
              ],
              [
                "Zoom",
                "Zoom to rectangle\nx/y fixes axis",
                "square-o",
                "zoom"
              ],
              [
                "Download",
                "Download plot",
                "floppy-o",
                "save_figure"
              ]
            ]
          }
        },
        "b4a6ff41c2c34aa0bc7a70cf0ca53a76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c21c438aab2642979828c1aaa5fd0c86": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2b1f74e6b202479ca5d04f3e9688135c",
              "IPY_MODEL_26df0b28f2854eccba441ffa4afbb401",
              "IPY_MODEL_3566380572174dc2b412de5f30de051f"
            ],
            "layout": "IPY_MODEL_c3a09656c1844f928d7b9835891f924e"
          }
        },
        "2b1f74e6b202479ca5d04f3e9688135c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4a145b66e71e44bdbbbcdc1a56599243",
              "IPY_MODEL_579acb6f014c4fc4bd45faf7110a221c"
            ],
            "layout": "IPY_MODEL_eb61094ebb39489796d1fdf44d0072e1"
          }
        },
        "26df0b28f2854eccba441ffa4afbb401": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_04fb80756bb84f228d39bbef242261ad",
              "IPY_MODEL_6fa43bd2ced54a04b8f3d6085d021879",
              "IPY_MODEL_b9b167d9de52414799696ed53df35687"
            ],
            "layout": "IPY_MODEL_f7346819dfb44fd9b5f5d4e9aa2424cb"
          }
        },
        "3566380572174dc2b412de5f30de051f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_413bbc1b44004efba70af502e1c376f9",
              "IPY_MODEL_e7c68b8e91f24279b9b91bef0a339412"
            ],
            "layout": "IPY_MODEL_10fd13ce8c8749e289b32bf5f375cdb6"
          }
        },
        "c3a09656c1844f928d7b9835891f924e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a145b66e71e44bdbbbcdc1a56599243": {
          "model_module": "jupyter-matplotlib",
          "model_name": "MPLCanvasModel",
          "model_module_version": "^0.11",
          "state": {
            "_cursor": "default",
            "_data_url": "data:image/png;base64,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",
            "_dom_classes": [],
            "_figure_label": "Figure 3",
            "_image_mode": "diff",
            "_message": "",
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "MPLCanvasModel",
            "_rubberband_height": 0,
            "_rubberband_width": 0,
            "_rubberband_x": 0,
            "_rubberband_y": 0,
            "_size": [
              400,
              400
            ],
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "MPLCanvasView",
            "capture_scroll": false,
            "footer_visible": false,
            "header_visible": false,
            "layout": "IPY_MODEL_0d4b7047c6ea482fb4af0d4616eabe89",
            "pan_zoom_throttle": 33,
            "resizable": false,
            "toolbar": "IPY_MODEL_e33f8e159b6b40d68d89338366df820f",
            "toolbar_position": "left",
            "toolbar_visible": false
          }
        },
        "579acb6f014c4fc4bd45faf7110a221c": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_8f7e6382af5e47598e16f8905e89f305",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "This player (tried) to move up and is now at (1, 0).\n",
                  "There's no food there.\n",
                  "Rounds Left: 0.0 \n",
                  "Food Eaten: 15.0 \n",
                  "Food Per Move: 0.50\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Game Over. Final Score 15.0\n",
                  "Resetting the board for another game\n"
                ]
              }
            ]
          }
        },
        "eb61094ebb39489796d1fdf44d0072e1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "04fb80756bb84f228d39bbef242261ad": {
          "model_module": "jupyter-matplotlib",
          "model_name": "MPLCanvasModel",
          "model_module_version": "^0.11",
          "state": {
            "_cursor": "default",
            "_data_url": "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",
            "_dom_classes": [],
            "_figure_label": "Figure 4",
            "_image_mode": "diff",
            "_message": "",
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "MPLCanvasModel",
            "_rubberband_height": 0,
            "_rubberband_width": 0,
            "_rubberband_x": 0,
            "_rubberband_y": 0,
            "_size": [
              150,
              150
            ],
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "MPLCanvasView",
            "capture_scroll": false,
            "footer_visible": false,
            "header_visible": false,
            "layout": "IPY_MODEL_f6d77bacfb71472fac0530163a76588a",
            "pan_zoom_throttle": 33,
            "resizable": false,
            "toolbar": "IPY_MODEL_07acb513f68142bd9a099bfcd302470a",
            "toolbar_position": "left",
            "toolbar_visible": false
          }
        },
        "6fa43bd2ced54a04b8f3d6085d021879": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_12c8e530025046d1b6144c62fad17097",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Games Played: 2\n",
                  "-------------  -----  -------\n",
                  "               Drift  Classic\n",
                  "High Score:    20.0   11.0\n",
                  "Last Score:    15.0   11.0\n",
                  "Average Score  17.50  10.00\n",
                  "-------------  -----  -------\n"
                ]
              }
            ]
          }
        },
        "b9b167d9de52414799696ed53df35687": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Start",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9b357f33032846b193bb334e00c85e6f",
            "style": "IPY_MODEL_994120fe25304eb5bb799da03dede0da",
            "tooltip": ""
          }
        },
        "f7346819dfb44fd9b5f5d4e9aa2424cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "413bbc1b44004efba70af502e1c376f9": {
          "model_module": "jupyter-matplotlib",
          "model_name": "MPLCanvasModel",
          "model_module_version": "^0.11",
          "state": {
            "_cursor": "default",
            "_data_url": "data:image/png;base64,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",
            "_dom_classes": [],
            "_figure_label": "Figure 5",
            "_image_mode": "diff",
            "_message": "",
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "MPLCanvasModel",
            "_rubberband_height": 0,
            "_rubberband_width": 0,
            "_rubberband_x": 0,
            "_rubberband_y": 0,
            "_size": [
              400,
              400
            ],
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "MPLCanvasView",
            "capture_scroll": false,
            "footer_visible": false,
            "header_visible": false,
            "layout": "IPY_MODEL_430b871d23ea4e99a9eb214a17639b1c",
            "pan_zoom_throttle": 33,
            "resizable": false,
            "toolbar": "IPY_MODEL_3a92abec75fd4e5f8eeb6b38d99a91f3",
            "toolbar_position": "left",
            "toolbar_visible": false
          }
        },
        "e7c68b8e91f24279b9b91bef0a339412": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_72b136e3c2a941f5989d63fc1b56f4b8",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "This player (tried) to move down and is now at (4, 1).\n",
                  "There's no food there.\n",
                  "Rounds Left: 0.0 \n",
                  "Food Eaten: 11.0 \n",
                  "Food Per Move: 0.37\n"
                ]
              },
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Game Over. Final Score 11.0\n",
                  "Resetting the board for another game\n"
                ]
              }
            ]
          }
        },
        "10fd13ce8c8749e289b32bf5f375cdb6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8f7e6382af5e47598e16f8905e89f305": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": "21.0em",
            "min_height": "10.0em",
            "min_width": "20.0em",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": "auto",
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20.0em"
          }
        },
        "12c8e530025046d1b6144c62fad17097": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": "21em",
            "min_height": "6.3em",
            "min_width": "20em",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": "auto",
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b357f33032846b193bb334e00c85e6f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": "0.6em 0 0 0",
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "6.3em"
          }
        },
        "994120fe25304eb5bb799da03dede0da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "72b136e3c2a941f5989d63fc1b56f4b8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": "21.0em",
            "min_height": "10.0em",
            "min_width": "20.0em",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": "auto",
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20.0em"
          }
        },
        "0d4b7047c6ea482fb4af0d4616eabe89": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e33f8e159b6b40d68d89338366df820f": {
          "model_module": "jupyter-matplotlib",
          "model_name": "ToolbarModel",
          "model_module_version": "^0.11",
          "state": {
            "_current_action": "",
            "_dom_classes": [],
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "ToolbarModel",
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "ToolbarView",
            "button_style": "",
            "collapsed": true,
            "layout": "IPY_MODEL_ad4eccde96fc467988052534199e1543",
            "orientation": "vertical",
            "toolitems": [
              [
                "Home",
                "Reset original view",
                "home",
                "home"
              ],
              [
                "Back",
                "Back to previous view",
                "arrow-left",
                "back"
              ],
              [
                "Forward",
                "Forward to next view",
                "arrow-right",
                "forward"
              ],
              [
                "Pan",
                "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
                "arrows",
                "pan"
              ],
              [
                "Zoom",
                "Zoom to rectangle\nx/y fixes axis",
                "square-o",
                "zoom"
              ],
              [
                "Download",
                "Download plot",
                "floppy-o",
                "save_figure"
              ]
            ]
          }
        },
        "f6d77bacfb71472fac0530163a76588a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "07acb513f68142bd9a099bfcd302470a": {
          "model_module": "jupyter-matplotlib",
          "model_name": "ToolbarModel",
          "model_module_version": "^0.11",
          "state": {
            "_current_action": "",
            "_dom_classes": [],
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "ToolbarModel",
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "ToolbarView",
            "button_style": "",
            "collapsed": true,
            "layout": "IPY_MODEL_29b234dde22b45e48df9db030157fa38",
            "orientation": "vertical",
            "toolitems": [
              [
                "Home",
                "Reset original view",
                "home",
                "home"
              ],
              [
                "Back",
                "Back to previous view",
                "arrow-left",
                "back"
              ],
              [
                "Forward",
                "Forward to next view",
                "arrow-right",
                "forward"
              ],
              [
                "Pan",
                "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
                "arrows",
                "pan"
              ],
              [
                "Zoom",
                "Zoom to rectangle\nx/y fixes axis",
                "square-o",
                "zoom"
              ],
              [
                "Download",
                "Download plot",
                "floppy-o",
                "save_figure"
              ]
            ]
          }
        },
        "430b871d23ea4e99a9eb214a17639b1c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3a92abec75fd4e5f8eeb6b38d99a91f3": {
          "model_module": "jupyter-matplotlib",
          "model_name": "ToolbarModel",
          "model_module_version": "^0.11",
          "state": {
            "_current_action": "",
            "_dom_classes": [],
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "ToolbarModel",
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "ToolbarView",
            "button_style": "",
            "collapsed": true,
            "layout": "IPY_MODEL_4c7813fd5acd49e581d739ade1e57c9c",
            "orientation": "vertical",
            "toolitems": [
              [
                "Home",
                "Reset original view",
                "home",
                "home"
              ],
              [
                "Back",
                "Back to previous view",
                "arrow-left",
                "back"
              ],
              [
                "Forward",
                "Forward to next view",
                "arrow-right",
                "forward"
              ],
              [
                "Pan",
                "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
                "arrows",
                "pan"
              ],
              [
                "Zoom",
                "Zoom to rectangle\nx/y fixes axis",
                "square-o",
                "zoom"
              ],
              [
                "Download",
                "Download plot",
                "floppy-o",
                "save_figure"
              ]
            ]
          }
        },
        "ad4eccde96fc467988052534199e1543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "29b234dde22b45e48df9db030157fa38": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4c7813fd5acd49e581d739ade1e57c9c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}