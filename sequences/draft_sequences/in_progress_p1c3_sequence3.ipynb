{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcownden/PerennialProblemsOfLifeWithABrain/blob/book-review/sequences/draft_sequences/in_progress_p1c3_sequence3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "feemYjcH_Rog"
      },
      "source": [
        "The following is part of a test for an upcoming text book on computational neuroscience from an optimization and learning perspective. The book will start with evolution because ultimately, all aspects of the brain are shaped by evolution and, as we will see, evolution can also be seen as an optimization algorithm. We are sharing it now to get feedback on what works and what does not and the developments we should do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "x0-QEY9K_Rog"
      },
      "source": [
        "___\n",
        "# **1.3.3: Competition and Interaction Within and Between Species Drives Evolution - Endless Forms Most Beautiful**\n",
        "### Objective: In the previous chapter on Optimization and the Environment we saw how alignment with environmental context is key to the effectiveness of a policy and how a changing environment thus creates a challenge to producing effective behaviour (Sequence 1.2.2), and even in sequence 1.1.3 we looked a little bit at interactions between organisms and the potential impacts of these interactions on the efficacy of an organism's policy. In this sequence we will expand on this theme, within the context evolution by considering a major source of 'environmental' variation: the evolution of other organisms. One organism's policy is another organism's environment! In this sequence we will:\n",
        "\n",
        "* Extend our our evolutionary simulation from the previous to sequences on evolution, allowing the prey population to evolve in tandem with the predator population.\n",
        "* Learn a tiny bit about Nash Equilibria and how they relate to optimization and dynamical systems."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "FQjJRuzm_Roi"
      },
      "source": [
        "# Setup\n",
        "\n",
        "Run the following cell to setup and install the various dependencies and helper functions for this ."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "execution": {},
        "id": "2HJlzgyb_Roi",
        "cellView": "form",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ad1a86a-27a3-4f86-c7aa-7e715f8153d8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed 2021 has been set.\n",
            "This notebook isn't using and doesn't need a GPU. Good.\n",
            "Running in colab\n"
          ]
        }
      ],
      "source": [
        "# @title Dependencies, Imports and Setup\n",
        "# @markdown You don't need to worry about how this code works â€“ but you do need to **run the cell**\n",
        "\n",
        "!pip install ipympl vibecheck datatops jupyterquiz > /dev/null 2> /dev/null #google.colab\n",
        "\n",
        "import requests\n",
        "from requests.exceptions import RequestException\n",
        "import numpy as np\n",
        "import itertools\n",
        "import collections\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import ipywidgets as widgets\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from io import BytesIO\n",
        "from enum import Enum\n",
        "from copy import copy\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.stats import norm\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tabulate import tabulate\n",
        "from IPython.display import display, clear_output, Markdown, HTML\n",
        "from jupyterquiz import display_quiz\n",
        "from vibecheck import DatatopsContentReviewContainer\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "\n",
        "# random seed settings and\n",
        "# getting torch to use gpu if it's there\n",
        "\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  \"\"\"\n",
        "  Function that controls randomness. NumPy and random modules must be imported.\n",
        "\n",
        "  Args:\n",
        "    seed : Integer\n",
        "      A non-negative integer that defines the random state. Default is `None`.\n",
        "    seed_torch : Boolean\n",
        "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
        "      must be imported. Default is `True`.\n",
        "\n",
        "  Returns:\n",
        "    Nothing.\n",
        "  \"\"\"\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "  \"\"\"\n",
        "  DataLoader will reseed workers following randomness in\n",
        "  multi-process data loading algorithm.\n",
        "\n",
        "  Args:\n",
        "    worker_id: integer\n",
        "      ID of subprocess to seed. 0 means that\n",
        "      the data will be loaded in the main process\n",
        "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def set_device():\n",
        "  \"\"\"\n",
        "  Set the device. CUDA if available, CPU otherwise\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"This notebook isn't using and doesn't need a GPU. Good.\")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook but not needed.\")\n",
        "    print(\"If possible, in the menu under `Runtime` -> \")\n",
        "    print(\"`Change runtime type.`  select `CPU`\")\n",
        "\n",
        "  return device\n",
        "\n",
        "\n",
        "SEED = 2021\n",
        "set_seed(seed=SEED)\n",
        "DEVICE = set_device()\n",
        "\n",
        "\n",
        "def printmd(string):\n",
        "  display(Markdown(string))\n",
        "\n",
        "\n",
        "# the different utility .py files used in this notebook\n",
        "filenames = ['gw_plotting.py', 'gw_board.py', 'gw_game.py',\n",
        "             'gw_widgets.py', 'gw_NN_RL.py']\n",
        "#filenames = []\n",
        "# just run the code straight out of the response, no local copies needed!\n",
        "for filename in filenames:\n",
        "  url = f'https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/utils/{filename}'\n",
        "  response = requests.get(url)\n",
        "  # Check that we got a valid response\n",
        "  if response.status_code == 200:\n",
        "    code = response.content.decode()\n",
        "    exec(code)\n",
        "  else:\n",
        "    print(f'Failed to download {url}')\n",
        "\n",
        "# environment contingent imports\n",
        "try:\n",
        "  print('Running in colab')\n",
        "  from google.colab import output\n",
        "  output.enable_custom_widget_manager()\n",
        "  from google.colab import data_table\n",
        "  data_table.disable_dataframe_formatter()\n",
        "  #from google.colab import output as colab_output\n",
        "  #colab_output.enable_custom_widget_manager()\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "  print('Not running in colab')\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib widget\n",
        "plt.style.use(\"https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/pplb.mplstyle\")\n",
        "plt.ioff() #need to use plt.show() or display explicitly\n",
        "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)\n",
        "\n",
        "\n",
        "def content_review(notebook_section: str):\n",
        "  return DatatopsContentReviewContainer(\n",
        "    \"\",  # No text prompt\n",
        "    notebook_section,\n",
        "    {\n",
        "      \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
        "      \"name\": \"neuro_book\",\n",
        "      \"user_key\": \"xuk960xj\",\n",
        "    },\n",
        "  ).render()\n",
        "feedback_prefix = \"P1C3_S3\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################################################\n",
        "# refactor Monte Carlo for boards that support multiple critters\n",
        "################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MonteCarlo():\n",
        "  \"\"\"\n",
        "  Implementation of Monte Carlo Algorithm\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, game, nnet, default_depth=5, random_seed=None):\n",
        "    \"\"\"\n",
        "    Initialize Monte Carlo Parameters\n",
        "\n",
        "    Args:\n",
        "      game: Gridworld Game instance\n",
        "        Instance of the gridworldGame class above;\n",
        "      nnet: gridworldNet instance\n",
        "        Instance of the gridworldNNet class above;\n",
        "      args: dictionary\n",
        "        Instantiates number of iterations and episodes, controls temperature threshold, queue length,\n",
        "        arena, checkpointing, and neural network parameters:\n",
        "        learning-rate: 0.001, dropout: 0.3, epochs: 10, batch_size: 64,\n",
        "        num_channels: 512\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    self.game = game\n",
        "    self.nnet = nnet\n",
        "    self.default_depth = default_depth\n",
        "    self.rng = np.random.default_rng(seed=random_seed)\n",
        "\n",
        "\n",
        "  def pis_vs_from_board(self, board, critter):\n",
        "    #helper function, to put board in canonical form that nn was trained on\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    co_pieces = board['pieces'].copy()\n",
        "    this_critter_locs = np.where(co_pieces == critter)\n",
        "    all_critter_locs = np.where(co_pieces >= 1)\n",
        "    # other critters are invisible to this player\n",
        "    co_pieces[all_critter_locs] = 0\n",
        "    # nnet trained to see self as 1\n",
        "    co_pieces[this_critter_locs] = 1\n",
        "    scalar_rounds_left = board['rounds_left'][0]\n",
        "    co_rounds_left = scalar_rounds_left // self.game.num_critters\n",
        "    if critter-1 < scalar_rounds_left % self.game.num_critters:\n",
        "       # add an extra if we haven't had this players turn yet in the round cycle\n",
        "       co_rounds_left = co_rounds_left + 1\n",
        "    co_rounds_left = np.array([co_rounds_left]*batch_size)\n",
        "    pis, vs = self.nnet.predict(co_pieces,\n",
        "                                board['scores'][:,critter-1],\n",
        "                                co_rounds_left)\n",
        "    return pis, vs\n",
        "\n",
        "\n",
        "  def simulate(self, board, actions, action_indexes, critter=1, depth=None):\n",
        "    \"\"\"\n",
        "    Helper function to simulate one Monte Carlo rollout\n",
        "\n",
        "    Args:\n",
        "      board: triple (batch_size x x_size x y_size np.array of board position,\n",
        "                     scalar of current score,\n",
        "                     scalar of rounds left\n",
        "      actions: batch size list/array of integer indexes for moves on each board\n",
        "      these are assumed to be legal, no check for validity of moves\n",
        "    Returns:\n",
        "      temp_v:\n",
        "        Terminal State\n",
        "    \"\"\"\n",
        "    batch_size, x_size, y_size = board['pieces'].shape\n",
        "    next_board = self.game.get_next_state(board, critter,\n",
        "                                          actions, action_indexes)\n",
        "    # in this version of the mc player, the existence of other players is\n",
        "    # ignored, in another version of mc other players moves might be simulated\n",
        "    next_board['active_player'] = critter-1\n",
        "\n",
        "    if depth is None:\n",
        "      depth = self.default_depth\n",
        "    # potentially expand the game tree here,\n",
        "    # but just do straight rollouts after this\n",
        "    # doesn't expand to deal with all random food generation possibilities\n",
        "    # just expands based on the actions given\n",
        "    expand_bs, _, _ = next_board['pieces'].shape\n",
        "\n",
        "    for i in range(depth):  # maxDepth\n",
        "      if next_board['rounds_left'][0] <= 0:\n",
        "        # check that game isn't over\n",
        "        # assumes all boards have the same rounds left\n",
        "        # no rounds left return scores as true values\n",
        "        terminal_vs = next_board['scores'][:,critter-1].copy()\n",
        "        return terminal_vs\n",
        "      else:\n",
        "        #pis, vs = self.nnet.predict(next_board['pieces'], next_board['scores'], next_board['rounds_left'])\n",
        "        pis, vs = self.pis_vs_from_board(next_board, critter)\n",
        "        valids = self.game.get_valid_actions(next_board, critter)\n",
        "        masked_pis = pis * valids\n",
        "        sum_pis = np.sum(masked_pis, axis=1)\n",
        "        probs = np.array(\n",
        "            [masked_pi / masked_pi.sum() if masked_pi.sum() > 0\n",
        "             else valid / valid.sum()\n",
        "             for valid, masked_pi in zip(valids, masked_pis)])\n",
        "        samp = self.rng.uniform(size = expand_bs).reshape((expand_bs,1))\n",
        "        sampled_actions = np.argmax(probs.cumsum(axis=1) > samp, axis=1)\n",
        "      next_board = self.game.get_next_state(next_board, critter,\n",
        "                                            sampled_actions)\n",
        "      # in this version of the mc player, existence of other players is ignored\n",
        "      # in another better version other players moves might be simulated, either\n",
        "      # as copies of self, or as distinct environmental dynamics\n",
        "      next_board['active_player'] = critter-1\n",
        "\n",
        "\n",
        "    pis, vs = self.pis_vs_from_board(next_board, critter)\n",
        "    #pis, vs = self.nnet.predict(next_board['pieces'], next_board['scores'],\n",
        "    #                            next_board['rounds_left'])\n",
        "    #print(vs.shape)\n",
        "    return vs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title plotting functions\n",
        "#################################################\n",
        "# More plotting functions\n",
        "#################################################\n",
        "\n",
        "\n",
        "def plot_directions(fig, ax, loc_prob_dict, critter, deterministic=False,\n",
        "                    name=None):\n",
        "  \"\"\"\n",
        "  Plot vector field indicating critter direction probabilities.\n",
        "\n",
        "  Args:\n",
        "    fig, ax (matplotlib objects): Figure and axes objects for plotting.\n",
        "    loc_prob_dict (dict): Dictionary with keys as (row, col) location tuples\n",
        "      and values as lists of direction probabilities corresponding to the\n",
        "      directions ['right', 'down', 'left', 'up'].\n",
        "    critter (int): Identifier for which critter directions are associated with.\n",
        "    deterministic (bool, optional): If True, the probabilities array is\n",
        "      converted to 1-hot, and the arrows are plotted at the center of the cell\n",
        "      and are larger. Defaults to False.\n",
        "  \"\"\"\n",
        "\n",
        "  #looks like direction ignores inverted axis\n",
        "  direction_vectors = {'right': (1, 0), 'down': (0, -1),\n",
        "                       'left': (-1, 0), 'up': (0, 1)}\n",
        "  # but offsets need to be aware of inverted\n",
        "  direction_offsets = {'right': (0.1, 0), 'down': (0, 0.1),\n",
        "                       'left': (-0.1, 0), 'up': (0, -0.1)}\n",
        "  # Offsets for each critter type 1 and 2 to be used together, 0 by itself\n",
        "  critter_offsets = {0: (0, 0), 1: (-0.05, -0.05), 2: (0.05, 0.05)}\n",
        "  # same logic for colors\n",
        "  critter_colors = {0: 'black', 1: 'red', 2: 'blue'}\n",
        "  # Get the offset and color for this critter\n",
        "  critter_offset = critter_offsets[critter]\n",
        "  critter_color = critter_colors[critter]\n",
        "\n",
        "  # Add legend only if critter is not 0\n",
        "  custom_leg_handles = []\n",
        "  if critter != 0:\n",
        "    if name is None:\n",
        "      name = f'Critter {critter}'\n",
        "    legend_patch = mpatches.Patch(color=critter_color, label=name)\n",
        "    # Add the legend for this critter\n",
        "    custom_leg_handles.append(legend_patch)\n",
        "\n",
        "  C, R, U, V, A = [], [], [], [], []\n",
        "\n",
        "  for loc in loc_prob_dict.keys():\n",
        "    row, col = loc\n",
        "    probs = loc_prob_dict[loc]\n",
        "    for dir_key, prob in probs.items():\n",
        "      C.append(col + critter_offset[0] + direction_offsets[dir_key][0])\n",
        "      R.append(row + critter_offset[1] + direction_offsets[dir_key][1])\n",
        "      U.append(direction_vectors[dir_key][0])\n",
        "      V.append(direction_vectors[dir_key][1])\n",
        "\n",
        "      if deterministic:\n",
        "        A.append(1 if prob == max(probs.values()) else 0)\n",
        "      else:\n",
        "        A.append(prob)\n",
        "\n",
        "  linewidth = 1.5 if deterministic else 0.5\n",
        "  scale = 15 if deterministic else 30\n",
        "\n",
        "  ax.quiver(C, R, U, V, alpha=A, color=critter_color,\n",
        "            scale=scale, linewidth=linewidth)\n",
        "  return fig, ax, custom_leg_handles\n",
        "\n",
        "\n",
        "def make_grid(num_rows, num_cols, figsize=(7,6), title=None):\n",
        "  \"\"\"Plots an n_rows by n_cols grid with cells centered on integer indices and\n",
        "  returns fig and ax handles for further use\n",
        "  Args:\n",
        "    num_rows (int): number of rows in the grid (vertical dimension)\n",
        "    num_cols (int): number of cols in the grid (horizontal dimension)\n",
        "\n",
        "  Returns:\n",
        "    fig (matplotlib.figure.Figure): figure handle for the grid\n",
        "    ax: (matplotlib.axes._axes.Axes): axes handle for the grid\n",
        "  \"\"\"\n",
        "  # Create a new figure and axes with given figsize\n",
        "  fig, ax = plt.subplots(figsize=figsize, layout='constrained')\n",
        "  # Set width and height padding, remove horizontal and vertical spacing\n",
        "  fig.get_layout_engine().set(w_pad=4 / 72, h_pad=4 / 72, hspace=0, wspace=0)\n",
        "  # Show right and top borders (spines) of the plot\n",
        "  ax.spines[['right', 'top']].set_visible(True)\n",
        "  # Set major ticks (where grid lines will be) on x and y axes\n",
        "  ax.set_xticks(np.arange(0, num_cols, 1))\n",
        "  ax.set_yticks(np.arange(0, num_rows, 1))\n",
        "  # Set labels for major ticks with font size of 8\n",
        "  ax.set_xticklabels(np.arange(0, num_cols, 1),fontsize=8)\n",
        "  ax.set_yticklabels(np.arange(0, num_rows, 1),fontsize=8)\n",
        "  # Set minor ticks (no grid lines here) to be between major ticks\n",
        "  ax.set_xticks(np.arange(0.5, num_cols-0.5, 1), minor=True)\n",
        "  ax.set_yticks(np.arange(0.5, num_rows-0.5, 1), minor=True)\n",
        "  # Move x-axis ticks to the top of the plot\n",
        "  ax.xaxis.tick_top()\n",
        "  # Set grid lines based on minor ticks, make them grey, dashed, and half transparent\n",
        "  ax.grid(which='minor', color='grey', linestyle='-', linewidth=2, alpha=0.5)\n",
        "  # Remove minor ticks (not the grid lines)\n",
        "  ax.tick_params(which='minor', bottom=False, left=False)\n",
        "  # Set limits of x and y axes\n",
        "  ax.set_xlim(( -0.5, num_cols-0.5))\n",
        "  ax.set_ylim(( -0.5, num_rows-0.5))\n",
        "  # Invert y axis direction\n",
        "  ax.invert_yaxis()\n",
        "  # If title is provided, set it as the figure title\n",
        "  if title is not None:\n",
        "    fig.suptitle(title)\n",
        "  # Hide header and footer, disable toolbar and resizing of the figure\n",
        "  fig.canvas.header_visible = False\n",
        "  fig.canvas.toolbar_visible = False\n",
        "  fig.canvas.resizable = False\n",
        "  fig.canvas.footer_visible = False\n",
        "  # Redraw the figure with these settings\n",
        "  fig.canvas.draw()\n",
        "  # Return figure and axes handles for further customization\n",
        "  return fig, ax\n",
        "\n",
        "\n",
        "def plot_food(fig, ax, rc_food_loc, food=None):\n",
        "  \"\"\"\n",
        "  Plots \"food\" on a grid implied by the given fig, ax arguments\n",
        "\n",
        "  Args:\n",
        "    fig, ax: matplotlib figure and axes objects\n",
        "    rc_food_loc: ndarry(int) of shape (N:num_food x 2:row,col)\n",
        "    food: a handle for the existing food matplotlib PatchCollection object\n",
        "    if one exists\n",
        "  Returns:\n",
        "    a handle for matplotlib PathCollection object of food scatter plot, either\n",
        "    new if no handle was passed or updated if it was\n",
        "  \"\"\"\n",
        "  # if no PathCollection handle passed in:\n",
        "  if food is None:\n",
        "    food = ax.scatter([], [], s=150, marker='o', color='red', label='Food')\n",
        "  rc_food_loc = np.array(rc_food_loc, dtype=int)\n",
        "  #matrix indexing convention is is [row-vertical, col-horizontal]\n",
        "  #plotting indexing convention is (x-horizontal,y-vertical), hence flip\n",
        "  food.set_offsets(np.fliplr(rc_food_loc))\n",
        "  return food\n",
        "\n",
        "\n",
        "def plot_critters(fig, ax, critter_specs: List[Dict[str, object]]) -> List[Dict[str, object]]:\n",
        "  \"\"\"\n",
        "  Plots multiple types of \"critters\" on a grid implied by the given\n",
        "  fig, ax arguments.\n",
        "\n",
        "  Args:\n",
        "    fig, ax: matplotlib figure and axes objects.\n",
        "    critter_specs: List of dictionaries with keys 'location', 'name', 'color',\n",
        "    'marker', 'int_id', 'rc_critter_loc' and optionally 'handle' for each\n",
        "    critter.\n",
        "\n",
        "  Returns:\n",
        "    Updated critter_specs with handles.\n",
        "  \"\"\"\n",
        "  for spec in critter_specs:\n",
        "    # Ensure required keys are present\n",
        "    for key in ['marker', 'color', 'name', 'rc_loc']:\n",
        "      if key not in spec:\n",
        "        raise ValueError(f\"Key '{key}' missing in critter spec.\")\n",
        "    handle_ = spec.get('handle')\n",
        "    if handle_ is None:\n",
        "      handle_ = ax.scatter([], [], s=250, marker=spec['marker'],\n",
        "                           color=spec['color'], label=spec['name'])\n",
        "    handle_.set_offsets(np.flip(spec['rc_loc']))\n",
        "    spec.update({'handle': handle_})\n",
        "  return critter_specs\n",
        "\n",
        "\n",
        "def plot_critter(fig, ax, rc_critter_loc,\n",
        "                 critter=None, critter_name='Critter'):\n",
        "  \"\"\"\n",
        "  Plots \"critter\" on a grid implied by the given fig, ax arguments\n",
        "\n",
        "  Args:\n",
        "    fig, ax: matplotlib figure and axes objects\n",
        "    rc_critter_loc: ndarry(int) of shape (N:num_critters x 2:row,col)\n",
        "    critter: a handle for the existing food matplotlib PatchCollection object\n",
        "    if one exists\n",
        "  Returns:\n",
        "    a handle for matplotlib PathCollection object of critter scatter plot,\n",
        "    either new if no handle was passed in or updated if it was.\n",
        "  \"\"\"\n",
        "  if critter is None:\n",
        "    critter = ax.scatter([], [], s=250, marker='h',\n",
        "                         color='blue', label=critter_name)\n",
        "  # matrix indexing convention is is [row-vertical, col-horizontal]\n",
        "  # plotting indexing convention is (x-horizontal,y-vertical), hence flip\n",
        "  critter.set_offsets(np.flip(rc_critter_loc))\n",
        "  return critter\n",
        "\n",
        "\n",
        "def plot_fov(fig, ax, rc_critter, n_rows, n_cols, radius, has_fov,\n",
        "             opaque=False, fov=None):\n",
        "  \"\"\"\n",
        "  Plots a mask on a grid implied by the given fig, ax arguments\n",
        "\n",
        "  Args:\n",
        "    fig, ax: matplotlib figure and axes objects\n",
        "    rc_critter: ndarry(int) (row,col) of the critter\n",
        "    mask: a handle for the existing mask matplotlib Image object if one exists\n",
        "  Returns:\n",
        "    a handle for matplotlib Image object of mask, either new if no handle\n",
        "    was passed in or updated if it was.\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize mask as a semi-transparent overlay for the entire grid\n",
        "  mask_array = np.ones((n_rows, n_cols, 4))\n",
        "  mask_array[:, :, :3] = 0.5  # light grey color\n",
        "  if has_fov == True:\n",
        "    if opaque:\n",
        "      mask_array[:, :, 3] = 1.0  # 50% opacity\n",
        "    else:\n",
        "      mask_array[:, :, 3] = 0.5  # 50% opacity\n",
        "    # Create arrays representing the row and column indices\n",
        "    rows = np.arange(n_rows)[:, np.newaxis]\n",
        "    cols = np.arange(n_cols)[np.newaxis, :]\n",
        "    # Iterate over each critter location\n",
        "    dist = np.abs(rows - rc_critter[0]) + np.abs(cols - rc_critter[1])\n",
        "    # Set the region within the specified radius around the critter to transparent\n",
        "    mask_array[dist <= radius, 3] = 0\n",
        "  else:\n",
        "    mask_array[:, :, 3] = 0\n",
        "\n",
        "  if fov is None:\n",
        "    fov = ax.imshow(mask_array, origin='lower', zorder=2)\n",
        "  else:\n",
        "    fov.set_data(mask_array)\n",
        "\n",
        "  return fov\n",
        "\n",
        "\n",
        "def remove_ip_clutter(fig):\n",
        "  fig.canvas.header_visible = False\n",
        "  fig.canvas.toolbar_visible = False\n",
        "  fig.canvas.resizable = False\n",
        "  fig.canvas.footer_visible = False\n",
        "  fig.canvas.draw()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title GridworldBoard class\n",
        "#######################################################################\n",
        "# extend GridworldGame class locally before integrating in shared utils\n",
        "#######################################################################\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class GridworldBoard():\n",
        "  \"\"\"\n",
        "  A collection methods and parameters of a gridworld game board that\n",
        "  define the logic of the game, and allows for multiple critters on the same\n",
        "  board\n",
        "\n",
        "  board state is represented by primarily by pieces, score, and rounds left\n",
        "  pieces is a batch x n_rows x n_cols numpy array positive integers are critter\n",
        "  locations 0's are empty space and -1's are food.\n",
        "\n",
        "  For pieces first dim is batch, second dim row , third is col,\n",
        "  so pieces[0][1][7] is the square in row 2, in column 8 of the first board in\n",
        "  the batch of boards.\n",
        "\n",
        "  scores is a batchsize x num_critters numpy array giving the scores for each\n",
        "  critter on each board in the batch (note off by one indexing)\n",
        "\n",
        "  rounds_left is how many rounds are left in the game.\n",
        "\n",
        "  active_player keeps track of which players turn it is\n",
        "\n",
        "  Note:\n",
        "    In 2d np.array first dim is row (vertical), second dim is col (horizontal),\n",
        "    i.e. top left corner is (0,0), so take care when visualizing/plotting\n",
        "    as np.array visualization inline with typical tensor notation but at odds\n",
        "    with conventional plotting where (0,0) is bottom left, first dim, x, is\n",
        "    horizontal, second dim, y, is vertical\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  class CritterFoodType(Enum):\n",
        "    FOOD = \"food\"\n",
        "    PREY = \"prey\"\n",
        "    PREDATOR = \"predator\"\n",
        "\n",
        "  ARRAY_PAD_VALUE = -200\n",
        "\n",
        "  def __init__(self, batch_size=1,\n",
        "               n_rows=7, n_cols=7,\n",
        "               num_food=10, num_prey=1, num_pred=1,\n",
        "               lifetime=30, rng=None):\n",
        "    \"\"\"Set the parameters of the game.\"\"\"\n",
        "    self.n_rows = n_rows\n",
        "    self.n_cols = n_cols\n",
        "    self.batch_size = batch_size\n",
        "    self.num_food = num_food\n",
        "    self.num_prey = num_prey\n",
        "    self.num_pred = num_pred\n",
        "    self.num_critters = num_pred + num_prey\n",
        "    self.lifetime = lifetime\n",
        "    self.pred_prey_threshold = self.num_prey\n",
        "    if rng is None:\n",
        "      self.rng = np.random.default_rng(seed=SEED)\n",
        "    else:\n",
        "      self.rng = rng\n",
        "    self.check_sum = np.sum(np.arange(start=-self.num_food,\n",
        "                                      stop=self.num_critters+1))\n",
        "\n",
        "\n",
        "  def init_loc(self, n_rows, n_cols, num, rng=None):\n",
        "    \"\"\"\n",
        "    Samples random 2d grid locations without replacement\n",
        "\n",
        "    Args:\n",
        "      n_rows: int, number of rows in the grid\n",
        "      n_cols: int, number of columns in the grid\n",
        "      num:    int, number of samples to generate. Should throw an error if num > n_rows x n_cols\n",
        "      rng:    instance of numpy.random's default rng. Used for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "      int_loc: ndarray(int) of shape (num,), flat indices for a 2D grid flattened into 1D\n",
        "      rc_index: tuple(ndarray(int), ndarray(int)), a pair of arrays with the first giving\n",
        "        the row indices and the second giving the col indices. Useful for indexing into\n",
        "        an n_rows by n_cols numpy array.\n",
        "      rc_plotting: ndarray(int) of shape (num, 2), 2D coordinates suitable for matplotlib plotting\n",
        "    \"\"\"\n",
        "\n",
        "    # Set up default random generator, use the boards default if none explicitly given\n",
        "    if rng is None:\n",
        "      rng = self.rng\n",
        "    # Choose 'num' unique random indices from a flat 1D array of size n_rows*n_cols\n",
        "    int_loc = rng.choice(n_rows * n_cols, num, replace=False)\n",
        "    # Convert the flat indices to 2D indices based on the original shape (n_rows, n_cols)\n",
        "    rc_index = np.unravel_index(int_loc, (n_rows, n_cols))\n",
        "    # Transpose indices to get num x 2 array for easy plotting with matplotlib\n",
        "    rc_plotting = np.array(rc_index).T\n",
        "    # Return 1D flat indices, 2D indices for numpy array indexing and 2D indices for plotting\n",
        "    return int_loc, rc_index, rc_plotting\n",
        "\n",
        "\n",
        "  def get_init_board_state(self):\n",
        "    \"\"\"Set up starting board using game parameters\"\"\"\n",
        "    #set rounds_left and score\n",
        "    self.rounds_left = (np.ones(self.batch_size) *\n",
        "                        self.lifetime)\n",
        "    self.is_over = np.zeros(self.batch_size, dtype=bool)\n",
        "    self.scores = np.zeros((self.batch_size, self.num_critters))\n",
        "    # create an empty board array.\n",
        "    self.pieces = np.zeros((self.batch_size, self.n_rows, self.n_cols),\n",
        "                           dtype=int)\n",
        "    # Place critter and initial food items on the board randomly\n",
        "    for ii in np.arange(self.batch_size):\n",
        "      # num_food+num_critter because we want critter and food locations\n",
        "      int_loc, rc_idx, rc_plot = self.init_loc(\n",
        "        self.n_rows, self.n_cols, self.num_food+self.num_critters)\n",
        "      # critter random start locations\n",
        "      for c_ in np.arange(self.num_critters):\n",
        "        self.pieces[(ii, rc_idx[0][c_], rc_idx[1][c_])] = c_ + 1\n",
        "      # food random start locations\n",
        "      for f_ in np.arange(self.num_food):\n",
        "        self.pieces[(ii, rc_idx[0][self.num_critters + f_],\n",
        "                         rc_idx[1][self.num_critters + f_])] = -f_ - 1\n",
        "    state = {'pieces': self.pieces.copy(),\n",
        "             'scores': self.scores.copy(),\n",
        "             'rounds_left': self.rounds_left.copy(),\n",
        "             'is_over': self.is_over.copy()}\n",
        "    return state\n",
        "\n",
        "\n",
        "  def set_state(self, board):\n",
        "    \"\"\" board is dictionary giving game state a triple of np arrays\n",
        "      pieces:        numpy array (batch_size x n_rows x n_cols),\n",
        "      scores:        numpy array (batch_size x num_critters)\n",
        "      rounds_left:   numpy array (batch_size)\n",
        "    \"\"\"\n",
        "    self.pieces = board['pieces'].copy()\n",
        "    self.scores = board['scores'].copy()\n",
        "    self.rounds_left = board['rounds_left'].copy()\n",
        "    self.is_over = board['is_over'].copy()\n",
        "\n",
        "\n",
        "  def get_state(self):\n",
        "    \"\"\" returns a board state, which is a triple of np arrays\n",
        "    pieces,       - batch_size x n_rows x n_cols\n",
        "    scores,       - batch_size\n",
        "    rounds_left   - batch_size\n",
        "    \"\"\"\n",
        "    state = {'pieces': self.pieces.copy(),\n",
        "             'scores': self.scores.copy(),\n",
        "             'rounds_left': self.rounds_left.copy(),\n",
        "             'is_over': self.is_over.copy()}\n",
        "    return state\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.pieces[index]\n",
        "\n",
        "\n",
        "  ################# CORE GAME STATE UPDATE LOGIC ##############################\n",
        "  ################# execute_moves is main, uses these helper functions ########\n",
        "  def get_critter_food_type(self, critter_food):\n",
        "    if critter_food <= -1:\n",
        "        critter_food_type = self.CritterFoodType.FOOD\n",
        "    elif critter_food > self.pred_prey_threshold:\n",
        "        critter_food_type = self.CritterFoodType.PREDATOR\n",
        "    else:\n",
        "        critter_food_type = self.CritterFoodType.PREY\n",
        "    return critter_food_type\n",
        "\n",
        "\n",
        "  def get_type_masks(self):\n",
        "    \"\"\"\n",
        "    Returns masks indicating the position types on the board.\n",
        "    Returns:\n",
        "        tuple: Tuple containing masks for empty spaces, food, prey, and predator.\n",
        "    \"\"\"\n",
        "    empt_mask = self.pieces == 0\n",
        "    food_mask = self.pieces <= -1\n",
        "    prey_mask = (1 <= self.pieces) & (self.pieces <= self.pred_prey_threshold)\n",
        "    pred_mask = self.pred_prey_threshold < self.pieces\n",
        "    return empt_mask, food_mask, prey_mask, pred_mask\n",
        "\n",
        "\n",
        "  def get_collisions(self, moves, critter_food, critter_food_type):\n",
        "    \"\"\"\n",
        "    Determine the collision results and update scores accordingly.\n",
        "    Args:\n",
        "        moves (tuple): Tuple of arrays indicating the moves.\n",
        "        critter_food (int): Index to identify the critter or food.\n",
        "        critter_food_type (enum): Type of the critter or food\n",
        "    Returns:\n",
        "        tuple: Tuple containing move collision messages and separates out the\n",
        "        moves by where they land i.e., empty spaces, food, prey, and predator.\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = self.pieces.shape\n",
        "    move_mask = np.zeros(self.pieces.shape, dtype=bool)\n",
        "    move_mask[moves] = True\n",
        "    (empt_mask, food_mask,\n",
        "     prey_mask, pred_mask) = self.get_type_masks()\n",
        "\n",
        "    move_coll_msg = np.zeros(batch_size)\n",
        "    empt_moves = np.where(empt_mask & move_mask)\n",
        "    food_moves = np.where(food_mask & move_mask)\n",
        "    prey_moves = np.where(prey_mask & move_mask)\n",
        "    pred_moves = np.where(pred_mask & move_mask)\n",
        "    move_coll_msg[empt_moves[0]] = 1\n",
        "\n",
        "    if critter_food_type == self.CritterFoodType.PREY:\n",
        "      move_coll_msg[food_moves[0]] = 2\n",
        "    elif critter_food_type == self.CritterFoodType.PREDATOR:\n",
        "      move_coll_msg[food_moves[0]] = 3\n",
        "      move_coll_msg[prey_moves[0]] = 4\n",
        "    # all collision types are blocking for food types\n",
        "\n",
        "    return (move_coll_msg, empt_moves, food_moves, prey_moves, pred_moves)\n",
        "\n",
        "\n",
        "  def update_scores(self, move_coll_msg, critter_food,\n",
        "                    critter_food_type, prey_moves):\n",
        "    if critter_food_type == self.CritterFoodType.PREY:\n",
        "      self.scores[:, critter_food-1] += (move_coll_msg == 2)\n",
        "    elif critter_food_type == self.CritterFoodType.PREDATOR:\n",
        "      # predators that eat get a point\n",
        "      self.scores[:, critter_food-1] += (move_coll_msg == 4)\n",
        "      # prey that are eaten lose 10 points\n",
        "      who_eaten = self.pieces[prey_moves]\n",
        "      self.scores[prey_moves[0], who_eaten-1] -= 10\n",
        "    # food types don't get a score, it's a neuro book\n",
        "\n",
        "\n",
        "  def move_pieces(self, critter_food, move_coll_msg, moves):\n",
        "    \"\"\"\n",
        "    Move the pieces on the board based on the collision messages.\n",
        "\n",
        "    Args:\n",
        "        critter_food (int): Index to identify the critter or food.\n",
        "        move_coll_msg (np.array): Array of collision messages.\n",
        "        moves (tuple): Tuple of arrays indicating the moves.\n",
        "    \"\"\"\n",
        "    old_locs = np.where(self.pieces == critter_food)\n",
        "    vacated_old_locs = np.column_stack(old_locs)[np.where(move_coll_msg > 0)]\n",
        "    vacated_old_locs_idx = (vacated_old_locs[:,0],\n",
        "                            vacated_old_locs[:,1],\n",
        "                            vacated_old_locs[:,2])\n",
        "    self.pieces[vacated_old_locs_idx] = 0\n",
        "    new_locs = np.column_stack(moves)[np.where(move_coll_msg > 0)]\n",
        "    new_locs_idx = (new_locs[:,0], new_locs[:,1], new_locs[:,2])\n",
        "    self.pieces[new_locs_idx] = critter_food\n",
        "\n",
        "\n",
        "  def replace_destroyed(self, destroying_moves, old_pieces):\n",
        "    \"\"\"\n",
        "    Replace the destroyed pieces on the board.\n",
        "\n",
        "    Args:\n",
        "        destroying_moves (tuple): Tuple of arrays indicating the moves that\n",
        "        resulted in destruction.\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = old_pieces.shape\n",
        "    g_gone = np.zeros(batch_size)\n",
        "    g_gone[destroying_moves[0]] = 1\n",
        "    which_gone = old_pieces[destroying_moves]\n",
        "    if np.sum(g_gone) > 0:\n",
        "      num_empty_after = (n_rows*n_cols - self.num_food - self.num_critters + 1)\n",
        "      p_new_locs = np.where(np.logical_and(\n",
        "        self.pieces == 0, g_gone.reshape(batch_size, 1, 1)))\n",
        "      food_sample_ = self.rng.choice(num_empty_after, size=int(np.sum(g_gone)))\n",
        "      food_sample = food_sample_ + np.arange(int(np.sum(g_gone)))*num_empty_after\n",
        "      new_loc_vals = self.pieces[(p_new_locs[0][food_sample],\n",
        "                   p_new_locs[1][food_sample],\n",
        "                   p_new_locs[2][food_sample])]\n",
        "      # this requires that p_new_locs and destroying moves are both\n",
        "      # lexographically sorted... but they are not always\n",
        "      self.pieces[(p_new_locs[0][food_sample],\n",
        "                   p_new_locs[1][food_sample],\n",
        "                   p_new_locs[2][food_sample])] = which_gone\n",
        "\n",
        "\n",
        "  def execute_moves(self, moves, critter_food):\n",
        "    \"\"\"\n",
        "    Execute the moves on the board, handle collisions, update scores,\n",
        "    and replace destroyed/eaten pieces.\n",
        "\n",
        "    Args:\n",
        "      moves (tuple): Tuple of arrays indicating the moves.\n",
        "      critter_food (int): Index to identify the critter or food.\n",
        "    \"\"\"\n",
        "    # what type of critter is moving\n",
        "    critter_food_type = self.get_critter_food_type(critter_food)\n",
        "    # what do they land on when the move\n",
        "    (move_coll_msg, empt_moves, food_moves,\n",
        "     prey_moves, pred_moves) = self.get_collisions(\n",
        "        moves, critter_food, critter_food_type)\n",
        "    # based on what they move onto increment/decrement scores\n",
        "    self.update_scores(move_coll_msg, critter_food,\n",
        "                       critter_food_type, prey_moves)\n",
        "    # move the pieces\n",
        "    old_pieces = self.pieces.copy()\n",
        "    self.move_pieces(critter_food, move_coll_msg, moves)\n",
        "    # eaten food and prey respawn\n",
        "    if critter_food_type == self.CritterFoodType.PREY:\n",
        "      self.replace_destroyed(food_moves, old_pieces)\n",
        "    elif critter_food_type == self.CritterFoodType.PREDATOR:\n",
        "      self.replace_destroyed(food_moves, old_pieces)\n",
        "      self.replace_destroyed(prey_moves, old_pieces)\n",
        "    if np.any(np.sum(self.pieces, axis=(1,2)) != self.check_sum):\n",
        "      print('something went terribly wrong')\n",
        "      print(old_pieces)\n",
        "      print(critter_food)\n",
        "      print(moves)\n",
        "      print(self.pieces)\n",
        "\n",
        "\n",
        "  def get_neighbor_grc_indices(self, critter_food, radius, pad=False):\n",
        "    \"\"\"\n",
        "    Returns all grid positions within a certain cityblock distance radius from\n",
        "    the place corresponding to critter_food.\n",
        "\n",
        "    Args:\n",
        "        critter_food (int): The idex of the focal critter_food.\n",
        "        radius (int): The cityblock distance.\n",
        "        pad (bool): whether or not to pad the array, if padded all row, col\n",
        "          indexes are valid for the padded array, useful for getting percept\n",
        "          if not all indexes are correct for the original array, useful for\n",
        "          figuring out legal moves.\n",
        "\n",
        "    Returns:\n",
        "        an array of indices, each row is a g, r, c index for the neighborhoods\n",
        "        around the critters, can use the g value to know which board you are in.\n",
        "        if pad=True also returns the padded array (the indices in that case) are\n",
        "        for the padded array, so won't work on self.pieces, whereas if pad is\n",
        "        False the indices will be for the offsets in reference to the original\n",
        "        self.pieces, but note that some of these will be invalid, and will\n",
        "        need to be filtered out (as we do in get_legal)\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = self.pieces.shape\n",
        "    # Create meshgrid for offsets\n",
        "    if pad is True:\n",
        "      padded_arr = np.pad(self.pieces, ((0, 0), (radius, radius),\n",
        "        (radius, radius)), constant_values=self.ARRAY_PAD_VALUE)\n",
        "      batch, rows, cols = np.where(padded_arr == critter_food)\n",
        "    else:\n",
        "      batch, rows, cols = np.where(self.pieces == critter_food)\n",
        "    row_offsets, col_offsets = np.meshgrid(\n",
        "        np.arange(-radius, radius + 1),\n",
        "        np.arange(-radius, radius + 1),\n",
        "        indexing='ij')\n",
        "\n",
        "    # Filter for valid cityblock distances\n",
        "    mask = np.abs(row_offsets) + np.abs(col_offsets) <= radius\n",
        "    valid_row_offsets = row_offsets[mask]\n",
        "    valid_col_offsets = col_offsets[mask]\n",
        "    # Extend rows and cols dimensions for broadcasting\n",
        "    extended_rows = rows[:, np.newaxis]\n",
        "    extended_cols = cols[:, np.newaxis]\n",
        "    # Compute all neighbors for each position in the batch\n",
        "    neighbors_rows = extended_rows + valid_row_offsets\n",
        "    neighbors_cols = extended_cols + valid_col_offsets\n",
        "\n",
        "    indices = np.column_stack((np.repeat(np.arange(batch_size),\n",
        "                                         neighbors_rows.shape[1]),\n",
        "                               neighbors_rows.ravel(),\n",
        "                               neighbors_cols.ravel()))\n",
        "    if pad is False:\n",
        "      return indices\n",
        "    elif pad is True:\n",
        "      return indices, padded_arr\n",
        "\n",
        "\n",
        "  def get_legal_moves(self, critter_food, radius=1):\n",
        "    \"\"\"\n",
        "    Identifies all legal moves for the critter, taking into acount which moves\n",
        "    are blocking based on type.\n",
        "\n",
        "    Returns:\n",
        "      A numpy int array of size batch x 3(g,x,y) x 4(possible moves)\n",
        "\n",
        "    Note:\n",
        "      moves[0,1,3] is the x coordinate of the move corresponding to the\n",
        "      fourth offset on the first board.\n",
        "      moves[1,:,1] will give the g,x,y triple corresponding to the\n",
        "      move on the second board and the second offset, actions are integers\n",
        "    \"\"\"\n",
        "\n",
        "    critter_locs = np.array(np.where(self.pieces == critter_food))\n",
        "    # turn those row, col offsets into a set of legal offsets\n",
        "    legal_offsets = self.get_neighbor_grc_indices(critter_food, radius)\n",
        "    legal_offsets = {tuple(m_) for m_ in legal_offsets}\n",
        "\n",
        "    # Apply logic of where a successful move can be made, by which\n",
        "    # type of critter, be they food, prey, predator or something else\n",
        "    empt_mask, food_mask, prey_mask, pred_mask = self.get_type_masks()\n",
        "    critter_food_type = self.get_critter_food_type(critter_food)\n",
        "    #print(critter_food_type)\n",
        "    if critter_food_type == self.CritterFoodType.FOOD:\n",
        "      #food only drifts into empty places\n",
        "      legal_destinations = np.where(empt_mask)\n",
        "    elif critter_food_type == self.CritterFoodType.PREY:\n",
        "      legal_destinations = np.where(empt_mask | food_mask)\n",
        "    elif critter_food_type == self.CritterFoodType.PREDATOR:\n",
        "      legal_destinations = np.where(empt_mask | food_mask | prey_mask)\n",
        "    else:\n",
        "      raise ValueError(\"Unexpected value for critter_food_type.\")\n",
        "    legal_destinations = {tuple(coords) for coords in zip(*legal_destinations)}\n",
        "    # Add the current locations of the critters to legal_destinations\n",
        "    current_locations = {tuple(loc) for loc in critter_locs.T}\n",
        "    legal_destinations = legal_destinations.union(current_locations)\n",
        "\n",
        "    # legal moves are both legal offsets and legal destinations\n",
        "    legal_moves = legal_offsets.intersection(legal_destinations)\n",
        "    return legal_moves\n",
        "\n",
        "\n",
        "  def get_legal_offsets(self, critter_food, radius):\n",
        "    \"\"\"\n",
        "    Identifies all legal offsets for a critter or food, so filter out moves\n",
        "    that are off the board, but does not filter out collisions that would be\n",
        "    blocking. For a random valid player likely better to use get_legal_moves,\n",
        "    but this is much quicker, because it doesn't check collision types, for\n",
        "    use by RL agents in training loops\n",
        "\n",
        "    Returns:\n",
        "      A numpy int array of size batch x 3(g,x,y) x 4(possible moves)\n",
        "\n",
        "    Note:\n",
        "      moves[0,1,3] is the x coordinate of the move corresponding to the\n",
        "      fourth offset on the first board.\n",
        "      moves[1,:,1] will give the g,x,y triple corresponding to the\n",
        "      move on the second board and the second offset, actions are integers\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = self.pieces.shape\n",
        "    batch, rows, cols = np.where(self.pieces == critter_food)\n",
        "    row_offsets, col_offsets = np.meshgrid(\n",
        "        np.arange(-radius, radius + 1),\n",
        "        np.arange(-radius, radius + 1),\n",
        "        indexing='ij')\n",
        "    # Filter for valid cityblock distances\n",
        "    mask = np.abs(row_offsets) + np.abs(col_offsets) <= radius\n",
        "    valid_row_offsets = row_offsets[mask]\n",
        "    valid_col_offsets = col_offsets[mask]\n",
        "    # Extend rows and cols dimensions for broadcasting\n",
        "    extended_rows = rows[:, np.newaxis]\n",
        "    extended_cols = cols[:, np.newaxis]\n",
        "    # Compute all neighbors for each position in the batch\n",
        "    potential_moves_rows = extended_rows + valid_row_offsets\n",
        "    potential_moves_cols = extended_cols + valid_col_offsets\n",
        "\n",
        "    # Filter offsets that would take the critter outside the board\n",
        "    c1 = potential_moves_rows >= 0\n",
        "    c2 = potential_moves_rows <= n_rows-1\n",
        "    c3 = potential_moves_cols >= 0\n",
        "    c4 = potential_moves_cols <= n_cols-1\n",
        "    valid_move_mask = np.logical_and.reduce([c1, c2, c3, c4])\n",
        "\n",
        "    legal_offsets_rows = potential_moves_rows[valid_move_mask]\n",
        "    legal_offsets_cols = potential_moves_cols[valid_move_mask]\n",
        "    batch_indexes = np.repeat(batch, valid_row_offsets.shape[0])\n",
        "    legal_offsets = np.column_stack((batch_indexes[valid_move_mask.ravel()],\n",
        "                                     legal_offsets_rows.ravel(),\n",
        "                                     legal_offsets_cols.ravel()))\n",
        "    return legal_offsets, valid_move_mask\n",
        "\n",
        "\n",
        "  def get_perceptions(self, critter_food, radius):\n",
        "    idx, pad_pieces = self.get_neighbor_grc_indices(critter_food,\n",
        "                                                    radius, pad=True)\n",
        "    #percept_mask = np.zeros(pad_pieces.shape, dtype=bool)\n",
        "    #percept_mask[idx[:,0], idx[:,1]], idx[:,2]] = True\n",
        "    percept = pad_pieces[idx[:,0], idx[:,1], idx[:,2]]\n",
        "    return(percept.reshape(self.batch_size, -1))\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title GridworldGame class\n",
        "#######################################################################\n",
        "# extend GridworldGame class locally before integrating in shared utils\n",
        "#######################################################################\n",
        "\n",
        "\n",
        "\n",
        "class GridworldGame():\n",
        "  \"\"\"\n",
        "  A collection methods and parameters of a gridworld game that allow\n",
        "  for interaction with and display of GridwordlBoard objects.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, batch_size=1, n_rows=7, n_cols=7,\n",
        "               num_food=10, num_prey=1, num_pred=1,\n",
        "               lifetime=30, rng=None, drift_player=None):\n",
        "    \"\"\"\n",
        "    Initializes an instance of the class with the specified parameters.\n",
        "    Args:\n",
        "      batch_size (int, optional): Number of instances in a batch. Default is 1.\n",
        "      n_rows (int, optional): Number of rows in the grid. Default is 7.\n",
        "      n_cols (int, optional): Number of columns in the grid. Default is 7.\n",
        "      num_food (int, optional): Number of food items. Default is 10.\n",
        "      num_prey (int, optional): Number of different agents running around\n",
        "        on each board in the batch eating food. Default is 1.\n",
        "      num_pred (int, optional): Number of different agents running around\n",
        "        on each board in the batch eating prey. Default is 1.\n",
        "      lifetime (int, optional): Time before critter's life ends, in terms of\n",
        "        time steps. Default is 30.\n",
        "      rng (numpy random number generator, optional): Random number generator\n",
        "        for reproducibility. If None, uses default RNG with a preset seed.\n",
        "      drift_player (player object, optional): a 'player' who moves the food\n",
        "        pieces around (drifting) if none, skip food movement\n",
        "    \"\"\"\n",
        "\n",
        "    # Check for positive integer inputs\n",
        "    assert all(isinstance(i, int) and i >= 0\n",
        "               for i in [batch_size, n_rows, n_cols, num_food, num_prey, num_pred,\n",
        "                         lifetime]), \"All inputs must be non-negative integers.\"\n",
        "    self.batch_size = batch_size\n",
        "    self.n_rows = n_rows\n",
        "    self.n_cols = n_cols\n",
        "    self.num_food = num_food\n",
        "    self.num_prey = num_prey\n",
        "    self.num_pred = num_pred\n",
        "    self.num_critters = num_pred + num_prey\n",
        "    self.pred_prey_threshold = self.num_prey\n",
        "    # Check for num_food exceeding maximum possible value\n",
        "    max_food = n_rows * n_cols - self.num_critters\n",
        "    if num_food > max_food:\n",
        "      print(f'num_food is too large, setting it to maximum possible value: {max_food}')\n",
        "      num_food = max_food\n",
        "    self.num_food = num_food\n",
        "    self.lifetime = lifetime\n",
        "    # Set up random number generator\n",
        "    if rng is None:\n",
        "      self.rng = np.random.default_rng(seed=SEED)\n",
        "    else:\n",
        "      self.rng = rng\n",
        "    self.drift_player = drift_player\n",
        "\n",
        "\n",
        "  def get_init_board(self):\n",
        "    \"\"\"\n",
        "    Generates a starting board given the parameters of the game.\n",
        "    Returns a tuple giving current state of the game\n",
        "    \"\"\"\n",
        "    # current score, and rounds left in the episode\n",
        "    b = GridworldBoard(batch_size=self.batch_size, n_rows=self.n_rows,\n",
        "                       n_cols=self.n_cols, num_food=self.num_food,\n",
        "                       num_prey=self.num_prey, num_pred=self.num_pred,\n",
        "                       lifetime=self.lifetime, rng=self.rng)\n",
        "    return b.get_init_board_state()\n",
        "\n",
        "\n",
        "  def get_board_shape(self):\n",
        "    \"\"\"Shape of a single board, doesn't give batch size\"\"\"\n",
        "    return (self.n_rows, self.n_cols)\n",
        "\n",
        "\n",
        "  def get_action_size(self):\n",
        "    \"\"\"\n",
        "    Returns the number of all possible actions, even though only  2-4 of\n",
        "    these will ever be valid on a given turn.\n",
        "    Actions correspond to integer indexes of board locations,\n",
        "    moves to g,r,c coordinate indexes of board locations\n",
        "    \"\"\"\n",
        "    return self.n_rows * self.n_cols\n",
        "\n",
        "\n",
        "  def get_batch_size(self):\n",
        "    \"\"\"\n",
        "    Returns the number of actions, only 0-4 of these will ever be valid.\n",
        "    Actions correspond to integer indexes of board locations,\n",
        "    moves to r,c indexes of board locations\n",
        "    \"\"\"\n",
        "    return self.batch_size\n",
        "\n",
        "\n",
        "  def string_rep(self, board, g=0):\n",
        "    \"\"\" A bytestring representation board g's state in the batch of boards\"\"\"\n",
        "    return (board['pieces'][g].tobytes() + board['scores'][g].tobytes() +\n",
        "            board['rounds_left'][g].tobytes())\n",
        "\n",
        "\n",
        "  def get_square_symbol(self, piece):\n",
        "    \"\"\" Translate integer piece value to symbol for display\"\"\"\n",
        "    if piece == -1:\n",
        "      return \"X\"\n",
        "    elif piece == 0:\n",
        "      return \"-\"\n",
        "    elif piece >= 1:\n",
        "      return \"0\"\n",
        "    else:\n",
        "      return \"???????????????????????????\"\n",
        "\n",
        "\n",
        "  def string_rep_readable(self, board, g=0):\n",
        "    \"\"\" A human readable representation of g-th board's state in the batch\"\"\"\n",
        "    board_s = \"\".join([self.get_square_symbol(square)\n",
        "                        for row in board['pieces'][g]\n",
        "                          for square in row])\n",
        "    board_s = board_s + '_' + str(board['scores'][g])\n",
        "    board_s = board_s + '_' + str(board['rounds_left'][g])\n",
        "    return board_s\n",
        "\n",
        "\n",
        "  def get_scores(self, board):\n",
        "    return board['scores'].copy()\n",
        "\n",
        "\n",
        "  def get_rounds_left(self, board):\n",
        "    return board['rounds_left'].copy()\n",
        "\n",
        "\n",
        "  def display(self, board, g=0):\n",
        "    \"\"\"Displays the g-th games in the batch of boards\"\"\"\n",
        "    print(\"   \", end=\"\")\n",
        "    for c_ in range(self.n_cols):\n",
        "      print(c_, end=\" \")\n",
        "    print(\"\")\n",
        "    print(\"-----------------------\")\n",
        "    for c_ in range(self.n_cols):\n",
        "      print(c_, \"|\", end=\"\")    # Print the row\n",
        "      for r_ in range(self.n_rows):\n",
        "        piece = board['pieces'][g,c_,r_]    # Get the piece to print\n",
        "        #print(piece)\n",
        "        print(self.get_square_symbol(piece), end=\" \")\n",
        "      print(\"|\")\n",
        "    print(\"-----------------------\")\n",
        "    print(\"Rounds Left: \" + str(board['rounds_left'][g]))\n",
        "    print(\"Score: \" + str(board['scores'][g]))\n",
        "\n",
        "\n",
        "  def get_critter_rc(self, board, g, critter_index):\n",
        "    return np.squeeze(np.array(np.where(board['pieces'][g]==critter_index)))\n",
        "\n",
        "\n",
        "  def plot_moves(self, board, player0, g=0, player1=None,\n",
        "                 fig=None, ax=None, p0_name='Player 0', p1_name='Player 1',\n",
        "                 figsize=(6,5), critter_name='Critter', title=None,\n",
        "                 deterministic=False):\n",
        "    \"\"\"\n",
        "    Uses plotting functions to make picture of the current board state, and what\n",
        "    a critter would do at each non-food location in the current board state\n",
        "    \"\"\"\n",
        "    def make_prob_dict(critter_locs, play):\n",
        "      offset_dict = {(0, 1): 'right',\n",
        "                     (0,-1): 'left',\n",
        "                     ( 1, 0): 'down',\n",
        "                     (-1, 0): 'up'}\n",
        "      index_probs = play[2].copy()\n",
        "      loc_prob_dict = {}\n",
        "      # for each non food locations\n",
        "      for g, loc_ in enumerate(critter_locs):\n",
        "        # this is the location as an r, c tuple\n",
        "        rc_tup = tuple((loc_[1], loc_[2]))\n",
        "        # the relevant probabilities\n",
        "        raw_probs = index_probs[g]\n",
        "        probs = raw_probs[raw_probs > 0]\n",
        "        indexes = np.argwhere(raw_probs > 0)\n",
        "        # turn the probability indexes into r, c coords\n",
        "        rows = np.floor_divide(indexes, gwg.n_cols)\n",
        "        cols = np.remainder(indexes, gwg.n_cols)\n",
        "        moves = np.squeeze(np.array([z for z in zip(rows, cols)]), axis=2)\n",
        "        #compute the offsets and turn them to strings\n",
        "        offsets = moves - loc_[1:]\n",
        "        str_offsets = np.array(list(map(offset_dict.get, map(tuple, offsets))))\n",
        "        # update the loc_prob_dict for plotting\n",
        "        prob_dict = dict(zip(str_offsets, probs))\n",
        "        loc_prob_dict.update({rc_tup: prob_dict})\n",
        "      return loc_prob_dict\n",
        "\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    plt.ioff()\n",
        "    if fig is None and ax is None:\n",
        "      fig, ax = make_grid(n_rows, n_cols, figsize=figsize, title=title)\n",
        "\n",
        "    rc_food_index = np.array(np.where(board['pieces'][g] <= -1))\n",
        "    rc_food_plotting = np.array(rc_food_index).T\n",
        "    food = plot_food(fig, ax, rc_food_plotting)\n",
        "\n",
        "    expanded_board = self.critter_everywhere_state_expansion(\n",
        "      board, player0.critter_index, to_expand=g)\n",
        "    critter_locs = np.argwhere(expanded_board['pieces']==player0.critter_index)\n",
        "    #play the expanded state\n",
        "    p0_play = player0.play(expanded_board)\n",
        "    #get the prob dict\n",
        "    p0_loc_prob_dict = make_prob_dict(critter_locs, p0_play)\n",
        "    # same for player1 if there is one\n",
        "    if player1 is not None:\n",
        "      p1_play = player1.play(expanded_board)\n",
        "      p1_loc_prob_dict = make_prob_dict(critter_locs, p1_play)\n",
        "\n",
        "    existing_handels, _ = ax.get_legend_handles_labels()\n",
        "    if player1 is None:\n",
        "      fig, ax, leg_handles_0 = plot_directions(fig, ax, p0_loc_prob_dict,\n",
        "        critter=0, deterministic=deterministic)\n",
        "      leg_handles = existing_handels\n",
        "    else:\n",
        "      fig, ax, leg_handles_0 = plot_directions(fig, ax, p0_loc_prob_dict,\n",
        "        critter=1, deterministic=deterministic, name=p0_name)\n",
        "      fig, ax, leg_handles_1 = plot_directions(fig, ax, p1_loc_prob_dict,\n",
        "        critter=2, deterministic=deterministic, name=p1_name)\n",
        "      leg_handles = existing_handels + leg_handles_0 + leg_handles_1\n",
        "\n",
        "    fig.legend(handles=leg_handles, loc=\"outside right upper\")\n",
        "    fig.canvas.draw()\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "  def plot_board(self, board, g=0,\n",
        "                 fig=None, ax=None, critter_specs=None, food=None, fov=None,\n",
        "                 legend_type='included',\n",
        "                 has_fov=False, #fog_of_war feild_of_view\n",
        "                 fov_opaque=False, #let human see trhough fog of war or not\n",
        "                 radius=2, figsize=(6,5), title=None,\n",
        "                 name='Critter',\n",
        "                 focal_critter_index = 0):\n",
        "    \"\"\"Uses plotting functions to make picture of the current board state\"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    plt.ioff()\n",
        "    if fig is None and ax is None:\n",
        "      fig, ax = make_grid(n_rows, n_cols, figsize=figsize, title=title)\n",
        "\n",
        "    # generate critter plotting specs if we don't already have them\n",
        "    if critter_specs is None:\n",
        "      critter_specs = []\n",
        "      markers = ['h', 'd']  # hexagon and diamond\n",
        "      colors = sns.color_palette(\"colorblind\")\n",
        "      for i in range(self.num_critters):\n",
        "        critter_name = name if self.num_critters == 1 else f'{name} {i+1}'\n",
        "        spec = {'marker': markers[i % len(markers)],\n",
        "                'color': colors[i // len(markers) % len(colors)],\n",
        "                'name': critter_name,\n",
        "                'int_id': i+1}\n",
        "        critter_specs.append(spec)\n",
        "    # get critter locs and plot them\n",
        "    assert len(critter_specs) == self.num_critters, \"More/fewer specs than critters\"\n",
        "    for spec in critter_specs:\n",
        "      rc_loc = np.array(np.where(board['pieces'][g] == spec['int_id'])).T\n",
        "      spec.update({'rc_loc': rc_loc})\n",
        "    critter_specs = plot_critters(fig, ax, critter_specs)\n",
        "\n",
        "    # get food locs and plot them\n",
        "    rc_food_index = np.array(np.where(board['pieces'][g] <= -1))\n",
        "    rc_food_plotting = np.array(rc_food_index).T\n",
        "    if food is None:\n",
        "      food = plot_food(fig, ax, rc_food_plotting)\n",
        "    else:\n",
        "      food = plot_food(fig, ax, rc_food_plotting, food)\n",
        "\n",
        "    #plot field of view if doing that\n",
        "    if has_fov:\n",
        "      # plot field of view around the 'active player'\n",
        "      if fov is None:\n",
        "        fov = plot_fov(fig, ax, critter_specs[focal_critter_index]['rc_loc'][0],\n",
        "                       n_rows, n_cols, radius, has_fov, opaque=fov_opaque)\n",
        "      else:\n",
        "        fov = plot_fov(fig, ax, critter_specs[focal_critter_index]['rc_loc'][0],\n",
        "                       n_rows, n_cols, radius, has_fov, opaque=fov_opaque, fov=fov)\n",
        "    # make legend and draw and return figure\n",
        "    if legend_type == 'included':\n",
        "      fig.legend(loc = \"outside right upper\", markerscale=0.8)\n",
        "      fig.canvas.draw()\n",
        "      return fig, ax, critter_specs, food, fov\n",
        "    elif legend_type == 'separate':\n",
        "      fig_legend, ax_legend = plt.subplots(figsize=(1.5,1.5), layout='constrained')\n",
        "      fig_legend.get_layout_engine().set(w_pad=0, h_pad=0, hspace=0, wspace=0)\n",
        "      handles, labels = ax.get_legend_handles_labels()\n",
        "      ax_legend.legend(handles, labels, loc='center', markerscale=0.8)\n",
        "      ax_legend.axis('off')\n",
        "      fig_legend.canvas.header_visible = False\n",
        "      fig_legend.canvas.toolbar_visible = False\n",
        "      fig_legend.canvas.resizable = False\n",
        "      fig_legend.canvas.footer_visible = False\n",
        "      fig_legend.canvas.draw()\n",
        "      return fig, ax, critter_specs, food, fov, fig_legend, ax_legend\n",
        "    else: #no legend\n",
        "      fig.canvas.draw()\n",
        "      return fig, ax, critter_specs, food, fov\n",
        "\n",
        "\n",
        "  def get_legal_moves(self, board, critter=1, radius=1):\n",
        "    \"\"\"\n",
        "    A Helper function to get the legal moves, as set of batch, row, col triples\n",
        "    giving for the given board. Does return moves that are technically legal\n",
        "    but that will result in a blocking move, this is good for a random valid\n",
        "    player, so that the don't have a high probability of staying still if\n",
        "    there are lots of blocking moves.\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "      critter (int): value of critter we are getting the valid actions for\n",
        "      radius (int): how far, in city block distance the critter can move\n",
        "\n",
        "    Returns:\n",
        "      moves: set or tuples (g, r, c)\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    b = GridworldBoard(batch_size=self.batch_size, n_rows=self.n_rows,\n",
        "                       n_cols=self.n_cols, num_food=self.num_food,\n",
        "                       num_prey=self.num_prey, num_pred=self.num_pred,\n",
        "                       lifetime=self.lifetime, rng=self.rng)\n",
        "    b.set_state(board)\n",
        "    legal_moves =  b.get_legal_moves(critter, radius)\n",
        "    return legal_moves\n",
        "\n",
        "\n",
        "  def get_legal_offsets(self, board, critter=1, radius=1):\n",
        "    \"\"\"\n",
        "    A Helper function to the legal moves, as an array where each row is\n",
        "    a batch, row, col index giving legal moves on a given board. Includes\n",
        "    blocking moves, but excludes offsets that will take the critter off the\n",
        "    board\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "      critter (int): value of critter we are getting the valid actions for\n",
        "      radius (int): how far, in city block distance the critter can move\n",
        "\n",
        "    Returns:\n",
        "      moves: set or tuples (g, r, c)\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    b = GridworldBoard(batch_size=self.batch_size, n_rows=self.n_rows,\n",
        "                       n_cols=self.n_cols, num_food=self.num_food,\n",
        "                       num_prey=self.num_prey, num_pred=self.num_pred,\n",
        "                       lifetime=self.lifetime, rng=self.rng)\n",
        "    b.set_state(board)\n",
        "    legal_offsets, valid_moves_mask =  b.get_legal_offsets(critter, radius)\n",
        "    return legal_offsets, valid_moves_mask\n",
        "\n",
        "\n",
        "  def get_valid_actions(self, board, critter=1, radius=1):\n",
        "    \"\"\"\n",
        "    A Helper function to translate the g,x,y, tuples provided the\n",
        "    GridworldBoard.get_legal_moves method into valid actions, represented\n",
        "    as binary vectors of len num_actions.\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "      critter (int): value of critter we are getting the valid actions for\n",
        "      radius (int): how far, in city block distance the critter can move\n",
        "\n",
        "    Returns:\n",
        "      valids: np.ndarray(binary) batch_size x num_actions, 1's represent\n",
        "              valid moves\n",
        "    \"\"\"\n",
        "    legal_moves =  self.get_legal_moves(board, critter, radius)\n",
        "    g, r, c = zip(*legal_moves)\n",
        "    valids = np.zeros((self.batch_size, self.n_rows * self.n_cols))\n",
        "    valids[g, np.array(r) * self.n_cols + np.array(c)] = 1\n",
        "    return valids\n",
        "\n",
        "\n",
        "  def display_moves(self, board, critter=1, g=0):\n",
        "    \"\"\"Displays possible moves for the g-th games in the batch of boards\"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    A=np.reshape(self.get_valid_actions(board, critter)[g],\n",
        "                 (n_rows, n_cols))\n",
        "    print(\"  \")\n",
        "    print(\"possible moves\")\n",
        "    print(\"   \", end=\"\")\n",
        "    for col in range(self.n_cols):\n",
        "      print(col, end=\" \")\n",
        "    print(\"\")\n",
        "    print(\"-----------------------\")\n",
        "    for col in range(self.n_cols):\n",
        "      print(col, \"|\", end=\"\")    # Print the row\n",
        "      for row in range(self.n_rows):\n",
        "        piece = A[col][row]    # Get the piece to print\n",
        "        print(self.get_square_symbol(piece), end=\" \")\n",
        "      print(\"|\")\n",
        "    print(\"-----------------------\")\n",
        "\n",
        "\n",
        "  def get_perceptions(self, board, radius, critter):\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    b = GridworldBoard(batch_size=self.batch_size, n_rows=self.n_rows,\n",
        "                       n_cols=self.n_cols, num_food=self.num_food,\n",
        "                       num_prey=self.num_prey, num_pred=self.num_pred,\n",
        "                       lifetime=self.lifetime, rng=self.rng)\n",
        "    b.set_state(board)\n",
        "    return(b.get_perceptions(radius, critter))\n",
        "\n",
        "\n",
        "  def get_next_state(self, board, critter, actions, a_indx=None):\n",
        "    \"\"\"\n",
        "    Helper function using GridworldBoard.execute_moves to update board state\n",
        "    given actions on a batch of boards, for a given critter\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "      critter: integer index of the critter type\n",
        "      actions: list of flat integer indexes of critter's new board positions\n",
        "      a_indx: list of integer indexes indicating which actions are being taken\n",
        "        on which boards in the batch\n",
        "\n",
        "    Returns:\n",
        "      a board triple signifying next state\n",
        "\n",
        "    Note:\n",
        "      if len(actions) > batch_size of board the returned board state will have\n",
        "      an expanded batch size, allowing multiple paths in the game tree to be\n",
        "      explored in parallel\n",
        "\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    if board['rounds_left'][0] <= 0:\n",
        "      # assumes all boards in the batch have the same rounds left\n",
        "      # no rounds left return the board unchanged\n",
        "      return board\n",
        "    else:\n",
        "      b = GridworldBoard(batch_size=len(actions), n_rows=n_rows,\n",
        "                         n_cols=n_cols, num_food=self.num_food,\n",
        "                         num_prey=self.num_prey, num_pred=self.num_pred,\n",
        "                         lifetime=self.lifetime, rng=self.rng)\n",
        "\n",
        "      if a_indx is None:\n",
        "        # just one move on each board in the batch\n",
        "        assert batch_size == len(actions)\n",
        "        b.set_state(board)\n",
        "      else:\n",
        "        # potentially multiple moves on each board, expand the batch\n",
        "        assert len(actions) == len(a_indx)\n",
        "        new_pieces = np.array([board['pieces'][ai].copy() for ai in a_indx])\n",
        "        new_scores = np.array([board['scores'][ai].copy() for ai in a_indx])\n",
        "        new_rounds_left = np.array([board['rounds_left'][ai].copy() for ai in a_indx])\n",
        "        new_active_player = copy(board['active_player'])\n",
        "        new_state = {'pieces': new_pieces,\n",
        "                     'scores': new_scores,\n",
        "                     'rounds_left': new_rounds_left,\n",
        "                     'active_player': new_active_player}\n",
        "        b.set_state(new_state)\n",
        "      moves = self.actions_to_moves(actions)\n",
        "      b.execute_moves(moves, critter)\n",
        "      return b.get_state()\n",
        "\n",
        "\n",
        "  def actions_to_moves(self, actions):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      actions: a batch length list of integer indexes for the flattened boards,\n",
        "      i.e. in the range(n_cols * n_rows) actions are often much easier to use\n",
        "      as training targets for NN based RL agents.\n",
        "    Returns\n",
        "      moves: a 3-tuple of 1-d arrays each of length batch_size,\n",
        "        the first array gives the specific board within the batch,\n",
        "        the second array in the tuple gives the new row coord for each critter\n",
        "        on each board and the third gives the new col coord. Note this is\n",
        "        exactly the format expected by GridworldBoard.execute_moves, and\n",
        "        is a canonical way of indexing arrays for quick numpy operations.\n",
        "    \"\"\"\n",
        "    moves = (np.arange(len(actions)),\n",
        "             np.floor_divide(actions, self.n_cols),\n",
        "             np.remainder(actions, self.n_cols))\n",
        "    return moves\n",
        "\n",
        "\n",
        "  def moves_to_actions(self, moves):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      moves: a 3-tuple of 1-d arrays each of length batch_size,\n",
        "        the first array gives the specific board within the batch,\n",
        "        the second array in the tuple gives the new row coord for each critter\n",
        "        on each board and the third gives the new col coord. Note this is\n",
        "        exactly the format expected by GridworldBoard.execute_moves, and\n",
        "        is a canonical way of indexing arrays for quick numpy operations.\n",
        "    Returns:\n",
        "      actions: a batch length list of integer indexes for the flattened boards,\n",
        "      i.e. in the range(n_cols * n_rows) actions are often much easier to use\n",
        "      as training targets for NN based RL agents.\n",
        "    \"\"\"\n",
        "    _, rows, cols = moves\n",
        "    actions = rows * self.n_cols + cols\n",
        "    return actions\n",
        "\n",
        "\n",
        "  def critter_oriented_get_next_state(self, board, critter, offsets):\n",
        "    \"\"\"\n",
        "    Translates directions in reference to the critter's location into\n",
        "    moves on the board in absolute terms, while checking for\n",
        "    bouncing/reflecting then get's the next state.\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "      offsets: batch length list of strings one 'up', 'down', 'left', 'right'\n",
        "\n",
        "    Returns:\n",
        "      a board triple signifying next state\n",
        "\n",
        "    Note:\n",
        "      Unlike get_next_state, this method does not allow for expansion\n",
        "      of the game tree, i.e. len(offsets)==batch_size required\n",
        "    \"\"\"\n",
        "    assert len(offsets) == board['pieces'].shape[0]\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    b = GridworldBoard(batch_size=self.batch_size, n_rows=self.n_rows,\n",
        "                       n_cols=self.n_cols, num_food=self.num_food,\n",
        "                       num_prey=self.num_prey, num_pred=self.num_pred,\n",
        "                       lifetime=self.lifetime, rng=self.rng)\n",
        "    b.set_state(board)\n",
        "    moves = self.critter_direction_to_move(board, offsets, critter)\n",
        "    b.execute_moves(moves, critter)\n",
        "    return(b.get_state())\n",
        "\n",
        "\n",
        "  def critter_direction_to_move(self, board, offsets, critter):\n",
        "    \"\"\"\n",
        "    Translates directions in reference to the critter's location into\n",
        "    moves on the board in absolute terms, while checking for\n",
        "    bouncing/reflecting then returns moves. Doesn't check for collisions with\n",
        "    other critters though. In general player's move methods should be checking\n",
        "    valid moves and only making legal ones.\n",
        "\n",
        "    Args:\n",
        "      board: dict of np arrays representing board state\n",
        "        'pieces':       batch_size x n_rows x n_cols\n",
        "        'scores':       batch_size\n",
        "        'rounds_left':  batch_size\n",
        "      offsets: batch length list of strings,\n",
        "        one of 'up', 'down', 'left', 'right'\n",
        "      critter: integer index for the critter we want moves for\n",
        "\n",
        "    Returns:\n",
        "      moves: a 3-tuple of 1-d arrays each of length batch_size,\n",
        "        the first array gives the specific board within the batch,\n",
        "        the second array in the tuple gives the new row coord for each critter\n",
        "        on each board and the third gives the new col coord. Note this is\n",
        "        exactly the format expected by GridworldBoard.execute_moves, and\n",
        "        is a canonical way of indexing arrays for numpy.\n",
        "\n",
        "    Note:\n",
        "      Unlike get_next_state, this method does not allow for expansion\n",
        "      of the game tree, i.e. len(offsets)==batch_size required\n",
        "    \"\"\"\n",
        "    assert len(offsets) == board['pieces'].shape[0]\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    offset_dict = {'up': (0, -1, 0),\n",
        "                   'down': (0, 1, 0),\n",
        "                   'left': (0, 0, -1),\n",
        "                   'right': (0, 0, 1),\n",
        "                   'still': (0, 0, 0)}\n",
        "    this_critter_locs = np.where(board['pieces'] == critter)\n",
        "    all_critter_locs = np.where(board['pieces'] >= 1)\n",
        "    offsets_array = np.hstack([np.array(offset_dict[ost_]).reshape((3,1))\n",
        "                           for ost_ in offsets])\n",
        "    new_locs = np.array(this_critter_locs) + offsets_array\n",
        "    #check bounces at boundaries\n",
        "    new_locs[1,:] = np.where(new_locs[1] >=\n",
        "                               n_rows, n_rows-2, new_locs[1])\n",
        "    new_locs[2,:] = np.where(new_locs[2,:] >=\n",
        "                               n_cols, n_cols-2, new_locs[2,:])\n",
        "    new_locs[1,:] = np.where(new_locs[1,:] < 0, 1, new_locs[1,:])\n",
        "    new_locs[2,:] = np.where(new_locs[2,:] < 0, 1, new_locs[2,:])\n",
        "    moves = tuple(new_locs)\n",
        "    return moves\n",
        "\n",
        "\n",
        "  def direction_probs_to_flat_probs(self, board, direction_probs, critter):\n",
        "    \"\"\"\n",
        "    Converts direction probabilities in reference to the critter's location into\n",
        "    probability arrays on the flattened board.\n",
        "\n",
        "    Args:\n",
        "      board: dict of np arrays representing board state\n",
        "        'pieces':       batch_size x n_rows x n_cols\n",
        "        'scores':       batch_size\n",
        "        'rounds_left':  batch_size\n",
        "      direction_probs: batch length list of dictionaries with keys\n",
        "        ['up', 'down', 'left', 'right'] and corresponding probabilities.\n",
        "\n",
        "    Returns:\n",
        "      probs_arrays: list of arrays, where each array is of length n_rows*n_cols\n",
        "                    and represents the flattened probability distribution for\n",
        "                    board in the batch.\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    offset_dict = {\n",
        "        'up': np.array((0, -1, 0)),\n",
        "        'down': np.array((0, 1, 0)),\n",
        "        'left': np.array((0, 0, -1)),\n",
        "        'right': np.array((0, 0, 1))}\n",
        "    critter_locs = np.where(board['pieces'] == critter)\n",
        "    probs_arrays = np.zeros((batch_size, n_rows * n_cols))\n",
        "    for batch_index in range(batch_size):\n",
        "      prob_array = np.zeros(n_rows * n_cols)\n",
        "      for direction, prob in direction_probs[batch_index].items():\n",
        "          offset = offset_dict[direction]\n",
        "          new_loc = np.array(critter_locs)[:, batch_index] + offset\n",
        "          # Check bounces at boundaries\n",
        "          new_loc[1] = np.where(new_loc[1] >= n_rows, n_rows-2, new_loc[1])\n",
        "          new_loc[2] = np.where(new_loc[2] >= n_cols, n_cols-2, new_loc[2])\n",
        "          new_loc[1] = np.where(new_loc[1] < 0, 1, new_loc[1])\n",
        "          new_loc[2] = np.where(new_loc[2] < 0, 1, new_loc[2])\n",
        "          # Convert 2D location to flattened index\n",
        "          flattened_index = new_loc[1] * n_cols + new_loc[2]\n",
        "          prob_array[flattened_index] += prob\n",
        "      probs_arrays[batch_index, :] = prob_array\n",
        "    return list(probs_arrays)\n",
        "\n",
        "\n",
        "  def action_to_critter_direction(self, board, critter, actions):\n",
        "    \"\"\"\n",
        "    Translates an integer index action into up/down/left/right\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "      actions: a batch size ndarry of integer indexes for actions on each board\n",
        "\n",
        "    Returns:\n",
        "      offsets: a batch length list of strings 'up', 'down', 'left', 'right', 'still'\n",
        "    \"\"\"\n",
        "    offset_dict = {(0, 0, 0): 'still',\n",
        "                   (0, 0, 1): 'right',\n",
        "                   (0, 0,-1): 'left',\n",
        "                   (0, 1, 0): 'down',\n",
        "                   (0,-1, 0): 'up'}\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    critter_locs = np.where(board['pieces'] == critter)\n",
        "    moves = (np.arange(len(actions)),\n",
        "               np.floor_divide(actions, n_cols),\n",
        "               np.remainder(actions, n_cols))\n",
        "    # need to reverse this from above, moves is equiv to new_locs\n",
        "    # new_locs = np.array(critter_locs) + offsets_array\n",
        "    offsets_array = np.array(moves) - np.array(critter_locs)\n",
        "    offsets = [offset_dict[tuple(o_)] for o_ in offsets_array.T]\n",
        "    return offsets\n",
        "\n",
        "\n",
        "  def get_valid_directions(self, board, critter):\n",
        "    \"\"\"\n",
        "    Transforms output of get_valid_actions to a list of the valid directions\n",
        "    for each board in the batch for a given critter.\n",
        "    \"\"\"\n",
        "    offset_dict = {( 0, 1): 'right',\n",
        "                   ( 0,-1): 'left',\n",
        "                   ( 1, 0): 'down',\n",
        "                   (-1, 0): 'up',\n",
        "                   ( 0, 0): 'still'}\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    valid_actions = self.get_valid_actions(board, critter)\n",
        "    if batch_size != len(valid_actions):\n",
        "      raise ValueError(\"Need Exactly one set of valid actions per board in batch\")\n",
        "    critter_locs = np.column_stack(np.where(board['pieces'] == critter))\n",
        "    valid_directions = []\n",
        "    for g, batch_valid in enumerate(valid_actions):\n",
        "      valid_int_indices = np.where(batch_valid==1)[0]\n",
        "      critter_loc = critter_locs[critter_locs[:, 0] == g, 1:]\n",
        "      # critter_loc shape is (1, 2)\n",
        "      critter_loc = np.squeeze(critter_loc)\n",
        "      moves = np.column_stack([valid_int_indices // n_cols, valid_int_indices % n_cols])\n",
        "      offsets = moves - critter_loc\n",
        "      batch_valid_directions = [offset_dict[tuple(offset)] for offset in offsets]\n",
        "      valid_directions.append(batch_valid_directions)\n",
        "    return valid_directions\n",
        "\n",
        "\n",
        "  def get_game_ended(self, board):\n",
        "    \"\"\"\n",
        "    Helper function to signify if game has ended\n",
        "    Returns a batch size np.array of -1 if not ended, and scores for each game\n",
        "    in the batch if it is ended, note only returns scores if all games in the\n",
        "    batch have ended\n",
        "    \"\"\"\n",
        "    rounds_left = board['rounds_left']\n",
        "    scores = board['scores']\n",
        "    if np.any(rounds_left >= 1):\n",
        "      return np.ones(self.batch_size) * -1.0\n",
        "    else:\n",
        "      return scores\n",
        "\n",
        "\n",
        "  def critter_everywhere_state_expansion(self, board_state,\n",
        "                                         critter=1, to_expand=0):\n",
        "    \"\"\"\n",
        "    Expand a given board state by placing a critter at each non-food location.\n",
        "\n",
        "    The function takes a game state and returns an expanded version of it. For\n",
        "    each board in the state, it creates a new version of the board for every\n",
        "    non-food location, placing a critter at that location. The scores and\n",
        "    remaining rounds are copied for each new board. The result is a new game state\n",
        "    with a larger number of boards, each representing a possible configuration\n",
        "    with a critter at a different location.\n",
        "\n",
        "    Args:\n",
        "      board_state (dict): A dictionary containing the current game state.\n",
        "      It should have the following keys:\n",
        "        - 'pieces': a 3D numpy array (batch x n_col x n_row) representing the game\n",
        "          board. -1 -> food, 0 -> empty cell, and 1 -> critter.\n",
        "        - 'scores': 1D numpy array of the score for each board in the batch.\n",
        "        - 'rounds_left': a 1D numpy array of the rounds left for\n",
        "          each board in the batch.\n",
        "      critter: integer index to place on the expanded board state\n",
        "      to_expand (list (int)): list of batch indices to have state expanded\n",
        "\n",
        "    Returns:\n",
        "      dict: A dictionary containing the expanded game state with the same keys\n",
        "        as the input. The number of boards will be larger than the input state.\n",
        "    \"\"\"\n",
        "    pieces = board_state['pieces'].copy()\n",
        "    scores = board_state['scores'].copy()\n",
        "    rounds_left = board_state['rounds_left'].copy()\n",
        "    active_player = copy(board_state['active_player'])\n",
        "    # Determine non-food locations\n",
        "    non_food_locs = np.argwhere(pieces[to_expand] != -1)\n",
        "    #scrub all existing critter locations,\n",
        "    # maybe later only scrub specific critter type\n",
        "    pieces[pieces >= 1] = 0\n",
        "    # lists to store expanded states\n",
        "    expanded_pieces = []\n",
        "    expanded_scores = []\n",
        "    expanded_rounds_left = []\n",
        "    # Iterate over each non-food location\n",
        "    for i in range(non_food_locs.shape[0]):\n",
        "      # Create a copy of the board\n",
        "      expanded_board = np.copy(pieces[to_expand])\n",
        "      # Place the critter at the non-food location\n",
        "      # later consider only placing at non-food,\n",
        "      # non-other critter locs\n",
        "      expanded_board[tuple(non_food_locs[i])] = critter\n",
        "      # Add the expanded board to the list along score and rounds_left\n",
        "      expanded_pieces.append(expanded_board)\n",
        "      expanded_scores.append(scores[to_expand])\n",
        "      expanded_rounds_left.append(rounds_left[to_expand])\n",
        "    # Convert to arrays and create expanded board state\n",
        "    expanded_state = {'pieces': np.stack(expanded_pieces),\n",
        "                      'scores': np.array(expanded_scores),\n",
        "                      'rounds_left': np.array(expanded_rounds_left),\n",
        "                      'active_player': active_player}\n",
        "    return expanded_state\n",
        "\n",
        "\n",
        "  def play_game(self, players=[], collect_fov_data=False, fov_radius=2,\n",
        "                visualize = False):\n",
        "    \"\"\"This method takes a list of players the same length as num_critters,\n",
        "        and then plays a batch of games with them and returns the final board\n",
        "        state\"\"\"\n",
        "    if len(players) != self.num_critters:\n",
        "      raise ValueError(\"number of players different than expected\")\n",
        "\n",
        "    board = self.get_init_board()\n",
        "    if visualize == True:\n",
        "      self.display(board, 0)\n",
        "\n",
        "    if collect_fov_data is True:\n",
        "      batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "      b = GridworldBoard(batch_size=self.batch_size, n_rows=self.n_rows,\n",
        "                         n_cols=self.n_cols, num_food=self.num_food,\n",
        "                         num_prey=self.num_prey, num_pred=self.num_pred,\n",
        "                         lifetime=self.lifetime, rng=self.rng)\n",
        "    for p_idx, player_ in enumerate(players):\n",
        "      if player_.critter_index != p_idx+1:\n",
        "        print(player_.critter_index)\n",
        "        print(p_idx + 1)\n",
        "        raise ValueError(\"player order does not match assigned critter index\")\n",
        "\n",
        "    for ii in range(self.lifetime):\n",
        "      for player_ in players:\n",
        "        old_scores = board['scores']\n",
        "        if collect_fov_data is True:\n",
        "          b.set_state(board)\n",
        "          percepts = b.get_perceptions(fov_radius)\n",
        "\n",
        "        a_player, _, _ = player_.play(board)\n",
        "        board = self.get_next_state(board, player_.critter_index, a_player)\n",
        "        if visualize == True:\n",
        "          self.display(board, 0)\n",
        "    return board\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title player zoo\n",
        "###########################################################################\n",
        "# make a separate player zoo\n",
        "###########################################################################\n",
        "\n",
        "class FoodDriftPlayer():\n",
        "  \"\"\"\n",
        "  A player the executes the drifting pattern of the food,\n",
        "  Treating move made by the environment as though maybe by another player as\n",
        "  a convenient coding abstraction... also just a good way to think about things\n",
        "  This will drift the food on the board based on the given offsets probabilities.\n",
        "  Collisions are handled by the execute moves logic of the board object\n",
        "\n",
        "  Parameters:\n",
        "  - offset_probs: Probabilities corresponding to each offset, note implicit\n",
        "    order dependence here\n",
        "  - wrapping, a boolean indicating whether drifting food can fall off the edge\n",
        "    of the board and re-appear on the other side of the board.\n",
        "\n",
        "\n",
        "  The play method returns a batch of moves\n",
        "    - nothing, just updates self.pieces\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, game, critter_index=-1, offset_probs=[1.0, 0, 0, 0, 0],\n",
        "               wrapping=False, wrap_type='random'):\n",
        "    self.game = game\n",
        "    self.critter_index = critter_index\n",
        "    assert (isinstance(critter_index, int) and\n",
        "          self.game.num_food  <= critter_index <= -1), \"Value is not a negative integer or exceeds the limit.\"\n",
        "    self.offset_probs = offset_probs\n",
        "    self.wrapping = wrapping\n",
        "    self.wrap_type = wrap_type\n",
        "\n",
        "\n",
        "  def play(self, board):\n",
        "    possible_offsets = np.array([[ 0, -1,  0], # up\n",
        "                                 [ 0,  1,  0], # down\n",
        "                                 [ 0,  0, -1], # left\n",
        "                                 [ 0,  0,  1], # right\n",
        "                                 [ 0,  0,  0]]) # still\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    # original food locations\n",
        "    food_locations = np.argwhere(board['pieces'] == self.critter_index)\n",
        "    # Sample offsets for each food location\n",
        "    num_food = food_locations.shape[0]\n",
        "    sampled_offsets = possible_offsets[self.rng.choice(\n",
        "        np.arange(possible_offsets.shape[0]),\n",
        "        size=num_food, replace=True, p=self.offset_probs)]\n",
        "    # Possible new food locations\n",
        "    p_new_locs = food_locations + sampled_offsets\n",
        "\n",
        "    #out of bounds rows and cols\n",
        "    oob_rows = (p_new_locs[:, 1] >= n_rows) | (p_new_locs[:, 1] < 0)\n",
        "    oob_cols = (p_new_locs[:, 2] >= n_cols) | (p_new_locs[:, 2] < 0)\n",
        "\n",
        "    if self.wrapping is True:\n",
        "      if self.wrap_type == 'random':\n",
        "        p_wrap_row_indexes = self.rng.choice(np.arange(n_rows),\n",
        "                                             size=num_food)\n",
        "        p_wrap_col_indexes = self.rng.choice(np.arange(n_cols),\n",
        "                                             size=num_food)\n",
        "        p_new_locs[oob_rows, 1] = p_wrap_row_indexes[oob_rows]\n",
        "        p_new_locs[oob_cols, 1] = p_wrap_col_indexes[oob_cols]\n",
        "      else:\n",
        "        #deterministic wrapping\n",
        "        p_new_locs[:, 1] = np.mod(p_new_locs[:, 1], n_rows)\n",
        "        p_new_locs[:, 2] = np.mod(p_new_locs[:, 2], n_cols)\n",
        "    else:\n",
        "      # they don't move if they hit an edge\n",
        "      p_new_locs[oob_rows, 1] = food_locations[oob_rows, 1]\n",
        "      p_new_locs[oob_cols, 2] = food_locations[oob_cols, 2]\n",
        "\n",
        "    a = p_new_locs[:,1] * n_cols + p_new_locs[:,2]\n",
        "    a_1hots = np.zeros((batch_size, n_cols*n_rows))\n",
        "    a_1hots[(range(batch_size), a)] = 1.0\n",
        "    return a, a_1hots, a_1hots, p_new_locs\n",
        "\n",
        "\n",
        "class RandomValidPlayer():\n",
        "  \"\"\"\n",
        "  Instantiate random player for GridWorld, could be prey or pred... or even food\n",
        "  It leans hard on the game's get valid method and then just samples from there\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, game, critter_index=1, speed=1):\n",
        "    self.game = game\n",
        "    self.critter_index = critter_index\n",
        "    self.speed = speed\n",
        "    assert (isinstance(critter_index, int) and\n",
        "        0 < critter_index <= game.num_critters), \"Value is not a positive integer or exceeds the upper limit.\"\n",
        "\n",
        "\n",
        "  def play(self, board):\n",
        "    \"\"\"\n",
        "    Simulates a batch of random game plays based on the given board state.\n",
        "\n",
        "    This function computes the probability of each valid move being played\n",
        "    (uniform for valid moves, 0 for others), then selects a move randomly for\n",
        "    each game in the batch based on these probabilities.\n",
        "\n",
        "    Args:\n",
        "      board (dict): A dictionary representing the state of the game. It\n",
        "          contains:\n",
        "          - 'pieces': A (batch_size, x_size, y_size) numpy array indicating\n",
        "                      the pieces on the board.\n",
        "          - 'scores' (not used directly in this function, but expected in dict)\n",
        "          - 'rounds_left' (not used directly in this function, but expected in dict)\n",
        "\n",
        "    Returns:\n",
        "      tuple:\n",
        "      - a (numpy array): An array of shape (batch_size,) containing randomly\n",
        "                         chosen actions for each game in the batch.\n",
        "      - a_1hots (numpy array): An array of shape (batch_size, action_size)\n",
        "                               with one-hot encoded actions.\n",
        "      - probs (numpy array): An array of the same shape as 'valids' containing\n",
        "                             the probability of each move being played.\n",
        "    \"\"\"\n",
        "    batch_size, x_size, y_size = board['pieces'].shape\n",
        "    valids = self.game.get_valid_actions(board, self.critter_index, self.speed)\n",
        "    action_size = self.game.get_action_size()\n",
        "\n",
        "    probs = valids / np.sum(valids, axis=1).reshape(batch_size,1)\n",
        "\n",
        "    a = [self.game.rng.choice(action_size, p=probs[ii])\n",
        "                                for ii in range(batch_size)]\n",
        "    a_1hots = np.zeros((batch_size, action_size))\n",
        "    a_1hots[(range(batch_size), a)] = 1.0\n",
        "    return np.array(a), a_1hots, probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class GeneralLinearPlayer():\n",
        "  \"\"\"\n",
        "  A Player playing a linear policy defined by the given weights. Content and\n",
        "  size of percept is parameterized, as is speed. Whether it is treated as a\n",
        "  prey or predator type by the game depends on the critter_index, specifically\n",
        "  0 < critter_index <= game.pred_prey_threshold --> prey type\n",
        "  game.pred_prey_threshold < critter_index --> predator type\n",
        "  note that many game loops re-assign critter index based on the order of the\n",
        "  player list handed to the game loop.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, game, critter_index=1, weights=None, fov_radius=1, speed=1,\n",
        "               has_food_percept = True,  has_edge_percept=False,\n",
        "               has_prey_percept = False, has_pred_percept=False,\n",
        "               get_probs=False, deterministic=False):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      game: Gridworld Game instance\n",
        "        Instance of the gridworldGame class above;\n",
        "      weights: a numpy array that gives the connection strengths between the\n",
        "      'perception' neurons and the direction 'neurons'\n",
        "      fov_radius: int how far around itself the critter perceives\n",
        "      speed: int how many grid cells a critter can move in a round\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    # all critters need these things\n",
        "    self.game = game\n",
        "    self.critter_index = critter_index\n",
        "    assert (isinstance(critter_index, int) and\n",
        "        0 < critter_index <= game.num_critters), \"Value is not a positive integer or exceeds the upper limit.\"\n",
        "    self.get_probs = get_probs\n",
        "    # these things are specific to this kind of critter\n",
        "    self.deterministic = deterministic\n",
        "    self.fov_radius = fov_radius\n",
        "    self.speed = speed\n",
        "    self.W_out_shape = 2*self.speed**2 + 2*self.speed + 1\n",
        "    self.W_in_shape = 2*self.fov_radius**2 + 2*self.fov_radius + 1\n",
        "    self.has_food_percept = has_food_percept\n",
        "    self.has_edge_percept = has_edge_percept\n",
        "    self.has_prey_percept = has_prey_percept\n",
        "    self.has_pred_percept = has_pred_percept\n",
        "    self.W_layers = np.sum([has_food_percept, has_edge_percept,\n",
        "                            has_prey_percept, has_pred_percept])\n",
        "    if weights is None:\n",
        "      self.W = np.ones((self.W_layers, self.W_out_shape, self.W_in_shape))\n",
        "    else:\n",
        "      self.W = weights\n",
        "    if self.W.shape != (self.W_layers, self.W_out_shape, self.W_in_shape):\n",
        "      raise ValueError(\"Weights don't match expected shape given fov, speed, and percepts\")\n",
        "    self.default_softmax_temp = 0.05\n",
        "\n",
        "\n",
        "  def direction_value_from_percept(self, percepts, W):\n",
        "    \"\"\"\n",
        "    Determine an action based on perception.\n",
        "\n",
        "    Args:\n",
        "      percept: A batch by self.W_in_shape array representing the perceptions of\n",
        "        the organism. Indices correspond to spaces around the organism. The\n",
        "        values in the array can be -200 (out-of-bounds), 0 (empty space),\n",
        "        or negative integers (food), or positive integers below or equal\n",
        "        game.pred_prey_threshold for prey organisms or positive integers above\n",
        "        game.predy_prey_threshold for predator organisms\n",
        "      W: a W_layers x W_out_shape x W_in_shape weight matrix of parameters\n",
        "        representing the connection strengths between the perception inputs and\n",
        "        the possible output actions.\n",
        "\n",
        "    Returns:\n",
        "      output: raw output activations, these filtered by which moves are valid\n",
        "        and then softmax normalized later\n",
        "    \"\"\"\n",
        "    expanded_percepts = []\n",
        "    if self.has_food_percept:\n",
        "      x_food = np.asarray((percepts <= -1) & (percepts > -200), float) # batch x len W_in\n",
        "      expanded_percepts.append(x_food)\n",
        "    if self.has_edge_percept:\n",
        "      x_edge = np.asarray(percepts == -200, float) # batch x len W_in\n",
        "      expanded_percepts.append(x_edge)\n",
        "    if self.has_prey_percept:\n",
        "      x_prey = np.asarray((percepts > 0) &\n",
        "       (percepts <= self.game.pred_prey_threshold), float) # batch x len W_in\n",
        "      expanded_percepts.append(x_prey)\n",
        "    if self.has_pred_percept:\n",
        "      x_pred = np.asarray(percepts > self.game.pred_prey_threshold, float) # batch x len W_in\n",
        "      expanded_percepts.append(x_pred)\n",
        "    percept_stack = np.stack(expanded_percepts) # W_layers x batch x len_W_in\n",
        "\n",
        "    output_activations = np.tensordot(percept_stack, W, [[0, 2], [0, 2]])\n",
        "    # output activations is batch by W_out, so each row gives the raw output\n",
        "    # activations for that batch.\n",
        "    return output_activations\n",
        "\n",
        "\n",
        "  def play(self, board, temp=None, W=None):\n",
        "    \"\"\"\n",
        "    Simulate Play on a Board\n",
        "\n",
        "    Args:\n",
        "      board: dict {'pieces':\n",
        "      (batch x num_rows x num_cols) np.ndarray of board position,\n",
        "                  'scores': batch len array of current scores,\n",
        "                  'rounds_left': batch len array of rounds left\n",
        "\n",
        "    Returns:\n",
        "      sampled_actions: a batch, row, col index of the move taken\n",
        "      by each player on each board\n",
        "      a_1hots: a batch nrow*ncol array of 1hot indices of those same moves\n",
        "      v_probs: sampling probabilities for those 1hots (If the policy\n",
        "      is deterministic a_1hots is returned here as well... or if getting the\n",
        "      probs is an un-needed fuss to compute)\n",
        "    \"\"\"\n",
        "    if temp is None:\n",
        "      temp = self.default_softmax_temp\n",
        "    if W is None:\n",
        "      W = self.W\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    perceptions = self.game.get_perceptions(board, self.critter_index,\n",
        "                                            self.fov_radius)\n",
        "    direction_v = self.direction_value_from_percept(perceptions, W)\n",
        "    #direction_v is batch x w_out, i.e. number of different moves\n",
        "    legal_offsets, valid_moves_mask = self.game.get_legal_offsets(\n",
        "        board, critter=self.critter_index, radius=self.speed)\n",
        "    flat_dv = direction_v[valid_moves_mask]\n",
        "    batch_indexes = legal_offsets[:,0]\n",
        "    # turn offsets into flat indexes, i.e. ints in range(n_rows*n_cols)\n",
        "    action_indexes = legal_offsets[:,1] * n_cols + legal_offsets[:,2]\n",
        "    # Set invalid positions to -inf\n",
        "    value_expand = np.ones((batch_size, n_rows*n_cols)) * -np.inf\n",
        "    # Fragile order dependency here in how legal offsets and flat_dv 'line up'\n",
        "    # and we can slot the direction values into value expand like this\n",
        "    value_expand[(batch_indexes, action_indexes)] = flat_dv\n",
        "\n",
        "    if self.deterministic:\n",
        "      sampled_actions = np.argmax(value_expand, axis=1)\n",
        "      a_1Hots = np.zeros((batch_size, n_rows * n_cols))\n",
        "      a_1Hots[np.arange(batch_size), sampled_actions] = 1.0\n",
        "      v_probs = a_1Hots\n",
        "    else:\n",
        "      # Subtract max for numerical stability\n",
        "      value_expand_shift = value_expand - np.max(value_expand,\n",
        "                                                 axis=1, keepdims=True)\n",
        "      # softmax temp scaling\n",
        "      value_expand_scale = value_expand_shift/temp\n",
        "      exp_value = np.exp(value_expand_scale)\n",
        "      # Normalize by the sum of the exponentiated values for each row\n",
        "      v_probs = exp_value / np.sum(exp_value, axis=1, keepdims=True)\n",
        "      v_probs = v_probs / np.sum(v_probs, axis=1, keepdims=True)\n",
        "      samp = self.game.rng.uniform(size = batch_size).reshape((batch_size,1))\n",
        "      sampled_actions = np.argmax(v_probs.cumsum(axis=1) > samp, axis=1)\n",
        "      a_1Hots = np.zeros((batch_size, n_rows*n_cols))\n",
        "      a_1Hots[(range(batch_size), sampled_actions)] = 1.0\n",
        "    return sampled_actions, a_1Hots, v_probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class EatNearPredPlayer():\n",
        "  \"\"\"\n",
        "  A Player playing a parameterized policy defined by the given weights\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, game, weights=None, fov_radius=1, critter_index=2,\n",
        "               get_probs=False, deterministic=False):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      game: Gridworld Game instance\n",
        "        Instance of the gridworldGame class above;\n",
        "      weights: 4 x 12 numpy array (assumes fov_radius = 2), that gives the\n",
        "        connection strengths between the 'perception' neurons and the direction\n",
        "        'neurons'\n",
        "      fov_radius: int how far around itself the critter perceives, weights is\n",
        "        expecting fov_radius = 1\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    # all critters need these things\n",
        "    self.game = game\n",
        "    self.critter_index = critter_index\n",
        "    assert (isinstance(critter_index, int) and\n",
        "        0 < critter_index <= game.num_critters), \"Value is not a positive integer or exceeds the upper limit.\"\n",
        "    self.get_probs = get_probs\n",
        "    # these things are specific to this kind of critter\n",
        "    self.deterministic = deterministic\n",
        "    if weights is None:\n",
        "      self.W = np.array(\n",
        "      [[20.,  0., 0.,  0.,  0.],\n",
        "       [ 0., 20., 0.,  0.,  0.],\n",
        "       [ 0.,  0., 0.,  0.,  0.],\n",
        "       [ 0.,  0., 0., 20.,  0.],\n",
        "       [ 0.,  0., 0.,  0., 20.]])\n",
        "    else:\n",
        "      self.W = weights\n",
        "    self.fov_radius = fov_radius\n",
        "    self.default_softmax_temp = 0.05\n",
        "\n",
        "\n",
        "  def direction_value_from_percept(self, percepts, W):\n",
        "    \"\"\"\n",
        "    Determine an action based on perception.\n",
        "\n",
        "    Args:\n",
        "      percept: A batch by 1D len 12 array representing the perceptions of the\n",
        "      organism. Indices correspond to spaces around the organism. The values in\n",
        "      the array can be -2 (out-of-bounds), 0 (empty space), or -1 (food).\n",
        "      W: a 4 x 12 weight matrix parameter representing the connection strengths\n",
        "        between the 12 perceptions inputs and the 4 possible output actions.\n",
        "\n",
        "    Returns:\n",
        "      direction_probs: array of probabilities of taking each action.\n",
        "    \"\"\"\n",
        "    # a human interpretable overview of the percept structure\n",
        "    #percept_struct = [\n",
        "    #  'up', 'left', 'center', 'right',  'down']\n",
        "    # a human interpretable overview of the out structure\n",
        "    #output_struct = ['up', 'left', 'center' 'right', 'down']\n",
        "    # boolean representation of percept, no edges, no food, no other predators\n",
        "    # just 1's where prey is,\n",
        "    # x is batch x 5\n",
        "    x = np.asarray(((percepts >= 1) &\n",
        "     (percepts <= self.game.pred_prey_threshold)), int)\n",
        "    # W is 5 x 5\n",
        "    # this does the broadcasting we want\n",
        "    output_activations = (W @ x.T).T\n",
        "    # output activations is batch by 4\n",
        "    return output_activations\n",
        "\n",
        "\n",
        "  def play(self, board, temp=None, W=None):\n",
        "    \"\"\"\n",
        "    Simulate Play on a Board\n",
        "\n",
        "    Args:\n",
        "      board: dict {'pieces':\n",
        "      (batch x num_rows x num_cols) np.ndarray of board position,\n",
        "                  'scores': batch len array of current scores,\n",
        "                  'rounds_left': batch len array of rounds left\n",
        "\n",
        "    Returns:\n",
        "      sampled_actions: a batch, row, col index of the move taken\n",
        "      by each player on each board\n",
        "      a_1hots: a batch nrow*ncol array of 1hot indices of those same moves\n",
        "      v_probs: sampling probabilities for those 1hots (If the policy\n",
        "      is deterministic a_1hots is returned here as well... or if getting the\n",
        "      probs is an un-needed fuss to compute)\n",
        "    \"\"\"\n",
        "    if temp is None:\n",
        "      temp = self.default_softmax_temp\n",
        "    if W is None:\n",
        "      W = self.W\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    perceptions = self.game.get_perceptions(board, self.critter_index,\n",
        "                                            self.fov_radius)\n",
        "    # note the fragile order based dependency on how legal offsets is written,\n",
        "    # and how output activations are interpreted\n",
        "    direction_v = self.direction_value_from_percept(perceptions, W)\n",
        "    flat_ds = direction_v.T.ravel()\n",
        "\n",
        "    critter_locs = np.array(np.where(board['pieces'] == self.critter_index))\n",
        "    legal_offsets = np.stack([\n",
        "    critter_locs + np.array([np.array([0, -1,  0])]*batch_size).T, # up\n",
        "    critter_locs + np.array([np.array([0,  0, -1])]*batch_size).T, # left\n",
        "    critter_locs + np.array([np.array([0,  0,  0])]*batch_size).T, # still\n",
        "    critter_locs + np.array([np.array([0,  0,  1])]*batch_size).T, # right\n",
        "    critter_locs + np.array([np.array([0,  1,  0])]*batch_size).T, # down\n",
        "    ])\n",
        "    legal_offsets = np.vstack(np.transpose(legal_offsets, (0, 2, 1)))\n",
        "\n",
        "    # conditions for offsets on the board\n",
        "    c1 = legal_offsets[:,1] >= 0\n",
        "    c2 = legal_offsets[:,1] <= n_rows-1\n",
        "    c3 = legal_offsets[:,2] >= 0\n",
        "    c4 = legal_offsets[:,2] <= n_cols-1\n",
        "    all_c = np.logical_and.reduce([c1, c2, c3, c4])\n",
        "\n",
        "    batch_indexes = legal_offsets[:,0][all_c]\n",
        "    # turn offsets into flat indexes, i.e. ints in range(n_rows*n_cols)\n",
        "    action_indexes = legal_offsets[:,1][all_c] * n_cols + legal_offsets[:,2][all_c]\n",
        "    direction_values = flat_ds[all_c]\n",
        "    # the fragile order dependency is here in that legal offsets and flat_ds\n",
        "    # 'line up' and can both be indexed by 'all_c' and we get what we want\n",
        "    value_expand = np.zeros((batch_size, n_rows*n_cols))\n",
        "    # i.e. we can slot the direction values into value expand like this\n",
        "    value_expand[(batch_indexes, action_indexes)] = direction_values\n",
        "    # valids is a batch x (n_rows * n_cols) binary np array, so we use it to\n",
        "    # index value_expand and set non-valid values to -inf\n",
        "    valids = gwg.get_valid_actions(board, self.critter_index)\n",
        "    # Set invalid positions to -inf\n",
        "    valid_value_expand = np.where(valids == 1, value_expand, -np.inf)\n",
        "    if self.deterministic:\n",
        "      sampled_actions = np.argmax(valid_value_expand, axis=1)\n",
        "      a_1Hots = np.zeros((batch_size, n_rows * n_cols))\n",
        "      a_1Hots[np.arange(batch_size), sampled_actions] = 1.0\n",
        "      v_probs = a_1Hots\n",
        "    else:\n",
        "      # Subtract max for numerical stability\n",
        "      value_expand_shift = valid_value_expand - np.max(valid_value_expand,\n",
        "                                                       axis=1, keepdims=True)\n",
        "      # softmax temp scaling\n",
        "      value_expand_scale = value_expand_shift/temp\n",
        "      exp_value = np.exp(value_expand_scale)\n",
        "      # Normalize by the sum of the exponentiated values for each row\n",
        "      v_probs = exp_value / np.sum(exp_value, axis=1, keepdims=True)\n",
        "      v_probs = v_probs / np.sum(v_probs, axis=1, keepdims=True)\n",
        "      samp = self.game.rng.uniform(size = batch_size).reshape((batch_size,1))\n",
        "      sampled_actions = np.argmax(v_probs.cumsum(axis=1) > samp, axis=1)\n",
        "      a_1Hots = np.zeros((batch_size, n_rows*n_cols))\n",
        "      a_1Hots[(range(batch_size), sampled_actions)] = 1.0\n",
        "    return sampled_actions, a_1Hots, v_probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class RandomDirectionPlayer():\n",
        "  \"\"\"\n",
        "  Instantiate random player for GridWorld\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, game, critter_index=1):\n",
        "    self.game = game\n",
        "    self.critter_index = critter_index\n",
        "    assert (isinstance(critter_index, int) and\n",
        "        0 < critter_index <= game.num_critters), \"Value is not a positive integer or exceeds the upper limit.\"\n",
        "\n",
        "  def play(self, board):\n",
        "    \"\"\"\n",
        "    Simulates a batch of random game plays based on the given board state.\n",
        "\n",
        "    This function assigns a uniform probability to going up down left or right\n",
        "    independent of whether it is at an edge or corner or not. Then because of\n",
        "    bouncing off edges it will have a higher probability of moving away from\n",
        "    edges as opposed to along them than the random valid move player.\n",
        "\n",
        "    Args:\n",
        "      board (dict): A dictionary representing the state of the game. It\n",
        "          contains:\n",
        "          - 'pieces': A (batch_size, x_size, y_size) numpy array indicating\n",
        "                      the pieces on the board.\n",
        "          - 'scores' (not used directly in this function, but expected in dict)\n",
        "          - 'rounds_left' (not used directly in this function, but expected in dict)\n",
        "\n",
        "    Returns:\n",
        "      tuple:\n",
        "      - a (numpy array): An array of shape (batch_size,) containing randomly\n",
        "                         chosen actions for each game in the batch.\n",
        "      - a_1hots (numpy array): An array of shape (batch_size, action_size)\n",
        "                               with one-hot encoded actions.\n",
        "      - probs (numpy array): An array of the same shape as 'valids' containing\n",
        "                             the probability of each move being played.\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    action_probs = {'up': 0.25, 'down': 0.25, 'left': 0.25, 'right': 0.25}\n",
        "\n",
        "    critter_oriented_moves = self.game.rng.choice(list(action_probs.keys()),\n",
        "                                                  size=(batch_size))\n",
        "    direction_probs = [action_probs] * batch_size\n",
        "    moves = self.game.critter_direction_to_move(board, critter_oriented_moves,\n",
        "                                                self.critter_index)\n",
        "    probs = self.game.direction_probs_to_flat_probs(board, direction_probs,\n",
        "                                                    self.critter_index)\n",
        "    sampled_actions = self.game.moves_to_actions(moves)\n",
        "    a_1hots = np.zeros((batch_size, n_rows*n_cols))\n",
        "    a_1hots[(range(batch_size), sampled_actions)] = 1.0\n",
        "\n",
        "    return sampled_actions, a_1hots, probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class MonteCarloBasedPlayer():\n",
        "  \"\"\"\n",
        "  Simulate Player based on Monte Carlo Algorithm\n",
        "\n",
        "  Note: Has dependencies in the gw_NN_RL.py util, namely a policy/value\n",
        "  network and the Monte Carlo class.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, game, nnet,\n",
        "               critter_index=1,\n",
        "               default_depth=1,\n",
        "               default_rollouts=1,\n",
        "               default_K=4,\n",
        "               default_temp=1.0,\n",
        "               random_seed=None):\n",
        "    \"\"\"\n",
        "    Initialize Monte Carlo Parameters\n",
        "\n",
        "    Args:\n",
        "      game: Gridworld Game instance\n",
        "        Instance of the gridworldGame class above;\n",
        "      nnet: gridworldNet instance\n",
        "        Instance of the gridworldNNet class above;\n",
        "      args: dictionary\n",
        "        Instantiates number of iterations and episodes, controls temperature threshold, queue length,\n",
        "        arena, checkpointing, and neural network parameters:\n",
        "        learning-rate: 0.001, dropout: 0.3, epochs: 10, batch_size: 64,\n",
        "        num_channels: 512\n",
        "\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    self.game = game\n",
        "    self.critter_index = critter_index\n",
        "    assert (isinstance(critter_index, int) and\n",
        "        0 < critter_index <= game.num_critters), \"Value is not a positive integer or exceeds the upper limit.\"\n",
        "    self.nnet = nnet\n",
        "    self.default_depth = default_depth\n",
        "    self.default_rollouts = default_rollouts\n",
        "    self.mc = MonteCarlo(self.game, self.nnet, self.default_depth)\n",
        "    self.default_K = default_K\n",
        "    self.default_temp = default_temp\n",
        "    self.rng = np.random.default_rng(seed=random_seed)\n",
        "\n",
        "\n",
        "  def play(self, board,\n",
        "           num_rollouts=None,\n",
        "           rollout_depth=None,\n",
        "           K=None,\n",
        "           softmax_temp=None):\n",
        "    \"\"\"\n",
        "    Simulates a batch Monte Carlo based plays on the given board state.\n",
        "\n",
        "    Computes the probability of each valid move being played using a softmax\n",
        "    activation on the Monte Carlo based value (Q) of each action then selects a\n",
        "    move randomly for each game in the batch based on those probabilities.\n",
        "\n",
        "    Args:\n",
        "      board (dict): A dictionary representing the state of the game. It\n",
        "          contains:\n",
        "          - 'pieces': A (batch_size, x_size, y_size) numpy array indicating\n",
        "                      the pieces on the board.\n",
        "          - 'scores' (not used directly in this function, but expected in dict)\n",
        "          - 'rounds_left' (not used directly in this function, but expected in dict)\n",
        "\n",
        "    Returns:\n",
        "      tuple:\n",
        "      - a (numpy array): An array of shape (batch_size,) containing randomly\n",
        "                         chosen actions for each game in the batch.\n",
        "      - a_1hots (numpy array): An array of shape (batch_size, action_size)\n",
        "                               with one-hot encoded actions.\n",
        "      - probs (numpy array): An array of the same shape as 'valids' containing\n",
        "                             the probability of each move being played.\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    if num_rollouts is None:\n",
        "      num_rollouts = self.default_rollouts\n",
        "    if rollout_depth is None:\n",
        "      rollout_depth = self.default_depth\n",
        "    if K is None:\n",
        "      K = self.default_K\n",
        "    if softmax_temp is None:\n",
        "      softmax_temp = self.default_temp\n",
        "\n",
        "    # figure out top k actions according to normalize action probability\n",
        "    # given by our policy network prediction\n",
        "    #co_pieces = board['pieces'].copy()\n",
        "    #this_critter_locs = np.where(co_pieces == self.critter_index+1)\n",
        "    #all_critter_locs = np.where(co_pieces >= 1)\n",
        "    # other critters are invisible to this player\n",
        "    #co_pieces[all_critter_locs] = 0\n",
        "    # nnet trained to see self as 1\n",
        "    #co_pieces[this_critter_locs] = 1\n",
        "    #scalar_rounds_left = board['rounds_left'][0]\n",
        "    #co_rounds_left = scalar_rounds_left // self.game.num_critters\n",
        "    #if self.critter_index-1 < scalar_rounds_left % self.game.num_critters:\n",
        "       # add an extra if we haven't had this players turn yet in the round cycle\n",
        "    #   co_rounds_left = co_rounds_left + 1\n",
        "    #co_rounds_left = np.array([co_rounds_left]*batch_size)\n",
        "    #pis, vs = self.nnet.predict(co_pieces,\n",
        "    #                            board['scores'][:,self.critter_index-1],\n",
        "    #                            co_rounds_left)\n",
        "    pis, vs = self.mc.pis_vs_from_board(board, self.critter_index)\n",
        "    valids = self.game.get_valid_actions(board, self.critter_index)\n",
        "    masked_pis = pis * valids  # Masking invalid moves\n",
        "    sum_pis = np.sum(masked_pis, axis=1)\n",
        "    num_valid_actions = np.sum(valids, axis=1)\n",
        "    effective_topk = np.array(np.minimum(num_valid_actions, K), dtype= int)\n",
        "    probs = np.array([masked_pi / masked_pi.sum() if masked_pi.sum() > 0\n",
        "                      else valid / valid.sum()\n",
        "                      for valid, masked_pi in zip(valids, masked_pis)])\n",
        "    partioned = np.argpartition(probs,-effective_topk)\n",
        "    topk_actions = [partioned[g,-(ii+1)]\n",
        "                      for g in range(batch_size)\n",
        "                        for ii in range(effective_topk[g])]\n",
        "    topk_actions_index = [ii\n",
        "                            for ii, etk in enumerate(effective_topk)\n",
        "                              for _ in range(etk)]\n",
        "    values = np.zeros(len(topk_actions))\n",
        "    # Do some rollouts\n",
        "    for _ in range(num_rollouts):\n",
        "      values = values + self.mc.simulate(board, topk_actions,\n",
        "                                         topk_actions_index,\n",
        "                                         critter=self.critter_index,\n",
        "                                         depth=rollout_depth)\n",
        "    values = values / num_rollouts\n",
        "\n",
        "    value_expand = np.zeros((batch_size, n_rows*n_cols))\n",
        "    value_expand[(topk_actions_index, topk_actions)] = values\n",
        "    value_expand_shift = value_expand - np.max(value_expand, axis=1, keepdims=True)\n",
        "    value_expand_scale = value_expand_shift/softmax_temp\n",
        "    v_probs = np.exp(value_expand_scale) / np.sum(\n",
        "        np.exp(value_expand_scale), axis=1, keepdims=True)\n",
        "    v_probs = v_probs * valids\n",
        "    v_probs = v_probs / np.sum(v_probs, axis=1, keepdims=True)\n",
        "    samp = self.rng.uniform(size = batch_size).reshape((batch_size,1))\n",
        "    sampled_actions = np.argmax(v_probs.cumsum(axis=1) > samp, axis=1)\n",
        "    a_1Hots = np.zeros((batch_size, n_rows*n_cols))\n",
        "    a_1Hots[(range(batch_size), sampled_actions)] = 1.0\n",
        "    return sampled_actions, a_1Hots, v_probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class SimpleRulePlayer():\n",
        "  \"\"\"\n",
        "  A Predator Player based on the following simple policy:\n",
        "  If there is any prey immediately nearby move towards it,\n",
        "  otherwise move to a random valid location.\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, game, fov_radius=1, critter_index=1):\n",
        "    self.game = game\n",
        "    self.critter_index = critter_index\n",
        "    assert (isinstance(critter_index, int) and\n",
        "        0 < critter_index <= game.num_critters), \"Value is not a positive integer or exceeds the upper limit.\"\n",
        "    self.fov_radius = fov_radius\n",
        "\n",
        "\n",
        "  def simple_action_from_percept(self, percept):\n",
        "    \"\"\"\n",
        "    Determine an action based on perception.\n",
        "\n",
        "    Args:\n",
        "      percept: A 1D array (len 4 if fov_radius = 1)representing the perception\n",
        "        of the organism. Indices correspond to spaces around the organism. The\n",
        "        values in the array can be -200 (out-of-bounds), 0 (empty space),\n",
        "        negative integers > -200 (food),\n",
        "        positive integers <= self.game.pred_prey_threshold are prey\n",
        "        positive integers > self.game.pred_prey_threshold are predators\n",
        "\n",
        "    Returns:\n",
        "      action: a str, one of 'up', 'down', 'left', 'right'. If food in one or\n",
        "        more of the spaces immediately beside the organism, the function will\n",
        "        return a random choice among these directions. If there is no food\n",
        "        nearby, the function will return a random direction.\n",
        "    \"\"\"\n",
        "    # a human interpretable overview of the percept structure if fov = 2\n",
        "    percept_struct = ['up', 'left', 'right', 'down']\n",
        "    # Defines directions corresponding to different perception indices\n",
        "    direction_struct = [\n",
        "      'None', 'None', 'up', 'None',\n",
        "      'None', 'left', 'right', 'None',\n",
        "      'None', 'down', 'None', 'None']\n",
        "    # these are what count as nearby in the percept\n",
        "    nearby_directions = ['near up', 'near left', 'near right', 'near down']\n",
        "    # Get the corresponding indices in the percept array\n",
        "    nearby_indices = [percept_struct.index(dir_) for dir_ in nearby_directions]\n",
        "    # Identify the directions where food is located\n",
        "    food_indices = [index for index in nearby_indices if percept[index] <= -1]\n",
        "    food_directions = [direction_struct[index] for index in food_indices]\n",
        "\n",
        "    action_probs = {'up': 0.0, 'down': 0.0, 'left': 0.0, 'right': 0.0}\n",
        "    if len(food_directions) > 0:  # If there is any food nearby\n",
        "      # If there is any food nearby randomly choose a direction with food\n",
        "      action = self.game.rng.choice(food_directions)  # Move towards a random one\n",
        "      for direction in food_directions:\n",
        "        action_probs[direction] = 1.0 /len(food_directions)\n",
        "    else:\n",
        "      # If there is no food nearby, move randomly\n",
        "      action = self.game.rng.choice(['up', 'down', 'left', 'right'])\n",
        "      for direction in ['up', 'down', 'left', 'right']:\n",
        "        action_probs[direction] = 0.25\n",
        "\n",
        "    return action, action_probs\n",
        "\n",
        "\n",
        "  def play(self, board):\n",
        "    \"\"\"\n",
        "    Simulate Play on a Board\n",
        "\n",
        "    Args:\n",
        "      board: dict {'pieces':\n",
        "      (batch x num_rows x num_cols) np.ndarray of board position,\n",
        "                  'scores': batch len array of current scores,\n",
        "                  'rounds_left': batch len array of rounds left\n",
        "\n",
        "    Returns:\n",
        "      sampled_actions: a batch, row, col index of the move taken\n",
        "      by each player on each board\n",
        "      a_1hots: a batch nrow*ncol array of 1hot indices of those same moves\n",
        "      probs: sampling probabilities for those 1hots (If the policy\n",
        "      is deterministic a_1hots is returned here as well... or if getting the\n",
        "      probs is an un-needed fuss to compute)\n",
        "\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    perceptions = self.game.get_perceptions(board, self.fov_radius,\n",
        "                                            self.critter_index)\n",
        "\n",
        "    critter_oriented_moves = []\n",
        "    direction_probs = []\n",
        "    for g in range(batch_size):\n",
        "      action, action_probs = self.simple_action_from_percept(perceptions[g])\n",
        "      critter_oriented_moves.append(action)\n",
        "      direction_probs.append(action_probs)\n",
        "    moves = self.game.critter_direction_to_move(board, critter_oriented_moves,\n",
        "                                                direction_probs,\n",
        "                                                self.critter_index)\n",
        "    probs = self.game.direction_probs_to_flat_probs(board, direction_probs)\n",
        "    sampled_actions = self.game.moves_to_actions(moves)\n",
        "    a_1hots = np.zeros((batch_size, n_rows*n_cols))\n",
        "    a_1hots[(range(batch_size), sampled_actions)] = 1.0\n",
        "\n",
        "    return sampled_actions, a_1hots, probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class PerceptParamPlayer():\n",
        "  \"\"\"\n",
        "  A Player playing a parameterized policy defined by the given weights\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, game, weights=None, fov_radius=2, critter_index=1):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      game: Gridworld Game instance\n",
        "        Instance of the gridworldGame class above;\n",
        "      weights: 4 x 12 numpy array (assumes fov_radius = 2), that gives the\n",
        "        connection strengths between the 'perception' neurons and the direction\n",
        "        'neurons'\n",
        "      fov_radius: int how far around itself the critter perceives, weights is\n",
        "        expecting fov_radius = 2\n",
        "    Returns:\n",
        "      Nothing\n",
        "    \"\"\"\n",
        "    self.game = game\n",
        "    self.critter_index = critter_index\n",
        "    assert (isinstance(critter_index, int) and\n",
        "        0 < critter_index <= game.num_critters), \"Value is not a positive integer or exceeds the upper limit.\"\n",
        "    if weights is None:\n",
        "      self.W = np.array(\n",
        "      [[1., 1., 4., 1., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
        "       [0., 0., 0., 0., 0., 0., 0., 0., 1., 4., 1., 1.],\n",
        "       [0., 1., 0., 0., 1., 4., 0., 0., 1., 0., 0., 0.],\n",
        "       [0., 0., 0., 1., 0., 0., 4., 1., 0., 0., 1., 0.]])\n",
        "    else:\n",
        "      self.W = weights\n",
        "    self.fov_radius = fov_radius\n",
        "    self.default_softmax_temp = 0.05\n",
        "\n",
        "\n",
        "  def param_action_from_percept(self, percept, valid_directions, W,\n",
        "                                softmax_temp=None):\n",
        "    \"\"\"\n",
        "    Determine an action based on perception.\n",
        "\n",
        "    Args:\n",
        "      percept: A 1D len 12 array representing the perception of the organism.\n",
        "        Indices correspond to spaces around the organism. The values in the\n",
        "        array can be -2 (out-of-bounds), 0 (empty space), or -1 (food).\n",
        "      W: a 4 x 12 weight matrix parameter representing the connection strengths\n",
        "        between the 12 perceptions inputs and the 4 possible output actions.\n",
        "\n",
        "    Returns:\n",
        "      direction: a str, one of 'up', 'down', 'left', 'right'. If food in one or\n",
        "        more of the spaces immediately beside the organism, the function will\n",
        "        return a random choice among these directions. If there is no food\n",
        "        nearby, the function will return a random direction.\n",
        "      direction_probs: dictionary with probabilities of taking each action.\n",
        "    \"\"\"\n",
        "    if len(valid_directions) == 0:\n",
        "      # if there is no where legit to move, stay put\n",
        "      return 'still', {direction: 0 for direction in output_struct}\n",
        "\n",
        "    if softmax_temp is None:\n",
        "      # very low temp, basically deterministic for this range of values\n",
        "      softmax_temp = self.default_softmax_temp\n",
        "    # a human interpretable overview of the percept structure\n",
        "    percept_struct = [\n",
        "      'far up', 'left up', 'near up', 'right up',\n",
        "      'far left', 'near left', 'near right', 'far right',\n",
        "      'left down', 'near down', 'right down', 'far down']\n",
        "    # a human interpretable overview of the out structure\n",
        "    output_struct = ['up', 'down', 'left', 'right']\n",
        "    # boolean representation of percept, no edges, just 1's where food is,\n",
        "    # zero otherwise, also means other organisms are invisible\n",
        "    x = np.asarray(percept <= -1, int)\n",
        "    output_activations = W @ x\n",
        "\n",
        "    # softmax shift by max, scale by temp\n",
        "    shift_scale_ex = np.exp((output_activations -\n",
        "                             np.max(output_activations))/softmax_temp)\n",
        "    # set invalid direction activations to zero\n",
        "    invalid_directions = [direction for direction in output_struct\n",
        "                           if direction not in valid_directions]\n",
        "    invalid_indices = [output_struct.index(direction)\n",
        "                        for direction in valid_directions]\n",
        "    sm = shift_scale_ex / shift_scale_ex.sum() #normalized\n",
        "    # set invalid direction probabilities to zero\n",
        "    invalid_directions = [direction for direction in output_struct\n",
        "                           if direction not in valid_directions]\n",
        "    invalid_indices = [output_struct.index(direction)\n",
        "                        for direction in invalid_directions]\n",
        "    sm[invalid_indices] = 0\n",
        "    probs_sm = sm / sm.sum(axis=0) #re-normalized again for fp issues\n",
        "    direction = self.game.rng.choice(output_struct, p=probs_sm)\n",
        "    direction_probs = {direction: prob\n",
        "                        for direction, prob in zip(output_struct, probs_sm)}\n",
        "    return direction, direction_probs\n",
        "\n",
        "\n",
        "  def play(self, board, temp=None):\n",
        "    \"\"\"\n",
        "    Simulate Play on a Board\n",
        "\n",
        "    Args:\n",
        "      board: dict {'pieces':\n",
        "      (batch x num_rows x num_cols) np.ndarray of board position,\n",
        "                  'scores': batch len array of current scores,\n",
        "                  'rounds_left': batch len array of rounds left\n",
        "\n",
        "    Returns:\n",
        "      sampled_actions: a batch, row, col index of the move taken\n",
        "      by each player on each board\n",
        "      a_1hots: a batch nrow*ncol array of 1hot indices of those same moves\n",
        "      v_probs: sampling probabilities for those 1hots (If the policy\n",
        "      is deterministic a_1hots is returned here as well... or if getting the\n",
        "      probs is an un-needed fuss to compute)\n",
        "    \"\"\"\n",
        "    if temp is None:\n",
        "      temp = self.default_softmax_temp\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    perceptions = self.game.get_perceptions(board, self.fov_radius,\n",
        "                                            self.critter_index)\n",
        "    critter_oriented_moves = []\n",
        "    direction_probs = []\n",
        "\n",
        "    # Get valid actions for each game in the batch\n",
        "    valid_directions = self.game.get_valid_directions(board, self.critter_index)\n",
        "    for g in range(batch_size):\n",
        "      direction, batch_direction_probs = self.param_action_from_percept(\n",
        "        perceptions[g], valid_directions[g], self.W, softmax_temp=temp)\n",
        "      critter_oriented_moves.append(direction)\n",
        "      direction_probs.append(batch_direction_probs)\n",
        "    moves = self.game.critter_direction_to_move(board, critter_oriented_moves,\n",
        "                                                self.critter_index)\n",
        "    probs = self.game.direction_probs_to_flat_probs(board, direction_probs, self.critter_index)\n",
        "    sampled_actions = self.game.moves_to_actions(moves)\n",
        "    a_1hots = np.zeros((batch_size, n_rows*n_cols))\n",
        "    a_1hots[(range(batch_size), sampled_actions)] = 1.0\n",
        "\n",
        "    return sampled_actions, a_1hots, probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title interactive gridworld widgets\n",
        "\n",
        "########################################\n",
        "# widgets refactor for multi-critter\n",
        "#########################################\n",
        "# Interactive Gridworld Game Widgets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class InteractiveGridworld():\n",
        "  \"\"\"\n",
        "  A widget based object for interacting with a gridworld game\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, gridworld_game, init_board=None, has_fov=False,\n",
        "               radius=2, fov_opaque=False, collect_fov_data=False,\n",
        "               figsize=(6,5), critter_names=['Critter'], players=['human']):\n",
        "    \"\"\"\n",
        "    Initializes a widget based object for interacting with a gridworld game\n",
        "\n",
        "    Args:\n",
        "      gridworld_game: an instance of GridworldGame object\n",
        "        expects this to have batchsize 1\n",
        "      init_board: (optional) a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "        if left out will initialize with a random board state\n",
        "      has_fov: bool, whether or not to display fog of war around the critter\n",
        "      radius: int, number of squares the critter can \"see\" around it\n",
        "      figsize: tuple (int, int), size of the figure\n",
        "      critter_names: a list of strings that determines what the critter is called\n",
        "        in the plot legend, order should align with players\n",
        "      player: a list of either 'human', None, or a player object with a play\n",
        "        method and a critter_index attribute. If 'human' use buttons,  if None\n",
        "        default to making a RandomValidPlayer object, otherwise use the\n",
        "        player class provided to make the player objects and use a start button.\n",
        "        The list needs to be as long as the gridworld_game.num_critters\n",
        "        attribute. Order should align with critter_name.\n",
        "\n",
        "      Note: fov is going to look pretty janky with more than one player, maybe\n",
        "      we get fov to only turn on for the 'active' player?\n",
        "    \"\"\"\n",
        "\n",
        "    # Set GridworldGame object and initialize the board state\n",
        "    self.gwg = gridworld_game\n",
        "    self.has_fov = has_fov\n",
        "    self.radius = radius\n",
        "    self.fov_opaque = fov_opaque\n",
        "    self.percept_len = 2*self.radius*(self.radius+1)\n",
        "    self.collect_fov_data = collect_fov_data\n",
        "    self.figsize = figsize\n",
        "    # initialize players and plotting specs together to ensure alignment\n",
        "    self.players = []\n",
        "    self.any_human_players = False\n",
        "    self.active_player_index = 0\n",
        "    self.crit_specs = []\n",
        "    markers = ['h', 'd']  # hexagon and diamond\n",
        "    colors = sns.color_palette(\"colorblind\")\n",
        "    for i in range(self.gwg.num_critters):\n",
        "      spec = {'marker': markers[i % len(markers)],\n",
        "              'color': colors[i // len(markers) % len(colors)],\n",
        "              'name': critter_names[i],\n",
        "              'int_id': i+1}\n",
        "      self.crit_specs.append(spec)\n",
        "      player = players[i] #implict check that players is at least long enough\n",
        "      if player is None:\n",
        "        self.players.append(RandomValidPlayer(self.gwg, critter_index=i+1))\n",
        "      elif player == 'human':\n",
        "        self.players.append('human')\n",
        "        # right now only ever have on human player with index 1\n",
        "        self.any_human_players = True\n",
        "      else:\n",
        "        # player objects expected to have a critter_index attribute\n",
        "        # we set it appropriately here so it aligns with the players list\n",
        "        # used to create the widget\n",
        "        player.critter_index = i+1\n",
        "        self.players.append(player)\n",
        "    self.final_scores = []\n",
        "    if init_board is None:\n",
        "      self.board_state = self.gwg.get_init_board()\n",
        "    else:\n",
        "      self.board_state = init_board\n",
        "    if self.collect_fov_data is True:\n",
        "      # keep raw records of percept and eating for manipulation later\n",
        "      self.percept_eat_records = []\n",
        "      # keep data in contingency table of how many food items were in\n",
        "      # the percept, and whether or not food was eaten\n",
        "      self.fov_eat_table_data = np.zeros((2, self.percept_len+1))\n",
        "    # Initialize widgets and buttons\n",
        "    self.output = widgets.Output(layout=widgets.Layout(\n",
        "      width = '20.0em', min_width='20.0em', max_width='21.0em',\n",
        "      min_height='10.0em', overflow='auto'))\n",
        "    self.scoreboard = widgets.Output(layout=widgets.Layout(\n",
        "      min_width='12.5em', max_width='18.8em',\n",
        "      min_height='6.3em', overflow='auto'))\n",
        "    self.fov_eat_table_display = widgets.Output(layout=widgets.Layout(\n",
        "      min_width='25.0em', min_height='18.8em', overflow='auto'))\n",
        "    self.up_button = widgets.Button(description=\"Up\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.down_button = widgets.Button(description=\"Down\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.left_button = widgets.Button(description=\"Left\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.right_button = widgets.Button(description=\"Right\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.start_button = widgets.Button(description=\"Start\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "\n",
        "    # get plot canvas widgets and other plotting objects\n",
        "    plt.ioff()\n",
        "    if self.collect_fov_data and self.any_human_players:\n",
        "      self.legend_type = None # don't keep regenerating the legend\n",
        "      # do legend separately if showing observations and no human player\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov,\n",
        "       self.b_fig_legend, self.b_ax_legend) = self.gwg.plot_board(\n",
        "          self.board_state, g=0, critter_specs=self.crit_specs,\n",
        "          legend_type='separate', figsize=self.figsize, has_fov=self.has_fov,\n",
        "          radius=self.radius, fov_opaque=self.fov_opaque)\n",
        "    elif len(self.players) > 1:\n",
        "      self.legend_type=None # don't keep regenerating the legend\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov,\n",
        "       self.b_fig_legend, self.b_ax_legend) = self.gwg.plot_board(\n",
        "          self.board_state, g=0, critter_specs=self.crit_specs,\n",
        "          has_fov=self.has_fov, legend_type='separate',\n",
        "          radius=self.radius, fov_opaque=self.fov_opaque, figsize=self.figsize)\n",
        "    else:\n",
        "      self.legend_type = 'included'\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov\n",
        "        ) = self.gwg.plot_board(self.board_state, g=0,\n",
        "                                critter_specs=self.crit_specs,\n",
        "                                has_fov=self.has_fov,\n",
        "                                fov_opaque=self.fov_opaque,\n",
        "                                radius=self.radius, figsize=self.figsize)\n",
        "    # lump buttons together\n",
        "    self.buttons = widgets.HBox([self.left_button,\n",
        "                               widgets.VBox([self.up_button, self.down_button]),\n",
        "                               self.right_button])\n",
        "    # automatically pick different layouts for different situations\n",
        "    if self.any_human_players:\n",
        "      self.board_and_buttons = widgets.VBox([self.b_fig.canvas,\n",
        "                                             self.buttons])\n",
        "      if len(self.players) == 1:\n",
        "        #one human player\n",
        "        self.output_and_score = widgets.HBox([self.scoreboard, self.output])\n",
        "        self.no_table_final_display = widgets.VBox([self.board_and_buttons,\n",
        "                                                  self.output_and_score])\n",
        "        if self.collect_fov_data == True:\n",
        "          # a single human player collecting data\n",
        "          self.final_display = widgets.HBox([self.no_table_final_display,\n",
        "                                           self.fov_eat_table_display])\n",
        "        else: # self.collect_fov_data == False:\n",
        "          # a single human player not collecting data\n",
        "          self.final_display = self.no_table_final_display\n",
        "      else:\n",
        "        # more than one player, one of them human\n",
        "        self.V_board_outbput = widgets.VBox([self.board_and_buttons,\n",
        "                                             self.output])\n",
        "        self.V_scoreboard_start_legend = widgets.VBox([\n",
        "        self.scoreboard, self.start_button, self.b_fig_legend.canvas])\n",
        "        self.final_display = widgets.HBox([self.V_board_outbput,\n",
        "                                             self.V_scoreboard_start_legend])\n",
        "    else: # player is some kind of ai\n",
        "      if self.collect_fov_data == True:\n",
        "        # an ai player with recording\n",
        "        # in this case legend is separate\n",
        "        self.V_score_start_output_legend = widgets.VBox([self.scoreboard,\n",
        "          self.start_button,  self.output, self.b_fig_legend.canvas])\n",
        "        self.V_board_table = widgets.VBox([self.b_fig.canvas,\n",
        "                                           self.fov_eat_table_display])\n",
        "        self.final_display = widgets.HBox([self.V_board_table,\n",
        "                                           self.V_score_start_output_legend])\n",
        "      else:\n",
        "        if len(self.players) == 1:\n",
        "          # an ai player without recording\n",
        "          self.H_score_output_start = widgets.HBox([\n",
        "            self.scoreboard, self.output, self.start_button])\n",
        "          self.final_display = widgets.VBox([\n",
        "            self.b_fig.canvas, self.H_score_output_start])\n",
        "        else:\n",
        "          # more than one ai player\n",
        "          self.V_board_outbput = widgets.VBox([self.b_fig.canvas, self.output])\n",
        "          self.V_scoreboard_start_legend = widgets.VBox([\n",
        "              self.scoreboard, self.start_button, self.b_fig_legend.canvas])\n",
        "          self.final_display = widgets.HBox([self.V_board_outbput,\n",
        "                                             self.V_scoreboard_start_legend])\n",
        "\n",
        "    # initialize text outputs\n",
        "    with self.scoreboard:\n",
        "      table = [['High Score:'] + ['--'] * self.gwg.num_critters,\n",
        "               ['Last Score:'] + ['--'] * self.gwg.num_critters,\n",
        "               ['Average Score:'] + ['--'] * self.gwg.num_critters,]\n",
        "      if len(self.players) > 1:\n",
        "        headers = [''] + [f'P{i+1}' for i in range(self.gwg.num_critters)]\n",
        "        print(tabulate(table, headers=headers))\n",
        "      else: # len(self.players) == 1\n",
        "        print(tabulate(table))\n",
        "    with self.output:\n",
        "      if self.any_human_players:\n",
        "        print('Click a button to start playing')\n",
        "      else:\n",
        "        print('Click the start button to run the simulation')\n",
        "    with self.fov_eat_table_display:\n",
        "      printmd(\"**Observations**\")\n",
        "      table_data = [[str(ii),\n",
        "                     str(self.fov_eat_table_data[0,ii]),\n",
        "                     str(self.fov_eat_table_data[1,ii])] for ii in range(11)]\n",
        "      table = ([['Food in Percept', 'Food Not Eaten', 'Food Eaten']] +\n",
        "               table_data)\n",
        "      print(tabulate(table))\n",
        "\n",
        "    # Connect the buttons to functions that do something\n",
        "    self.up_button.on_click(self.on_up_button_clicked)\n",
        "    self.down_button.on_click(self.on_down_button_clicked)\n",
        "    self.left_button.on_click(self.on_left_button_clicked)\n",
        "    self.right_button.on_click(self.on_right_button_clicked)\n",
        "    self.start_button.on_click(self.on_start_button_clicked)\n",
        "\n",
        "\n",
        "  def button_output_update(self, which_button):\n",
        "    old_board = self.board_state.copy()\n",
        "    # index of players is 0 through num_critter-1,\n",
        "    # same player represented by value of index + 1 in\n",
        "    old_scores = old_board['scores'][0]\n",
        "    if self.collect_fov_data is True:\n",
        "      batch_size, n_rows, n_cols = old_board['pieces'].shape\n",
        "      b = GridworldBoard(batch_size, n_rows, n_cols,\n",
        "                         self.gwg.num_food, self.gwg.lifetime,\n",
        "                         rng=self.gwg.rng)\n",
        "      b.set_state(old_board)\n",
        "      percept = b.get_perceptions(self.radius)[0]\n",
        "\n",
        "    if (isinstance(self.players[self.active_player_index], str) and\n",
        "        'human' in self.players[self.active_player_index]):\n",
        "      direction = which_button\n",
        "    else:\n",
        "      a_player, _, _ = self.players[self.active_player_index].play(old_board)\n",
        "      # print(a_player)\n",
        "      a_player = self.gwg.action_to_critter_direction(old_board,\n",
        "                                                      self.active_player_index+1,\n",
        "                                                      a_player)\n",
        "      # but we only want to apply their move to the appropriate board\n",
        "      direction = a_player[0]\n",
        "\n",
        "    self.board_state = self.gwg.critter_oriented_get_next_state(\n",
        "          self.board_state, self.active_player_index+1, [direction])\n",
        "    new_scores = self.board_state['scores'][0] #first batch first critter type\n",
        "    rounds_left = self.board_state['rounds_left'][0]\n",
        "    num_moves = np.floor(self.gwg.lifetime -\n",
        "                         rounds_left / self.gwg.num_critters)\n",
        "    if new_scores[self.active_player_index] > old_scores[self.active_player_index]:\n",
        "      #eating happened\n",
        "      eating_string = \"They ate the food/prey there!\"\n",
        "      did_eat = 1\n",
        "    else: #eating didn't happen\n",
        "      eating_string = \"There's no food/prey there.\"\n",
        "      did_eat = 0\n",
        "    row, col = self.gwg.get_critter_rc(self.board_state, 0,\n",
        "                                       self.active_player_index+1)\n",
        "    (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov\n",
        "     ) = self.gwg.plot_board(self.board_state, g=0,\n",
        "                             fig=self.b_fig, ax=self.b_ax,\n",
        "                             critter_specs=self.b_crit_specs, food=self.b_food,\n",
        "                             fov=self.b_fov, has_fov=self.has_fov,\n",
        "                             fov_opaque=self.fov_opaque,\n",
        "                             radius=self.radius, legend_type=self.legend_type)\n",
        "    if self.collect_fov_data is True:\n",
        "      p_e_data = {'perception': percept.copy(),\n",
        "                  'state': old_board,\n",
        "                  'did_eat': bool(did_eat)}\n",
        "      self.percept_eat_records.append(p_e_data)\n",
        "      percept_int = np.sum(percept==-1) # number of food items in FoV\n",
        "      self.fov_eat_table_data[did_eat, percept_int] += 1\n",
        "\n",
        "    with self.output:\n",
        "      clear_output()\n",
        "      if len(self.players) == 1:\n",
        "        print(\"The critter (tried) to move \" + direction +\n",
        "              \" and is now at ({}, {}).\".format(row,col))\n",
        "        print(eating_string)\n",
        "        print(\"Rounds Left: {}\\nFood Eaten: {}\\nFood Per Move: {:.2f}\".format(\n",
        "            rounds_left, new_scores[self.active_player_index],\n",
        "            new_scores[self.active_player_index] / num_moves))\n",
        "      else: # more than one players\n",
        "        print(\"Critter {} (tried) to move \".format(self.active_player_index+1) +\n",
        "              direction +\n",
        "              \" and is now at ({}, {}).\".format(row, col))\n",
        "        print(eating_string)\n",
        "        print(\"Rounds Left: {}\\nFood Eaten: {}\".format(\n",
        "            rounds_left, new_scores))\n",
        "    if rounds_left == 0:\n",
        "      self.final_scores.append(new_scores)\n",
        "      with self.output:\n",
        "        clear_output\n",
        "        print('Game Over. Final Score {}'.format(new_scores))\n",
        "        print('Resetting the board for another game')\n",
        "        self.board_state = self.gwg.get_init_board()\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov\n",
        "       ) = self.gwg.plot_board(self.board_state, 0, self.b_fig, self.b_ax,\n",
        "                               self.b_crit_specs, self.b_food, self.b_fov,\n",
        "                               has_fov=self.has_fov, radius=self.radius,\n",
        "                               fov_opaque=self.fov_opaque,\n",
        "                               legend_type=self.legend_type)\n",
        "    with self.scoreboard:\n",
        "        clear_output()\n",
        "        print('Games Played: ' + str(len(self.final_scores)))\n",
        "        if len(self.players) == 1:\n",
        "          if len(self.final_scores) > 0:\n",
        "            table = [\n",
        "              ['High Score:', str(np.max(np.array(self.final_scores)))],\n",
        "              ['Last Score:', str(self.final_scores[-1])],\n",
        "              ['Average Score',\n",
        "              '{:.2f}'.format(np.mean(np.array(self.final_scores)))]]\n",
        "          else:\n",
        "            table = [['High Score:', '--'],\n",
        "                     ['Last Score:', '--'],\n",
        "                     ['Average Score:', '--']]\n",
        "          print(tabulate(table))\n",
        "        else: # len(self.players) > 1\n",
        "          headers = [''] + [f'P{i+1}' for i in range(self.gwg.num_critters)]\n",
        "          if len(self.final_scores) > 0:\n",
        "            table = []\n",
        "            # Assuming the batch size is 1 for now\n",
        "            current_scores = self.final_scores[-1]\n",
        "            max_scores = np.max(np.array(self.final_scores), axis=0)\n",
        "            average_scores = np.mean(np.array(self.final_scores), axis=0)\n",
        "            table.append(['High Scores:'] +\n",
        "              [str(score) for score in max_scores])\n",
        "            table.append(['Last Scores:'] +\n",
        "              [str(score) for score in current_scores])\n",
        "            table.append(['Average Scores:'] +\n",
        "              ['{:.2f}'.format(score) for score in average_scores])\n",
        "          else:\n",
        "            table = [\n",
        "              ['High Score:'] + ['--'] * self.gwg.num_critters,\n",
        "              ['Last Score:'] + ['--'] * self.gwg.num_critters,\n",
        "              ['Average Score:'] + ['--'] * self.gwg.num_critters,]\n",
        "          print(tabulate(table, headers=headers))\n",
        "\n",
        "    with self.fov_eat_table_display:\n",
        "      clear_output()\n",
        "      printmd(\"**Observations**\")\n",
        "      table_data = [[str(ii),\n",
        "                     str(self.fov_eat_table_data[0,ii]),\n",
        "                     str(self.fov_eat_table_data[1,ii])] for ii in range(11)]\n",
        "      table = ([['Food in Percept', 'Food Not Eaten', 'Food Eaten']] +\n",
        "               table_data)\n",
        "      print(tabulate(table))\n",
        "\n",
        "  def disable_direction_buttons(self):\n",
        "    self.up_button.disabled = True\n",
        "    self.down_button.disabled = True\n",
        "    self.left_button.disabled = True\n",
        "    self.right_button.disabled = True\n",
        "\n",
        "  def enable_direction_buttons(self):\n",
        "    self.up_button.disabled = False\n",
        "    self.down_button.disabled = False\n",
        "    self.left_button.disabled = False\n",
        "    self.right_button.disabled = False\n",
        "\n",
        "  def human_ai_player_loop(self, direction):\n",
        "    self.disable_direction_buttons()  # Disable buttons, no double clicks\n",
        "    # Execute the move of the human who clicked the button\n",
        "    self.button_output_update(direction)\n",
        "    # Move to the next player\n",
        "    def update_player_and_rounds():\n",
        "      \"\"\"Update the player index and decrement rounds if a full loop is completed.\"\"\"\n",
        "      self.active_player_index = (self.active_player_index + 1) % len(self.players)\n",
        "      if self.active_player_index == 0:\n",
        "        self.board_state['rounds_left'] -= 1\n",
        "    update_player_and_rounds()\n",
        "    # Do AI moves if there are any\n",
        "    while self.players[self.active_player_index] != 'human':\n",
        "      self.button_output_update('tbd')\n",
        "      # Move to the next player\n",
        "      update_player_and_rounds()\n",
        "    # Next player is human turn buttons on for them\n",
        "    self.enable_direction_buttons()\n",
        "\n",
        "  def on_up_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('up')\n",
        "\n",
        "  def on_down_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('down')\n",
        "\n",
        "  def on_left_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('left')\n",
        "\n",
        "  def on_right_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('right')\n",
        "\n",
        "  def on_start_button_clicked(self, *args):\n",
        "    self.start_button.disabled = True\n",
        "    for ii in range(self.gwg.lifetime*self.gwg.num_critters):\n",
        "      self.button_output_update('tbd')\n",
        "      time.sleep(0.2)\n",
        "    self.start_button.disabled = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class Head2HeadGridworld():\n",
        "  \"\"\"\n",
        "  A widget for interacting with a gridworld game while an artificial player\n",
        "  plays on an identical board or watching two artificial players play, again\n",
        "  with identical starting positions (though RNG not synched between the two\n",
        "  boards, so not like duplicate bridge). We are not going to worry about having\n",
        "  more than 1 critter type playing in head to head, (maybe we will to talk\n",
        "  about cooperation... maybe).\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, gridworld_game, init_board=None,\n",
        "               player0='human', p0_short_name='YOU', p0_long_name=None,\n",
        "               player1=None, p1_short_name='THEM', p1_long_name=None,\n",
        "               has_fov=False, radius=2, fov_opaque=False,\n",
        "               collect_fov_data=False, critter_name='Critter',\n",
        "               figsize=(5,4.5), has_temp_slider=False):\n",
        "    \"\"\"\n",
        "    Initializes a widget based object for interacting with a gridworld game\n",
        "\n",
        "    Args:\n",
        "      gridworld_game: an instance of GridworldGame object\n",
        "        expects this to have batch_size of 2\n",
        "      init_board: (optional) a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "        if left out will initialize with a random board state\n",
        "      player0: object with a play method that takes a board state\n",
        "        as an argument and returns a move. If none will use a random player\n",
        "        if the special string 'human' is passed make arrow keys for that player\n",
        "      player1: same deal as player0, never more than 1 human player\n",
        "      has_fov: bool, whether or not to display field of view around the critter\n",
        "      radius: int, number of squares the critter can \"see\" around it\n",
        "    \"\"\"\n",
        "    # Set GridworldGame object and initialize the board state\n",
        "    self.gwg = gridworld_game\n",
        "    self.final_scores = []\n",
        "    self.player0 = player0\n",
        "    self.p0_short_name = p0_short_name\n",
        "    self.p0_long_name = p0_long_name\n",
        "    self.player1 = player1\n",
        "    self.p1_short_name = p1_short_name\n",
        "    self.p1_long_name = p1_long_name\n",
        "    self.no_human = True\n",
        "    if self.player0 == 'human':\n",
        "      assert self.player1 != 'human'\n",
        "      self.no_human = False\n",
        "    if self.player1 == 'human':\n",
        "      assert self.player0 != 'human'\n",
        "      self.no_human = False\n",
        "    self.p0_next_move = None\n",
        "    self.p1_next_move = None\n",
        "    self.has_fov = has_fov\n",
        "    self.radius = radius\n",
        "    self.fov_opaque = fov_opaque\n",
        "    self.percept_len = 2*self.radius*(self.radius+1)\n",
        "    self.collect_fov_data = collect_fov_data\n",
        "    self.critter_name = critter_name\n",
        "    self.figsize = figsize\n",
        "    if player0 is None:\n",
        "      self.player0 = RandomValidPlayer(self.gwg)\n",
        "    else:\n",
        "      self.player0 = player0\n",
        "    if player1 is None:\n",
        "      self.player1 = RandomValidPlayer(self.gwg)\n",
        "    else:\n",
        "      self.player1 = player1\n",
        "    self.has_temp_slider = has_temp_slider\n",
        "\n",
        "    if self.collect_fov_data is True:\n",
        "      self.percept_eat_records = []\n",
        "      self.fov_eat_table_data = np.zeros((2, self.percept_len+1))\n",
        "    if init_board is None:\n",
        "      self.board_state = self.gwg.get_init_board()\n",
        "    else:\n",
        "      self.board_state = init_board\n",
        "    #print(self.board_state)\n",
        "\n",
        "    # both players have same starting board\n",
        "    self.board_state['pieces'][1] = self.board_state['pieces'][0].copy()\n",
        "\n",
        "    # Initialize widgets and buttons\n",
        "    if self.has_temp_slider:\n",
        "      self.sft_slider_label = widgets.Label(value='Softmax Temperature')\n",
        "      self.sft_slider = widgets.FloatSlider(value=1.0, min=0.05,\n",
        "                                            max=5.0, step=0.05)\n",
        "      self.softmax_temp_slider = widgets.VBox([self.sft_slider_label,\n",
        "                                               self.sft_slider])\n",
        "    self.output0 = widgets.Output(layout=widgets.Layout(\n",
        "      width = '20.0em', min_width='20.0em', max_width='21.0em',\n",
        "      min_height='10.0em', overflow='auto'))\n",
        "    self.output1 = widgets.Output(layout=widgets.Layout(\n",
        "      width = '20.0em', min_width='20.0em', max_width='21.0em',\n",
        "      min_height='10.0em', overflow='auto'))\n",
        "    self.scoreboard = widgets.Output(layout=widgets.Layout(\n",
        "      min_width='20em', max_width='21em', min_height='6.3em', overflow='auto'))\n",
        "    self.up_button = widgets.Button(description=\"Up\",\n",
        "                                    layout=widgets.Layout(width='6.3em'))\n",
        "    self.down_button = widgets.Button(description=\"Down\",\n",
        "                                      layout=widgets.Layout(width='6.3em'))\n",
        "    self.left_button = widgets.Button(description=\"Left\",\n",
        "                                      layout=widgets.Layout(width='6.3em'))\n",
        "    self.right_button = widgets.Button(description=\"Right\",\n",
        "                                       layout=widgets.Layout(width='6.3em'))\n",
        "    self.start_button = widgets.Button(description=\"Start\",\n",
        "      layout=widgets.Layout(width='6.3em', margin='0.6em 0 0 0'))  # 0.6em top margin\n",
        "\n",
        "    #set up buttons and outputs and layouts\n",
        "    self.buttons = widgets.HBox([self.left_button,\n",
        "                               widgets.VBox([self.up_button, self.down_button]),\n",
        "                               self.right_button])\n",
        "    plt.ioff()\n",
        "    (self.b_fig0, self.b_ax0, self.b_crit_specs0, self.b_food0, self.b_fov0,\n",
        "     self.b_fig_legend, self.b_ax_legend) = self.gwg.plot_board(\n",
        "        self.board_state, g=0, legend_type='separate', figsize=self.figsize,\n",
        "        has_fov=self.has_fov, radius=self.radius, fov_opaque=self.fov_opaque,\n",
        "        name=self.critter_name, title=self.p0_long_name)\n",
        "    (self.b_fig1, self.b_ax1, self.b_crit_specs1, self.b_food1, self.b_fov1\n",
        "     ) = self.gwg.plot_board(self.board_state, g=1, legend_type=None,\n",
        "                             figsize=self.figsize, has_fov=self.has_fov,\n",
        "                             radius=self.radius, fov_opaque=self.fov_opaque,\n",
        "                             title=self.p1_long_name)\n",
        "    # player 0 is human\n",
        "    self.board_buttons_and_output0 = widgets.VBox(\n",
        "      [self.b_fig0.canvas, self.buttons, self.output0])\n",
        "    # player 1 is human\n",
        "    self.board_buttons_and_output1 = widgets.VBox(\n",
        "      [self.b_fig1.canvas, self.buttons, self.output1])\n",
        "    # non human players\n",
        "    self.board_and_output0 = widgets.VBox([self.b_fig0.canvas, self.output0])\n",
        "    self.board_and_output1 = widgets.VBox([self.b_fig1.canvas, self.output1])\n",
        "\n",
        "    self.legend_and_scores = widgets.VBox([self.b_fig_legend.canvas,\n",
        "                                           self.scoreboard])\n",
        "    if self.has_temp_slider:\n",
        "      self.legend_scores_start = widgets.VBox([self.b_fig_legend.canvas,\n",
        "                                               self.scoreboard,\n",
        "                                               self.softmax_temp_slider,\n",
        "                                               self.start_button])\n",
        "    else:\n",
        "      self.legend_scores_start = widgets.VBox([self.b_fig_legend.canvas,\n",
        "                                               self.scoreboard,\n",
        "                                               self.start_button])\n",
        "    if self.player0 == 'human':\n",
        "      self.final_display = widgets.HBox([self.board_buttons_and_output0,\n",
        "                                         self.legend_and_scores,\n",
        "                                         self.board_and_output1])\n",
        "    elif self.player1 == 'human':\n",
        "      self.final_display = widgets.HBox([self.board_and_output0,\n",
        "                                         self.legend_and_scores,\n",
        "                                         self.board_buttons_and_output1])\n",
        "    else: # no human player\n",
        "      self.final_display = widgets.HBox([self.board_and_output0,\n",
        "                                          self.legend_scores_start,\n",
        "                                          self.board_and_output1])\n",
        "    # initial text outputs\n",
        "    # if there's a temp slider check who, if anyone uses it\n",
        "    self.p0_uses_temp = False\n",
        "    self.p1_uses_temp = False\n",
        "    if self.has_temp_slider:\n",
        "      if self.player0=='human':\n",
        "        pass\n",
        "      else:\n",
        "        try:\n",
        "          _ = self.player0.play(self.board_state, temp=1.0)\n",
        "          self.p0_uses_temp = True\n",
        "        except TypeError: pass\n",
        "      if self.player1 == 'human':\n",
        "        pass\n",
        "      else:\n",
        "        try:\n",
        "          _ = self.player1.play(self.board_state, temp=1.0)\n",
        "          self.p1_uses_temp = True\n",
        "        except TypeError: pass\n",
        "      if not self.p0_uses_temp and not self.p1_uses_temp:\n",
        "        with self.output0:\n",
        "          print(\"Warning: neither player supports temperature adjustment. \"\n",
        "                \"The slider will have no effect.\")\n",
        "    with self.output0:\n",
        "      if self.no_human == False:\n",
        "        print('Click a button to start.')\n",
        "      else:\n",
        "        print('Click the start button to run the simulation')\n",
        "    with self.scoreboard:\n",
        "      print('Games Played: ' + str(len(self.final_scores)))\n",
        "      table = [['', self.p0_short_name, self.p1_short_name],\n",
        "          ['High Score:', '--', '--'],\n",
        "          ['Last Score:', '--', '--'],\n",
        "          ['Avg. Score:', '--', '--']]\n",
        "      print(tabulate(table))\n",
        "\n",
        "    # Connect the buttons to functions that do something\n",
        "    self.up_button.on_click(self.on_up_button_clicked)\n",
        "    self.down_button.on_click(self.on_down_button_clicked)\n",
        "    self.left_button.on_click(self.on_left_button_clicked)\n",
        "    self.right_button.on_click(self.on_right_button_clicked)\n",
        "    self.start_button.on_click(self.on_start_button_clicked)\n",
        "\n",
        "\n",
        "  def button_output_update(self, which_button):\n",
        "    old_board = self.board_state.copy()\n",
        "    old_scores = old_board['scores'][:,0] #both batches only one critter type\n",
        "    self.active_player = old_board['active_player']\n",
        "    self.disable_buttons()\n",
        "    if self.player0 == 'human':\n",
        "      a_player0 = which_button\n",
        "    else:\n",
        "      if self.p0_next_move is not None:\n",
        "        a_player0_ = self.p0_next_move\n",
        "        self.p0_next_move = None\n",
        "      else:\n",
        "        with self.output0:\n",
        "          print(\"AI is thinking...\")\n",
        "        if self.p0_uses_temp:\n",
        "          a_player0_, _, _ = self.player0.play(old_board,\n",
        "                                               temp=self.sft_slider.value)\n",
        "        else:\n",
        "          a_player0_, _, _ = self.player0.play(old_board)\n",
        "      a_player0_ = self.gwg.action_to_critter_direction(old_board,\n",
        "                                                        self.active_player+1,\n",
        "                                                        a_player0_)\n",
        "      a_player0 = a_player0_[0]\n",
        "    if self.player1 == 'human':\n",
        "      a_player1 = which_button\n",
        "    else:\n",
        "      if self.p1_next_move is not None:\n",
        "        a_player1_ = self.p1_next_move\n",
        "        self.p1_next_move = None\n",
        "      else:\n",
        "        with self.output1:\n",
        "          print(\"AI is thinking...\")\n",
        "        if self.p1_uses_temp:\n",
        "          a_player1_, _, _ = self.player1.play(old_board,\n",
        "                                               temp=self.sft_slider.value)\n",
        "        else:\n",
        "          a_player1_, _, _ = self.player1.play(old_board)\n",
        "      a_player1_ = self.gwg.action_to_critter_direction(old_board,\n",
        "                                                        self.active_player+1,\n",
        "                                                        a_player1_)\n",
        "      a_player1 = a_player1_[1]\n",
        "    self.enable_buttons()\n",
        "\n",
        "    self.board_state = self.gwg.critter_oriented_get_next_state(\n",
        "        self.board_state, self.active_player+1, [a_player0, a_player1])\n",
        "\n",
        "    # Try to precompute next AI player move(s) if there are any rounds left\n",
        "    if self.board_state['rounds_left'][0] > 0:\n",
        "      if self.player0 != 'human':\n",
        "        if self.p0_uses_temp:\n",
        "          self.p0_next_move, _, _ = self.player0.play(\n",
        "            self.board_state, temp=self.sft_slider.value)\n",
        "        else:\n",
        "          self.p0_next_move, _, _ = self.player0.play(self.board_state)\n",
        "      if self.player1 != 'human':\n",
        "        if self.p1_uses_temp:\n",
        "          self.p1_next_move, _, _ = self.player1.play(\n",
        "            self.board_state, temp=self.sft_slider.value)\n",
        "        else:\n",
        "          self.p1_next_move, _, _ = self.player1.play(self.board_state)\n",
        "\n",
        "    if self.collect_fov_data is True:\n",
        "      batch_size, n_rows, n_cols = old_board['pieces'].shape\n",
        "      b = GridworldBoard(batch_size, n_rows, n_cols,\n",
        "                         self.gwg.num_food, self.gwg.lifetime,\n",
        "                         rng=self.gwg.rng)\n",
        "      b.set_state(old_board)\n",
        "      percept = b.get_perceptions(self.radius)\n",
        "\n",
        "    new_scores = self.board_state['scores'][:,0] #both batches one critter type\n",
        "    rounds_left = self.board_state['rounds_left'][0]\n",
        "    num_moves = self.gwg.lifetime - rounds_left\n",
        "\n",
        "    if new_scores[0] > old_scores[0]:\n",
        "      eating_string0 = \"They ate the food there!\"\n",
        "    else:\n",
        "      eating_string0 = \"There's no food there.\"\n",
        "    if new_scores[1] > old_scores[1]:\n",
        "      eating_string1 = \"They ate the food there!\"\n",
        "    else:\n",
        "      eating_string1 = \"There's no food there.\"\n",
        "    did_eat = int(new_scores[0] > old_scores[0])\n",
        "\n",
        "    row0, col0 = self.gwg.get_critter_rc(self.board_state, 0, 1)\n",
        "    (self.b_fig0, self.b_ax0, self.b_crit_specs0, self.b_food0, self.b_fov0\n",
        "     ) = self.gwg.plot_board(self.board_state, 0, self.b_fig0, self.b_ax0,\n",
        "                             self.b_crit_specs0, self.b_food0, self.b_fov0,\n",
        "                             has_fov=self.has_fov, radius=self.radius,\n",
        "                             fov_opaque=self.fov_opaque,\n",
        "                             legend_type=None)\n",
        "    row1, col1 = self.gwg.get_critter_rc(self.board_state, 1, 1)\n",
        "    (self.b_fig1, self.b_ax1, self.b_crit_specs1, self.b_food1, self.b_fov1\n",
        "     ) = self.gwg.plot_board(self.board_state, 1, self.b_fig1, self.b_ax1,\n",
        "                             self.b_crit_specs1, self.b_food1, self.b_fov1,\n",
        "                             has_fov=self.has_fov, radius=self.radius,\n",
        "                             fov_opaque=self.fov_opaque,\n",
        "                             legend_type=None)\n",
        "\n",
        "    with self.output0:\n",
        "      clear_output()\n",
        "      if self.player0 == 'human':\n",
        "        print(\"You clicked the \" + which_button +\n",
        "              \" button and your critter is now at ({}, {}).\".format(row0,col0))\n",
        "      else:\n",
        "        print(\"This player (tried) to move \" + a_player0 +\n",
        "              \" and is now at ({}, {}).\".format(row0,col0))\n",
        "      print(eating_string0)\n",
        "      print(\"Rounds Left: {} \\nFood Eaten: {} \\nFood Per Move: {:.2f}\".format(\n",
        "          rounds_left, new_scores[0], new_scores[0] / num_moves))\n",
        "    with self.output1:\n",
        "      clear_output()\n",
        "      if self.player1 == 'human':\n",
        "        print(\"You clicked the \" + which_button +\n",
        "              \" button and your critter is now at ({}, {}).\".format(row1,col1))\n",
        "      else:\n",
        "        print(\"This player (tried) to move \" + a_player1 +\n",
        "              \" and is now at ({}, {}).\".format(row1,col1))\n",
        "      print(eating_string1)\n",
        "      print(\"Rounds Left: {} \\nFood Eaten: {} \\nFood Per Move: {:.2f}\".format(\n",
        "        rounds_left, new_scores[1], new_scores[1] / num_moves))\n",
        "\n",
        "    if self.collect_fov_data is True:\n",
        "      p_e_data = (percept.copy(), did_eat, old_board)\n",
        "      self.percept_eat_records.append(p_e_data)\n",
        "      percept_int = np.sum(percept==-1, axis=1)\n",
        "      self.fov_eat_table_data[did_eat, percept_int] += 1\n",
        "\n",
        "    if rounds_left == 0:\n",
        "      self.final_scores.append(new_scores)\n",
        "      self.board_state = self.gwg.get_init_board()\n",
        "      self.board_state['pieces'][1] = self.board_state['pieces'][0].copy()\n",
        "      (self.b_fig0, self.b_ax0, self.b_crit_specs0, self.b_food0, self.b_fov0\n",
        "       ) = self.gwg.plot_board(self.board_state, 0, self.b_fig0, self.b_ax0,\n",
        "                              self.b_crit_specs0, self.b_food0, self.b_fov0,\n",
        "                              has_fov=self.has_fov, radius=self.radius,\n",
        "                              fov_opaque=self.fov_opaque,\n",
        "                              legend_type=None)\n",
        "      (self.b_fig1, self.b_ax1, self.b_crit_specs1, self.b_food1, self.b_fov1\n",
        "       ) = self.gwg.plot_board(self.board_state, 1, self.b_fig1, self.b_ax1,\n",
        "                               self.b_crit_specs1, self.b_food1, self.b_fov1,\n",
        "                               has_fov=self.has_fov, radius=self.radius,\n",
        "                               fov_opaque=self.fov_opaque,\n",
        "                               legend_type=None)\n",
        "      with self.output0:\n",
        "        clear_output\n",
        "        print('Game Over. Final Score {}'.format(new_scores[0]))\n",
        "        print('Resetting the board for another game')\n",
        "      with self.output1:\n",
        "        clear_output\n",
        "        print('Game Over. Final Score {}'.format(new_scores[1]))\n",
        "        print('Resetting the board for another game')\n",
        "    with self.scoreboard:\n",
        "      clear_output()\n",
        "      self.b_fig_legend.canvas.draw()\n",
        "      print('Games Played: ' + str(len(self.final_scores)))\n",
        "      if len(self.final_scores) > 0:\n",
        "        table = [['', self.p0_short_name, self.p1_short_name],\n",
        "          ['High Score:', str(np.max(np.array(self.final_scores)[:,0])),\n",
        "                          str(np.max(np.array(self.final_scores)[:,1]))],\n",
        "          ['Last Score:', str(self.final_scores[-1][0]),\n",
        "                          str(self.final_scores[-1][1])],\n",
        "          ['Average Score',\n",
        "            '{:.2f}'.format(np.mean(np.array(self.final_scores)[:,0])),\n",
        "            '{:.2f}'.format(np.mean(np.array(self.final_scores)[:,1]))]]\n",
        "      else:\n",
        "        table = [['', self.p0_short_name, self.p1_short_name],\n",
        "          ['High Score:', '--', '--'],\n",
        "          ['Last Score:', '--', '--'],\n",
        "          ['Average Score:', '--', '--']]\n",
        "      print(tabulate(table))\n",
        "\n",
        "\n",
        "  def on_up_button_clicked(self, *args):\n",
        "    self.button_output_update('up')\n",
        "\n",
        "  def on_down_button_clicked(self, *args):\n",
        "    self.button_output_update('down')\n",
        "\n",
        "  def on_left_button_clicked(self, *args):\n",
        "    self.button_output_update('left')\n",
        "\n",
        "  def on_right_button_clicked(self, *args):\n",
        "    self.button_output_update('right')\n",
        "\n",
        "  def on_start_button_clicked(self, *args):\n",
        "    self.start_button.disabled = True\n",
        "    if self.has_temp_slider:\n",
        "      self.softmax_temp_slider.disabled = True\n",
        "    for ii in range(self.gwg.lifetime):\n",
        "      self.button_output_update('tbd')\n",
        "      time.sleep(0.2)\n",
        "    self.start_button.disabled = False\n",
        "    if self.has_temp_slider:\n",
        "      self.softmax_temp_slider.disabled = False\n",
        "\n",
        "  def disable_buttons(self):\n",
        "    self.up_button.disabled = True\n",
        "    self.down_button.disabled = True\n",
        "    self.left_button.disabled = True\n",
        "    self.right_button.disabled = True\n",
        "\n",
        "  def enable_buttons(self):\n",
        "    self.up_button.disabled = False\n",
        "    self.down_button.disabled = False\n",
        "    self.left_button.disabled = False\n",
        "    self.right_button.disabled = False\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ExploreWeightsWidget:\n",
        "  def __init__(self, game):\n",
        "    self.game = game\n",
        "    self.n_rows, self.n_cols = 4, 12  # four directions, twelve fov cells\n",
        "    self.row_labels = ['Up', 'Down', 'Left', 'Right']\n",
        "    self.col_labels = [\n",
        "      'Far<br>Up', 'Left<br>Up', 'Near<br>Up', 'Right<br>Up',\n",
        "      'Far<br>Left', 'Near<br>Left', 'Near<br>Right', 'Far<br>Right',\n",
        "      'Left<br>Down', 'Near<br>Down', 'Right<br>Down', 'Far<br>Down'\n",
        "      ]\n",
        "\n",
        "    # Create column headers\n",
        "    col_header = [widgets.Label(value='', layout=widgets.Layout(width='50px'))] + \\\n",
        "                 [widgets.HTML(value=label, layout=widgets.Layout(width='60px', min_height='60px')) for label in self.col_labels]\n",
        "\n",
        "    self.text_fields = [widgets.HBox(col_header)]\n",
        "\n",
        "    for label in self.row_labels:\n",
        "      row_fields = [widgets.FloatText(value=0.0, step=0.1, layout=widgets.Layout(width='60px'))\n",
        "                    for _ in range(self.n_cols)]\n",
        "      row_label = widgets.Label(value=f\"{label}:\", layout=widgets.Layout(width='50px'))\n",
        "      self.text_fields.append(widgets.HBox([row_label] + row_fields))\n",
        "\n",
        "    # Create a button to start the game\n",
        "    self.run_button = widgets.Button(description=\"Run Game\")\n",
        "    self.run_button.on_click(self.run_game)\n",
        "\n",
        "    # set up fig and create placeholders for vertical lines and histograms\n",
        "    colors = sns.color_palette(\"colorblind\")\n",
        "    self.current_color = colors[0]\n",
        "    self.best_color = colors[1]\n",
        "    self.prev_color = colors[2]\n",
        "    self.fig, self.ax = plt.subplots(figsize=(6,4))\n",
        "    self.ax.set_xlim([0,25])\n",
        "    self.ax.set_ylim([0,1])\n",
        "    remove_ip_clutter(self.fig)\n",
        "    self.current_avg_line = self.ax.axvline(-1, color=self.current_color,\n",
        "                                            linestyle='dashed', linewidth=3,\n",
        "                                            label='Current')\n",
        "    self.prev_avg_line = self.ax.axvline(-1, color=self.prev_color,\n",
        "                                         linestyle='dashed', linewidth=3,\n",
        "                                         label='Previous')\n",
        "    self.best_avg_line = self.ax.axvline(-1, color=self.best_color,\n",
        "                                         linestyle='dashed', linewidth=3,\n",
        "                                         label='Best')\n",
        "    if self.game.batch_size > 1:\n",
        "      #only do hist for batches\n",
        "      self.current_hist_bars = self.ax.bar([0]*10, [0]*10,\n",
        "                                           color=self.current_color,\n",
        "                                           label='Current Run')\n",
        "      self.prev_hist_bars = self.ax.bar([0]*10, [0]*10, color=self.prev_color,\n",
        "                                        label='Previous Run', alpha=0.5)\n",
        "    self.fig.legend(loc='outside right upper')\n",
        "    self.fig.canvas.draw()\n",
        "\n",
        "    # Output widget to display game output and any other information\n",
        "    self.out = widgets.Output()\n",
        "\n",
        "    # keep track of important values\n",
        "    self.best_avg_score = float('-inf')\n",
        "    self.best_params = None\n",
        "    self.prev_scores = []\n",
        "    self.scores = np.array([])\n",
        "\n",
        "    # Button to set the best weights\n",
        "    self.best_button = widgets.Button(description=\"Set Best Weights\")\n",
        "    self.best_button.on_click(self.set_best_weights)\n",
        "\n",
        "    # Add a ToggleButton for symmetry\n",
        "    self.symmetry_toggle = widgets.ToggleButton(value=False,\n",
        "                                                description='Enforce Symmetry',\n",
        "                                                disabled=False,\n",
        "                                                button_style='',\n",
        "                                                tooltip='Toggle symmetry enforcement',\n",
        "                                                icon='check')\n",
        "    self.symmetry_toggle.observe(self.toggle_symmetry, 'value')\n",
        "\n",
        "    self.final_display = widgets.VBox([\n",
        "      *self.text_fields,\n",
        "      widgets.HBox([self.run_button, self.best_button, self.symmetry_toggle]),\n",
        "      self.fig.canvas,\n",
        "      self.out])\n",
        "\n",
        "    self.links = []  # To keep track of the jslink objects\n",
        "\n",
        "\n",
        "  def run_game(self, *args):\n",
        "    weights = []\n",
        "    for hbox in self.text_fields[1:]:  # Skip the header row\n",
        "      row_weights = [field.value for field in hbox.children[1:]]  # Skip the label at the first position\n",
        "      weights.append(row_weights)\n",
        "    weights = np.array(weights)\n",
        "    ppp = PerceptParamPlayer(self.game, weights=weights)\n",
        "    # Run the game\n",
        "    final_board = self.game.play_game(players=[ppp], visualize=False)\n",
        "\n",
        "    self.scores = final_board['scores'].flatten()\n",
        "    avg_score = np.mean(self.scores)\n",
        "\n",
        "    if avg_score > self.best_avg_score:\n",
        "      self.best_avg_score = avg_score\n",
        "      self.best_params = weights\n",
        "\n",
        "    if self.game.batch_size > 1:\n",
        "      # Compute and update histogram data\n",
        "      counts, edges = np.histogram(self.scores, bins=10)\n",
        "      counts = counts/np.sum(counts)\n",
        "      prev_counts, prev_edges = np.histogram(self.prev_scores[-1], bins=10) if len(self.prev_scores) > 0 else ([0]*10, edges)\n",
        "      prev_sum = np.sum(prev_counts)\n",
        "      if prev_sum > 0:\n",
        "        prev_counts = prev_counts / np.sum(prev_counts)\n",
        "      # Update the height of bars for the current scores\n",
        "      for bar, height, left in zip(self.current_hist_bars, counts, edges[:-1]):\n",
        "          bar.set_height(height)\n",
        "          bar.set_x(left)\n",
        "          bar.set_width(edges[1] - edges[0])\n",
        "      # Update the height of bars for the previous scores\n",
        "      for bar, height, left in zip(self.prev_hist_bars, prev_counts, prev_edges[:-1]):\n",
        "          bar.set_height(height)\n",
        "          bar.set_x(left)\n",
        "          bar.set_width(prev_edges[1] - prev_edges[0])\n",
        "    # set vline data\n",
        "    self.current_avg_line.set_xdata([avg_score])\n",
        "    if len(self.prev_scores) > 0:\n",
        "        prev_avg_score = np.mean(self.prev_scores[-1])\n",
        "        self.prev_avg_line.set_xdata([prev_avg_score])\n",
        "    self.best_avg_line.set_xdata([self.best_avg_score])\n",
        "\n",
        "    #update the fig\n",
        "    self.fig.legend(loc='outside right upper')\n",
        "    self.fig.canvas.draw()\n",
        "    # Display the output\n",
        "    with self.out:\n",
        "      clear_output()\n",
        "\n",
        "      if self.game.batch_size > 1:\n",
        "        print(f\"Average Score This Time: {avg_score}\")\n",
        "        if len(self.prev_scores) > 0:\n",
        "          prev_avg_score = np.mean(self.prev_scores[-1])\n",
        "          print(f\"Average Score Last Time: {prev_avg_score}\")\n",
        "        print(f\"Best Ever Average Score: {self.best_avg_score}\")\n",
        "      else:\n",
        "        print(f\"Score This Run: {avg_score}\")\n",
        "        if len(self.prev_scores) > 0:\n",
        "          print(f\"Score Last Run: {prev_avg_score}\")\n",
        "        print(f\"Best Score: {self.best_avg_score}\")\n",
        "\n",
        "    self.prev_scores.append(self.scores.copy())\n",
        "\n",
        "\n",
        "  def link_symmetric_widgets(self, change):\n",
        "    # Each row's symmetry permutation indices\n",
        "    symmetry_indices = {\n",
        "      'Up':    [ 0,  1,  2,  1,  3,  4,  4,  3,  5,  6,  5,  7],\n",
        "      'Down':  [ 7,  5,  6,  5,  3,  4,  4,  3,  1,  2,  1,  0],\n",
        "      'Left':  [ 3,  1,  4,  5,  0,  2,  6,  7,  1,  4,  5,  3],\n",
        "      'Right': [ 3,  5,  4,  1,  7,  6,  2,  0,  5,  4,  1,  3]}\n",
        "\n",
        "    if change['new']:  # If the toggle button is activated\n",
        "      base_row = self.text_fields[1].children[1:]  # The 'Up' row\n",
        "      base_perm = np.array(symmetry_indices['Up'])  # Convert to a NumPy array for easier manipulation\n",
        "\n",
        "      for row_label, hbox in zip(self.row_labels, self.text_fields[1:]):  # Include all rows\n",
        "        link_row = hbox.children[1:]  # Skip the label\n",
        "        perm = np.array(symmetry_indices[row_label])  # Convert to a NumPy array for easier manipulation\n",
        "        for i, j in enumerate(perm):\n",
        "          base_index = np.flatnonzero(base_perm == j)[0]\n",
        "          if row_label != 'Up' or base_index != i:  # Skip self-links\n",
        "            link = widgets.jslink((base_row[base_index], 'value'), (link_row[i], 'value'))\n",
        "            self.links.append(link)\n",
        "\n",
        "\n",
        "  def unlink_symmetric_widgets(self):\n",
        "    for link in self.links:\n",
        "      link.unlink()\n",
        "    self.links.clear()\n",
        "\n",
        "\n",
        "  def toggle_symmetry(self, change):\n",
        "    if change.new:\n",
        "      self.link_symmetric_widgets(change)\n",
        "    else:\n",
        "      self.unlink_symmetric_widgets()\n",
        "\n",
        "\n",
        "  def set_best_weights(self, *args):\n",
        "    if self.best_params is not None:\n",
        "      for i, hbox in enumerate(self.text_fields[1:]):\n",
        "        for j, field in enumerate(hbox.children[1:]):\n",
        "          field.value = self.best_params[i][j]\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class ComplexMoveInteractiveGridworld():\n",
        "  \"\"\"\n",
        "  A widget based object for interacting with a gridworld game when more\n",
        "  complicated (fast) moves are allowed\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, gridworld_game, init_board=None, has_fov=False,\n",
        "               radius=2, fov_opaque=False, collect_fov_data=False,\n",
        "               figsize=(6,5), critter_names=['Critter'], players=['human']):\n",
        "    \"\"\"\n",
        "    Initializes a widget based object for interacting with a gridworld game\n",
        "\n",
        "    Args:\n",
        "      gridworld_game: an instance of GridworldGame object\n",
        "        expects this to have batchsize 1\n",
        "      init_board: (optional) a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "        if left out will initialize with a random board state\n",
        "      has_fov: bool, whether or not to display fog of war around the critter\n",
        "      radius: int, number of squares the critter can \"see\" around it\n",
        "      figsize: tuple (int, int), size of the figure\n",
        "      critter_names: a list of strings that determines what the critter is called\n",
        "        in the plot legend, order should align with players\n",
        "      player: a list of either 'human', None, or a player object with a play\n",
        "        method and a critter_index attribute. If 'human' use buttons,  if None\n",
        "        default to making a RandomValidPlayer object, otherwise use the\n",
        "        player class provided to make the player objects and use a start button.\n",
        "        The list needs to be as long as the gridworld_game.num_critters\n",
        "        attribute. Order should align with critter_name.\n",
        "\n",
        "      Note: fov is going to look pretty janky with more than one player, maybe\n",
        "      we get fov to only turn on for the 'active' player?\n",
        "    \"\"\"\n",
        "\n",
        "    # Set GridworldGame object and initialize the board state\n",
        "    self.gwg = gridworld_game\n",
        "    self.has_fov = has_fov\n",
        "    self.radius = radius\n",
        "    self.fov_opaque = fov_opaque\n",
        "    self.percept_len = 2*self.radius*(self.radius+1)\n",
        "    self.collect_fov_data = collect_fov_data\n",
        "    self.figsize = figsize\n",
        "    # initialize players and plotting specs together to ensure alignment\n",
        "    self.players = []\n",
        "    self.any_human_players = False\n",
        "    self.active_player_index = 0\n",
        "    self.crit_specs = []\n",
        "    markers = ['h', 'd']  # hexagon and diamond\n",
        "    colors = sns.color_palette(\"colorblind\")\n",
        "    for i in range(self.gwg.num_critters):\n",
        "      spec = {'marker': markers[i % len(markers)],\n",
        "              'color': colors[i // len(markers) % len(colors)],\n",
        "              'name': critter_names[i],\n",
        "              'int_id': i+1}\n",
        "      self.crit_specs.append(spec)\n",
        "      player = players[i] #implict check that players is at least long enough\n",
        "      if player is None:\n",
        "        self.players.append(RandomValidPlayer(self.gwg, critter_index=i+1))\n",
        "      elif player == 'human':\n",
        "        self.players.append('human')\n",
        "        # right now only ever have on human player with index 1\n",
        "        self.any_human_players = True\n",
        "      else:\n",
        "        # player objects expected to have a critter_index attribute\n",
        "        # we set it appropriately here so it aligns with the players list\n",
        "        # used to create the widget\n",
        "        player.critter_index = i+1\n",
        "        self.players.append(player)\n",
        "    self.final_scores = []\n",
        "    if init_board is None:\n",
        "      self.board_state = self.gwg.get_init_board()\n",
        "    else:\n",
        "      self.board_state = init_board\n",
        "    if self.collect_fov_data is True:\n",
        "      # keep raw records of percept and eating for manipulation later\n",
        "      self.percept_eat_records = []\n",
        "      # keep data in contingency table of how many food items were in\n",
        "      # the percept, and whether or not food was eaten\n",
        "      self.fov_eat_table_data = np.zeros((2, self.percept_len+1))\n",
        "    # Initialize widgets and buttons\n",
        "    self.output = widgets.Output(layout=widgets.Layout(\n",
        "      width = '21.0em', min_width='21.0em', max_width='22.0em',\n",
        "      min_height='10.0em', overflow='auto'))\n",
        "    self.scoreboard = widgets.Output(layout=widgets.Layout(\n",
        "      min_width='12.5em', max_width='18.8em',\n",
        "      min_height='6.3em', overflow='auto'))\n",
        "    self.fov_eat_table_display = widgets.Output(layout=widgets.Layout(\n",
        "      min_width='25.0em', min_height='18.8em', overflow='auto'))\n",
        "    self.up_button = widgets.Button(description=\"Up\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.down_button = widgets.Button(description=\"Down\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.left_button = widgets.Button(description=\"Left\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.right_button = widgets.Button(description=\"Right\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.move_options = ['Stay', 'Up', 'Down', 'Left', 'Right']\n",
        "    self.move1_dropdown = widgets.Dropdown(\n",
        "      options=self.move_options,\n",
        "      value='Stay',\n",
        "      description='First Move Part:')\n",
        "    self.move2_dropdown = widgets.Dropdown(\n",
        "      options=self.move_options,\n",
        "      value='Stay',\n",
        "      description='Second Move Part:')\n",
        "    self.confirm_button = widgets.Button(description=\"Confirm Move\")\n",
        "    self.start_button = widgets.Button(description=\"Start\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.game_running = False\n",
        "\n",
        "    # get plot canvas widgets and other plotting objects\n",
        "    plt.ioff()\n",
        "    if self.collect_fov_data and self.any_human_players:\n",
        "      self.legend_type = None # don't keep regenerating the legend\n",
        "      # do legend separately if showing observations and no human player\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov,\n",
        "       self.b_fig_legend, self.b_ax_legend) = self.gwg.plot_board(\n",
        "          self.board_state, g=0, critter_specs=self.crit_specs,\n",
        "          legend_type='separate', figsize=self.figsize, has_fov=self.has_fov,\n",
        "          radius=self.radius, fov_opaque=self.fov_opaque,\n",
        "          focal_critter_index=self.active_player_index)\n",
        "    elif len(self.players) > 1:\n",
        "      self.legend_type=None # don't keep regenerating the legend\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov,\n",
        "       self.b_fig_legend, self.b_ax_legend) = self.gwg.plot_board(\n",
        "          self.board_state, g=0, critter_specs=self.crit_specs,\n",
        "          has_fov=self.has_fov, legend_type='separate',\n",
        "          radius=self.radius, fov_opaque=self.fov_opaque, figsize=self.figsize,\n",
        "          focal_critter_index=self.active_player_index)\n",
        "    else:\n",
        "      self.legend_type = 'included'\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov\n",
        "        ) = self.gwg.plot_board(self.board_state, g=0,\n",
        "                                critter_specs=self.crit_specs,\n",
        "                                has_fov=self.has_fov,\n",
        "                                fov_opaque=self.fov_opaque,\n",
        "                                radius=self.radius, figsize=self.figsize,\n",
        "                                focal_critter_index=self.active_player_index)\n",
        "    # lump buttons together\n",
        "    self.buttons = widgets.HBox([self.left_button,\n",
        "                               widgets.VBox([self.up_button, self.down_button]),\n",
        "                               self.right_button])\n",
        "    # automatically pick different layouts for different situations\n",
        "    if self.any_human_players:\n",
        "      self.board_and_buttons = widgets.VBox([self.b_fig.canvas, self.buttons])\n",
        "      if self.players[0] != 'human':\n",
        "        # first player isn't human disable direction buttons\n",
        "        self.disable_direction_buttons()\n",
        "\n",
        "      if len(self.players) == 1:\n",
        "        #one human player\n",
        "        self.output_and_score = widgets.HBox([self.scoreboard, self.output])\n",
        "        self.no_table_final_display = widgets.VBox([self.board_and_buttons,\n",
        "                                                  self.output_and_score])\n",
        "        if self.collect_fov_data == True:\n",
        "          # a single human player collecting data\n",
        "          self.final_display = widgets.HBox([self.no_table_final_display,\n",
        "                                           self.fov_eat_table_display])\n",
        "        else: # self.collect_fov_data == False:\n",
        "          # a single human player not collecting data\n",
        "          self.final_display = self.no_table_final_display\n",
        "      else:\n",
        "        # more than one player, at least one of them human\n",
        "        self.V_board_outbput = widgets.VBox([self.board_and_buttons,\n",
        "                                             self.output])\n",
        "        self.V_scoreboard_start_legend = widgets.VBox([\n",
        "        self.scoreboard, self.start_button, self.b_fig_legend.canvas])\n",
        "        self.final_display = widgets.HBox([self.V_board_outbput,\n",
        "                                             self.V_scoreboard_start_legend])\n",
        "    else: # player is some kind of ai\n",
        "      if self.collect_fov_data == True:\n",
        "        # an ai player with recording\n",
        "        # in this case legend is separate\n",
        "        self.V_score_start_output_legend = widgets.VBox([self.scoreboard,\n",
        "          self.start_button,  self.output, self.b_fig_legend.canvas])\n",
        "        self.V_board_table = widgets.VBox([self.b_fig.canvas,\n",
        "                                           self.fov_eat_table_display])\n",
        "        self.final_display = widgets.HBox([self.V_board_table,\n",
        "                                           self.V_score_start_output_legend])\n",
        "      else:\n",
        "        if len(self.players) == 1:\n",
        "          # an ai player without recording\n",
        "          self.H_score_output_start = widgets.HBox([\n",
        "            self.scoreboard, self.output, self.start_button])\n",
        "          self.final_display = widgets.VBox([\n",
        "            self.b_fig.canvas, self.H_score_output_start])\n",
        "        else:\n",
        "          # more than one ai player\n",
        "          self.V_board_outbput = widgets.VBox([self.b_fig.canvas, self.output])\n",
        "          self.V_scoreboard_start_legend = widgets.VBox([\n",
        "              self.scoreboard, self.start_button, self.b_fig_legend.canvas])\n",
        "          self.final_display = widgets.HBox([self.V_board_outbput,\n",
        "                                             self.V_scoreboard_start_legend])\n",
        "\n",
        "    # initialize text outputs\n",
        "    with self.scoreboard:\n",
        "      table = [['High Score:'] + ['--'] * self.gwg.num_critters,\n",
        "               ['Last Score:'] + ['--'] * self.gwg.num_critters,\n",
        "               ['Average Score:'] + ['--'] * self.gwg.num_critters,]\n",
        "      if len(self.players) > 1:\n",
        "        headers = [''] + [f'P{i+1}' for i in range(self.gwg.num_critters)]\n",
        "        print(tabulate(table, headers=headers))\n",
        "      else: # len(self.players) == 1\n",
        "        print(tabulate(table))\n",
        "    with self.output:\n",
        "      if self.any_human_players:\n",
        "        print('Click a button to start playing')\n",
        "      else:\n",
        "        print('Click the start button to run the simulation')\n",
        "    with self.fov_eat_table_display:\n",
        "      printmd(\"**Observations**\")\n",
        "      table_data = [[str(ii),\n",
        "                     str(self.fov_eat_table_data[0,ii]),\n",
        "                     str(self.fov_eat_table_data[1,ii])] for ii in range(11)]\n",
        "      table = ([['Food in Percept', 'Food Not Eaten', 'Food Eaten']] +\n",
        "               table_data)\n",
        "      print(tabulate(table))\n",
        "\n",
        "    # Connect the buttons to functions that do something\n",
        "    self.up_button.on_click(self.on_up_button_clicked)\n",
        "    self.down_button.on_click(self.on_down_button_clicked)\n",
        "    self.left_button.on_click(self.on_left_button_clicked)\n",
        "    self.right_button.on_click(self.on_right_button_clicked)\n",
        "    self.start_button.on_click(self.on_start_button_clicked)\n",
        "\n",
        "\n",
        "  def button_output_update(self, which_button):\n",
        "    old_board = self.board_state.copy()\n",
        "    next_player_index = (self.active_player_index + 1) % len(self.players)\n",
        "    # index of players is 0 through num_critter-1,\n",
        "    # same player represented by value of index + 1 in\n",
        "    old_scores = old_board['scores'][0]\n",
        "    if self.collect_fov_data is True:\n",
        "      batch_size, n_rows, n_cols = old_board['pieces'].shape\n",
        "      b = GridworldBoard(batch_size, n_rows, n_cols,\n",
        "                         self.gwg.num_food, self.gwg.lifetime,\n",
        "                         rng=self.gwg.rng)\n",
        "      b.set_state(old_board)\n",
        "      percept = b.get_perceptions(self.radius)[0]\n",
        "\n",
        "    direction = None\n",
        "    if (isinstance(self.players[self.active_player_index], str) and\n",
        "        'human' in self.players[self.active_player_index]):\n",
        "      direction = which_button\n",
        "      self.board_state = self.gwg.critter_oriented_get_next_state(\n",
        "          self.board_state, self.active_player_index+1, [direction])\n",
        "    else:\n",
        "      a_player, _, _ = self.players[self.active_player_index].play(old_board)\n",
        "      self.board_state = self.gwg.get_next_state(\n",
        "          self.board_state, self.active_player_index+1, a_player)\n",
        "      a_r = np.floor_divide(a_player[0], self.gwg.n_cols)\n",
        "      a_c = np.remainder(a_player[0], self.gwg.n_cols)\n",
        "\n",
        "    new_scores = self.board_state['scores'][0] #first batch first critter type\n",
        "    rounds_left = self.board_state['rounds_left'][0]\n",
        "    num_moves = np.floor(self.gwg.lifetime -\n",
        "                         rounds_left / self.gwg.num_critters)\n",
        "    if new_scores[self.active_player_index] > old_scores[self.active_player_index]:\n",
        "      #eating happened\n",
        "      eating_string = \"They ate the food/prey there!\"\n",
        "      did_eat = 1\n",
        "    else: #eating didn't happen\n",
        "      eating_string = \"There's no food/prey there.\"\n",
        "      did_eat = 0\n",
        "    row, col = self.gwg.get_critter_rc(self.board_state, 0,\n",
        "                                       self.active_player_index+1)\n",
        "    (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov\n",
        "     ) = self.gwg.plot_board(self.board_state, g=0,\n",
        "                             fig=self.b_fig, ax=self.b_ax,\n",
        "                             critter_specs=self.b_crit_specs, food=self.b_food,\n",
        "                             fov=self.b_fov, has_fov=self.has_fov,\n",
        "                             fov_opaque=self.fov_opaque,\n",
        "                             radius=self.radius, legend_type=self.legend_type,\n",
        "                             focal_critter_index=next_player_index)\n",
        "    if self.collect_fov_data is True:\n",
        "      p_e_data = {'perception': percept.copy(),\n",
        "                  'state': old_board,\n",
        "                  'did_eat': bool(did_eat)}\n",
        "      self.percept_eat_records.append(p_e_data)\n",
        "      percept_int = np.sum(percept==-1) # number of food items in FoV\n",
        "      self.fov_eat_table_data[did_eat, percept_int] += 1\n",
        "\n",
        "    with self.output:\n",
        "      clear_output()\n",
        "      if len(self.players) == 1:\n",
        "        if direction is not None:\n",
        "          print(\"The critter (tried) to move \" +\n",
        "                direction +\n",
        "                \" and is now at ({}, {}).\".format(row, col))\n",
        "        else:\n",
        "          print(\"The critter (tried) to move \" +\n",
        "                \"to \" + \"({}, {})\".format(a_r, a_c) +\n",
        "                \" and is now at ({}, {}).\".format(row, col))\n",
        "        print(eating_string)\n",
        "        print(\"Rounds Left: {}\\nScores: {:.2f}\".format(\n",
        "            rounds_left, new_scores[self.active_player_index]))\n",
        "      else: # more than one players\n",
        "        if direction is not None:\n",
        "          print(\"Critter {} (tried) to move \".format(self.active_player_index+1) +\n",
        "                direction +\n",
        "                \" and is now at ({}, {}).\".format(row, col))\n",
        "        else:\n",
        "          print(\"Critter {} (tried) to move \".format(self.active_player_index+1) +\n",
        "                \"to \" + \"({}, {})\".format(a_r, a_c) +\n",
        "                \" and is now at ({}, {}).\".format(row, col))\n",
        "        print(eating_string)\n",
        "        print(\"Rounds Left: {}\\nScores: {}\".format(\n",
        "            rounds_left, new_scores))\n",
        "    if rounds_left == 0:\n",
        "      self.final_scores.append(new_scores)\n",
        "      self.game_running = False\n",
        "      with self.output:\n",
        "        clear_output\n",
        "        print('Game Over. Final Score {}'.format(new_scores))\n",
        "        print('Resetting the board for another game')\n",
        "        self.board_state = self.gwg.get_init_board()\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov\n",
        "       ) = self.gwg.plot_board(self.board_state, 0, self.b_fig, self.b_ax,\n",
        "                               self.b_crit_specs, self.b_food, self.b_fov,\n",
        "                               has_fov=self.has_fov, radius=self.radius,\n",
        "                               fov_opaque=self.fov_opaque,\n",
        "                               legend_type=self.legend_type,\n",
        "                               focal_critter_index=next_player_index)\n",
        "      # start_button can be clicked now\n",
        "      self.start_button.disabled = False\n",
        "    with self.scoreboard:\n",
        "        clear_output()\n",
        "        print('Games Played: ' + str(len(self.final_scores)))\n",
        "        if len(self.players) == 1:\n",
        "          if len(self.final_scores) > 0:\n",
        "            table = [\n",
        "              ['High Score:', str(np.max(np.array(self.final_scores)))],\n",
        "              ['Last Score:', str(self.final_scores[-1])],\n",
        "              ['Average Score',\n",
        "              '{:.2f}'.format(np.mean(np.array(self.final_scores)))]]\n",
        "          else:\n",
        "            table = [['High Score:', '--'],\n",
        "                     ['Last Score:', '--'],\n",
        "                     ['Average Score:', '--']]\n",
        "          print(tabulate(table))\n",
        "        else: # len(self.players) > 1\n",
        "          headers = [''] + [f'P{i+1}' for i in range(self.gwg.num_critters)]\n",
        "          if len(self.final_scores) > 0:\n",
        "            table = []\n",
        "            # Assuming the batch size is 1 for now\n",
        "            current_scores = self.final_scores[-1]\n",
        "            max_scores = np.max(np.array(self.final_scores), axis=0)\n",
        "            average_scores = np.mean(np.array(self.final_scores), axis=0)\n",
        "            table.append(['High Scores:'] +\n",
        "              [str(score) for score in max_scores])\n",
        "            table.append(['Last Scores:'] +\n",
        "              [str(score) for score in current_scores])\n",
        "            table.append(['Average Scores:'] +\n",
        "              ['{:.2f}'.format(score) for score in average_scores])\n",
        "          else:\n",
        "            table = [\n",
        "              ['High Score:'] + ['--'] * self.gwg.num_critters,\n",
        "              ['Last Score:'] + ['--'] * self.gwg.num_critters,\n",
        "              ['Average Score:'] + ['--'] * self.gwg.num_critters,]\n",
        "          print(tabulate(table, headers=headers))\n",
        "\n",
        "    with self.fov_eat_table_display:\n",
        "      clear_output()\n",
        "      printmd(\"**Observations**\")\n",
        "      table_data = [[str(ii),\n",
        "                     str(self.fov_eat_table_data[0,ii]),\n",
        "                     str(self.fov_eat_table_data[1,ii])] for ii in range(11)]\n",
        "      table = ([['Food in Percept', 'Food Not Eaten', 'Food Eaten']] +\n",
        "               table_data)\n",
        "      print(tabulate(table))\n",
        "\n",
        "    # last thing after all display stuff is done\n",
        "    self.update_player_and_rounds()\n",
        "\n",
        "  def disable_direction_buttons(self):\n",
        "    self.up_button.disabled = True\n",
        "    self.down_button.disabled = True\n",
        "    self.left_button.disabled = True\n",
        "    self.right_button.disabled = True\n",
        "\n",
        "  def enable_direction_buttons(self):\n",
        "    self.up_button.disabled = False\n",
        "    self.down_button.disabled = False\n",
        "    self.left_button.disabled = False\n",
        "    self.right_button.disabled = False\n",
        "\n",
        "  def update_player_and_rounds(self):\n",
        "    \"\"\"Update the player index and decrement rounds if a full loop is completed.\"\"\"\n",
        "    self.active_player_index = (self.active_player_index + 1) % len(self.players)\n",
        "    if self.active_player_index == len(self.players) - 1:\n",
        "      self.board_state['rounds_left'] -= 1\n",
        "\n",
        "  def human_ai_player_loop(self, direction):\n",
        "    self.disable_direction_buttons()  # Disable buttons, no double clicks\n",
        "    self.game_running = True\n",
        "    # Execute the move of the human who clicked the button\n",
        "    self.button_output_update(direction)\n",
        "    # Move to the next player\n",
        "    # Do AI moves if there are any\n",
        "    while self.players[self.active_player_index] != 'human' and self.game_running:\n",
        "      self.button_output_update('tbd')\n",
        "      time.sleep(0.5)\n",
        "    # Next player is human turn buttons on for them\n",
        "    self.enable_direction_buttons()\n",
        "\n",
        "  def start_game(self):\n",
        "    # If first player is AI start button kicks off this loop\n",
        "    self.game_running = True\n",
        "    while self.players[self.active_player_index] != 'human' and self.game_running:\n",
        "      self.button_output_update('tbd')\n",
        "      time.sleep(0.5)\n",
        "    # Next player is human, turn buttons on for them\n",
        "    self.enable_direction_buttons()\n",
        "\n",
        "  def on_up_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('up')\n",
        "\n",
        "  def on_down_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('down')\n",
        "\n",
        "  def on_left_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('left')\n",
        "\n",
        "  def on_right_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('right')\n",
        "\n",
        "  def on_start_button_clicked(self, *args):\n",
        "    self.start_button.disabled = True\n",
        "    self.start_game()\n",
        "    self.enable_direction_buttons()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "LMSz1v80_Ron"
      },
      "source": [
        "# 1.3.3.1: Eat and Be Eaten\n",
        "\n",
        "Previously, in sequences 1.1.3 and 1.2.2, we touched upon how competition (or interactions) with other organisms can play a crucial role in the environment an organism adapts its behavior to. Now that we have a richer optimization and evolutionary framework we're going to dig into how these kinds of interactions really exacerbate optimization or evelutionary search. We are going to stick with our simple strike-no-strike scenario from sequences 1.3.1 and 1.3.2, but modify it in a few significant ways. Previously our population of lurk-and-strike predators were the only thing evolving, however, now we are going to consider not just the lurk-and-strik predators, but also their prey population. Instead of treating the markers of the food items as an environmental given, we are going to let these markers emerge from the (highly abstracted) evolutionary process of the prey population. Now, we have two distinct populations facing two distinct problems: the predators with their strike-no-strike game, and the prey item tyring to remain undetectable."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will continue to use the 'strike-no-strike' decision problem of the last two sequences, again with a specific environment tailored to streamline our simulations and reasoning. Our prey organism will have $2n$ chemosensory receptors, each corresponding to $2n$ possible food/non-food chemical markers in the environment. The expression of these receptors is determined by $2n$ distinct genetic switches, represented as a bit-string $g$ of length $n$ with 1 corresponding to expression and 0 to absence of the corresponding receptor.\n",
        "\n",
        "The big difference from before is that now the population of the prey species (food items) is also evolving. We asssume there are some constraints on what is possible, i.e. if the food item had no markers, it would be undetectable and never eaten, however. So for the sake of simplicity and an interesting model we assume that the prey species is contrained to express exactly $n$, that is half, of the $2n$ possible markers. To operationalize this in a more tractable way, we further assume that each of the $n$ markers expressed by the prey species comes in one of two possible (and mutually exclusive) flavours, e.g. for marker 1, the prey expresses either variant $a$ of $b$ for marker 2, the prey expresses either variant $c$ or $d$ and so on. This means that there will be $2^n$ distinct patterns of markers possible for the prey species. The marker expression pattern for the prey species will be determined by $n$ genetic switches, specifying which of two possible variants is expressed for each of $n$ different marker types.\n",
        "\n",
        "As in the previous sequence the non-food items will closely mimic possible food items. Specifically, evey non-food item will have a marker pattern which is identical to that of a food item, but with one $n$ possible marker types not expressed. Thus there will be $n \\cdot 2^{n-1}$ distinct such non-food item marker patterns, each represented as bitstrings consisting of $n+1$ zeros and $n-1$ ones.\n",
        "\n",
        "Recall a successful strike at edible food yields a reward, $r$ and conversely, a missed strike has a cost, $c$. Not striking (both true and false negative) yield zero cost or reward. We think of these costs and rewards as a constant increment by $r$ or decrement by $c$ respectively to offspring quality and/or quantity. The organism's decision rule is to strike only if ***all*** of its receptors pick up a marker and refrains from striking if ***any*** of its receptors are left unactivated. (When the organism has no receptors technically all of its non-existent receptors are activated and so it strikes in all situations.)\n",
        "\n",
        "With this decision rule, in this environment, the organism will only strike at a its prey if all of its receptor are activated by that prey sepecies. Thus expressing a receptor which is not matched to a corresponding marker on the prey will result in missed opportunities to eat. Conversely, expressing receptors that are present on a prey species will supress false positive strikes and save the predator from the cost of false postive strikes. Already the fitness score function for the predator is much more complex, as it will depend on the frequencies of the various prey types in the prey population, which will themsleves be the result of an ongoing evoltionary process.\n",
        "\n",
        "Let $p$ be the probability of encountering a food item and $1-p$ be the probability of an encounter with a non-food item. Given $k$ trials, an organism is expected to encounter $p k$ food items. However, each of these food items will express a different set of markers, according to the current (genetic) composition of the prey population. We let $h\\in\\mathcal{H}$ denote a specfic pattern of markers for a food item, within the set $\\mathcal{H}$ of $2^n$ possible marker configurations for the prey species. (0 denotes absence of a marker, 1 presence). Then we let $\\rho(h)$ denote the frequency of the $h$ type in the prey population, and we assume that probability of encounter for predators is equal to the frequency (abundance) of this type in the prey population. Then the expected reward from successful eating for a predator is\n",
        "\n",
        "$$ p k r \\sum_{h\\in \\mathcal{H}} \\left( \\rho(h) \\prod_{i=1}^{2n} \\mathrm{I}_{\\{g_i = g_i h_i\\}} \\right)$$\n",
        "\n",
        "This needs a little bit of unpacking. There are $pk$ exected encounters with food items. The probability of encountering any particular type $h$ is given by $\\rho(h)$. In general $\\rho(\\cdot)$ is used to represent the density function of the argument variable. Recall that $\\mathrm{I}_{\\{g_i = g_i h_i\\}}$ is an indicator function which takes a value of $1$ when the condition in the subscript, in this case $g_i = g_ih_i$ is true, and a value of $0$ when the condition in the subscript is false. Thus the product of these indicators is $1$ only if for every marker type where the predator expresses a receptor has a corresponding marker on the food item. The product of these indicators will be zero if any of the predator's receptors does not have a corresponding marker on the food-item. Note that markers on the food item that do not have corresponding receptors expressed by the predator have no bearing, i.e. $g_i = g_i h_i$ regardless of the value of $h_i$ when $g_i = 0$, only when $g_i =1$ is the value of $h_i$ relevant.\n",
        "\n",
        "Now turning our attention to the cost of false strikes. We start by letting $m\\in \\mathcal{M}$ denote the various marker patters for non-food items, each with equal probability of encounter\n",
        "\n",
        "$$(1-p)k c \\sum_{m\\in\\mathcal{M}} \\frac{1}{n \\cdot 2^{n-1}} \\left( \\prod_{i=1}^{2n} \\mathrm{I}_{\\{g_i = g_i m_i\\}} \\right)$$\n",
        "\n",
        "Unpacking this, we have that the predator can expect to encounter $(1-p)k$ non-food items, with each of the non-food item types encountered with equal probability, $\\frac{1}{n \\cdot 2^{n-1}}$. The logic with the indicator function is the same as with the food items, but now striking causes a cost. The total expected gamete quality/quantity increment is\n",
        "\n",
        "$$pkr \\sum_{h\\in\\mathcal{H}} \\rho(h) \\left( \\prod_{i=1}^{2n} \\mathrm{I}_{\\{g_i = g_i h_i\\}} \\right) - (1-p)k c \\sum_{m\\in\\mathcal{M}} \\frac{1}{n \\cdot 2^{n-1}} \\left( \\prod_{i=1}^{2n} \\mathrm{I}_{\\{g_i = g_i m_i\\}} \\right)$$\n",
        "\n",
        "We can further simplify, setting $p = \\frac{1}{2}$ and $c=r= \\frac{2}{k}$, and assuming that $k$ is very large. Even though the gamete increment for any one individual is a random variable dependent on the particular number and type food and non-food items they encounter and which non-food items for large enough $k$ this randomness averages out and we will treat the gamete increment of an individual as a deterministic function of their genotype and the environment, specifically\n",
        "\n",
        "$$ z_{pred}(g) = \\sum_{h\\in\\mathcal{H}} \\rho(h) \\left( \\prod_{i=1}^{2n} \\mathrm{I}_{\\{g_i = g_i h_i\\}} \\right) - \\sum_{m\\in\\mathcal{M}} \\frac{1}{n \\cdot 2^{n-1}} \\left( \\prod_{i=1}^{2n} \\mathrm{I}_{\\{g_i = g_i m_i\\}} \\right) $$\n",
        "\n",
        "If there was only one food type, the optimal predator would express all the receptors corresponding to the one food type, receving an inrement of $1$ from eating and would filter all of non-food items recieving a decrement of $0$ for a total score of $1$, in this highly simplified scenario.\n",
        "\n",
        "In the case where the food marker types are perfectly evenly distributed the best a predator can do is express a single receptor, which will enable detection of half of the food-types, whereas only $\\frac{1}{2} \\cdot \\frac{n-1}{n}$ of the non-food types will be struck at for a total score of $\\frac{1}{2n}$ in this other highly simplified secnario.\n",
        "\n",
        "That is how the fitness score of the predator species is computed, but what of the fitness score for the prey species. Here we take the fitness score of the prey speices to be a function of how frequently they are preyed upon relative to the rest of their species. If a prey type is preyed upon in every food encounter they find themselves, (as a result of the receptor patterns expressed by the current predator population) they have a fitness score of $0$. Conversely if a prey type is never preyed upon (again as a result of the receptor patterns of the current predator population) they recieve a fitness score of $1$.\n",
        "\n",
        "$$ z_{prey}(h) = 1 - \\sum_{g\\in\\mathcal{G}} \\rho(g) \\left( \\prod_{i=1}^{2n} \\mathrm{I}_{\\{g_i = g_i h_i\\}} \\right) $$\n",
        "\n",
        "Here $\\rho(g)$ gives the frequencies of the different predator genotypes $g$ in the set of all possible predator genotypes $\\mathcal{G}$.\n",
        "\n",
        "Now that we know how fitness scores are determined we're ready to code up an evolutionary simulation."
      ],
      "metadata": {
        "id": "_InlYDaBqUnP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def pred_prey_coev_simulation(\n",
        "  pred_pop_size = 50, prey_pop_size = 200, n_gen = 100, n_markers = 2,\n",
        "  pred_selection_type = 'softmax', prey_selection_type = 'softmax',\n",
        "  pred_proportion_scale = 20, pred_proportion_shift = 1,\n",
        "  prey_proportion_scale = 20, prey_proportion_shift = 1,\n",
        "  pred_softmax_temp = 0.5, prey_softmax_temp = 0.5,\n",
        "  pred_truncation_threshold = 0.5,\n",
        "  prey_truncation_threshold = 0.5,\n",
        "  pred_has_mutation = True, pred_has_recombination = True,\n",
        "  prey_has_mutation = True, prey_has_recombination = True,\n",
        "  pred_has_distinct_types = True, prey_has_distinct_types = True,\n",
        "  pred_recombination_type = 'crossover',\n",
        "  prey_recombination_type = 'crossover',\n",
        "  pred_has_assortative_pairing = True,\n",
        "  prey_has_assortative_pairing = True,\n",
        "  pred_mutation_rate = 0.005, prey_mutation_rate = 0.005,\n",
        "  density_depletion_max=0.5,\n",
        "  track_marker_receptor_frequencies=True,\n",
        "  reward=1, cost=1,\n",
        "  seed=None):\n",
        "  \"\"\"\n",
        "  Simulates the co-evolutionary process in predators and prey populations.\n",
        "  \"\"\"\n",
        "  # Set seed\n",
        "  rng = np.random.default_rng(seed)\n",
        "\n",
        "  n_rcpt = 2 * n_markers\n",
        "  # Initialize the predator population\n",
        "  # Each row of this array is a different individual predator\n",
        "  pred_population = rng.integers(0, 2, size=(pred_pop_size, n_rcpt+2),\n",
        "                                 dtype=np.bool_)\n",
        "  prey_population = rng.integers(0, 2, size=(prey_pop_size, n_markers+2),\n",
        "                                 dtype=np.bool_)\n",
        "  # last two cols are for mutation and recombination respectively\n",
        "  if pred_has_mutation:\n",
        "    if pred_has_distinct_types:\n",
        "      # some predators mutate some don't\n",
        "      pass # the random initialization is good\n",
        "    else:\n",
        "      # every predator mutates\n",
        "      pred_population[:, -2] = True\n",
        "  else:\n",
        "    # no predators mutates\n",
        "    pred_population[:, -2] = False\n",
        "  if prey_has_mutation:\n",
        "    if prey_has_distinct_types:\n",
        "      # some prey mutate some don't\n",
        "      pass # the random initialization is good\n",
        "    else:\n",
        "      # every prey mutates\n",
        "      prey_population[:, -2] = True\n",
        "  else:\n",
        "    # no prey mutates\n",
        "    prey_population[:, -2] = False\n",
        "\n",
        "  if pred_has_recombination:\n",
        "    if pred_has_distinct_types:\n",
        "      pass # the random initialization is good\n",
        "    else:\n",
        "      # every predator recombines\n",
        "      pred_population[:, -1] = True\n",
        "  else:\n",
        "    # no predators recombines\n",
        "    pred_population[:, -1] = False\n",
        "  if prey_has_recombination:\n",
        "    if prey_has_distinct_types:\n",
        "      pass # the random initialization is good\n",
        "    else:\n",
        "      # every prey recombines\n",
        "      prey_population[:, -1] = True\n",
        "  else:\n",
        "    # no prey recombines\n",
        "    prey_population[:, -1] = False\n",
        "\n",
        "  #initialize non-food markers\n",
        "  non_food_markers = {}\n",
        "  base_marker_patterns = {}\n",
        "  num_base_patterns = 2 ** (n_markers - 1)\n",
        "  for i in range(num_base_patterns):\n",
        "    # A representation of the marker patterns for each type\n",
        "    binary_array = np.zeros((n_markers-1, 2), dtype=np.bool_)\n",
        "    binary_str = format(i, f'0{n_markers-1}b')\n",
        "    for idx, bit in enumerate(binary_str):\n",
        "      binary_array[idx, int(bit)] = True\n",
        "    base_marker_patterns[i]= binary_array.copy()\n",
        "  non_food_marker_id = 0\n",
        "  for i in range(n_markers):\n",
        "    for _, base_pattern in base_marker_patterns.items():\n",
        "      extended_pattern = np.zeros((n_markers, 2), dtype=np.bool_)\n",
        "      extended_pattern[:i, :] = base_pattern[:i, :]\n",
        "      extended_pattern[i+1:, :] = base_pattern[i:, :]\n",
        "      non_food_markers[non_food_marker_id] = extended_pattern.flatten()\n",
        "      non_food_marker_id += 1\n",
        "\n",
        "  expected_id = n_markers * 2**(n_markers-1)\n",
        "  if non_food_marker_id == expected_id:\n",
        "    pass\n",
        "    #print(f\"Check passed: non_food_marker_id is {non_food_marker_id}, as expected.\")\n",
        "  else:\n",
        "    print(f\"Check failed: non_food_marker_id is {non_food_marker_id}, expected {expected_id}.\")\n",
        "  non_food_patterns_array = np.array([nfm for nfm in non_food_markers.values()])\n",
        "\n",
        "  # ensure even divisors/multiples for deterministic truncation with predators\n",
        "  def calc_offspring_per_parent(pop_size, truncation_threshold):\n",
        "    num_parents = pop_size * (1 - truncation_threshold)\n",
        "    offspring_per_parent = pop_size / num_parents\n",
        "    # Check if the numbers are close to integers\n",
        "    if not (np.isclose(num_parents, np.round(num_parents)) and np.isclose(offspring_per_parent, np.round(offspring_per_parent))):\n",
        "      print(truncation_threshold)\n",
        "      print(num_parents)\n",
        "      print(offspring_per_parent)\n",
        "      raise ValueError(\"For deterministic truncation, both pop_size * (1-truncation_threshold) and 1/(1-truncation_threshold) must result in integers.\")\n",
        "    num_parents = int(num_parents)\n",
        "    offspring_per_parent = int(offspring_per_parent)\n",
        "    return offspring_per_parent, num_parents\n",
        "\n",
        "  pred_offspring_per_parent, pred_num_parents = calc_offspring_per_parent(pred_pop_size, pred_truncation_threshold)\n",
        "  prey_offspring_per_parent, prey_num_parents = calc_offspring_per_parent(prey_pop_size, prey_truncation_threshold)\n",
        "\n",
        "  # Track statistics of the population over generations.\n",
        "  pred_results = {\n",
        "    'mean_hist': np.zeros(n_gen),\n",
        "    'var_hist': np.zeros(n_gen),\n",
        "    'upper_quartile_hist': np.zeros(n_gen),\n",
        "    'lower_quartile_hist': np.zeros(n_gen),\n",
        "    'type_count_hist': {'mutator_non_recombinator': [0] * n_gen,\n",
        "                        'recombinator_non_mutator': [0] * n_gen,\n",
        "                        'neither': [0] * n_gen,\n",
        "                        'both': [0] * n_gen},\n",
        "    'type_mean_score_hist': {'mutator_non_recombinator': [0] * n_gen,\n",
        "                             'recombinator_non_mutator': [0] * n_gen,\n",
        "                             'neither': [0] * n_gen,\n",
        "                             'both': [0] * n_gen},\n",
        "    'rm_freq_history': collections.defaultdict(lambda: [0] * n_gen),\n",
        "    'rm_fitness_history': collections.defaultdict(lambda: [None] * n_gen)\n",
        "  }\n",
        "\n",
        "  prey_results = {\n",
        "    'mean_hist': np.zeros(n_gen),\n",
        "    'var_hist': np.zeros(n_gen),\n",
        "    'upper_quartile_hist': np.zeros(n_gen),\n",
        "    'lower_quartile_hist': np.zeros(n_gen),\n",
        "    'type_count_hist': {'mutator_non_recombinator': [0] * n_gen,\n",
        "                        'recombinator_non_mutator': [0] * n_gen,\n",
        "                        'neither': [0] * n_gen,\n",
        "                        'both': [0] * n_gen},\n",
        "    'type_mean_score_hist': {'mutator_non_recombinator': [0] * n_gen,\n",
        "                             'recombinator_non_mutator': [0] * n_gen,\n",
        "                             'neither': [0] * n_gen,\n",
        "                             'both': [0] * n_gen},\n",
        "    'rm_freq_history': collections.defaultdict(lambda: [0] * n_gen),\n",
        "    'rm_fitness_history': collections.defaultdict(lambda: [None] * n_gen)\n",
        "  }\n",
        "\n",
        "  #different helper function for the simulation loop\n",
        "  def update_history(population, scores, results,\n",
        "                     has_distinct_types, generation):\n",
        "    # population level stats\n",
        "    mean_ = np.mean(scores)\n",
        "    var_ = np.var(scores)\n",
        "    results['mean_hist'][generation] = mean_\n",
        "    results['var_hist'][generation] = var_\n",
        "    results['lower_quartile_hist'][generation] = np.percentile(scores, 25)\n",
        "    results['upper_quartile_hist'][generation] = np.percentile(scores, 75)\n",
        "\n",
        "    # mutant recomb combination statistics\n",
        "    if has_distinct_types:\n",
        "      mutation_labels = population[:, -2]\n",
        "      recombination_labels = population[:, -1] == -1\n",
        "      mutator_non_recombinator = mutation_labels & ~recombination_labels\n",
        "      recombinator_non_mutator = ~mutation_labels & recombination_labels\n",
        "      neither = ~mutation_labels & ~recombination_labels\n",
        "      both = mutation_labels & recombination_labels\n",
        "      type_label_indices_dict = {\n",
        "        'mutator_non_recombinator': mutator_non_recombinator,\n",
        "        'recombinator_non_mutator': recombinator_non_mutator,\n",
        "        'neither': neither,\n",
        "        'both': both}\n",
        "      for type_label, type_indices in type_label_indices_dict.items():\n",
        "        # Count individuals of this type\n",
        "        results['type_count_hist'][type_label][generation] = np.sum(type_indices)\n",
        "        # Calculate mean fitness for this type\n",
        "        if np.any(type_indices):\n",
        "          type_mean_score = np.mean(scores[type_indices])\n",
        "        else:\n",
        "          type_mean_score = 0\n",
        "        results['type_mean_score_hist'][type_label][generation] = type_mean_score\n",
        "\n",
        "    if track_marker_receptor_frequencies:\n",
        "      pop_counter = collections.Counter([tuple(ind[:-2]) for ind in population])\n",
        "      rm_to_scores = collections.defaultdict(list)\n",
        "      for ind, score in zip(population[:,:-2], scores):\n",
        "        rm_key = tuple(ind)\n",
        "        rm_to_scores[rm_key].append(score)\n",
        "      for rm, freq in pop_counter.items():\n",
        "        results['rm_freq_history'][rm][generation] = freq\n",
        "      for rm, scores in rm_to_scores.items():\n",
        "        results['rm_fitness_history'][rm][generation] = np.mean(scores)\n",
        "\n",
        "\n",
        "  def calculate_scores(pred_population, prey_population,\n",
        "                       non_food_patterns_array, reward, cost):\n",
        "    # Calculate scores for each pred genotype\n",
        "    pred_receptors = pred_population[:, :n_rcpt].copy() # predator population size x 2*n_markers receptor expression\n",
        "    prey_marker_genome = prey_population[:, :n_markers]\n",
        "    # expand marker genome to pattern that aligns with predator receptors\n",
        "    # specifically '1' -> '10' and '0' -> '01'\n",
        "    prey_marker_patterns = np.zeros((prey_pop_size, 2 * n_markers), dtype=np.bool_)\n",
        "    prey_marker_patterns[:, ::2] = prey_marker_genome\n",
        "    prey_marker_patterns[:, 1::2] = 1 - prey_marker_genome\n",
        "    # pred_receptors: Add an axis to make it (predator population size, 1, 2*n_markers)\n",
        "    pred_receptors_expanded = pred_receptors[:, np.newaxis, :]\n",
        "    # Broadcasting comparison automatically expandeds pattern arrays\n",
        "    # element i,j,k indicates whether the kth receptor of the ith predator\n",
        "    # matches the kth marker of the jth prey/non_food pattern\n",
        "    food_matches = (pred_receptors_expanded == prey_marker_patterns) # pred_pop_size x prey_pop_size x 2*n_markers)\n",
        "    food_match_or_no_receptor = np.logical_or(food_matches, ~pred_receptors_expanded)\n",
        "    non_food_matches = (pred_receptors_expanded == non_food_patterns_array)\n",
        "    non_food_match_or_no_receptor = np.logical_or(non_food_matches, ~pred_receptors_expanded)\n",
        "    # whether ith predator strikes jth prey/non-food type or not\n",
        "    food_strikes = np.all(food_match_or_no_receptor, axis=2) # pred_pop_size x 2**(n_markers+2)\n",
        "    non_food_strikes = np.all(non_food_match_or_no_receptor, axis=2)\n",
        "    # calcuate predation load for each prey type\n",
        "    predation_load = np.mean(food_strikes, axis=0)\n",
        "    prey_scores = 1 - predation_load\n",
        "    # density dependence, i.e. if every predator eats a food type, there are\n",
        "    # fewer of those around so less reward,\n",
        "    # Here depletion is linear and maxes out at density_depletion_max\n",
        "    pred_prey_density_scaling = 1 - density_depletion_max * predation_load\n",
        "    # density scaled strikes\n",
        "    density_scaled_food_strikes = np.dot(food_strikes, pred_prey_density_scaling)\n",
        "    eating_rewards = density_scaled_food_strikes * reward\n",
        "    scaled_non_food_strikes = non_food_strikes.astype(float) / non_food_strikes.shape[1]\n",
        "    false_strike_costs = np.sum(scaled_non_food_strikes, axis=1) * cost\n",
        "    pred_scores = eating_rewards - false_strike_costs\n",
        "    return pred_scores, prey_scores\n",
        "\n",
        "\n",
        "  def parent_selection_recombination_mutation(\n",
        "    population, scores, selection_type,\n",
        "    proportion_scale, proportion_shift,\n",
        "    softmax_temp,\n",
        "    truncation_threshold, offspring_per_parent, num_parents,\n",
        "    has_assortative_pairing, recombination_type, mutation_rate,\n",
        "    rng):\n",
        "    \"\"\"\n",
        "    Perform parent selection, recombination, and mutation on a population for an evolutionary simulation.\n",
        "\n",
        "    Parameters:\n",
        "    - population (pop_size x genome_length np.bool_ array): Current population's genomes.\n",
        "    - scores (pop_size float array): Fitness scores corresponding to each individual in the population.\n",
        "    - selection_type (str): Method of parent selection ('proportional', 'softmax', 'proportional truncation', 'deterministic truncation').\n",
        "    - proportion_scale (float), proportion_shift (float): Scaling and shifting scores for proportional selection.\n",
        "    - softmax_temp (float): Temperature parameter for softmax selection.\n",
        "    - truncation_threshold (float): Threshold for truncation selection methods.\n",
        "    - num_parents (int): Number of parents to selected in truncation selection\n",
        "    - offspring_per_parent (int): Number of offspring per parent in truncation selection\n",
        "    - has_assortative_pairing (bool): If true, pairs are formed based on similarity.\n",
        "    - recombination_type (str): Method of recombination ('random', 'crossover').\n",
        "    - mutation_rate (float): Probability of point mutations per bit in genome.\n",
        "    - rng (np.random.Generator): Random number generator for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "    - np.bool_ array: The new population after selection, recombination, and mutation.\n",
        "    has same shape as population.\n",
        "    \"\"\"\n",
        "    pop_size, genome_length = population.shape\n",
        "\n",
        "    # Calculate selection probabilites based on scores according to selection_type\n",
        "    if selection_type == 'proportional':\n",
        "      pos_scores = np.where(scores < 0, 0, scores)\n",
        "      scale_shift_scores = (pos_scores * proportion_scale) + proportion_shift\n",
        "      if np.sum(scores) > 0:\n",
        "        prob_scores = scale_shift_scores / np.sum(scale_shift_scores)\n",
        "      else:\n",
        "        prob_scores = np.ones_like(scores) / len(scores)\n",
        "    elif selection_type == 'softmax':\n",
        "      stabilized_scores = scores - np.max(scores)\n",
        "      exp_scaled_scores = np.exp(stabilized_scores / softmax_temp)\n",
        "      prob_scores = exp_scaled_scores / np.sum(exp_scaled_scores)\n",
        "    elif selection_type == 'proportional truncation':\n",
        "      pos_scores = np.where(scores < 0, 0, scores)\n",
        "      trunc_scores = np.zeros_like(scores)\n",
        "      selected = scores >= np.quantile(scores, truncation_threshold)\n",
        "      trunc_scores[selected] = pos_scores[selected]\n",
        "      if np.sum(trunc_scores) > 0:\n",
        "        prob_scores = trunc_scores / np.sum(trunc_scores)\n",
        "      else:\n",
        "        prob_scores = np.ones_like(scores) / len(scores)\n",
        "    elif selection_type == 'deterministic truncation':\n",
        "      # No prob scores since deterministic\n",
        "      threshold_score = np.quantile(scores, truncation_threshold)\n",
        "      # Indices of individuals who meet or exceed the threshold score\n",
        "      eligible_indices = np.where(scores >= threshold_score)[0]\n",
        "      # If there are more eligible individuals than needed, take only the top\n",
        "      # num_parents individuals\n",
        "      selected_indices = sorted(eligible_indices, key=lambda x: scores[x], reverse=True)[:num_parents]\n",
        "      selected_population = population[selected_indices]\n",
        "      selected_scores = scores[selected_indices]\n",
        "      # Recombination method specific to deterministic truncation\n",
        "      sorted_indices = np.argsort(selected_scores)[::-1]  # Higher scores are better\n",
        "      selected_population = selected_population[sorted_indices]\n",
        "      selected_scores = selected_scores[sorted_indices]\n",
        "      # last bit of genome determines recombination or not\n",
        "      selected_recombiners = selected_population[selected_population[:, -1]]\n",
        "      selected_non_recombiners = population[~selected_population[:, -1]]\n",
        "      #make sure even number of recombiners\n",
        "      if selected_recombiners.shape[0] % 2 != 0:\n",
        "        # Move the last recombiner to the non-recombiners\n",
        "        selected_non_recombiners = np.append(selected_non_recombiners, [selected_recombiners[-1]], axis=0)\n",
        "        selected_recombiners = selected_recombiners[:-1]\n",
        "      num_recombiners = selected_recombiners.shape[0]\n",
        "      parent_pairs_shape = (num_recombiners // 2, 2, genome_length,)\n",
        "      parent_pairs = np.zeros(parent_pairs_shape, dtype=np.bool_)\n",
        "      #alternate pairs to avoid self mating\n",
        "      parent_pairs[:, 0, genome_length] = selected_recombiners[::2]\n",
        "      parent_pairs[:, 1, genome_length] = selected_recombiners[1::2]\n",
        "      # expand by children per parent\n",
        "      parent_pairs = np.repeat(parent_pairs, offspring_per_parent, axis=0)\n",
        "      if not has_assortative_pairing:\n",
        "        # if mating isn't assortative scramble the parent pairings\n",
        "        shuffle_parent_indices = np.arange(parent_pairs.shape[0])\n",
        "        rng.shuffle(shuffle_parent_indices)  # Shuffle indices in-place\n",
        "        parent_pairs[:, 1, :] = parent_pairs[shuffle_parent_indices, 1, :] # apply the shuffle\n",
        "      selected_non_recombiners = np.repeat(selected_non_recombiners, offspring_per_parent, axis=0)\n",
        "      if len(selected_non_recombiners) + 2 * parent_pairs.shape[0] != pop_size:\n",
        "        raise ValueError(\"Incorrect number of individuals selected in deterministic truncation\")\n",
        "    else:\n",
        "      raise ValueError(\"Invalid selection_type string, use one of proportional, softmax, proportional truncation, or deterministic truncation\")\n",
        "\n",
        "    # selecting parent pairs for recombination and non-recombiners\n",
        "    if selection_type != 'deterministic truncation':\n",
        "      recombiners = population[population[:, -1]]\n",
        "      recombiner_probs = prob_scores[population[:, -1]]\n",
        "      non_recombiners = population[~population[:, -1]]\n",
        "      non_recombiner_probs = prob_scores[~population[:, -1]]\n",
        "      recomb_sort_indices = np.argsort(recombiner_probs)[::-1]  # Higher scores are better\n",
        "      recombiners = recombiners[recomb_sort_indices]\n",
        "      recombiner_probs = recombiner_probs[recomb_sort_indices]\n",
        "      # first determine number of selected recombiners versus number of selecte non-recombiners\n",
        "      init_num_recombiners = recombiners.shape[0]\n",
        "      init_num_non_recombiners = non_recombiners.shape[0]\n",
        "      selected_num_recomb_pairs = rng.binomial(pop_size/2,\n",
        "        np.sum(recombiner_probs)/(np.sum(recombiner_probs) + np.sum(non_recombiner_probs)))\n",
        "      selected_num_non_recombiners = pop_size - 2 * selected_num_recomb_pairs\n",
        "      if selected_num_non_recombiners >= 1:\n",
        "        select_non_recomb_indx = rng.choice(init_num_non_recombiners,\n",
        "                                            size=selected_num_non_recombiners,\n",
        "                                            p=non_recombiner_probs/np.sum(non_recombiner_probs),\n",
        "                                            replace=True)\n",
        "        selected_non_recombiners = non_recombiners[select_non_recomb_indx]\n",
        "      # select the recombiners to avoid self mating\n",
        "      if selected_num_recomb_pairs >= 1:\n",
        "        print(selected_num_recomb_pairs)\n",
        "        selected_parent_indices_1 = rng.choice(init_num_recombiners,\n",
        "                                               size=selected_num_recomb_pairs,\n",
        "                                               p=recombiner_probs/np.sum(recombiner_probs),\n",
        "                                               replace=True)\n",
        "        # use pair directions for assortative mating and avoid self matings\n",
        "        # equally likely to pair up or down in the rankings\n",
        "        pair_directions = rng.integers(0, 2, size=selected_num_recomb_pairs) * 2 - 1  # Results in either -1 or 1\n",
        "        if has_assortative_pairing:\n",
        "          selected_parent_indices_2 = selected_parent_indices_1 + pair_directions\n",
        "        else:\n",
        "          selected_parent_indices_2 = rng.choice(init_num_recombiners,\n",
        "                                                 size=selected_num_recomb_pairs,\n",
        "                                                 p=recombiner_probs/np.sum(recombiner_probs),\n",
        "                                                 replace=True)\n",
        "        # Correct self-pairing by making the assortative mating choice if\n",
        "        # self was randomly selected as a partner\n",
        "        selected_parent_indices_2 = np.where( #ternary use of where\n",
        "          selected_parent_indices_1 == selected_parent_indices_2, # if self-paired\n",
        "          (selected_parent_indices_1 + pair_directions), # use assortative\n",
        "          selected_parent_indices_2) # otherwise leave it alone\n",
        "        # Adjust any out-of-bounds indices (result of pairing up at the top\n",
        "        # or down at the bottom\n",
        "        selected_parent_indices_2[selected_parent_indices_2 < 0] = 1\n",
        "        selected_parent_indices_2[selected_parent_indices_2 >= init_num_recombiners] = init_num_recombiners - 2\n",
        "        # now make the parent pairs with the selected indices\n",
        "        parent_pairs_shape = (selected_num_recomb_pairs, 2, genome_length,)\n",
        "        parent_pairs = np.zeros(parent_pairs_shape, dtype=np.bool_)\n",
        "        parent_pairs[:, 0, :] = recombiners[selected_parent_indices_1]\n",
        "        parent_pairs[:, 1, :] = recombiners[selected_parent_indices_2]\n",
        "\n",
        "        # do the recombination\n",
        "        if recombination_type == 'random':\n",
        "          # each gene is equally likely to come from each parent for each child\n",
        "          mask1 = rng.integers(0, 2, size=parent_pairs.shape).astype(np.bool_)\n",
        "          mask2 = rng.integers(0, 2, size=parent_pairs.shape).astype(np.bool_)\n",
        "        elif recombination_type == 'crossover':\n",
        "          crossover_points_1 = rng.integers(1, genome_length, size=parent_pairs.shape[0])\n",
        "          crossover_points_2 = rng.integers(1, genome_length, size=parent_pairs.shape[0])\n",
        "          range_array = np.arange(genome_length)\n",
        "          # Use broadcasting to create masks: True if index is less than the crossover point\n",
        "          mask1 = range_array < crossover_points_1[:, np.newaxis]\n",
        "          mask2 = range_array < crossover_points_2[:, np.newaxis]\n",
        "          mask2 = ~mask2\n",
        "        else:\n",
        "          raise ValueError(\"Invalid recombination_type string, use one of 'random' or 'crossover'\")\n",
        "        children = np.empty_like(parent_pairs)\n",
        "        children[:, 0, :] = np.where(mask1, parent_pairs[:, 0, :], parent_pairs[:, 1, :])\n",
        "        children[:, 1, :] = np.where(mask2, parent_pairs[:, 0, :], parent_pairs[:, 1, :])\n",
        "\n",
        "    # put the children of the recombiners back together with\n",
        "    # the children of non-recombiners (who are identical to their parents)\n",
        "    arrays_to_concatenate = []\n",
        "    if selected_num_non_recombiners >= 1:\n",
        "      arrays_to_concatenate.append(selected_non_recombiners)\n",
        "    if selected_num_recomb_pairs >= 1:  # Assuming children array is created only when there are recombiners\n",
        "      arrays_to_concatenate.append(children.reshape((2 * selected_num_recomb_pairs, genome_length)))\n",
        "\n",
        "    selected_population = np.concatenate(arrays_to_concatenate, axis=0)\n",
        "\n",
        "    # apply mutation\n",
        "    mutators_index = selected_population[:,-2]\n",
        "    mutation_mask = rng.random(population.shape) < mutation_rate\n",
        "    selected_population[mutators_index, :] ^= mutation_mask[mutators_index, :]\n",
        "\n",
        "    return selected_population\n",
        "\n",
        "\n",
        "  # Run the simulation\n",
        "  for generation in range(n_gen):\n",
        "    # Calculate scores for each genotype in both populations\n",
        "    pred_scores, prey_scores = calculate_scores(pred_population,\n",
        "                                                prey_population,\n",
        "                                                non_food_patterns_array,\n",
        "                                                reward, cost)\n",
        "    # update history of frequencies and scores\n",
        "    update_history(pred_population, pred_scores, pred_results,\n",
        "                   pred_has_distinct_types, generation)\n",
        "    update_history(prey_population, prey_scores, prey_results,\n",
        "                   prey_has_distinct_types, generation)\n",
        "    # Selective Reproduction, Recombination and Mutation based on scores\n",
        "    pred_population = parent_selection_recombination_mutation(\n",
        "        pred_population, pred_scores, pred_selection_type,\n",
        "        pred_proportion_scale, pred_proportion_shift,\n",
        "        pred_softmax_temp,\n",
        "        pred_truncation_threshold, pred_offspring_per_parent, pred_num_parents,\n",
        "        pred_has_assortative_pairing, pred_recombination_type,\n",
        "        pred_mutation_rate, rng)\n",
        "    prey_population = parent_selection_recombination_mutation(\n",
        "        prey_population, prey_scores, prey_selection_type,\n",
        "        prey_proportion_scale, prey_proportion_shift,\n",
        "        prey_softmax_temp,\n",
        "        prey_truncation_threshold, prey_offspring_per_parent, prey_num_parents,\n",
        "        prey_has_assortative_pairing, prey_recombination_type,\n",
        "        prey_mutation_rate, rng)\n",
        "\n",
        "  return pred_results, prey_results\n",
        "\n",
        "\n",
        "def plot_selection_results(ax_pred, ax_prey, n_gen=200,\n",
        "      pred_pop_size=50, prey_pop_size=200,\n",
        "      pred_selection_type='softmax', prey_selection_type='softmax',\n",
        "      pred_softmax_temp=0.5, prey_softmax_temp=0.5,\n",
        "      pred_truncation_threshold=0.5, prey_truncation_threshold=0.5,\n",
        "      pred_mutation_rate=0.005, prey_mutation_rate=0.005,\n",
        "      pred_has_mutation=True, prey_has_mutation=True,\n",
        "      pred_has_recombination=True, prey_has_recombination=True,\n",
        "      pred_has_distinct_types=True, prey_has_distinct_types=True,\n",
        "      pred_has_assortative_pairing=True, prey_has_assortative_pairing=True,\n",
        "      pred_color='blue', prey_color='red', pred_label='', prey_label='',seed=None,\n",
        "      plot_IQR=True, population_to_plot='predator'):\n",
        "  # Call the pred_prey_coev_simulation function\n",
        "  r_pred, r_prey = pred_prey_coev_simulation(\n",
        "      pred_pop_size=pred_pop_size, prey_pop_size=prey_pop_size, n_gen=n_gen,\n",
        "      pred_selection_type=pred_selection_type, prey_selection_type=prey_selection_type,\n",
        "      pred_softmax_temp=pred_softmax_temp, prey_softmax_temp=prey_softmax_temp,\n",
        "      pred_truncation_threshold=pred_truncation_threshold, prey_truncation_threshold=prey_truncation_threshold,\n",
        "      pred_mutation_rate=pred_mutation_rate, prey_mutation_rate=prey_mutation_rate,\n",
        "      pred_has_mutation=pred_has_mutation, prey_has_mutation=prey_has_mutation,\n",
        "      pred_has_recombination=pred_has_recombination, prey_has_recombination=prey_has_recombination,\n",
        "      pred_has_distinct_types=pred_has_distinct_types, prey_has_distinct_types=prey_has_distinct_types,\n",
        "      pred_has_assortative_pairing=pred_has_assortative_pairing, prey_has_assortative_pairing=prey_has_assortative_pairing,\n",
        "      seed=seed)\n",
        "  generations = np.arange(n_gen)\n",
        "\n",
        "  ax_pred.plot(generations, r_pred['mean_hist'], color=pred_color, label=pred_label)\n",
        "  ax_pred.plot(generations, r_prey['mean_hist'], color=prey_color, label=prey_label)\n",
        "\n",
        "\n",
        "fig, (ax_pred, ax_prey) = plt.subplots(2, 1, figsize=(10, 4))\n",
        "\n",
        "plot_selection_results(ax_pred, ax_prey)\n",
        "remove_ip_clutter(fig)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "m4gJd84-V06p",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "220506df7a414121b461f430f292018f",
            "d9c2e59d3d884c70ad7fd20c131aea3e",
            "c73ee6d814064c878aaa3eafecbf68e4",
            "37f6cac87b93478ab3259521a4fedbed"
          ]
        },
        "outputId": "09ae2684-8310-473c-eef8-0e4607bb1400"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "9\n",
            "40\n",
            "7\n",
            "42\n",
            "12\n",
            "35\n",
            "6\n",
            "34\n",
            "4\n",
            "35\n",
            "4\n",
            "38\n",
            "5\n",
            "33\n",
            "3\n",
            "36\n",
            "2\n",
            "31\n",
            "27\n",
            "28\n",
            "29\n",
            "25\n",
            "24\n",
            "34\n",
            "40\n",
            "41\n",
            "35\n",
            "37\n",
            "41\n",
            "45\n",
            "47\n",
            "46\n",
            "51\n",
            "44\n",
            "45\n",
            "50\n",
            "51\n",
            "50\n",
            "59\n",
            "60\n",
            "61\n",
            "49\n",
            "57\n",
            "61\n",
            "59\n",
            "56\n",
            "53\n",
            "58\n",
            "61\n",
            "2\n",
            "61\n",
            "1\n",
            "56\n",
            "56\n",
            "52\n",
            "46\n",
            "46\n",
            "41\n",
            "36\n",
            "37\n",
            "1\n",
            "35\n",
            "2\n",
            "24\n",
            "3\n",
            "24\n",
            "4\n",
            "20\n",
            "4\n",
            "22\n",
            "6\n",
            "17\n",
            "6\n",
            "13\n",
            "5\n",
            "13\n",
            "6\n",
            "16\n",
            "6\n",
            "16\n",
            "8\n",
            "23\n",
            "5\n",
            "23\n",
            "3\n",
            "21\n",
            "2\n",
            "22\n",
            "3\n",
            "30\n",
            "2\n",
            "28\n",
            "3\n",
            "35\n",
            "33\n",
            "38\n",
            "43\n",
            "40\n",
            "32\n",
            "2\n",
            "39\n",
            "4\n",
            "38\n",
            "4\n",
            "39\n",
            "2\n",
            "36\n",
            "1\n",
            "45\n",
            "44\n",
            "41\n",
            "36\n",
            "42\n",
            "47\n",
            "40\n",
            "43\n",
            "38\n",
            "39\n",
            "45\n",
            "43\n",
            "48\n",
            "41\n",
            "35\n",
            "35\n",
            "35\n",
            "34\n",
            "31\n",
            "33\n",
            "38\n",
            "29\n",
            "35\n",
            "32\n",
            "30\n",
            "27\n",
            "22\n",
            "27\n",
            "26\n",
            "30\n",
            "23\n",
            "22\n",
            "17\n",
            "18\n",
            "14\n",
            "11\n",
            "14\n",
            "8\n",
            "4\n",
            "1\n",
            "3\n",
            "3\n",
            "4\n",
            "3\n",
            "6\n",
            "9\n",
            "13\n",
            "16\n",
            "14\n",
            "9\n",
            "6\n",
            "6\n",
            "7\n",
            "6\n",
            "6\n",
            "7\n",
            "6\n",
            "3\n",
            "2\n",
            "2\n",
            "2\n",
            "2\n",
            "1\n",
            "2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Canvas(footer_visible=False, header_visible=False, resizable=False, toolbar=Toolbar(toolitems=[('Home', 'Resetâ€¦"
            ],
            "image/png": "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",
            "text/html": [
              "\n",
              "            <div style=\"display: inline-block;\">\n",
              "                <div class=\"jupyter-widgets widget-label\" style=\"text-align: center;\">\n",
              "                    Figure\n",
              "                </div>\n",
              "                <img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAA+gAAAGQCAYAAAA9TUphAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAvd0lEQVR4nO3dfXBddZ0/8M8tJWlLmyBqQxtCicRFXJpuCePQlocBdVdqQbGscZWdtjMMRd2WLGoxqAP9QW0Ulba0lIHulKLMtjIs7tYZXRfWYd2KumG1hF2qIKmkCbaWh6aPIU3P749uqyEPzfM99/b1mrmT9HvO9+Zzz/l+7+k759yTTJIkSQAAAABZNSrbBQAAAAACOgAAAKSCgA4AAAApIKADAABACgjoAAAAkAICOgAAAKSAgA4AAAApIKADAABACgjoAAAAkAICOgAAAKSAgA4AAAApIKADAABACgjoAAAAkAICOgAAAKSAgA4AAAApIKADAABACgjoAAAAkAICOgAAAKSAgA4AAAApIKADAABACgjoAAAAkAICOgAAAKTAsAf0ffv2xR133BFXX311TJo0KTKZTMyfP7/bdTs6OqKuri4qKiqisLAwKioqoq6uLjo6Oga1LgAAAKTdsAf03bt3x9KlS+OZZ56Jiy66qNd1Fy1aFLW1tXHZZZfFmjVr4tJLL43a2tpYvHjxoNbtiyRJorW1NZIkGVB/AAAAGIxMMsyJtK2tLXbv3h2lpaVx+PDhOPXUU2PevHnx0EMPdVqvoaEhpk2bFosWLYqVK1ceb7/55pvj3nvvja1bt8bUqVP7vW5ftba2RnFxcezZsyeKiooG/oIBAABgAIb9DHphYWGUlpaecL2NGzdGkiRRU1PTqb2mpiaSJIlNmzYNaF0AAADIBam5SVx9fX2UlJREeXl5p/by8vKYOHFi1NfXD2hdAAAAyAWjs13AMS0tLT2eaS8tLY3m5uYBrftWbW1t0dbW1qW9tbW1nxUDAADA0ElNQD9w4EBMmDCh22VjxozpFKD7s+5bLV++PJYuXTq4YlMoSSL+538itm3LdiUw/IbizhmZzB+/9uX73pYnyR8fb/33iZYBAOSzj30sYnRqUmf6pWZTjRs3rtsz2xERhw4dirFjxw5o3beqra2NW265pUt7a2trlJWV9bPq7Hr99YjHH4944omIf//3iJ07s10RAADAH+3bJ6D3R2o21eTJk2Pr1q3dLmtubo7p06cPaN23KiwsjMLCwsEVmxJXXRXx85//8d9jx0b8xV9EnHpq1krKW850Do8k+eNZ6P4aaL9jP/etXwfTduxsendn2PuyDAAgX41KzV3PckNqAnpVVVX86Ec/isbGxk43f2tsbIxdu3ZFVVXVgNbNZ7/+9dGvN98cce21ERdfHJEnv3sAAAA46aTm9xnV1dWRyWRixYoVndpXrFgRmUwmqqurB7RuvkqSiGMftb/11ojLLxfOAQAActmInEFfvXp1vPHGG3HkyJGIiHj22WfjrrvuioiIa665JiorK2PatGlx4403xqpVq2Lv3r0xa9as2LJlS6xfvz4WLlwYlZWVx5+vP+vmqwMHIv5vc0ZRUXZrAQAAYPAySTL8n64955xz4ne/+123y9avXx/z58+PiIjDhw/H17/+9Vi3bl00NzdHaWlp3HDDDbFkyZIY/ZY7C/Rn3b5obW2N4uLi2LNnTxTlQOJ95ZWIyZOPfqbj8GGfYwUAAMh1IxLQc0GuBfRf/zriPe+JOP30o3dzBwAAILel5jPo9M+xz5/nwO8SAAAA6AMBPUcdC+gTJmS3DgAAAIaGgJ6jnEEHAADILwJ6jtq79+hXAR0AACA/COg5yhl0AACA/CKg5ygBHQAAIL8I6DlKQAcAAMgvAnqOEtABAADyi4CeowR0AACA/CKg5ygBHQAAIL8I6DlKQAcAAMgvAnqOEtABAADyi4Ceo44F9AkTslsHAAAAQ0NAz1F79x796gw6AABAfhDQc5RL3AEAAPKLgJ6D3nwz4tCho98L6AAAAPlBQM9Bxy5vj/AZdAAAgHwhoOegY5e3jxsXMXp0dmsBAABgaAjoOcjnzwEAAPKPgJ6DBHQAAID8I6DnIAEdAAAg/wjoOUhABwAAyD8Ceg46dhd3d3AHAADIHwJ6DnIGHQAAIP8I6DlIQAcAAMg/AnoOEtABAADyj4CegwR0AACA/COg5yABHQAAIP8I6DlIQAcAAMg/AnoOEtABAADyj4CegwR0AACA/COg5yABHQAAIP8I6Dlo796jXwV0AACA/CGg55gjR/4Y0CdMyG4tAAAADB0BPcfs3x+RJEe/dwYdAAAgfwjoOebY589Hj44YMya7tQAAADB0BPQc86c3iMtkslsLAAAAQ0dAzzHu4A4AAJCfBPQcI6ADAADkJwE9xwjoAAAA+UlAzzECOgAAQH4S0HOMgA4AAJCfBPQcs3fv0a8COgAAQH4R0HPMsTPoEyZktw4AAACGloCeY1ziDgAAkJ8E9BwjoAMAAOQnAT3HCOgAAAD5KVUBffv27ZHJZLp93HDDDZ3W7ejoiLq6uqioqIjCwsKoqKiIurq66OjoyFL1I0NABwAAyE+js11Adz7ykY/Edddd16mtoqKi078XLVoUa9eujQULFsTMmTNjy5YtUVtbG01NTbFmzZqRLHdECegAAAD5KZUB/YILLojrr7++x+UNDQ1x//33x+LFi2PlypUREXHDDTdEUVFR3HvvvXHTTTfF1KlTR6rcESWgAwAA5KdUXeL+pw4ePBgHDx7sdtnGjRsjSZKoqanp1F5TUxNJksSmTZtGoMLsENABAADyUyoD+sqVK2PcuHExbty4ePe73x333Xdfp+X19fVRUlIS5eXlndrLy8tj4sSJUV9fP5LljigBHQAAID+l6hL3UaNGxfvf//649tpr4+yzz46WlpZ44IEH4rOf/Ww0NjbG3XffHRERLS0tUVpa2u1zlJaWRnNzc48/o62tLdra2rq0tx5LvinW1hbR3n70ewEdAAAgv2SSJEmyXURvOjo64vLLL4+nn346fvOb38S5554b5557bpSUlMRPf/rTLuvPnDkzdu3aFS+++GK3z3fHHXfE0qVLe/x5e/bsiaKUpt8//CFi4sSj33d0RIxK5fUPAAAADETqI94pp5wSt956axw5ciSefPLJiIgYN25ct2fBIyIOHToUY8eO7fH5amtrY8+ePV0eTU1Nw1L/UDp2kn/8eOEcAAAg36TqEveeTJkyJSIidu/eHRERkydPjq1bt3a7bnNzc0yfPr3H5yosLIzCwsKhL3IE+Pw5AABA/sqJ87DHLlcvKSmJiIiqqqrYuXNnNDY2dlqvsbExdu3aFVVVVSNe40gQ0AEAAPJXqgL6rl27urQdPHgw7rrrrjj11FPjL//yLyMiorq6OjKZTKxYsaLTuitWrIhMJhPV1dUjUe6IE9ABAADyV6oucV+4cGG8+uqrceWVV8ZZZ50VLS0tsWHDhnjppZdi+fLlUVZWFhER06ZNixtvvDFWrVoVe/fujVmzZsWWLVti/fr1sXDhwqisrMzyKxkeAjoAAED+SlVAnzNnTmzYsCHWrl0br732WowfPz4uvPDCuOeee+Kaa67ptO7q1avj7LPPjnXr1sUjjzwSpaWlsWzZsliyZEmWqh9+AjoAAED+Sv2fWRspra2tUVxcnOo/s/a1r0V88YsR8+dHrF+f7WoAAAAYSqn6DDq9cwYdAAAgfwnoOWTv3qNfBXQAAID8I6DnEGfQAQAA8peAnkMEdAAAgPwloOeQYwF9woTs1gEAAMDQE9BziDPoAAAA+UtAzyECOgAAQP4S0HOIgA4AAJC/BPQcIqADAADkLwE9R3R0ROzff/R7AR0AACD/jM52AfTdU08dPYt++unZrgQAAIChJqDniFNOibjssmxXAQAAwHBxiTsAAACkgIAOAAAAKSCgAwAAQAoI6AAAAJACAjoAAACkgIAOAAAAKSCgAwAAQAoI6AAAAJACAjoAAACkgIAOAAAAKSCgAwAAQAoI6AAAAJACAjoAAACkgIAOAAAAKSCgAwAAQAoI6AAAAJACAjoAAACkgIAOAAAAKSCgAwAAQAoI6AAAAJACAjoAAACkgIAOAAAAKSCgAwAAQAoI6AAAAJACAjoAAACkgIAOAAAAKSCgAwAAQAoI6AAAAJACAjoAAACkgIAOAAAAKSCgAwAAQAoI6AAAAJACAjoAAACkgIAOAAAAKSCgAwAAQArkdEDv6OiIurq6qKioiMLCwqioqIi6urro6OjIdmkAAADQL6OzXcBgLFq0KNauXRsLFiyImTNnxpYtW6K2tjaamppizZo12S4PAAAA+iyTJEmS7SIGoqGhIaZNmxaLFi2KlStXHm+/+eab4957742tW7fG1KlT+/x8ra2tUVxcHHv27ImioqLhKBkAAAB6lLOXuG/cuDGSJImamppO7TU1NZEkSWzatCk7hQ2nZcsiHnww4tlnIw4fznY1AAAADKGcvcS9vr4+SkpKory8vFN7eXl5TJw4Merr67NU2TBpa4v4f/8v4s03j/77tNMiqqoi3vOeiNGjI0455ehj1KiuXzOZ3p97uJf3dR0AACC/fPGLEQUF2a4iZ+RsQG9paYnS0tJul5WWlkZzc3O3y9ra2qKtra1Le2tr65DWN+QOHYq45ZaIX/wi4r/+K2Lv3oj/+I+jDwAAgDT63OcE9H7I2YB+4MCBmDBhQrfLxowZ02PgXr58eSxdunQ4SxsexcURy5cf/b6jI+LXv474+c8jXn756L+PHDn6tbvv+6o/tyMYrnUBAID8MTpnI2dW5OxN4qZOnRoFBQXxzDPPdFl24YUXRnt7ezQ0NHRZ1tsZ9LKyMjeJAwAAICty9tcZkydPjq1bt3a7rLm5OaZPn97tssLCwigsLBzO0gAAAKDfcvYu7lVVVbFz585obGzs1N7Y2Bi7du2KqqqqLFUGAAAA/ZezAb26ujoymUysWLGiU/uKFSsik8lEdXV1dgoDAACAAcjZS9ynTZsWN954Y6xatSr27t0bs2bNii1btsT69etj4cKFUVlZ2a/nO/ZR/NTfzR0AAIAhM2HChMik5M9C5+xN4iIiDh8+HF//+tdj3bp10dzcHKWlpXHDDTfEkiVLYnQ/7xa4Y8eOKCsrG6ZKAQAASKM03Sg8pwP6UDpy5Ei0tLSk6rcnb3XsTvNNTU2pGUDYL2lm36ST/ZJe9k062S/pZL+kl32TTmneL2nKgDl7iftQGzVqVJx11lnZLqNPioqKUjeosV/SzL5JJ/slveybdLJf0sl+SS/7Jp3sl97l7E3iAAAAIJ8I6AAAAJACAjoAAACkgIAOAAAAKSCg55DCwsK4/fbbo7CwMNul8Cfsl/Syb9LJfkkv+yad7Jd0sl/Sy75JJ/ulb/yZNQAAAEgBZ9ABAAAgBQR0AAAASAEBHQAAAFJAQM8BHR0dUVdXFxUVFVFYWBgVFRVRV1cXHR0d2S7tpFBfXx81NTVRWVkZEyZMiDPPPDPe//73xxNPPNFpve3bt0cmk+n2ccMNN2Sp+vzVn+1tDo2s+fPn97hvMplMLFu2LCLMmeG0b9++uOOOO+Lqq6+OSZMmRSaTifnz53e7bn/mh7k0OH3dL3097kSYR0Olr/umv9vbnBmcvu6Xvh53IsyZodCf9yjHmP4bne0COLFFixbF2rVrY8GCBTFz5szYsmVL1NbWRlNTU6xZsybb5eW9urq6eOqpp2Lu3Lnxd3/3d7Fv375Yv359fPCDH4z77rsvPv3pT3da/yMf+Uhcd911ndoqKipGsuSTSl+2tzk0shYuXBgf+MAHurSvXLky6uvr46qrrurUbs4Mvd27d8fSpUtj0qRJcdFFF8X3v//9Htftz/wwlwanr/ulv8edCPNosPozZyL6vr3NmcHp637p73EnwpwZjP68RznGDEBCqj377LNJJpNJFi9e3Kl98eLFSSaTSZ599tksVXby+M///M/k0KFDndoOHDiQ/Nmf/Vnytre9LWlvb0+SJEkaGxuTiEi+9KUvZaPMk05ft7c5lA779+9PJkyYkEydOvV4mzkzfA4dOpTs2LEjSZIkaW9vTyIimTdvXpf1+jM/zKXB6+t+6etxJ0nMo6HS133Tn+1tzgxeX/dLd7o77iSJOTMU+voe5RgzMC5xT7mNGzdGkiRRU1PTqb2mpiaSJIlNmzZlp7CTyKxZs7r8vcaxY8fGnDlz4vXXX4/f//73XfocPHgwDh48OFIlnvR6297mUDo8/vjjsXfv3pg3b163y82ZoVVYWBilpaUnXK8/88NcGry+7peBHHcizKPB6Ou++VMn2t7mzOANZL8cc6LjToQ5M1B9fY9yjBkYAT3l6uvro6SkJMrLyzu1l5eXx8SJE6O+vj5LldHS0hKjR4+O008/vVP7ypUrY9y4cTFu3Lh497vfHffdd192CjxJnGh7m0PpsGHDhhg9enRcf/31XZaZM9nTn/lhLmVfT8edCPNopPVle5sz2dXbcSfCnBkOb32PcowZGJ9BT7mWlpYef3NYWloazc3NI1wRERHPP/98/NM//VNcc801MX78+IiIGDVqVLz//e+Pa6+9Ns4+++xoaWmJBx54ID772c9GY2Nj3H333VmuOr/0dXubQ9nX3NwcTz75ZFx11VVRUlJyvN2cyb7+zA9zKbu6O+5EmEcjrT/b25zJnp6OOxHmzHDp7j3KMWaAsnFdPX33rne9K5kxY0a3y2bMmJGce+65I1wRb7zxRnL++ecnxcXFyfbt23td9/Dhw8msWbOSUaNGJS+++OIIVXjy6m57m0PZt3z58iQikkcfffSE65ozQ6+3z232Z36YS0OrP5+n7c9xJ0nMo8Hq72ede9re5szQ6s9+6c9xJ0nMmcHq6T3KMWZgXOKecuPGjYu2trZulx06dCjGjh07whWd3A4ePBhXX311vPTSS/H444/HlClTel3/lFNOiVtvvTWOHDkSTz755AhVefLqbnubQ9n38MMPxxlnnBFXX331Cdc1Z0ZWf+aHuZQd/T3uRJhHI62n7W3OZE9/jjsR5sxg9PYe5RgzMAJ6yk2ePLnHSzqam5sHfOMM+u/NN9+Ma6+9Np5++unYtGlTXHHFFX3qd+yNavfu3cNZHv/nrdvbHMqu//qv/4rnn38+PvGJT3S5oUxPzJmR05/5YS6NvIEedyLMo5HW3fY2Z7JjIMedCHNmIE70HuUYMzACespVVVXFzp07o7GxsVN7Y2Nj7Nq1K6qqqrJU2cnl8OHD8fGPfzz+7d/+LR566KH4yEc+0ue+L774YkREl89AMTzeur3NoezasGFDRESvd9F9K3Nm5PRnfphLI2swx50I82ikdbe9zZnsGMhxJ8Kc6a++vEc5xgxQtq+xp3e/+tWvev2bgFu3bs1SZSePjo6OpLq6OomI5P777+9xvZ07d3ZpO3DgQDJ9+vTk1FNPTV5++eXhLPOk09ftbQ5lT1tbW3LGGWck559/frfLzZmR0dvnNvszP8ylodXbfunrcSdJzKPh0Nu+6c/2NmeGVl8+g36i406SmDNDoa/vUY4xA+Mu7ik3bdq0uPHGG2PVqlWxd+/emDVrVmzZsiXWr18fCxcujMrKymyXmPc+//nPx6ZNm+Kyyy6L0047Lb7zne90Wv7BD34wSkpKYuHChfHqq6/GlVdeGWeddVa0tLTEhg0b4qWXXorly5dHWVlZll5Bfurr9jaHsuf73/9+vPbaa7FkyZJul5szw2v16tXxxhtvxJEjRyIi4tlnn4277rorIiKuueaaqKys7Nf8MJeGRl/2S1+POxHm0VDqy77pz/Y2Z4ZGX/bLMSc67kSYM0Ohr+9RjjEDlO3fEHBi7e3tybJly5Ly8vKkoKAgKS8vT5YtW5a0t7dnu7STwuWXX55ERI+PH//4x0mSJMm6deuSSy+9NJk4cWIyevTo5PTTT0+uvPLK5J//+Z+z+wLyVH+2tzmUHddcc00yatSopLm5udvl5szwmjJlSo/vW+vXrz++Xn/mh7k0eH3ZL3097iSJeTSU+rJv+ru9zZnB6+t7WZKc+LiTJObMUOjPe5RjTP9lkiRJhiX5AwAAAH3mJnEAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACmQtYC+b9++uOOOO+Lqq6+OSZMmRSaTifnz5/frOZ577rmYPXt2FBUVRVFRUcyePTuee+654SkYAAAAhlHWAvru3btj6dKl8cwzz8RFF13U7/4vvPBCXHLJJbFt27ZYunRpLF26NJ5//vm49NJL44UXXhiGigEAAGD4jM7WD540aVLs2LEjSktL4/Dhw3Hqqaf2q39tbW0cPnw4nnrqqSgrK4uIiOuuuy7OP//8uO222+LRRx8djrIBAABgWGTtDHphYWGUlpYOqO++ffti8+bNMXfu3OPhPCKirKws5s6dG5s3b479+/cPVakAAAAw7HLyJnENDQ3x5ptvxowZM7osu/jii6OtrS0aGhqyUBkAAAAMTNYucR+MlpaWiIhuz8Afa2tubu62b1tbW7S1tXVpT5Ik3nzzzXjHO94RmUxmCKsFAACAE8vJM+gHDhyIiKOXyb/VmDFjIiLi4MGD3fZdvnx5FBcXd3mcfvrpMXHixNi7d+/wFQ4AAAA9yMmAPm7cuIiIbs+EHzp0KCIixo4d223f2tra2LNnT5dHU1PT8BUMAAAAJ5CTl7hPnjw5Irq/jP1YW083oCssLOz2zDsAAABkU06eQZ86dWoUFBTE008/3WXZz372sygoKIgLLrggC5UBAADAwKQ+oLe3t8e2bdvilVdeOd42fvz4mDNnTjz22GOxY8eO4+1NTU3x2GOPxZw5c2L8+PHZKBcAAAAGJJMkSZKtH7569ep444034siRI3H77bfH9OnT42Mf+1hERFxzzTVRWVkZ27dvj/Ly8pg3b1489NBDx/v++te/jve9733x9re/PRYvXhwREatWrYpXX301fvGLX8R5553Xr1paW1ujuLg49uzZE0VFRUP2GgEAAKAvsvoZ9G984xvxu9/97vi/f/nLX8Yvf/nLiIg466yzorKysse+5513XvzkJz+JW2+9Nb7yla9ERMQll1wSX/va1/odzgEAACDbsnoGPU2cQQcAACCbUv8ZdAAAADgZCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACmQtYDe0dERdXV1UVFREYWFhVFRURF1dXXR0dFxwr7z58+PTCbT7WPHjh0jUD0AAAAMrdHZ+sGLFi2KtWvXxoIFC2LmzJmxZcuWqK2tjaamplizZk2fnmPDhg0xalTn3zGcccYZw1EuAAAADKusBPSGhoa4//77Y/HixbFy5cqIiLjhhhuiqKgo7r333rjpppti6tSpJ3yeT37ykzF6dNZ+xwAAAABDJiuXuG/cuDGSJImamppO7TU1NZEkSWzatKlPz5MkSbS2tsaRI0eGoUoAAAAYOVkJ6PX19VFSUhLl5eWd2svLy2PixIlRX1/fp+d5+9vfHsXFxTF+/PiYO3du/Pa3vx2OcgEAAGDYZeX68JaWligtLe12WWlpaTQ3N/fa/8wzz4zPfe5zUVVVFQUFBfHTn/40Vq9eHf/xH/8R9fX1MWXKlB77trW1RVtbW5f21tbW/r0IAAAAGEKZJEmSkf6h5557bpSUlMRPf/rTLstmzpwZu3btihdffLFfz/nDH/4wrrrqqpg3b1489NBDPa53xx13xNKlS3tcvmfPnigqKurXzwYAAIDBykpAnzp1ahQUFMQzzzzTZdmFF14Y7e3t0dDQ0O/nraqqildeeSVaWlp6XKe3M+hlZWUCOgAAAFmRlUvcJ0+eHFu3bu12WXNzc0yfPn1AzztlypQTBvvCwsIoLCwc0PMDAADAcMnKTeKqqqpi586d0djY2Km9sbExdu3aFVVVVQN63hdffDFKSkqGokQAAAAYUVkJ6NXV1ZHJZGLFihWd2lesWBGZTCaqq6sjIqK9vT22bdsWr7zyyvF19u/fH/v37+/ynJs2bYqGhob48Ic/PKy1AwAAwHDIyiXu06ZNixtvvDFWrVoVe/fujVmzZsWWLVti/fr1sXDhwqisrIyIo5e7n3/++Z1u/PbCCy/ElVdeGdXV1XHeeedFQUFBPP300/HII4/ElClTer0BHAAAAKRVVgJ6RMTq1avj7LPPjnXr1sUjjzwSpaWlsWzZsliyZEmv/c4888y46qqr4sknn4xvf/vb0d7eHmVlZXHzzTfHl770pXjHO94xQq8AAAAAhk5W7uKeRq2trVFcXOwu7gAAAGRFVj6DDgAAAHQmoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApEDWAnpHR0fU1dVFRUVFFBYWRkVFRdTV1UVHR0ef+j/33HMxe/bsKCoqiqKiopg9e3Y899xzw1w1AAAADI/R2frBixYtirVr18aCBQti5syZsWXLlqitrY2mpqZYs2ZNr31feOGFuOSSS+KMM86IpUuXRkTEqlWr4tJLL41f/OIX8e53v3skXgIAAAAMmUySJMlI/9CGhoaYNm1aLFq0KFauXHm8/eabb4577703tm7dGlOnTu2x/3XXXRc//OEP4/nnn4+ysrKIiGhqaorzzz8/rrrqqnj00Uf7XVNra2sUFxfHnj17oqioqP8vCgAAAAYhK5e4b9y4MZIkiZqamk7tNTU1kSRJbNq0qce++/bti82bN8fcuXOPh/OIiLKyspg7d25s3rw59u/fP1ylAwAAwLDISkCvr6+PkpKSKC8v79ReXl4eEydOjPr6+h77NjQ0xJtvvhkzZszosuziiy+Otra2aGhoGPKaAQAAYDhl5TPoLS0tUVpa2u2y0tLSaG5u7rXvsfW66xsRvfZva2uLtra2Lu179uyJiKOXugMAAHBymDBhQmQymWyXERFZCugHDhyICRMmdLtszJgxvYbkAwcOREREYWFht30jIg4ePNhj/+XLlx+/sVx3/vSyeQAAAPLbrl274p3vfGe2y4iILAX0cePGdXsWOyLi0KFDMXbs2F77RkS3/Q8dOhQR0Wv/2trauOWWW7q0v/HGGzFlypR4+eWXo7i4uNf6Ie1aW1ujrKwsmpqa3PSQnGYsky+MZfKFsUw+OTaeCwoKsl3KcVkJ6JMnT46tW7d2u6y5uTmmT5/ea99j63XXN6L7y9+PKSws7Pbs+zHFxcXebMgbRUVFxjN5wVgmXxjL5AtjmXySlsvbI7J0k7iqqqrYuXNnNDY2dmpvbGyMXbt2RVVVVY99p06dGgUFBfH00093Wfazn/0sCgoK4oILLhjymgEAAGA4ZSWgV1dXRyaTiRUrVnRqX7FiRWQymaiuro6IiPb29ti2bVu88sorx9cZP358zJkzJx577LHYsWPH8fampqZ47LHHYs6cOTF+/PgReR0AAAAwVLJyifu0adPixhtvjFWrVsXevXtj1qxZsWXLlli/fn0sXLgwKisrI+LoJevnn39+zJs3Lx566KHj/b/61a/GE088EZdddlksXrw4IiJWrVoVp5xySnz1q1/NxksCAACAQclKQI+IWL16dZx99tmxbt26eOSRR6K0tDSWLVsWS5YsOWHf8847L37yk5/ErbfeGl/5ylciIuKSSy6Jr33ta3HeeecNd+kAAAAw5LIW0EePHh233XZb3HbbbT2uc84550SSJN0uq6ysjB/84AdDVk9hYWHcfvvtvd5ADnKF8Uy+MJbJF8Yy+cJYJp+kcTxnkp4SMAAAADBisnKTOAAAAKAzAR0AAABSQEAHAACAFBDQAQAAIAXyPqB3dHREXV1dVFRURGFhYVRUVERdXV10dHT0qf9zzz0Xs2fPjqKioigqKorZs2fHc889N8xVQ1cDHcsHDhyI+++/P2bPnh1nnXVWjBs3Lt773vfGkiVL4o033hiZ4uFPDPZ9+U9dfvnlkclk4vrrrx+GSqF3QzGWv/vd78all14aRUVFMX78+KisrIyVK1cOY9XQvcGO540bN8aMGTPibW97W5x++ulx0UUXxQMPPBBHjhwZ5sqhs3379sUdd9wRV199dUyaNCkymUzMnz+/X8+R1QyY5LlPf/rTSUQkCxYsSB588MFk/vz5SUQkn/nMZ07Y9ze/+U1SXFyclJeXJ9/61reSb33rW8k555yTnH766clvfvObEage/migY7mhoSHJZDLJZZddlixbtix58MEHk5tuuikZPXp0UlFRkezZs2eEXgEcNZj35T/18MMPJ6eddloSEcmnPvWpYaoWejbYsXzLLbcko0aNSj7+8Y8n9913X7J27drk85//fPL3f//3w1w5dDWY8bx8+fIkIpK/+qu/StasWZOsXr06ueKKK5KISD73uc+NQPXwR42NjUlEJJMmTUrmzJmTREQyb968PvfPdgbM64D+7LPPJplMJlm8eHGn9sWLFyeZTCZ59tlne+0/d+7c5LTTTktefvnl420vv/xyctpppyXXXXfdsNQM3RnMWP7DH/6QbN26tUv7P/zDPyQRkXzzm98c8nqhJ4N9Xz7m9ddfT0pKSo7/p1BAZ6QNdixv3rw5iYjk4YcfHs4yoU8GO54nTpyYXHTRRcmRI0eOt3V0dCTTpk1LiouLh6Nk6NGhQ4eSHTt2JEmSJO3t7f0O6NnOgHl9ifvGjRsjSZKoqanp1F5TUxNJksSmTZt67Ltv377YvHlzzJ07N8rKyo63l5WVxdy5c2Pz5s2xf//+4SodOhnMWH7HO94RlZWVXdr/+q//OiIi/vd//3dIa4XeDGYs/6kvf/nLUVRUFLfccsswVAknNtix/PWvfz0uvPDC+Nu//duIiNi7d+9wlQonNNjx3NraGiUlJZHJZI63jRo1KkpKSmLcuHHDUTL0qLCwMEpLSwfUNw0ZMK8Den19fZSUlER5eXmn9vLy8pg4cWLU19f32LehoSHefPPNmDFjRpdlF198cbS1tUVDQ8OQ1wzdGcxY7klLS0tERLzzne8ckhqhL4ZiLP/3f/93rF27NlasWBEFBQXDVSr0ajBjed++fbFly5aYMWNG3HXXXfH2t789ioqK4owzzogvfOEL0d7ePtzlQyeDfW++4oor4gc/+EHcc8898dJLL8Vvf/vbqKuriyeeeCK+8pWvDGfpMKTSkAFHD+uzZ1lLS0uPvz0pLS2N5ubmXvseW6+7vhHRa38YSoMZyz1ZtmxZZDKZ+MQnPjHY8qDPBjuWjxw5Ep/5zGfiwx/+cMyePXs4SoQ+GcxYfvHFF+PIkSPx3e9+N9rb2+PLX/5ynHPOOfEv//Iv8Y1vfCNeeeWV+M53vjNcpUMXg31vXrduXVx//fVxyy23HL+yacyYMbFhwwY38SSnpCED5nVAP3DgQEyYMKHbZWPGjInW1tZe+0YcvUSiu74REQcPHhyCKuHEBjOWu/PAAw/Et7/97aipqYlp06YNRYnQJ4Mdy+vWrYtf/epX8T//8z/DUR702WDG8r59+yIi4g9/+EP8+7//e1xxxRURETF37tzo6OiIRx55JG677bZ473vfO/SFQzcG+9582mmnxXve8544++yzY/bs2dHe3h4PP/xwLFiwIMaMGRPXXXfdcJQNQy4NGTCvL3EfN25ctLW1dbvs0KFDMXbs2F77RkS3/Q8dOhQR0Wt/GEqDGctv9b3vfe/4Gci77757qEqEPhnMWN69e3fU1tbGF77whTj33HOHq0Tok8GM5WPLzjrrrOPh/Jh58+ZFRMRTTz01RJXCiQ1mPB85ciQ+8IEPxO7du+Ohhx6Kj3/84/GpT30qfvjDH8b73ve+uOmmm5zUImekIQPmdUCfPHlyj5cgNDc393rzgMmTJx9fr7u+Ed1f+gDDYTBj+U/96Ec/ik984hMxa9asePTRR2P06Ly+iIYUGsxYvvPOOyMi4m/+5m9i+/btxx8REfv374/t27f3+2oSGKjBjOVjy0pKSrosmzRpUkREvP7660NQJfTNYMbzT37yk6ivr+9yljyTycTHPvaxePXVV131RM5IQwbM64BeVVUVO3fujMbGxk7tjY2NsWvXrqiqquqx79SpU6OgoCCefvrpLst+9rOfRUFBQVxwwQVDXjN0ZzBj+ZinnnoqPvrRj8bUqVNj8+bNrgAhKwYzln/3u9/Fa6+9Fn/+538e5eXlxx8RR68MKS8vjwceeGBY64djBjOWzzzzzDjrrLO6/Q9gU1NTRERMnDhxaAuGXgxmPB/7zG5HR0eXZYcPH+70FdIuDRkwrwN6dXV1ZDKZWLFiRaf2FStWRCaTierq6oiIaG9vj23btsUrr7xyfJ3x48fHnDlz4rHHHosdO3Ycb29qaorHHnss5syZE+PHjx+R1wGDGcsRET//+c9jzpw5ce6558a//uu/RlFR0UiVDp0MZizX1tbG448/3uUREXH55ZfH448/Hh/96EdH6qVwkhvs+/InP/nJ+P3vfx/f+973jrclSRJr166NU045JT7wgQ8M90uA4wYznt/znvdERMTDDz/cqe/hw4fjH//xH2PMmDFOapFKqc2Aw/6X1rNs4cKFSUQkCxYsSNatW5csWLAgiYhk4cKFx9dpbGzs9g/Yb9u2LSkqKkrKy8uTe+65J7nnnnuS8vLypKioKNm2bdsIvxJOdgMdy9u3b0/e9ra3JaNHj07uvvvu5Nvf/nanx49+9KMsvBpOZoN5X+5ORCSf+tSnhrFi6N5gxvJrr72WvOtd70rGjBmTfOELX0jWrFmTfOhDH0oiIvniF784wq8EBjeeP/zhDycRkVx++eXJypUrk29+85vJ9OnTk4hIbr/99pF9IZAkyb333pvceeedydKlS5OISKZPn57ceeedyZ133pls3bo1SZL0ZsC8D+jt7e3JsmXLkvLy8qSgoCApLy9Pli1blrS3tx9fp7f/CG7dujX50Ic+lIwfPz4ZP3588qEPfej4ToWRNNCx/OMf/ziJiB4fl19++ci/GE5qg31ffisBnWwZ7FhuaWlJ5s2bl7zzne9MCgoKkve+973JfffdN4KvAP5oMOP50KFDybe+9a3kL/7iL5KioqJkzJgxyYUXXpg8+OCDI/wq4KgpU6b0+H/f9evXJ0mS3gyYSZIkGbbT8wAAAECf5PVn0AEAACBXCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAKCOgAAACQAgI6AAAApICADgAAACkgoAMAAEAK/H9m9j7TZLFEFgAAAABJRU5ErkJggg==' width=1000.0/>\n",
              "            </div>\n",
              "        "
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "220506df7a414121b461f430f292018f"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_pred, r_prey = pred_prey_coev_simulation()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T2DACA3hcYZ8",
        "outputId": "84fccfe7-585f-42be-9c88-c30eddcb748f"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "44\n",
            "51\n",
            "52\n",
            "58\n",
            "54\n",
            "64\n",
            "63\n",
            "63\n",
            "63\n",
            "63\n",
            "59\n",
            "60\n",
            "62\n",
            "62\n",
            "53\n",
            "71\n",
            "62\n",
            "64\n",
            "55\n",
            "49\n",
            "53\n",
            "62\n",
            "59\n",
            "59\n",
            "58\n",
            "66\n",
            "70\n",
            "69\n",
            "73\n",
            "76\n",
            "77\n",
            "76\n",
            "74\n",
            "78\n",
            "79\n",
            "74\n",
            "76\n",
            "72\n",
            "65\n",
            "60\n",
            "60\n",
            "59\n",
            "54\n",
            "60\n",
            "55\n",
            "50\n",
            "56\n",
            "61\n",
            "53\n",
            "61\n",
            "65\n",
            "70\n",
            "72\n",
            "78\n",
            "76\n",
            "78\n",
            "76\n",
            "71\n",
            "75\n",
            "76\n",
            "77\n",
            "80\n",
            "82\n",
            "82\n",
            "82\n",
            "82\n",
            "82\n",
            "80\n",
            "82\n",
            "85\n",
            "81\n",
            "82\n",
            "84\n",
            "85\n",
            "87\n",
            "92\n",
            "93\n",
            "96\n",
            "98\n",
            "99\n",
            "99\n",
            "98\n",
            "98\n",
            "99\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n",
            "100\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_pred.keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Flkgy7q-4zc1",
        "outputId": "2259b2d8-8c86-4349-ea5f-16d32ea7e675"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['mean_hist', 'var_hist', 'upper_quartile_hist', 'lower_quartile_hist', 'type_count_hist', 'type_mean_score_hist', 'rm_freq_history', 'rm_fitness_history'])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "r_pred['rm_freq_history'].keys()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "poqJqAdC4VOr",
        "outputId": "42fc6311-260b-4941-fe15-fbc76b814542"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys([(False, True, False, True), (True, True, True, False), (True, False, False, False), (False, True, False, False), (False, False, True, False), (True, False, True, False), (False, False, False, True), (True, True, True, True), (True, False, True, True), (True, True, False, False), (True, False, False, True), (False, False, False, False), (False, True, True, True), (False, False, True, True), (False, True, True, False)])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "avg_freqs = {genotype: np.mean(freqs) for genotype, freqs in r_pred['rm_freq_history'].items()}\n",
        "top_4_genotypes = sorted(avg_freqs, key=avg_freqs.get, reverse=True)[:4]"
      ],
      "metadata": {
        "id": "7XuB_JKz5XoG"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "top_4_genotypes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_LooFNKt5q6N",
        "outputId": "0cb30857-0f61-40b6-d5ed-f1b349d92efc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(False, False, False, False),\n",
              " (True, True, True, False),\n",
              " (True, False, True, False),\n",
              " (False, False, False, True)]"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Parameters\n",
        "common_params = {\n",
        "    'n_gen': 200,\n",
        "    'pop_size': 1000,\n",
        "    'seed': 123,\n",
        "    'mutation_rate': 0.005,\n",
        "    'has_mutation': True,\n",
        "    'has_recombination': False,\n",
        "    'has_assortative_pairing': True,\n",
        "    'has_distinct_types': False\n",
        "}\n",
        "#**softmax_params, **common_params)\n",
        "#plot_selection_results(ax, **truncation_params, **common_params)\n",
        "#plot_selection_results(ax, **proportional_params, **common_params)\n",
        "\n",
        "softmax_params = {\n",
        "    'selection_type': 'softmax',\n",
        "    'color': 'green',\n",
        "    'label': 'Softmax',\n",
        "    'softmax_temp': 1,\n",
        "}\n",
        "\n",
        "truncation_params = {\n",
        "    'selection_type': 'deterministic truncation',\n",
        "    'color': 'red',\n",
        "    'label': 'Truncation - 50%',\n",
        "    'truncation_threshold': 0.5,\n",
        "}\n",
        "\n",
        "proportional_params = {\n",
        "    'selection_type': 'proportional',\n",
        "    'color': 'blue',\n",
        "    'label': 'Proportional',\n",
        "    }\n"
      ],
      "metadata": {
        "id": "l94hkHMyQWxb"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "cMfVz2O8_Rop"
      },
      "source": [
        "# 1.2.3.2: Optimize the Prey, Optimize the Predator\n",
        "\n",
        "Now that we have a sense of the Predator Prey game dynamics it's time to start optimizing policies for this new competitive environment. An effective policy for a prey organism will differ markedly from that of a predator; each type warrants a distinct policy, each requiring a separate optimization process."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "4ERsN89Z_Rop"
      },
      "source": [
        "Before starting on policy optimization, we first need to extend and generalize our parameterized policy player from earlier sequences.\n",
        "Specifically, instead of solely perceiving food, a policy should now also respond to the presence of other organisms and the board's edges, augmenting the initial food-only perception. Moreover, to allow for diverse policies to emerge, we're enhancing the prey's speed, allowing movement across two grid cells. This means the prey can target any of the 12 nearest cells, as opposed to just the 4 adjacent ones, effectively reaching any grid cell within its sight. Likewise, the predator's perceptive field is expanded, now encompassing 24 surrounding grid cellsâ€”effectively covering half the board when centered. Previously we didn't allow for organisms to stay in one spot, but now this will also be enabled for both prey and predator types. Below, we define a general class for these players (feel free to skim). Both the prey and predator organisms will be constructed from this foundational class using suitable parameters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "-f6T-M9q_Ror"
      },
      "source": [
        "Observing both organisms executing a random drift policy, we notice that the average predator score is slightly positive, and the average prey score is slightly negative. This outcome aligns with expectations. While predator-prey encounters are infrequent, they result in minor gains for predators but substantial losses for prey. These significant losses aren't totally balanced by the prey's more common, but lower scoring, food-eating events."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "yZGl-m9O_Ror"
      },
      "source": [
        "With our evaluation function in place, we're ready to properly start on the optimization process. For optimization, we'll use an enhanced version of the evolutionary algorithm from sequence 1.3.1, known as the Covariance Matrix Adapted Evolutionary Strategy (CMA-ES). While CMA-ES primarily mirrors our basic evolutionary algorithm its distinction lies in its 'mutation' distribution. Guided by an evolving covariance matrix, this distribution changes over time, leading to mutants with an increased likelihood of fitness improvement. This changing 'mutation' distribution can be seen as a kind of meta-evolution, where mutability itself evolves."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "2hILAPIF_Ror"
      },
      "outputs": [],
      "source": [
        "# @markdown You don't need to know how this code works right now, but you do need to run this cell, and you might want to skim this code out of curiosity.\n",
        "def cma_es(n, eval_func, focal_pop=0, init_m=None, init_C=None, init_sigma=None,\n",
        "           pop_size=None, select_frac=0.5, weight_scheme='skew', # other magic word is flat\n",
        "           c_1=None, c_mu=None, c_c = None, c_sig = None, d_sig = None,\n",
        "           max_gen=100, sigma_tol=0.0001, value_tol=0.0001,\n",
        "           rng = np.random.default_rng(),\n",
        "           verbose = True):\n",
        "  # assumes eval_func returns scores for multiple populations\n",
        "  # focal_pop indexes which of these scores is the one we are optimizing for\n",
        "  # use heuristics to set constants if none provided\n",
        "  # these are the same as in a simple ES algo\n",
        "  if pop_size is None:\n",
        "    pop_size = 4 + np.floor(3 * np.log(n))\n",
        "    if verbose: print(f\"pop_size set to: {pop_size}\")\n",
        "  select_size = int(np.floor(pop_size * select_frac))\n",
        "\n",
        "  if weight_scheme == 'skew':\n",
        "    mu_w = np.array([np.log(select_size + 0.5) - np.log(i)\n",
        "                      for i in range(1, select_size + 1)])\n",
        "    mu_w = mu_w / np.sum(mu_w)\n",
        "    mu_eff = 1 / np.sum(mu_w**2)\n",
        "    if verbose: print(f\"mu_w set using skew scheme: {mu_w}\")\n",
        "    if verbose: print(f\"mu_eff set to: {mu_eff}\")\n",
        "  elif weight_scheme == 'flat':\n",
        "    mu_w = np.ones(select_size) / float(select_size)\n",
        "    mu_eff = select_size / 2\n",
        "    if verbose: print(f\"mu_w set using flat scheme: {mu_w}\")\n",
        "    if verbose: print(f\"mu_eff set to: {mu_eff}\")\n",
        "\n",
        "  # this is fancy stuff for updating the mutation distribution\n",
        "  if c_1 is None:\n",
        "    c_1 = 2 / n**2\n",
        "    if verbose: print(f\"c_1 set to: {c_1}\")\n",
        "  if c_mu is None:\n",
        "    c_mu = min(1 - c_1, 2 * (mu_eff - 2 + 1/mu_eff) / (n + 2))\n",
        "    if verbose: print(f\"c_mu set to: {c_mu}\")\n",
        "  if c_c is None:\n",
        "    c_c = (4 + mu_eff/n) / (n + 4 + 2 * mu_eff/n)\n",
        "    if verbose: print(f\"c_c set to: {c_c}\")\n",
        "  if c_sig is None:\n",
        "    c_sig = (mu_eff + 2) / (n + mu_eff + 5)\n",
        "    if verbose: print(f\"c_sig set to: {c_sig}\")\n",
        "  if d_sig is None:\n",
        "    d_sig = 1 + c_sig + 2 * max(0, np.sqrt((mu_eff - 1) / (n + 1)) - 1)\n",
        "    if verbose: print(f\"d_sig set to: {d_sig}\")\n",
        "\n",
        "  # Initialize variables of the process to these defaults if none given\n",
        "  # (weighted) population mean parameters\n",
        "  if init_m is None:\n",
        "    m = np.zeros(n)\n",
        "  else:\n",
        "    m = init_m\n",
        "  if init_C is None:\n",
        "    # inially the Covariance of the proposal/offspring distribution is just\n",
        "    # a standard i.i.d. Gaussian\n",
        "    C = np.eye(n)\n",
        "  else:\n",
        "    C = init_C\n",
        "  if init_sigma is None:\n",
        "    sigma = 1.0\n",
        "  else:\n",
        "    sigma = init_sigma\n",
        "  # p_c is used as a kind of momentum to inform how C is updated\n",
        "  p_c = np.zeros(n)\n",
        "\n",
        "\n",
        "  # Main loop\n",
        "  start_time = time.time()\n",
        "  mean_scores_history = []\n",
        "  for gen in range(max_gen):\n",
        "    # Steps 1-3 are standard Evolutionary Optimization\n",
        "    # 1. Sampe params of this generation\n",
        "    samples = rng.multivariate_normal(m, sigma**2 * C, size=int(pop_size))\n",
        "    # 2. Evaluate each member of the new population\n",
        "    fitness_values = np.vstack([eval_func(x) for x in samples])\n",
        "    focal_fitness_values = fitness_values[:, focal_pop]\n",
        "    sorted_indices = np.argsort(-focal_fitness_values) #argsort does low to high, so sort neg\n",
        "    mean_scores = np.mean(fitness_values, axis=0)\n",
        "    mean_scores_history.append(mean_scores)\n",
        "    # If verbose flag is true, print generation info and mean score\n",
        "    elapsed_time = time.time() - start_time\n",
        "    if verbose:\n",
        "      all_mean_scores = \", \".join([f\"{score:.4f}\" for score in mean_scores])\n",
        "      print(f\"Generation {gen + 1}/{max_gen}. Mean Scores: [{all_mean_scores}]. Elapsed Time: {elapsed_time:.2f} seconds\")\n",
        "    # 3. Update mean based on selection\n",
        "    old_m = m.copy()\n",
        "    selected_samples = samples[sorted_indices[:select_size]]\n",
        "    m = (mu_w[:, np.newaxis].T @ selected_samples).squeeze()\n",
        "    # Steps 4-7 are all about cleverly updating the sampling distribution\n",
        "    # 4. Compute weighted sample deviations from the old mean\n",
        "    y = np.sqrt(mu_w[:, np.newaxis]) * (selected_samples - old_m) / sigma\n",
        "    # 5. Update the covariance matrix\n",
        "    C = (1 - c_1 - c_mu) * C + c_1 * np.outer(p_c, p_c)\n",
        "    C += c_mu * sum(np.outer(yi, yi) for yi in y)\n",
        "    # 6. Update the evolution path\n",
        "    p_c = (1 - c_c) * p_c + np.sqrt(c_c * (2 - c_c) * mu_eff) * (m - old_m) / sigma\n",
        "    # 7. Adapt the step size sigma\n",
        "    sigma *= np.exp(c_sig/d_sig * (np.linalg.norm(p_c) / np.sqrt(n) - 1))\n",
        "    # 8. Check stopping criteria\n",
        "    if sigma < sigma_tol:\n",
        "        print(\"Stopping due to sigma below threshold.\")\n",
        "        break\n",
        "    if np.abs(np.max(fitness_values) - np.min(fitness_values)) < value_tol:\n",
        "        print(\"Stopping due to objective function values convergence.\")\n",
        "        break\n",
        "  return m, C, mean_scores"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "jgd0xKSJ_Ror"
      },
      "source": [
        "## Optimized Prey Policy when the Predator Drifts Randomly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "HTRXn6Hv_Ror"
      },
      "source": [
        "The prey organism has 'evolved' to avoid being eaten and does a pretty good job of eating lots of food despite its limited perceptual field, and efforts to avoid the predator. Now lets look at the reverse situation where the prey organism executes a random drift policy and the predator organism is optimized."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "1oq2DJOF_Ror"
      },
      "source": [
        "## Optimized Predator Policy when the Prey Drifts Randomly"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "sczqiaPN_Rot"
      },
      "source": [
        "In this scenario as well the predator organism gets better at tracking down and eating the unpredictable prey, even though the prey is moves unpredictably and more quickly than the predator. Finally we are going to look at a simultaneous evolution scenario where both the prey and predator populations constantly co-adapt to each-other."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "fSP7DNNB_Rot",
        "outputId": "a22be0d5-72f4-4824-cc50-87b9d10fa540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62,
          "referenced_widgets": [
            "4a17a0b2e80d4a549bf1a02aa0590988",
            "77be50b15a264bc49700fbdaaeb046c6",
            "0fd65add8f8542289b99685ba4c5c0d4",
            "3065b3ab1a4b4c8d929cb010b7bf6fd3",
            "f1a9e15cb33e46d99c51fabd3d1c03b6",
            "948e7586c3614e7c80d131af0f228ca8",
            "b846350e0f08460381d337fbd98f15e2",
            "78d607aa8f2a453fa34c6688b9cc0e72",
            "c0d1a4299d4d4ce89b73ed86b6b0dd90",
            "e91040291fa945758dd76551bdf90e3b",
            "355feffd28ff42bcae2a79b53b1dffee",
            "56c59808c69d4c64879dc3180defa987",
            "629e188ddbe04c53bd363f551b707bb4",
            "973a7db8caab4563948e76790017b8c0",
            "d8f6e29aee6746edbd7d5841f500022c",
            "ab8e31abbe1c4695ad33d0c3161ddcef",
            "ae24b3d38264474da619c9fbb413631e",
            "63bebe6d113d470d81603897ad59b707",
            "f1dfa8adac954dd998e949e86a8e2924",
            "20fa51a990b44e49b60447ec265993c7",
            "0a4a34f15fca4404a2336721404f338f",
            "649ff9244b5941779ceedc232b524f97",
            "6183ea78ab964c02a1200a5de0d4027d",
            "62c220edae6a49fa83527369a6de41e2",
            "635a09f5114743fc8b2d998537b01de8",
            "ba6cfdc6254d43989059f3fa27d97cb6"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a17a0b2e80d4a549bf1a02aa0590988"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "# @markdown Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_M2\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "_2e99GjX_Rot"
      },
      "source": [
        "# 1.2.3.3: Prey and Predator Co-Evolve\n",
        "\n",
        "We need to adapt our CMA-ES algo to update both populations, predator and prey, simultaneously."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "gUzAouLl_Rou"
      },
      "source": [
        "The predator organism, with its slower movement, can not directly chase down the faster prey. To successfully hunt, the predator must stay out of the prey's field of view, hoping that the prey will move within striking distance. Meanwhile, the prey organism faces its own challenges, constantly deciding between two conflicting approaches:\n",
        "\n",
        "1. Slow, cautious movement that reduces food intake but minimizes the risk of being preyed upon.\n",
        "2. Quick, recklessly optimistic movement that boosts food consumption but increases vulnerability to predators.\n",
        "\n",
        "Note that relative predation risks depend critically on the predator's policy. The resulting equilibrium from such an evolutionary tug-of-war is a set of policies where no single policy can unilaterally improve its outcome. In game theory, this stable state of the systemâ€”based on game payoffsâ€”is termed a Nash Equilibrium. (In Game Theory the term \"strategies\" is typically used instead of policy, but we will continue to use \"policy\" in line with standard reinforcement learning terminology.)\n",
        "\n",
        "A few clarifications are necessary about what this Nash Equilibrium is not:\n",
        "\n",
        "1. A set of policies maximizing the prey's scoreâ€”prey would fare much better against less skilled predators.\n",
        "2. The best set of policies for the predator; they'd have higher success rates against less evasive prey.\n",
        "3. The set of policies optimizing the average payoff across both populations.\n",
        "\n",
        "It's due to such nuances that we say evolution doesn't \"optimize\" in a traditional sense. Yet, while technically correct, a Nash Equilibrium is a set of policies that the \"best response\" to the each other. In this sense, evolutionary outcomes can be thought of as \"optimal.\"\n",
        "\n",
        "In Sequence 1.2.3, we explored the idea that optima depict an ideal state. The concept of equilibria, as illustrated here, extends and refines this notion. While our world remains in perpetual change, the underlying evolutionary dynamics constantly steer systems towards these \"mutual best response\" equilibrium points."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "zaIddvhR_Rou"
      },
      "source": [
        "This concludes our exploration of how competition and interaction introduce complexities into optimization. While evolutionary processes are more than just optimization processes, as we progress in this book, we'll primarily sidestep these game-theoretic considerations. Our primary take-away is that because living organisms are embedded in such evolutionary systems, which inherently drive change, there are selective pressures not just for adaptation to changing environments but ***rapid*** adaptation. In the next sequence we will see how within lifetime learning can play an integral role in adapting to rapidly changing environments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "tntr2LlL_Rou",
        "outputId": "670a51b5-2c66-4512-b53f-367bbba56708",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 62,
          "referenced_widgets": [
            "d2fccb46a3a343f3ad8edc9c085a011f",
            "9d806f63ae824472b124db967498675c",
            "66fee31a2634432cae5872bafb78d6b3",
            "ccd0591d92a14f5193a543aa15d29b21",
            "316ac12604a243ecabe89ef9f9f72dda",
            "2a8e417918e74e26aab42bafa63832aa",
            "303689966e9646acb06ea58e2edda9a6",
            "a1cf3f5068854233b0353fe904640b7c",
            "e2f3ca28d55f45e28b8ea2f17afd6c96",
            "bb39207116ed479d95aa67f9a30b495b",
            "8172ac70e39341429202e5be8984b002",
            "79189f7479f44117a35f900655bacd74",
            "970eaf384f3b4498bfe54e3cdae9e6aa",
            "9672c62472fd435d9bb68e6ddf48c16c",
            "fd2a337ddb53446ca3f20d1468f11811",
            "a57c811637644df594b25b11fa799879",
            "dfb48d232372450899e787bc4ab97087",
            "c4c7caaf5dff46cfab43743aa674f7d4",
            "9fb7e291b5594cef91b74c8e5d61e665",
            "fde716b82ee04cb48b5301cd7cd14f90",
            "f097f7d589fc4d7d9a3c949cecbbdb7f",
            "dde09dc500cb4091bc8c7f61c16d5b01",
            "bf602362152a49a2a49ce01d95d8940f",
            "8abcf26e44c749e2809ad44386d7b166",
            "a7d037a321db48d6a8295788de5f2690",
            "9830dfcb2662499c891053949e742b0f"
          ]
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(VBox(children=(HBox(children=(Button(description='ðŸ™‚', layout=Layout(height='auto', padding='0.5â€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d2fccb46a3a343f3ad8edc9c085a011f"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ],
      "source": [
        "# @markdown Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_M3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "cMh2cK7__Rou"
      },
      "source": [
        "# Quiz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "8vD_ibpe_Rou",
        "outputId": "bdcfe6e7-6068-4868-b305-6dda1d6054c1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div id=\"zOIrpOcCEKeu\" data-shufflequestions=\"False\"\n",
              "               data-shuffleanswers=\"True\"\n",
              "               data-preserveresponses=\"false\"\n",
              "               data-numquestions=\"1000000\"\n",
              "               data-maxwidth=\"600\"\n",
              "               style=\"border-radius: 10px; text-align: left\"> <style>\n",
              "#zOIrpOcCEKeu {\n",
              "   --jq-multiple-choice-bg: #6f78ffff;\n",
              "   --jq-mc-button-bg: #fafafa;\n",
              "   --jq-mc-button-border: #e0e0e0e0;\n",
              "   --jq-mc-button-inset-shadow: #555555;\n",
              "   --jq-many-choice-bg: #f75c03ff;\n",
              "   --jq-numeric-bg: #392061ff;\n",
              "   --jq-numeric-input-bg: #c0c0c0;\n",
              "   --jq-numeric-input-label: #101010;\n",
              "   --jq-numeric-input-shadow: #999999;\n",
              "   --jq-incorrect-color: #c80202;\n",
              "   --jq-correct-color: #009113;\n",
              "   --jq-text-color: #fafafa;\n",
              "}\n",
              "\n",
              ".Quiz {\n",
              "    max-width: 600px;\n",
              "    margin-top: 15px;\n",
              "    margin-left: auto;\n",
              "    margin-right: auto;\n",
              "    margin-bottom: 15px;\n",
              "    padding-bottom: 4px;\n",
              "    padding-top: 4px;\n",
              "    line-height: 1.1;\n",
              "    font-size: 16pt;\n",
              "    border-radius: inherit;\n",
              "}\n",
              "\n",
              ".QuizCode {\n",
              "    font-size: 14pt;\n",
              "    margin-top: 10px;\n",
              "    margin-left: 20px;\n",
              "    margin-right: 20px;\n",
              "}\n",
              "\n",
              ".QuizCode>pre {\n",
              "    padding: 4px;\n",
              "}\n",
              "\n",
              ".Answer {\n",
              "    margin: 10px 0;\n",
              "    display: grid;\n",
              "    grid-template-columns: 1fr 1fr;\n",
              "    grid-gap: 10px;\n",
              "    border-radius: inherit;\n",
              "}\n",
              "\n",
              ".Feedback {\n",
              "    font-size: 16pt;\n",
              "    text-align: center;\n",
              "    min-height: 2em;\n",
              "}\n",
              "\n",
              ".Input {\n",
              "    align: left;\n",
              "    font-size: 20pt;\n",
              "}\n",
              "\n",
              ".Input-text {\n",
              "    display: block;\n",
              "    margin: 10px;\n",
              "    color: inherit;\n",
              "    width: 140px;\n",
              "    background-color: var(--jq-numeric-input-bg);\n",
              "    color: var(--jq-text-color);\n",
              "    padding: 5px;\n",
              "    padding-left: 10px;\n",
              "    font-family: inherit;\n",
              "    font-size: 20px;\n",
              "    font-weight: inherit;\n",
              "    line-height: 20pt;\n",
              "    border: none;\n",
              "    border-radius: 0.2rem;\n",
              "    transition: box-shadow 0.1s);\n",
              "}\n",
              "\n",
              ".Input-text:focus {\n",
              "    outline: none;\n",
              "    background-color: var(--jq-numeric-input-bg);\n",
              "    box-shadow: 0.6rem 0.8rem 1.4rem -0.5rem var(--jq-numeric-input-shadow);\n",
              "}\n",
              "\n",
              ".MCButton {\n",
              "    background: var(--jq-mc-button-bg);\n",
              "    border: 1px solid var(--jq-mc-button-border);\n",
              "    border-radius: inherit;\n",
              "    padding: 10px;\n",
              "    font-size: 16px;\n",
              "    cursor: pointer;\n",
              "    text-align: center;\n",
              "    display: flex;\n",
              "    align-items: center;\n",
              "    justify-content: center;\n",
              "}\n",
              "\n",
              ".MCButton p {\n",
              "    color: inherit;\n",
              "}\n",
              "\n",
              ".MultipleChoiceQn {\n",
              "    padding: 10px;\n",
              "    background: var(--jq-multiple-choice-bg);\n",
              "    color: var(--jq-text-color);\n",
              "    border-radius: inherit;\n",
              "}\n",
              "\n",
              ".ManyChoiceQn {\n",
              "    padding: 10px;\n",
              "    background: var(--jq-many-choice-bg);\n",
              "    color: var(--jq-text-color);\n",
              "    border-radius: inherit;\n",
              "}\n",
              "\n",
              ".NumericQn {\n",
              "    padding: 10px;\n",
              "    background: var(--jq-numeric-bg);\n",
              "    color: var(--jq-text-color);\n",
              "    border-radius: inherit;\n",
              "}\n",
              "\n",
              ".NumericQn p {\n",
              "    color: inherit;\n",
              "}\n",
              "\n",
              ".InpLabel {\n",
              "    line-height: 34px;\n",
              "    float: left;\n",
              "    margin-right: 10px;\n",
              "    color: var(--jq-numeric-input-label);\n",
              "    font-size: 15pt;\n",
              "}\n",
              "\n",
              ".incorrect {\n",
              "    color: var(--jq-incorrect-color);\n",
              "}\n",
              "\n",
              ".correct {\n",
              "    color: var(--jq-correct-color);\n",
              "}\n",
              "\n",
              ".correctButton {\n",
              "    /*\n",
              "    background: var(--jq-correct-color);\n",
              "   */\n",
              "    animation: correct-anim 0.6s ease;\n",
              "    animation-fill-mode: forwards;\n",
              "    color: var(--jq-text-color);\n",
              "    box-shadow: inset 0px 0px 5px var(--jq-mc-button-inset-shadow);\n",
              "    outline: none;\n",
              "}\n",
              "\n",
              ".incorrectButton {\n",
              "    animation: incorrect-anim 0.8s ease;\n",
              "    animation-fill-mode: forwards;\n",
              "    color: var(--jq-text-color);\n",
              "    box-shadow: inset 0px 0px 5px var(--jq-mc-button-inset-shadow);\n",
              "    outline: none;\n",
              "}\n",
              "\n",
              "@keyframes incorrect-anim {\n",
              "    100% {\n",
              "        background-color: var(--jq-incorrect-color);\n",
              "    }\n",
              "}\n",
              "\n",
              "@keyframes correct-anim {\n",
              "    100% {\n",
              "        background-color: var(--jq-correct-color);\n",
              "    }\n",
              "}\n",
              "</style>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "var questionszOIrpOcCEKeu=[{\"question\": \"What overarching principles was illustrated in these evolutionary Gridworld simulation?\", \"type\": \"multiple_choice\", \"answers\": [{\"answer\": \"Static behaviours result in predictable outcomes.\", \"correct\": false, \"feedback\": \"While this is sometimes true, these simulations were primarily about adaptive and evolving behaviours.\"}, {\"answer\": \"Organisms constantly adapt their behaviours in response to their environment and other organisms.\", \"correct\": true, \"feedback\": \"Exactly! The predator-prey dynamic in the Gridworld simulation demonstrates the continuous adaptation of behaviors in response to both environmental and inter-organismal factors.\"}, {\"answer\": \"Organisms with faster movement are always dominant in their environment.\", \"correct\": false, \"feedback\": \"Speed might be advantageous, but adaptation and strategy can often overcome sheer speed.\"}, {\"answer\": \"Evolutionary outcomes are entirely random and lack predictability.\", \"correct\": false, \"feedback\": \"While there might be elements of randomness, evolutionary outcomes are largely driven by environmental pressures and are not entirely random.\"}]}, {\"question\": \"What is a primary goal of using evolutionary strategies like CMA-ES in optimization problems?\", \"type\": \"multiple_choice\", \"answers\": [{\"answer\": \"To maintain a static solution throughout iterations.\", \"correct\": false, \"feedback\": \"Evolutionary strategies aim to adapt and refine solutions, not keep them static.\"}, {\"answer\": \"To iteratively refine solutions, increasing the likelihood of better outcomes over time.\", \"correct\": true, \"feedback\": \"Correct! Evolutionary strategies like CMA-ES work iteratively, refining solutions to yield better outcomes as they progress.\"}, {\"answer\": \"To always ensure a perfect solution in the first iteration.\", \"correct\": false, \"feedback\": \"Evolutionary strategies work over multiple iterations and don't guarantee perfection in the first attempt.\"}, {\"answer\": \"To decrease the randomness in evolutionary algorithms.\", \"correct\": false, \"feedback\": \"While they refine solutions, evolutionary strategies still incorporate randomness or stochastic processes to discover optimal solutions.\"}]}, {\"question\": \"When both prey and predator populations are allowed to evolve simultaneously, this process of mutual adaptation can best be described as:\", \"type\": \"multiple_choice\", \"answers\": [{\"answer\": \"Mono-evolution, where only one species evolves while the other remains static.\", \"correct\": false, \"feedback\": \"Mono-evolution implies evolution in isolation, which is not the case here.\"}, {\"answer\": \"Static evolution, where both species remain unchanged despite environmental pressures.\", \"correct\": false, \"feedback\": \"Static evolution doesn't capture the essence of mutual adaptation observed in the discussed scenario.\"}, {\"answer\": \"Co-evolution, where both species undergo evolutionary adjustments in response to each other.\", \"correct\": true, \"feedback\": \"Exactly! Co-evolution refers to the process where two or more species reciprocally affect each other's evolution.\"}, {\"answer\": \"Random evolution, where changes in species are entirely unpredictable and lack direction.\", \"correct\": false, \"feedback\": \"The process described is systematic and driven by environmental and interspecies dynamics, not entirely random.\"}]}];\n",
              "    // Make a random ID\n",
              "function makeid(length) {\n",
              "    var result = [];\n",
              "    var characters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz';\n",
              "    var charactersLength = characters.length;\n",
              "    for (var i = 0; i < length; i++) {\n",
              "        result.push(characters.charAt(Math.floor(Math.random() * charactersLength)));\n",
              "    }\n",
              "    return result.join('');\n",
              "}\n",
              "\n",
              "// Choose a random subset of an array. Can also be used to shuffle the array\n",
              "function getRandomSubarray(arr, size) {\n",
              "    var shuffled = arr.slice(0), i = arr.length, temp, index;\n",
              "    while (i--) {\n",
              "        index = Math.floor((i + 1) * Math.random());\n",
              "        temp = shuffled[index];\n",
              "        shuffled[index] = shuffled[i];\n",
              "        shuffled[i] = temp;\n",
              "    }\n",
              "    return shuffled.slice(0, size);\n",
              "}\n",
              "\n",
              "function printResponses(responsesContainer) {\n",
              "    var responses=JSON.parse(responsesContainer.dataset.responses);\n",
              "    var stringResponses='<B>IMPORTANT!</B>To preserve this answer sequence for submission, when you have finalized your answers: <ol> <li> Copy the text in this cell below \"Answer String\"</li> <li> Double click on the cell directly below the Answer String, labeled \"Replace Me\"</li> <li> Select the whole \"Replace Me\" text</li> <li> Paste in your answer string and press shift-Enter.</li><li>Save the notebook using the save icon or File->Save Notebook menu item</li></ul><br><br><br><b>Answer String:</b><br> ';\n",
              "    console.log(responses);\n",
              "    responses.forEach((response, index) => {\n",
              "        if (response) {\n",
              "            console.log(index + ': ' + response);\n",
              "            stringResponses+= index + ': ' + response +\"<BR>\";\n",
              "        }\n",
              "    });\n",
              "    responsesContainer.innerHTML=stringResponses;\n",
              "}\n",
              "function check_mc() {\n",
              "    var id = this.id.split('-')[0];\n",
              "    //var response = this.id.split('-')[1];\n",
              "    //console.log(response);\n",
              "    //console.log(\"In check_mc(), id=\"+id);\n",
              "    //console.log(event.srcElement.id)           \n",
              "    //console.log(event.srcElement.dataset.correct)   \n",
              "    //console.log(event.srcElement.dataset.feedback)\n",
              "\n",
              "    var label = event.srcElement;\n",
              "    //console.log(label, label.nodeName);\n",
              "    var depth = 0;\n",
              "    while ((label.nodeName != \"LABEL\") && (depth < 20)) {\n",
              "        label = label.parentElement;\n",
              "        console.log(depth, label);\n",
              "        depth++;\n",
              "    }\n",
              "\n",
              "\n",
              "\n",
              "    var answers = label.parentElement.children;\n",
              "\n",
              "    //console.log(answers);\n",
              "\n",
              "\n",
              "    // Split behavior based on multiple choice vs many choice:\n",
              "    var fb = document.getElementById(\"fb\" + id);\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "    if (fb.dataset.numcorrect == 1) {\n",
              "        // What follows is for the saved responses stuff\n",
              "        var outerContainer = fb.parentElement.parentElement;\n",
              "        var responsesContainer = document.getElementById(\"responses\" + outerContainer.id);\n",
              "        if (responsesContainer) {\n",
              "            //console.log(responsesContainer);\n",
              "            var response = label.firstChild.innerText;\n",
              "            if (label.querySelector(\".QuizCode\")){\n",
              "                response+= label.querySelector(\".QuizCode\").firstChild.innerText;\n",
              "            }\n",
              "            console.log(response);\n",
              "            //console.log(document.getElementById(\"quizWrap\"+id));\n",
              "            var qnum = document.getElementById(\"quizWrap\"+id).dataset.qnum;\n",
              "            console.log(\"Question \" + qnum);\n",
              "            //console.log(id, \", got numcorrect=\",fb.dataset.numcorrect);\n",
              "            var responses=JSON.parse(responsesContainer.dataset.responses);\n",
              "            console.log(responses);\n",
              "            responses[qnum]= response;\n",
              "            responsesContainer.setAttribute('data-responses', JSON.stringify(responses));\n",
              "            printResponses(responsesContainer);\n",
              "        }\n",
              "        // End code to preserve responses\n",
              "        \n",
              "        for (var i = 0; i < answers.length; i++) {\n",
              "            var child = answers[i];\n",
              "            //console.log(child);\n",
              "            child.className = \"MCButton\";\n",
              "        }\n",
              "\n",
              "\n",
              "\n",
              "        if (label.dataset.correct == \"true\") {\n",
              "            // console.log(\"Correct action\");\n",
              "            if (\"feedback\" in label.dataset) {\n",
              "                fb.textContent = jaxify(label.dataset.feedback);\n",
              "            } else {\n",
              "                fb.textContent = \"Correct!\";\n",
              "            }\n",
              "            label.classList.add(\"correctButton\");\n",
              "\n",
              "            fb.className = \"Feedback\";\n",
              "            fb.classList.add(\"correct\");\n",
              "\n",
              "        } else {\n",
              "            if (\"feedback\" in label.dataset) {\n",
              "                fb.textContent = jaxify(label.dataset.feedback);\n",
              "            } else {\n",
              "                fb.textContent = \"Incorrect -- try again.\";\n",
              "            }\n",
              "            //console.log(\"Error action\");\n",
              "            label.classList.add(\"incorrectButton\");\n",
              "            fb.className = \"Feedback\";\n",
              "            fb.classList.add(\"incorrect\");\n",
              "        }\n",
              "    }\n",
              "    else {\n",
              "        var reset = false;\n",
              "        var feedback;\n",
              "         if (label.dataset.correct == \"true\") {\n",
              "            if (\"feedback\" in label.dataset) {\n",
              "                feedback = jaxify(label.dataset.feedback);\n",
              "            } else {\n",
              "                feedback = \"Correct!\";\n",
              "            }\n",
              "            if (label.dataset.answered <= 0) {\n",
              "                if (fb.dataset.answeredcorrect < 0) {\n",
              "                    fb.dataset.answeredcorrect = 1;\n",
              "                    reset = true;\n",
              "                } else {\n",
              "                    fb.dataset.answeredcorrect++;\n",
              "                }\n",
              "                if (reset) {\n",
              "                    for (var i = 0; i < answers.length; i++) {\n",
              "                        var child = answers[i];\n",
              "                        child.className = \"MCButton\";\n",
              "                        child.dataset.answered = 0;\n",
              "                    }\n",
              "                }\n",
              "                label.classList.add(\"correctButton\");\n",
              "                label.dataset.answered = 1;\n",
              "                fb.className = \"Feedback\";\n",
              "                fb.classList.add(\"correct\");\n",
              "\n",
              "            }\n",
              "        } else {\n",
              "            if (\"feedback\" in label.dataset) {\n",
              "                feedback = jaxify(label.dataset.feedback);\n",
              "            } else {\n",
              "                feedback = \"Incorrect -- try again.\";\n",
              "            }\n",
              "            if (fb.dataset.answeredcorrect > 0) {\n",
              "                fb.dataset.answeredcorrect = -1;\n",
              "                reset = true;\n",
              "            } else {\n",
              "                fb.dataset.answeredcorrect--;\n",
              "            }\n",
              "\n",
              "            if (reset) {\n",
              "                for (var i = 0; i < answers.length; i++) {\n",
              "                    var child = answers[i];\n",
              "                    child.className = \"MCButton\";\n",
              "                    child.dataset.answered = 0;\n",
              "                }\n",
              "            }\n",
              "            label.classList.add(\"incorrectButton\");\n",
              "            fb.className = \"Feedback\";\n",
              "            fb.classList.add(\"incorrect\");\n",
              "        }\n",
              "        // What follows is for the saved responses stuff\n",
              "        var outerContainer = fb.parentElement.parentElement;\n",
              "        var responsesContainer = document.getElementById(\"responses\" + outerContainer.id);\n",
              "        if (responsesContainer) {\n",
              "            //console.log(responsesContainer);\n",
              "            var response = label.firstChild.innerText;\n",
              "            if (label.querySelector(\".QuizCode\")){\n",
              "                response+= label.querySelector(\".QuizCode\").firstChild.innerText;\n",
              "            }\n",
              "            console.log(response);\n",
              "            //console.log(document.getElementById(\"quizWrap\"+id));\n",
              "            var qnum = document.getElementById(\"quizWrap\"+id).dataset.qnum;\n",
              "            console.log(\"Question \" + qnum);\n",
              "            //console.log(id, \", got numcorrect=\",fb.dataset.numcorrect);\n",
              "            var responses=JSON.parse(responsesContainer.dataset.responses);\n",
              "            if (label.dataset.correct == \"true\") {\n",
              "                if (typeof(responses[qnum]) == \"object\"){\n",
              "                    if (!responses[qnum].includes(response))\n",
              "                        responses[qnum].push(response);\n",
              "                } else{\n",
              "                    responses[qnum]= [ response ];\n",
              "                }\n",
              "            } else {\n",
              "                responses[qnum]= response;\n",
              "            }\n",
              "            console.log(responses);\n",
              "            responsesContainer.setAttribute('data-responses', JSON.stringify(responses));\n",
              "            printResponses(responsesContainer);\n",
              "        }\n",
              "        // End save responses stuff\n",
              "\n",
              "\n",
              "\n",
              "        var numcorrect = fb.dataset.numcorrect;\n",
              "        var answeredcorrect = fb.dataset.answeredcorrect;\n",
              "        if (answeredcorrect >= 0) {\n",
              "            fb.textContent = feedback + \" [\" + answeredcorrect + \"/\" + numcorrect + \"]\";\n",
              "        } else {\n",
              "            fb.textContent = feedback + \" [\" + 0 + \"/\" + numcorrect + \"]\";\n",
              "        }\n",
              "\n",
              "\n",
              "    }\n",
              "\n",
              "    if (typeof MathJax != 'undefined') {\n",
              "        var version = MathJax.version;\n",
              "        console.log('MathJax version', version);\n",
              "        if (version[0] == \"2\") {\n",
              "            MathJax.Hub.Queue([\"Typeset\", MathJax.Hub]);\n",
              "        } else if (version[0] == \"3\") {\n",
              "            MathJax.typeset([fb]);\n",
              "        }\n",
              "    } else {\n",
              "        console.log('MathJax not detected');\n",
              "    }\n",
              "\n",
              "}\n",
              "\n",
              "function make_mc(qa, shuffle_answers, outerqDiv, qDiv, aDiv, id) {\n",
              "    var shuffled;\n",
              "    if (shuffle_answers == \"True\") {\n",
              "        //console.log(shuffle_answers+\" read as true\");\n",
              "        shuffled = getRandomSubarray(qa.answers, qa.answers.length);\n",
              "    } else {\n",
              "        //console.log(shuffle_answers+\" read as false\");\n",
              "        shuffled = qa.answers;\n",
              "    }\n",
              "\n",
              "\n",
              "    var num_correct = 0;\n",
              "\n",
              "\n",
              "\n",
              "    shuffled.forEach((item, index, ans_array) => {\n",
              "        //console.log(answer);\n",
              "\n",
              "        // Make input element\n",
              "        var inp = document.createElement(\"input\");\n",
              "        inp.type = \"radio\";\n",
              "        inp.id = \"quizo\" + id + index;\n",
              "        inp.style = \"display:none;\";\n",
              "        aDiv.append(inp);\n",
              "\n",
              "        //Make label for input element\n",
              "        var lab = document.createElement(\"label\");\n",
              "        lab.className = \"MCButton\";\n",
              "        lab.id = id + '-' + index;\n",
              "        lab.onclick = check_mc;\n",
              "        var aSpan = document.createElement('span');\n",
              "        aSpan.classsName = \"\";\n",
              "        //qDiv.id=\"quizQn\"+id+index;\n",
              "        if (\"answer\" in item) {\n",
              "            aSpan.innerHTML = jaxify(item.answer);\n",
              "            //aSpan.innerHTML=item.answer;\n",
              "        }\n",
              "        lab.append(aSpan);\n",
              "\n",
              "        // Create div for code inside question\n",
              "        var codeSpan;\n",
              "        if (\"code\" in item) {\n",
              "            codeSpan = document.createElement('span');\n",
              "            codeSpan.id = \"code\" + id + index;\n",
              "            codeSpan.className = \"QuizCode\";\n",
              "            var codePre = document.createElement('pre');\n",
              "            codeSpan.append(codePre);\n",
              "            var codeCode = document.createElement('code');\n",
              "            codePre.append(codeCode);\n",
              "            codeCode.innerHTML = item.code;\n",
              "            lab.append(codeSpan);\n",
              "            //console.log(codeSpan);\n",
              "        }\n",
              "\n",
              "        //lab.textContent=item.answer;\n",
              "\n",
              "        // Set the data attributes for the answer\n",
              "        lab.setAttribute('data-correct', item.correct);\n",
              "        if (item.correct) {\n",
              "            num_correct++;\n",
              "        }\n",
              "        if (\"feedback\" in item) {\n",
              "            lab.setAttribute('data-feedback', item.feedback);\n",
              "        }\n",
              "        lab.setAttribute('data-answered', 0);\n",
              "\n",
              "        aDiv.append(lab);\n",
              "\n",
              "    });\n",
              "\n",
              "    if (num_correct > 1) {\n",
              "        outerqDiv.className = \"ManyChoiceQn\";\n",
              "    } else {\n",
              "        outerqDiv.className = \"MultipleChoiceQn\";\n",
              "    }\n",
              "\n",
              "    return num_correct;\n",
              "\n",
              "}\n",
              "function check_numeric(ths, event) {\n",
              "\n",
              "    if (event.keyCode === 13) {\n",
              "        ths.blur();\n",
              "\n",
              "        var id = ths.id.split('-')[0];\n",
              "\n",
              "        var submission = ths.value;\n",
              "        if (submission.indexOf('/') != -1) {\n",
              "            var sub_parts = submission.split('/');\n",
              "            //console.log(sub_parts);\n",
              "            submission = sub_parts[0] / sub_parts[1];\n",
              "        }\n",
              "        //console.log(\"Reader entered\", submission);\n",
              "\n",
              "        if (\"precision\" in ths.dataset) {\n",
              "            var precision = ths.dataset.precision;\n",
              "            // console.log(\"1:\", submission)\n",
              "            submission = Math.round((1 * submission + Number.EPSILON) * 10 ** precision) / 10 ** precision;\n",
              "            // console.log(\"Rounded to \", submission, \" precision=\", precision  );\n",
              "        }\n",
              "\n",
              "\n",
              "        //console.log(\"In check_numeric(), id=\"+id);\n",
              "        //console.log(event.srcElement.id)           \n",
              "        //console.log(event.srcElement.dataset.feedback)\n",
              "\n",
              "        var fb = document.getElementById(\"fb\" + id);\n",
              "        fb.style.display = \"none\";\n",
              "        fb.textContent = \"Incorrect -- try again.\";\n",
              "\n",
              "        var answers = JSON.parse(ths.dataset.answers);\n",
              "        //console.log(answers);\n",
              "\n",
              "        var defaultFB = \"\";\n",
              "        var correct;\n",
              "        var done = false;\n",
              "        answers.every(answer => {\n",
              "            //console.log(answer.type);\n",
              "\n",
              "            correct = false;\n",
              "            // if (answer.type==\"value\"){\n",
              "            if ('value' in answer) {\n",
              "                if (submission == answer.value) {\n",
              "                    if (\"feedback\" in answer) {\n",
              "                        fb.textContent = jaxify(answer.feedback);\n",
              "                    } else {\n",
              "                        fb.textContent = jaxify(\"Correct\");\n",
              "                    }\n",
              "                    correct = answer.correct;\n",
              "                    //console.log(answer.correct);\n",
              "                    done = true;\n",
              "                }\n",
              "                // } else if (answer.type==\"range\") {\n",
              "            } else if ('range' in answer) {\n",
              "                //console.log(answer.range);\n",
              "                if ((submission >= answer.range[0]) && (submission < answer.range[1])) {\n",
              "                    fb.textContent = jaxify(answer.feedback);\n",
              "                    correct = answer.correct;\n",
              "                    //console.log(answer.correct);\n",
              "                    done = true;\n",
              "                }\n",
              "            } else if (answer.type == \"default\") {\n",
              "                defaultFB = answer.feedback;\n",
              "            }\n",
              "            if (done) {\n",
              "                return false; // Break out of loop if this has been marked correct\n",
              "            } else {\n",
              "                return true; // Keep looking for case that includes this as a correct answer\n",
              "            }\n",
              "        });\n",
              "\n",
              "        if ((!done) && (defaultFB != \"\")) {\n",
              "            fb.innerHTML = jaxify(defaultFB);\n",
              "            //console.log(\"Default feedback\", defaultFB);\n",
              "        }\n",
              "\n",
              "        fb.style.display = \"block\";\n",
              "        if (correct) {\n",
              "            ths.className = \"Input-text\";\n",
              "            ths.classList.add(\"correctButton\");\n",
              "            fb.className = \"Feedback\";\n",
              "            fb.classList.add(\"correct\");\n",
              "        } else {\n",
              "            ths.className = \"Input-text\";\n",
              "            ths.classList.add(\"incorrectButton\");\n",
              "            fb.className = \"Feedback\";\n",
              "            fb.classList.add(\"incorrect\");\n",
              "        }\n",
              "\n",
              "        // What follows is for the saved responses stuff\n",
              "        var outerContainer = fb.parentElement.parentElement;\n",
              "        var responsesContainer = document.getElementById(\"responses\" + outerContainer.id);\n",
              "        if (responsesContainer) {\n",
              "            console.log(submission);\n",
              "            var qnum = document.getElementById(\"quizWrap\"+id).dataset.qnum;\n",
              "            //console.log(\"Question \" + qnum);\n",
              "            //console.log(id, \", got numcorrect=\",fb.dataset.numcorrect);\n",
              "            var responses=JSON.parse(responsesContainer.dataset.responses);\n",
              "            console.log(responses);\n",
              "            if (submission == ths.value){\n",
              "                responses[qnum]= submission;\n",
              "            } else {\n",
              "                responses[qnum]= ths.value + \"(\" + submission +\")\";\n",
              "            }\n",
              "            responsesContainer.setAttribute('data-responses', JSON.stringify(responses));\n",
              "            printResponses(responsesContainer);\n",
              "        }\n",
              "        // End code to preserve responses\n",
              "\n",
              "        if (typeof MathJax != 'undefined') {\n",
              "            var version = MathJax.version;\n",
              "            console.log('MathJax version', version);\n",
              "            if (version[0] == \"2\") {\n",
              "                MathJax.Hub.Queue([\"Typeset\", MathJax.Hub]);\n",
              "            } else if (version[0] == \"3\") {\n",
              "                MathJax.typeset([fb]);\n",
              "            }\n",
              "        } else {\n",
              "            console.log('MathJax not detected');\n",
              "        }\n",
              "        return false;\n",
              "    }\n",
              "\n",
              "}\n",
              "\n",
              "function isValid(el, charC) {\n",
              "    //console.log(\"Input char: \", charC);\n",
              "    if (charC == 46) {\n",
              "        if (el.value.indexOf('.') === -1) {\n",
              "            return true;\n",
              "        } else if (el.value.indexOf('/') != -1) {\n",
              "            var parts = el.value.split('/');\n",
              "            if (parts[1].indexOf('.') === -1) {\n",
              "                return true;\n",
              "            }\n",
              "        }\n",
              "        else {\n",
              "            return false;\n",
              "        }\n",
              "    } else if (charC == 47) {\n",
              "        if (el.value.indexOf('/') === -1) {\n",
              "            if ((el.value != \"\") && (el.value != \".\")) {\n",
              "                return true;\n",
              "            } else {\n",
              "                return false;\n",
              "            }\n",
              "        } else {\n",
              "            return false;\n",
              "        }\n",
              "    } else if (charC == 45) {\n",
              "        var edex = el.value.indexOf('e');\n",
              "        if (edex == -1) {\n",
              "            edex = el.value.indexOf('E');\n",
              "        }\n",
              "\n",
              "        if (el.value == \"\") {\n",
              "            return true;\n",
              "        } else if (edex == (el.value.length - 1)) { // If just after e or E\n",
              "            return true;\n",
              "        } else {\n",
              "            return false;\n",
              "        }\n",
              "    } else if (charC == 101) { // \"e\"\n",
              "        if ((el.value.indexOf('e') === -1) && (el.value.indexOf('E') === -1) && (el.value.indexOf('/') == -1)) {\n",
              "            // Prev symbol must be digit or decimal point:\n",
              "            if (el.value.slice(-1).search(/\\d/) >= 0) {\n",
              "                return true;\n",
              "            } else if (el.value.slice(-1).search(/\\./) >= 0) {\n",
              "                return true;\n",
              "            } else {\n",
              "                return false;\n",
              "            }\n",
              "        } else {\n",
              "            return false;\n",
              "        }\n",
              "    } else {\n",
              "        if (charC > 31 && (charC < 48 || charC > 57))\n",
              "            return false;\n",
              "    }\n",
              "    return true;\n",
              "}\n",
              "\n",
              "function numeric_keypress(evnt) {\n",
              "    var charC = (evnt.which) ? evnt.which : evnt.keyCode;\n",
              "\n",
              "    if (charC == 13) {\n",
              "        check_numeric(this, evnt);\n",
              "    } else {\n",
              "        return isValid(this, charC);\n",
              "    }\n",
              "}\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "\n",
              "function make_numeric(qa, outerqDiv, qDiv, aDiv, id) {\n",
              "\n",
              "\n",
              "\n",
              "    //console.log(answer);\n",
              "\n",
              "\n",
              "    outerqDiv.className = \"NumericQn\";\n",
              "    aDiv.style.display = 'block';\n",
              "\n",
              "    var lab = document.createElement(\"label\");\n",
              "    lab.className = \"InpLabel\";\n",
              "    lab.textContent = \"Type numeric answer here:\";\n",
              "    aDiv.append(lab);\n",
              "\n",
              "    var inp = document.createElement(\"input\");\n",
              "    inp.type = \"text\";\n",
              "    //inp.id=\"input-\"+id;\n",
              "    inp.id = id + \"-0\";\n",
              "    inp.className = \"Input-text\";\n",
              "    inp.setAttribute('data-answers', JSON.stringify(qa.answers));\n",
              "    if (\"precision\" in qa) {\n",
              "        inp.setAttribute('data-precision', qa.precision);\n",
              "    }\n",
              "    aDiv.append(inp);\n",
              "    //console.log(inp);\n",
              "\n",
              "    //inp.addEventListener(\"keypress\", check_numeric);\n",
              "    //inp.addEventListener(\"keypress\", numeric_keypress);\n",
              "    /*\n",
              "    inp.addEventListener(\"keypress\", function(event) {\n",
              "        return numeric_keypress(this, event);\n",
              "    }\n",
              "                        );\n",
              "                        */\n",
              "    //inp.onkeypress=\"return numeric_keypress(this, event)\";\n",
              "    inp.onkeypress = numeric_keypress;\n",
              "    inp.onpaste = event => false;\n",
              "\n",
              "    inp.addEventListener(\"focus\", function (event) {\n",
              "        this.value = \"\";\n",
              "        return false;\n",
              "    }\n",
              "    );\n",
              "\n",
              "\n",
              "}\n",
              "function jaxify(string) {\n",
              "    var mystring = string;\n",
              "\n",
              "    var count = 0;\n",
              "    var loc = mystring.search(/([^\\\\]|^)(\\$)/);\n",
              "\n",
              "    var count2 = 0;\n",
              "    var loc2 = mystring.search(/([^\\\\]|^)(\\$\\$)/);\n",
              "\n",
              "    //console.log(loc);\n",
              "\n",
              "    while ((loc >= 0) || (loc2 >= 0)) {\n",
              "\n",
              "        /* Have to replace all the double $$ first with current implementation */\n",
              "        if (loc2 >= 0) {\n",
              "            if (count2 % 2 == 0) {\n",
              "                mystring = mystring.replace(/([^\\\\]|^)(\\$\\$)/, \"$1\\\\[\");\n",
              "            } else {\n",
              "                mystring = mystring.replace(/([^\\\\]|^)(\\$\\$)/, \"$1\\\\]\");\n",
              "            }\n",
              "            count2++;\n",
              "        } else {\n",
              "            if (count % 2 == 0) {\n",
              "                mystring = mystring.replace(/([^\\\\]|^)(\\$)/, \"$1\\\\(\");\n",
              "            } else {\n",
              "                mystring = mystring.replace(/([^\\\\]|^)(\\$)/, \"$1\\\\)\");\n",
              "            }\n",
              "            count++;\n",
              "        }\n",
              "        loc = mystring.search(/([^\\\\]|^)(\\$)/);\n",
              "        loc2 = mystring.search(/([^\\\\]|^)(\\$\\$)/);\n",
              "        //console.log(mystring,\", loc:\",loc,\", loc2:\",loc2);\n",
              "    }\n",
              "\n",
              "    //console.log(mystring);\n",
              "    return mystring;\n",
              "}\n",
              "\n",
              "\n",
              "function show_questions(json, mydiv) {\n",
              "    console.log('show_questions');\n",
              "    //var mydiv=document.getElementById(myid);\n",
              "    var shuffle_questions = mydiv.dataset.shufflequestions;\n",
              "    var num_questions = mydiv.dataset.numquestions;\n",
              "    var shuffle_answers = mydiv.dataset.shuffleanswers;\n",
              "    var max_width = mydiv.dataset.maxwidth;\n",
              "\n",
              "    if (num_questions > json.length) {\n",
              "        num_questions = json.length;\n",
              "    }\n",
              "\n",
              "    var questions;\n",
              "    if ((num_questions < json.length) || (shuffle_questions == \"True\")) {\n",
              "        //console.log(num_questions+\",\"+json.length);\n",
              "        questions = getRandomSubarray(json, num_questions);\n",
              "    } else {\n",
              "        questions = json;\n",
              "    }\n",
              "\n",
              "    //console.log(\"SQ: \"+shuffle_questions+\", NQ: \" + num_questions + \", SA: \", shuffle_answers);\n",
              "\n",
              "    // Iterate over questions\n",
              "    questions.forEach((qa, index, array) => {\n",
              "        //console.log(qa.question); \n",
              "\n",
              "        var id = makeid(8);\n",
              "        //console.log(id);\n",
              "\n",
              "\n",
              "        // Create Div to contain question and answers\n",
              "        var iDiv = document.createElement('div');\n",
              "        //iDiv.id = 'quizWrap' + id + index;\n",
              "        iDiv.id = 'quizWrap' + id;\n",
              "        iDiv.className = 'Quiz';\n",
              "        iDiv.setAttribute('data-qnum', index);\n",
              "        iDiv.style.maxWidth  =max_width+\"px\";\n",
              "        mydiv.appendChild(iDiv);\n",
              "        // iDiv.innerHTML=qa.question;\n",
              "        \n",
              "        var outerqDiv = document.createElement('div');\n",
              "        outerqDiv.id = \"OuterquizQn\" + id + index;\n",
              "        // Create div to contain question part\n",
              "        var qDiv = document.createElement('div');\n",
              "        qDiv.id = \"quizQn\" + id + index;\n",
              "        \n",
              "        if (qa.question) {\n",
              "            iDiv.append(outerqDiv);\n",
              "\n",
              "            //qDiv.textContent=qa.question;\n",
              "            qDiv.innerHTML = jaxify(qa.question);\n",
              "            outerqDiv.append(qDiv);\n",
              "        }\n",
              "\n",
              "        // Create div for code inside question\n",
              "        var codeDiv;\n",
              "        if (\"code\" in qa) {\n",
              "            codeDiv = document.createElement('div');\n",
              "            codeDiv.id = \"code\" + id + index;\n",
              "            codeDiv.className = \"QuizCode\";\n",
              "            var codePre = document.createElement('pre');\n",
              "            codeDiv.append(codePre);\n",
              "            var codeCode = document.createElement('code');\n",
              "            codePre.append(codeCode);\n",
              "            codeCode.innerHTML = qa.code;\n",
              "            outerqDiv.append(codeDiv);\n",
              "            //console.log(codeDiv);\n",
              "        }\n",
              "\n",
              "\n",
              "        // Create div to contain answer part\n",
              "        var aDiv = document.createElement('div');\n",
              "        aDiv.id = \"quizAns\" + id + index;\n",
              "        aDiv.className = 'Answer';\n",
              "        iDiv.append(aDiv);\n",
              "\n",
              "        //console.log(qa.type);\n",
              "\n",
              "        var num_correct;\n",
              "        if ((qa.type == \"multiple_choice\") || (qa.type == \"many_choice\") ) {\n",
              "            num_correct = make_mc(qa, shuffle_answers, outerqDiv, qDiv, aDiv, id);\n",
              "            if (\"answer_cols\" in qa) {\n",
              "                //aDiv.style.gridTemplateColumns = 'auto '.repeat(qa.answer_cols);\n",
              "                aDiv.style.gridTemplateColumns = 'repeat(' + qa.answer_cols + ', 1fr)';\n",
              "            }\n",
              "        } else if (qa.type == \"numeric\") {\n",
              "            //console.log(\"numeric\");\n",
              "            make_numeric(qa, outerqDiv, qDiv, aDiv, id);\n",
              "        }\n",
              "\n",
              "\n",
              "        //Make div for feedback\n",
              "        var fb = document.createElement(\"div\");\n",
              "        fb.id = \"fb\" + id;\n",
              "        //fb.style=\"font-size: 20px;text-align:center;\";\n",
              "        fb.className = \"Feedback\";\n",
              "        fb.setAttribute(\"data-answeredcorrect\", 0);\n",
              "        fb.setAttribute(\"data-numcorrect\", num_correct);\n",
              "        iDiv.append(fb);\n",
              "\n",
              "\n",
              "    });\n",
              "    var preserveResponses = mydiv.dataset.preserveresponses;\n",
              "    console.log(preserveResponses);\n",
              "    console.log(preserveResponses == \"true\");\n",
              "    if (preserveResponses == \"true\") {\n",
              "        console.log(preserveResponses);\n",
              "        // Create Div to contain record of answers\n",
              "        var iDiv = document.createElement('div');\n",
              "        iDiv.id = 'responses' + mydiv.id;\n",
              "        iDiv.className = 'JCResponses';\n",
              "        // Create a place to store responses as an empty array\n",
              "        iDiv.setAttribute('data-responses', '[]');\n",
              "\n",
              "        // Dummy Text\n",
              "        iDiv.innerHTML=\"<b>Select your answers and then follow the directions that will appear here.</b>\"\n",
              "        //iDiv.className = 'Quiz';\n",
              "        mydiv.appendChild(iDiv);\n",
              "    }\n",
              "//console.log(\"At end of show_questions\");\n",
              "    if (typeof MathJax != 'undefined') {\n",
              "        console.log(\"MathJax version\", MathJax.version);\n",
              "        var version = MathJax.version;\n",
              "        setTimeout(function(){\n",
              "            var version = MathJax.version;\n",
              "            console.log('After sleep, MathJax version', version);\n",
              "            if (version[0] == \"2\") {\n",
              "                MathJax.Hub.Queue([\"Typeset\", MathJax.Hub]);\n",
              "            } else if (version[0] == \"3\") {\n",
              "                MathJax.typeset([mydiv]);\n",
              "            }\n",
              "        }, 500);\n",
              "if (typeof version == 'undefined') {\n",
              "        } else\n",
              "        {\n",
              "            if (version[0] == \"2\") {\n",
              "                MathJax.Hub.Queue([\"Typeset\", MathJax.Hub]);\n",
              "            } else if (version[0] == \"3\") {\n",
              "                MathJax.typeset([mydiv]);\n",
              "            } else {\n",
              "                console.log(\"MathJax not found\");\n",
              "            }\n",
              "        }\n",
              "    }\n",
              "    return false;\n",
              "}\n",
              "/* This is to handle asynchrony issues in loading Jupyter notebooks\n",
              "           where the quiz has been previously run. The Javascript was generally\n",
              "           being run before the div was added to the DOM. I tried to do this\n",
              "           more elegantly using Mutation Observer, but I didn't get it to work.\n",
              "\n",
              "           Someone more knowledgeable could make this better ;-) */\n",
              "\n",
              "        function try_show() {\n",
              "          if(document.getElementById(\"zOIrpOcCEKeu\")) {\n",
              "            show_questions(questionszOIrpOcCEKeu,  zOIrpOcCEKeu); \n",
              "          } else {\n",
              "             setTimeout(try_show, 200);\n",
              "          }\n",
              "        };\n",
              "    \n",
              "        {\n",
              "        // console.log(element);\n",
              "\n",
              "        //console.log(\"zOIrpOcCEKeu\");\n",
              "        // console.log(document.getElementById(\"zOIrpOcCEKeu\"));\n",
              "\n",
              "        try_show();\n",
              "        }\n",
              "        "
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "# @markdown **Run this cell** to take the quiz\n",
        "comprehension_quiz = [\n",
        "  {\n",
        "    \"question\": \"What overarching principles was illustrated in these evolutionary Gridworld simulation?\",\n",
        "    \"type\": \"multiple_choice\",\n",
        "    \"answers\": [\n",
        "      {\n",
        "        \"answer\": \"Static behaviours result in predictable outcomes.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"While this is sometimes true, these simulations were primarily about adaptive and evolving behaviours.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"Organisms constantly adapt their behaviours in response to their environment and other organisms.\",\n",
        "        \"correct\": True,\n",
        "        \"feedback\": \"Exactly! The predator-prey dynamic in the Gridworld simulation demonstrates the continuous adaptation of behaviors in response to both environmental and inter-organismal factors.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"Organisms with faster movement are always dominant in their environment.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"Speed might be advantageous, but adaptation and strategy can often overcome sheer speed.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"Evolutionary outcomes are entirely random and lack predictability.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"While there might be elements of randomness, evolutionary outcomes are largely driven by environmental pressures and are not entirely random.\"\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"question\": \"What is a primary goal of using evolutionary strategies like CMA-ES in optimization problems?\",\n",
        "    \"type\": \"multiple_choice\",\n",
        "    \"answers\": [\n",
        "      {\n",
        "        \"answer\": \"To maintain a static solution throughout iterations.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"Evolutionary strategies aim to adapt and refine solutions, not keep them static.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"To iteratively refine solutions, increasing the likelihood of better outcomes over time.\",\n",
        "        \"correct\": True,\n",
        "        \"feedback\": \"Correct! Evolutionary strategies like CMA-ES work iteratively, refining solutions to yield better outcomes as they progress.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"To always ensure a perfect solution in the first iteration.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"Evolutionary strategies work over multiple iterations and don't guarantee perfection in the first attempt.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"To decrease the randomness in evolutionary algorithms.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"While they refine solutions, evolutionary strategies still incorporate randomness or stochastic processes to discover optimal solutions.\"\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"question\": \"When both prey and predator populations are allowed to evolve simultaneously, this process of mutual adaptation can best be described as:\",\n",
        "    \"type\": \"multiple_choice\",\n",
        "    \"answers\": [\n",
        "      {\n",
        "        \"answer\": \"Mono-evolution, where only one species evolves while the other remains static.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"Mono-evolution implies evolution in isolation, which is not the case here.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"Static evolution, where both species remain unchanged despite environmental pressures.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"Static evolution doesn't capture the essence of mutual adaptation observed in the discussed scenario.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"Co-evolution, where both species undergo evolutionary adjustments in response to each other.\",\n",
        "        \"correct\": True,\n",
        "        \"feedback\": \"Exactly! Co-evolution refers to the process where two or more species reciprocally affect each other's evolution.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"Random evolution, where changes in species are entirely unpredictable and lack direction.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"The process described is systematic and driven by environmental and interspecies dynamics, not entirely random.\"\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "]\n",
        "\n",
        "\n",
        "\n",
        "display_quiz(comprehension_quiz)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "P1C3_Sequence3",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "220506df7a414121b461f430f292018f": {
          "model_module": "jupyter-matplotlib",
          "model_name": "MPLCanvasModel",
          "model_module_version": "^0.11",
          "state": {
            "_cursor": "default",
            "_data_url": "data:image/png;base64,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",
            "_dom_classes": [],
            "_figure_label": "Figure 1",
            "_image_mode": "full",
            "_message": "",
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "MPLCanvasModel",
            "_rubberband_height": 0,
            "_rubberband_width": 0,
            "_rubberband_x": 0,
            "_rubberband_y": 0,
            "_size": [
              1000,
              400
            ],
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "MPLCanvasView",
            "capture_scroll": false,
            "footer_visible": false,
            "header_visible": false,
            "layout": "IPY_MODEL_d9c2e59d3d884c70ad7fd20c131aea3e",
            "pan_zoom_throttle": 33,
            "resizable": false,
            "toolbar": "IPY_MODEL_c73ee6d814064c878aaa3eafecbf68e4",
            "toolbar_position": "left",
            "toolbar_visible": false
          }
        },
        "d9c2e59d3d884c70ad7fd20c131aea3e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c73ee6d814064c878aaa3eafecbf68e4": {
          "model_module": "jupyter-matplotlib",
          "model_name": "ToolbarModel",
          "model_module_version": "^0.11",
          "state": {
            "_current_action": "",
            "_dom_classes": [],
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "ToolbarModel",
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "ToolbarView",
            "button_style": "",
            "collapsed": true,
            "layout": "IPY_MODEL_37f6cac87b93478ab3259521a4fedbed",
            "orientation": "vertical",
            "toolitems": [
              [
                "Home",
                "Reset original view",
                "home",
                "home"
              ],
              [
                "Back",
                "Back to previous view",
                "arrow-left",
                "back"
              ],
              [
                "Forward",
                "Forward to next view",
                "arrow-right",
                "forward"
              ],
              [
                "Pan",
                "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
                "arrows",
                "pan"
              ],
              [
                "Zoom",
                "Zoom to rectangle\nx/y fixes axis",
                "square-o",
                "zoom"
              ],
              [
                "Download",
                "Download plot",
                "floppy-o",
                "save_figure"
              ]
            ]
          }
        },
        "37f6cac87b93478ab3259521a4fedbed": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4a17a0b2e80d4a549bf1a02aa0590988": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_77be50b15a264bc49700fbdaaeb046c6"
            ],
            "layout": "IPY_MODEL_0fd65add8f8542289b99685ba4c5c0d4"
          }
        },
        "77be50b15a264bc49700fbdaaeb046c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3065b3ab1a4b4c8d929cb010b7bf6fd3",
              "IPY_MODEL_f1a9e15cb33e46d99c51fabd3d1c03b6",
              "IPY_MODEL_948e7586c3614e7c80d131af0f228ca8"
            ],
            "layout": "IPY_MODEL_b846350e0f08460381d337fbd98f15e2"
          }
        },
        "0fd65add8f8542289b99685ba4c5c0d4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3065b3ab1a4b4c8d929cb010b7bf6fd3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_78d607aa8f2a453fa34c6688b9cc0e72",
              "IPY_MODEL_c0d1a4299d4d4ce89b73ed86b6b0dd90",
              "IPY_MODEL_e91040291fa945758dd76551bdf90e3b"
            ],
            "layout": "IPY_MODEL_355feffd28ff42bcae2a79b53b1dffee"
          }
        },
        "f1a9e15cb33e46d99c51fabd3d1c03b6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_56c59808c69d4c64879dc3180defa987",
              "IPY_MODEL_629e188ddbe04c53bd363f551b707bb4"
            ],
            "layout": "IPY_MODEL_973a7db8caab4563948e76790017b8c0"
          }
        },
        "948e7586c3614e7c80d131af0f228ca8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d8f6e29aee6746edbd7d5841f500022c",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_ab8e31abbe1c4695ad33d0c3161ddcef",
            "value": "Thanks for your feedback!"
          }
        },
        "b846350e0f08460381d337fbd98f15e2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "78d607aa8f2a453fa34c6688b9cc0e72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "happy"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "ðŸ™‚",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_ae24b3d38264474da619c9fbb413631e",
            "style": "IPY_MODEL_63bebe6d113d470d81603897ad59b707",
            "tooltip": "happy"
          }
        },
        "c0d1a4299d4d4ce89b73ed86b6b0dd90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "medium"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "ðŸ˜",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f1dfa8adac954dd998e949e86a8e2924",
            "style": "IPY_MODEL_20fa51a990b44e49b60447ec265993c7",
            "tooltip": "medium"
          }
        },
        "e91040291fa945758dd76551bdf90e3b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "sad"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "ðŸ™",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_0a4a34f15fca4404a2336721404f338f",
            "style": "IPY_MODEL_649ff9244b5941779ceedc232b524f97",
            "tooltip": "sad"
          }
        },
        "355feffd28ff42bcae2a79b53b1dffee": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "56c59808c69d4c64879dc3180defa987": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_6183ea78ab964c02a1200a5de0d4027d",
            "placeholder": "We want your feedback!",
            "rows": null,
            "style": "IPY_MODEL_62c220edae6a49fa83527369a6de41e2",
            "value": ""
          }
        },
        "629e188ddbe04c53bd363f551b707bb4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Submit",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_635a09f5114743fc8b2d998537b01de8",
            "style": "IPY_MODEL_ba6cfdc6254d43989059f3fa27d97cb6",
            "tooltip": ""
          }
        },
        "973a7db8caab4563948e76790017b8c0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "none",
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d8f6e29aee6746edbd7d5841f500022c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "none",
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ab8e31abbe1c4695ad33d0c3161ddcef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ae24b3d38264474da619c9fbb413631e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "auto",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "0.5em",
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "63bebe6d113d470d81603897ad59b707": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": "#aaffaa",
            "font_weight": ""
          }
        },
        "f1dfa8adac954dd998e949e86a8e2924": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "auto",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "0.5em",
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "20fa51a990b44e49b60447ec265993c7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": "#dddd77",
            "font_weight": ""
          }
        },
        "0a4a34f15fca4404a2336721404f338f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "auto",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "0.5em",
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "649ff9244b5941779ceedc232b524f97": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": "#ffaaaa",
            "font_weight": ""
          }
        },
        "6183ea78ab964c02a1200a5de0d4027d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "auto",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "62c220edae6a49fa83527369a6de41e2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "635a09f5114743fc8b2d998537b01de8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "auto",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "ba6cfdc6254d43989059f3fa27d97cb6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "d2fccb46a3a343f3ad8edc9c085a011f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_9d806f63ae824472b124db967498675c"
            ],
            "layout": "IPY_MODEL_66fee31a2634432cae5872bafb78d6b3"
          }
        },
        "9d806f63ae824472b124db967498675c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_ccd0591d92a14f5193a543aa15d29b21",
              "IPY_MODEL_316ac12604a243ecabe89ef9f9f72dda",
              "IPY_MODEL_2a8e417918e74e26aab42bafa63832aa"
            ],
            "layout": "IPY_MODEL_303689966e9646acb06ea58e2edda9a6"
          }
        },
        "66fee31a2634432cae5872bafb78d6b3": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ccd0591d92a14f5193a543aa15d29b21": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a1cf3f5068854233b0353fe904640b7c",
              "IPY_MODEL_e2f3ca28d55f45e28b8ea2f17afd6c96",
              "IPY_MODEL_bb39207116ed479d95aa67f9a30b495b"
            ],
            "layout": "IPY_MODEL_8172ac70e39341429202e5be8984b002"
          }
        },
        "316ac12604a243ecabe89ef9f9f72dda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_79189f7479f44117a35f900655bacd74",
              "IPY_MODEL_970eaf384f3b4498bfe54e3cdae9e6aa"
            ],
            "layout": "IPY_MODEL_9672c62472fd435d9bb68e6ddf48c16c"
          }
        },
        "2a8e417918e74e26aab42bafa63832aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "LabelModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "LabelView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_fd2a337ddb53446ca3f20d1468f11811",
            "placeholder": "â€‹",
            "style": "IPY_MODEL_a57c811637644df594b25b11fa799879",
            "value": "Thanks for your feedback!"
          }
        },
        "303689966e9646acb06ea58e2edda9a6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a1cf3f5068854233b0353fe904640b7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "happy"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "ðŸ™‚",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_dfb48d232372450899e787bc4ab97087",
            "style": "IPY_MODEL_c4c7caaf5dff46cfab43743aa674f7d4",
            "tooltip": "happy"
          }
        },
        "e2f3ca28d55f45e28b8ea2f17afd6c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "medium"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "ðŸ˜",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_9fb7e291b5594cef91b74c8e5d61e665",
            "style": "IPY_MODEL_fde716b82ee04cb48b5301cd7cd14f90",
            "tooltip": "medium"
          }
        },
        "bb39207116ed479d95aa67f9a30b495b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [
              "sad"
            ],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "ðŸ™",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f097f7d589fc4d7d9a3c949cecbbdb7f",
            "style": "IPY_MODEL_dde09dc500cb4091bc8c7f61c16d5b01",
            "tooltip": "sad"
          }
        },
        "8172ac70e39341429202e5be8984b002": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "79189f7479f44117a35f900655bacd74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "TextareaModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "TextareaModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "TextareaView",
            "continuous_update": true,
            "description": "",
            "description_tooltip": null,
            "disabled": false,
            "layout": "IPY_MODEL_bf602362152a49a2a49ce01d95d8940f",
            "placeholder": "We want your feedback!",
            "rows": null,
            "style": "IPY_MODEL_8abcf26e44c749e2809ad44386d7b166",
            "value": ""
          }
        },
        "970eaf384f3b4498bfe54e3cdae9e6aa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Submit",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_a7d037a321db48d6a8295788de5f2690",
            "style": "IPY_MODEL_9830dfcb2662499c891053949e742b0f",
            "tooltip": ""
          }
        },
        "9672c62472fd435d9bb68e6ddf48c16c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "none",
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "fd2a337ddb53446ca3f20d1468f11811": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": "none",
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a57c811637644df594b25b11fa799879": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dfb48d232372450899e787bc4ab97087": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "auto",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "0.5em",
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "c4c7caaf5dff46cfab43743aa674f7d4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": "#aaffaa",
            "font_weight": ""
          }
        },
        "9fb7e291b5594cef91b74c8e5d61e665": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "auto",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "0.5em",
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "fde716b82ee04cb48b5301cd7cd14f90": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": "#dddd77",
            "font_weight": ""
          }
        },
        "f097f7d589fc4d7d9a3c949cecbbdb7f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "auto",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": "0.5em",
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "dde09dc500cb4091bc8c7f61c16d5b01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": "#ffaaaa",
            "font_weight": ""
          }
        },
        "bf602362152a49a2a49ce01d95d8940f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "auto",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "8abcf26e44c749e2809ad44386d7b166": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a7d037a321db48d6a8295788de5f2690": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": "auto",
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "auto"
          }
        },
        "9830dfcb2662499c891053949e742b0f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}