{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dcownden/PerennialProblemsOfLifeWithABrain/blob/main/sequences/P1C1_BehaviourAsPolicy/student/P1C1_Sequence1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/sequences/P1C1_BehaviourAsPolicy/student/P1C1_Sequence1.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The following is part of a test for an upcoming text book on computational neuroscience from an optimization and learning perspective. The book will start with evolution because ultimately, all aspects of the brain are shaped by evolution and, as we will see, evolution can also be seen as an optimization algorithm. We are sharing it now to get feedback on what works and what does not and the developments we should do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "# **Sequence 1.1.1: Gridworld Introduction**\n",
    "\n",
    "### Objective: In this sequence, we will create a simple environment-organism system to demonstrate how an organism's **behaviour**, within an **environment**, can be evaluated using **rewards**. We will also see how intelligent behaviour can lead to better outcomes and how **randomness** can make evaluation of behaviour more difficult."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Setup\n",
    "Run the following cell to setup and install the various dependencies and helper functions for this sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Dependencies, Imports and Setup\n",
    "# @markdown You don't need to worry about how this code works â€“ but you do need to **run the cell**\n",
    "\n",
    "!pip install ipympl vibecheck datatops jupyterquiz > /dev/null 2> /dev/null #google.colab\n",
    "\n",
    "import requests\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from scipy.spatial.distance import cdist\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, clear_output, Markdown\n",
    "from jupyterquiz import display_quiz\n",
    "from vibecheck import DatatopsContentReviewContainer\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# random seed settings and\n",
    "# getting torch to use gpu if it's there\n",
    "\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  \"\"\"\n",
    "  Function that controls randomness. NumPy and random modules must be imported.\n",
    "\n",
    "  Args:\n",
    "    seed : Integer\n",
    "      A non-negative integer that defines the random state. Default is `None`.\n",
    "    seed_torch : Boolean\n",
    "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
    "      must be imported. Default is `True`.\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "  \"\"\"\n",
    "  DataLoader will reseed workers following randomness in\n",
    "  multi-process data loading algorithm.\n",
    "\n",
    "  Args:\n",
    "    worker_id: integer\n",
    "      ID of subprocess to seed. 0 means that\n",
    "      the data will be loaded in the main process\n",
    "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def set_device():\n",
    "  \"\"\"\n",
    "  Set the device. CUDA if available, CPU otherwise\n",
    "\n",
    "  Args:\n",
    "    None\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "    print(\"WARNING: For this notebook to perform best, \"\n",
    "        \"if possible, in the menu under `Runtime` -> \"\n",
    "        \"`Change runtime type.`  select `GPU` \")\n",
    "  else:\n",
    "    print(\"GPU is enabled in this notebook.\")\n",
    "\n",
    "  return device\n",
    "\n",
    "\n",
    "SEED = 2021\n",
    "set_seed(seed=SEED)\n",
    "DEVICE = set_device()\n",
    "\n",
    "def printmd(string):\n",
    "  display(Markdown(string))\n",
    "\n",
    "\n",
    "# the different utility .py files used in this notebook\n",
    "filenames = ['gw_plotting.py', 'gw_board.py', 'gw_game.py', 'gw_widgets.py',\n",
    "             'gw_NN_RL.py']\n",
    "# A directory to store these utility .py files\n",
    "Path('utils').mkdir(parents=True, exist_ok=True)\n",
    "# Get the IPython interactive shell to run/load the utility files\n",
    "ipython = get_ipython()\n",
    "\n",
    "for filename in filenames:\n",
    "  url = f'https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/utils/{filename}'\n",
    "  response = requests.get(url)\n",
    "  # Check that we got a valid response\n",
    "  if response.status_code == 200:\n",
    "    code = response.content.decode()\n",
    "    exec(code)\n",
    "  else:\n",
    "    print(f'Failed to download {url}')\n",
    "\n",
    "# environment contingent imports\n",
    "try:\n",
    "  print('Running in colab')\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "  #from google.colab import output as colab_output\n",
    "  #colab_output.enable_custom_widget_manager()\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "  print('Not running in colab')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib widget\n",
    "plt.style.use(\"https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/pplb.mplstyle\")\n",
    "plt.ioff() #need to use plt.show() or display explicitly\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "def content_review(notebook_section: str):\n",
    "  return DatatopsContentReviewContainer(\n",
    "    \"\",  # No text prompt\n",
    "    notebook_section,\n",
    "    {\n",
    "      \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "      \"name\": \"neuro_book\",\n",
    "      \"user_key\": \"xuk960xj\",\n",
    "    },\n",
    "  ).render()\n",
    "feedback_prefix = \"P1C1_S1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# 1.1.1.1: Initializing Gridworld\n",
    "\n",
    "Before we introduce an organism with **behaviour** we're going to build an **environment** for them to behave in. To start, this world will consist of a 7 x 7 grid. Let's make a picture of that and see what it looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "############################################################################\n",
    "## TODO for students: Replace ... with the correct arguments(inputs) in the\n",
    "## make_grid function below to make our grid the right size and shape (7x7).\n",
    "## The function definition is duplicated here for convenience and hackability,\n",
    "## but in general you can use the tool tip by hovering over the word make_grid,\n",
    "## when this is the active cell, to find out how to use the make_grid function.\n",
    "## You can also use the tool tip to view the source code. How does it work?\n",
    "## Comment out or remove these next two lines.\n",
    "raise NotImplementedError(\n",
    "  \"Exercise: make a grid using the make_grid function\")\n",
    "############################################################################\n",
    "\n",
    "\n",
    "def make_grid(num_rows, num_cols, figsize=(7,6), title=None):\n",
    "  \"\"\"Plots an n_rows by n_cols grid with cells centered on integer indices and\n",
    "  returns fig and ax handles for further use\n",
    "  Args:\n",
    "    num_rows (int): number of rows in the grid (vertical dimension)\n",
    "    num_cols (int): number of cols in the grid (horizontal dimension)\n",
    "\n",
    "  Returns:\n",
    "    fig (matplotlib.figure.Figure): figure handle for the grid\n",
    "    ax: (matplotlib.axes._axes.Axes): axes handle for the grid\n",
    "  \"\"\"\n",
    "  # Create a new figure and axes with given figsize\n",
    "  fig, ax = plt.subplots(figsize=figsize, layout='constrained')\n",
    "  # Set width and height padding, remove horizontal and vertical spacing\n",
    "  fig.get_layout_engine().set(w_pad=4 / 72, h_pad=4 / 72, hspace=0, wspace=0)\n",
    "  # Show right and top borders (spines) of the plot\n",
    "  ax.spines[['right', 'top']].set_visible(True)\n",
    "  # Set major ticks (where grid lines will be) on x and y axes\n",
    "  ax.set_xticks(np.arange(0, num_cols, 1))\n",
    "  ax.set_yticks(np.arange(0, num_rows, 1))\n",
    "  # Set labels for major ticks with font size of 8\n",
    "  ax.set_xticklabels(np.arange(0, num_cols, 1),fontsize=8)\n",
    "  ax.set_yticklabels(np.arange(0, num_rows, 1),fontsize=8)\n",
    "  # Set minor ticks (no grid lines here) to be between major ticks\n",
    "  ax.set_xticks(np.arange(0.5, num_cols-0.5, 1), minor=True)\n",
    "  ax.set_yticks(np.arange(0.5, num_rows-0.5, 1), minor=True)\n",
    "  # Move x-axis ticks to the top of the plot\n",
    "  ax.xaxis.tick_top()\n",
    "  # Set grid lines based on minor ticks, make them grey, dashed, and half transparent\n",
    "  ax.grid(which='minor', color='grey', linestyle='-', linewidth=2, alpha=0.5)\n",
    "  # Remove minor ticks (not the grid lines)\n",
    "  ax.tick_params(which='minor', bottom=False, left=False)\n",
    "  # Set limits of x and y axes\n",
    "  ax.set_xlim(( -0.5, num_cols-0.5))\n",
    "  ax.set_ylim(( -0.5, num_rows-0.5))\n",
    "  # Invert y axis direction\n",
    "  ax.invert_yaxis()\n",
    "  # If title is provided, set it as the figure title\n",
    "  if title is not None:\n",
    "    fig.suptitle(title)\n",
    "  # Hide header and footer, disable toolbar and resizing of the figure\n",
    "  fig.canvas.header_visible = False\n",
    "  fig.canvas.toolbar_visible = False\n",
    "  fig.canvas.resizable = False\n",
    "  fig.canvas.footer_visible = False\n",
    "  # Redraw the figure with these settings\n",
    "  fig.canvas.draw()\n",
    "  # Return figure and axes handles for further customization\n",
    "  return fig, ax\n",
    "\n",
    "fig, ax = make_grid(...)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/dcownden/PerennialProblemsOfLifeWithABrain/tree/main//sequences/P1C1_BehaviourAsPolicy/solutions/P1C1_Sequence1_Solution_203f6ddd.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=700.0 height=600.0 src=https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/sequences/P1C1_BehaviourAsPolicy/static/P1C1_Sequence1_Solution_203f6ddd_0.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "***Bonus: change the function definition:***\n",
    "\n",
    "Tweak the make_grid function in the cell above to make the grid lines green."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Wow, what a boring environment. Let's add an organism and something for that organism to interact with. We'll start with 10 food items scattered randomly throughout the grid, never more than one food item per grid cell. To plot these food items we need their locations. We will set these by randomly sampling grid coordinates [without replacement](## \"never picking the same (row,col) coordinate pair twice\"). We'll place the organism in the same way and not on a food item to start. (We will use [blue, underlined text](## \"example tool tip\") to indicate tooltips, i.e. where more information will be provided when the mouse hovers over the text.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO for students: Replace ... in init_loc(...) to initialize the right\n",
    "# number of food item locations and critter locations in coordinates that make\n",
    "# sense for our grid environment. Then replace the ... in rc_plotting[...] to\n",
    "# index the plotting coordinates for the food locations.\n",
    "# Hint: The syntax for indexing elements of numpy arrays using [] can be\n",
    "# confusing at first. If you're lost read the docs,\n",
    "# https://numpy.org/doc/stable/user/basics.indexing.html and add some code\n",
    "# cells below to play around with indexing and displaying different sub-arrays\n",
    "# of the rc_plotting array.\n",
    "# Comment out or remove this next line.\n",
    "raise NotImplementedError(\"Exercise: initialize food and critter locations\")\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def init_loc(n_rows, n_cols, num, rng=None):\n",
    "  \"\"\"\n",
    "  Samples random 2d grid locations without replacement\n",
    "\n",
    "  Args:\n",
    "    n_rows: int, number of rows in the grid\n",
    "    n_cols: int, number of columns in the grid\n",
    "    num:    int, number of samples to generate. Should throw an error if num > n_rows x n_cols\n",
    "    rng:    instance of numpy.random's default rng. Used for reproducibility.\n",
    "\n",
    "  Returns:\n",
    "    int_loc: ndarray(int) of shape (num,), flat indices for a 2D grid flattened into 1D\n",
    "    rc_index: tuple(ndarray(int), ndarray(int)), a pair of arrays with the first giving\n",
    "      the row indices and the second giving the col indices. Useful for indexing into\n",
    "      an n_rows by n_cols numpy array.\n",
    "    rc_plotting: ndarray(int) of shape (num, 2), 2D coordinates suitable for matplotlib plotting\n",
    "  \"\"\"\n",
    "  # If no random number generator given, make one using predefined global SEED\n",
    "  if rng is None:\n",
    "    rng = np.random.default_rng(seed=SEED)\n",
    "  # Choose 'num' unique random indices from a flat\n",
    "  # 1D array of size n_rows*n_cols\n",
    "  int_loc = rng.choice(n_rows * n_cols, num, replace=False)\n",
    "  # Convert flat indices to 2D indices based on shape (n_rows, n_cols)\n",
    "  rc_index = np.unravel_index(int_loc, (n_rows, n_cols))\n",
    "  # Transpose indices to get num x 2 array for easy plotting with matplotlib\n",
    "  rc_plotting = np.array(rc_index).T\n",
    "  # Return 1D flat indices, 2D indices for numpy array indexing\n",
    "  # and 2D indices for plotting\n",
    "  return int_loc, rc_index, rc_plotting\n",
    "\n",
    "# Create a grid for the plot\n",
    "fig, ax = make_grid(7, 7)\n",
    "# Generate 11 unique locations on the grid\n",
    "int_locs, rc_index, rc_plotting = init_loc(..., ..., ...)\n",
    "# The first location is for the \"critter\"\n",
    "rc_critter = rc_plotting[0]\n",
    "plot_critter(fig, ax, rc_critter)\n",
    "# Remaining locations are for \"food\"\n",
    "rc_food = rc_plotting[...]\n",
    "plot_food(fig, ax, rc_food)\n",
    "# Add legend outside the upper right corner\n",
    "fig.legend(loc='outside right upper')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/dcownden/PerennialProblemsOfLifeWithABrain/tree/main//sequences/P1C1_BehaviourAsPolicy/solutions/P1C1_Sequence1_Solution_ef4746c6.py)\n",
    "\n",
    "*Example output:*\n",
    "\n",
    "<img alt='Solution hint' align='left' width=700.0 height=600.0 src=https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/sequences/P1C1_BehaviourAsPolicy/static/P1C1_Sequence1_Solution_ef4746c6_0.png>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_M1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# 1.1.1.2: Random Eating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now that we have an environment scattered with food and an organism, let's introduce some behaviour. The organism drifts around the environment randomly and eats the food it happens to stumble upon. (Can you think of any organisms that employ this strategy? [hint](## \"think about the way very very small living things move around\")). When food is eaten, the organism gets a **reward**, in this case a *Food Eaten* point, and a new food item appears randomly somewhere else in the environment (that doesn't already have food). Run the code cell below to see what this looks like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Random Movement\n",
    "# @markdown Don't worry about how this code works â€“ just **run this cell** then click the start button and watch what happens.\n",
    "\n",
    "rng = np.random.default_rng(seed=420)\n",
    "gwg = GridworldGame(batch_size=1, n_rows=7, n_cols=7, num_food=10,\n",
    "                    lifetime=30, rng=rng)\n",
    "random_igwg = InteractiveGridworld(gwg, player=None, figsize=(5,4))\n",
    "display(random_igwg.b_fig.canvas)\n",
    "clear_output()\n",
    "display(random_igwg.final_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "*Question:* When the organism is just drifting around randomly how good is it at eating lots of food, what is its efficiency in terms of food per movement? Now click the start button again and run the simulation a few more times. Does the organism always eat the same amount of food or does it change between simulation runs? [explanation](## \"The amount of food eaten varies from simulation run to simulation run,usually the organism manages to eat one or two or three pieces of food, sometimes more\n",
    "sometimes less.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "*Bonus: see how the effectiveness of a strategy depends on the environment:*\n",
    "\n",
    "Before we move on it's important to test that our simulation is running as we expect. Randomness can make testing hard, but can be overcome in part by setting up the environment in such a way that the outcome becomes deterministic. In the code cells bellow change how the Gridworld is initialized. By altering the size, shape and number of food items available create a scenario where the organism will always achieve perfect efficiency and a scenario where the organism will fail completely.\n",
    "\n",
    "We will do this here by either providing food everywhere or nowhere."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# TODO for students: Replace the ...'s in GridworldGame(...) to initialize a\n",
    "# Gridworld where the organism is always 100% efficient. Food. Everywhere.\n",
    "raise NotImplementedError(\"Exercise: make random movement 100% efficient\")\n",
    "################################################################################\n",
    "\n",
    "gwg100 = GridworldGame(batch_size=1, n_cols=..., n_rows=..., num_food=...,\n",
    "                       lifetime=30)\n",
    "random_igwg_100 = InteractiveGridworld(gwg100, player=None, figsize=(5,4))\n",
    "display(random_igwg_100.b_fig.canvas)\n",
    "clear_output()\n",
    "display(random_igwg_100.final_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "tags": []
   },
   "source": [
    "[*Click for solution*](https://github.com/dcownden/PerennialProblemsOfLifeWithABrain/tree/main//sequences/P1C1_BehaviourAsPolicy/solutions/P1C1_Sequence1_Solution_5ccc5cd7.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Ok. We have just seen a super successful (albeit completely dumb) organism. Lets see if we can have an environment where any organism would fail (maybe surprisingly intelligence can not make food out of nothing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "###############################################################################\n",
    "# TODO for students: Replace the ...'s in GridworldGame(...) to initialize a\n",
    "# Gridworld where the organism is always 0% efficient.\n",
    "raise NotImplementedError(\"Exercise: make random movement 0% efficient\")\n",
    "################################################################################\n",
    "\n",
    "gwg0 = GridworldGame(batch_size=1, n_cols=..., n_rows=..., num_food=...,\n",
    "                     lifetime=30)\n",
    "random_igwg_0 = InteractiveGridworld(gwg0, player=None, figsize=(5,4))\n",
    "display(random_igwg_0.b_fig.canvas)\n",
    "clear_output()\n",
    "display(random_igwg_0.final_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "tags": []
   },
   "source": [
    "[*Click for solution*](https://github.com/dcownden/PerennialProblemsOfLifeWithABrain/tree/main//sequences/P1C1_BehaviourAsPolicy/solutions/P1C1_Sequence1_Solution_504dfb15.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_M2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# 1.1.1.3: Better Than Random Eating\n",
    "Now it's your turn to actually control the organism with some level of intelligence (give it your all). Run the next cell and see how much more efficient than random drifting your control of the organism is in terms of food per movement. Does intelligence help?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {},
    "tags": []
   },
   "outputs": [],
   "source": [
    "# @title Controlled Movement\n",
    "# @markdown Don't worry about how this code works â€“ just **run the cell** and then use the buttons to guide the organism\n",
    "\n",
    "# user in control\n",
    "gwg_c = GridworldGame(2, 7, 7, 10, 30,\n",
    "                    rng=np.random.default_rng(seed=9))\n",
    "h2h_igwg = Head2HeadGridworld(gwg_c, player0='human',\n",
    "                              player1=None, figsize=(3,3),\n",
    "                              )\n",
    "display(h2h_igwg.b_fig0.canvas)\n",
    "display(h2h_igwg.b_fig1.canvas)\n",
    "display(h2h_igwg.b_fig_legend.canvas)\n",
    "clear_output()\n",
    "display(h2h_igwg.final_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Hopefully your performance was more successful than random flailing (if not, reset to the safe point). Even in this relatively simple and contrived foraging scenario intelligence can help a lot. What kinds of strategies and heuristics did you use to guide your choice of direction? A fundamental purpose of nervous systems and brains is to solve problems of this kind â€” choosing which actions to take based on environmental inputs to maximize rewards."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_M3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# 1.1.1.4: Optimized Eating\n",
    "\n",
    "\n",
    "Let's welcome a special guest, GW7x7-10-30, from the final chapter of this book. Utilizing a blend of deep reinforcement learning and Monte-Carlo search based on the AlphaZero optimization algorithm, GW7x7-10-30 has achieved mastery of the 7x7 Gridworld environment, with 10 food items and a game duration of 30 rounds.\n",
    "\n",
    "The AlphaZero optimization algorithm finds inspiration from our understanding of the brain, and also draws upon various concepts from machine learning. As such, our specific computer implementation of the algorithm is unlikely to mirror the learning algorithms used by the brain in any particular detail.\n",
    "\n",
    "Despite this lack of immediate correspondence, we can still gain significant insight by identifying the generalized form of learning problems that the brain solves together with the classes of optimization algorithms capable of feasibly solving these learning problems subject to biological constraints. These constraints derive from a multitude of factors based on the evolution, ecology, physiology, development, etc, of the organism. These insights will enable us to deduce the most probable types of learning algorithms employed by brains.\n",
    "\n",
    "Subsequently, these deductions can guide us in seeking out the specific mechanisms and intricate details of the learning algorithms found in brains. Throughout this book, we will focus on introducing the general learning problems encountered by living organisms. We will identify different machine learning techniques that can presently solve these problems under various conditions. Furthermore, we will link the feasible machine learning solutions of these broader learning problems to our current empirical understanding of how a brain might implement similar solutions.\n",
    "\n",
    "Our aim with this approach is to foster a principled, systematic, and integrative groundwork for neuroscience research. Now, let's run the next code cell to see who is more efficient â€“ you or GW7x7-10-30. Reading this book will empower you to design the next generation of GW7x7-10-30.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Optimized Movement\n",
    "# @markdown Don't worry about how this code works â€“ **run this cell** to set up the superorganism and an environment for it and you. Note, the superorganism will be **slow** to compute its moves if GPU acceleration is not enabled for this runtime. If possible, in the menu under `Runtime` -> \"`Change runtime type`  select `GPU`.\n",
    "\n",
    "# initialize the game, network, and MonteCarlo player\n",
    "gwg = GridworldGame(batch_size=1, n_rows=7, n_cols=7, num_food=10,\n",
    "                    lifetime=30)\n",
    "pvnetMC = PolicyValueNetwork(gwg)\n",
    "mcp = MonteCarloBasedPlayer(gwg, pvnetMC, default_depth=3,\n",
    "                            default_rollouts=80, default_temp=0.02)\n",
    "\n",
    "\n",
    "#grab the saved model from the repo or where it ends up being hosted\n",
    "url = \"https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/sequences/P1C1_BehaviourAsPolicy/data/pvnetMC.pth.tar\"\n",
    "r = requests.get(url)\n",
    "\n",
    "if r.status_code == 200:\n",
    "  filename = os.path.basename(url)\n",
    "  # Write the contents to a file in the current working directory\n",
    "  with open(filename, 'wb') as file:\n",
    "    file.write(r.content)\n",
    "    #print(f'{filename} downloaded successfully.')\n",
    "else:\n",
    "  print('Error occurred while downloading the file.')\n",
    "\n",
    "# load the saved model\n",
    "pvnetMC.load_checkpoint(folder=os.getcwd(), filename='pvnetMC.pth.tar')\n",
    "\n",
    "# user in control versus mc player\n",
    "gwg = GridworldGame(2, 7, 7, 10, 30,\n",
    "                    rng=np.random.default_rng(seed=2000))\n",
    "h2h_igwg = Head2HeadGridworld(gwg, player0='human', player1=mcp, figsize=(4,4),\n",
    "                              p0_long_name='The Human',\n",
    "                              p1_long_name='gw7x7-10-30')\n",
    "display(h2h_igwg.b_fig0.canvas)\n",
    "display(h2h_igwg.b_fig1.canvas)\n",
    "display(h2h_igwg.b_fig_legend.canvas)\n",
    "clear_output()\n",
    "display(h2h_igwg.final_display)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Who was more efficient in this environment you or gw7x7-10-30? If gw7x7-10-30 was better, you really have read this book ðŸ˜‰ (If you can't beat the AIs, at least learn how to program them.) Even if you were about as good as gw7x7-10-30 you still might want to read this book. A deep understanding of the optimization processes that shape behaviour in simple organism-environment systems like this one will allow for generalization to more intricate systems, specifically, a rich understanding of how brains generate adaptive behaviour as a result of optimization processes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_M4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "---\n",
    "# Comprehension Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Quiz\n",
    "# @markdown **Run this cell** to take the quiz\n",
    "comprehension_quiz = [\n",
    "{\n",
    "  \"question\": \"What does a policy represent in the context of behaviour?\",\n",
    "  \"type\": \"multiple_choice\",\n",
    "  \"answers\": [\n",
    "  {\n",
    "    \"answer\": \"The evolutionary history of an organism\",\n",
    "    \"correct\": False,\n",
    "    \"feedback\": \"This is true in a broad and abstract sense, but there is a more precise answer here.\"\n",
    "  },\n",
    "  {\n",
    "    \"answer\": \"The environment in which an organism lives\",\n",
    "    \"correct\": False,\n",
    "    \"feedback\": \"There is a sense in which a policy shaped by evolution can reflect aspects of an organism's environment, but there is a more precise answer here.\"\n",
    "  },\n",
    "  {\n",
    "    \"answer\": \"The formal description of behaviour as a function that maps experiences to actions\",\n",
    "    \"correct\": True,\n",
    "    \"feedback\": \"Correct.\"\n",
    "  },\n",
    "  {\n",
    "    \"answer\": \"The randomness present in an organism's behavior\",\n",
    "    \"correct\": False,\n",
    "    \"feedback\": \"The policy might have randomness in it, but that's not what it is.\"\n",
    "  }]\n",
    "},\n",
    "{\n",
    "  \"question\": \"How is a policy evaluated in terms of its goodness?\",\n",
    "  \"type\": \"multiple_choice\",\n",
    "  \"answers\": [\n",
    "  {\n",
    "    \"answer\": \"By integrating rewards and environmental signals into a loss/objective function\",\n",
    "    \"correct\": True,\n",
    "    \"feedback\": \"Correct, 'goodness' needs to be formalized in a loss/objective function\"\n",
    "  },\n",
    "  {\n",
    "    \"answer\": \"By measuring the organism's fitness in the environment\",\n",
    "    \"correct\": True,\n",
    "    \"feedback\": \"This is one important way of evaluating a policy, but there is a more generally correct answer here.\"\n",
    "  },\n",
    "  {\n",
    "    \"answer\": \"By determining the amount of randomness present in the policy\",\n",
    "    \"correct\": False,\n",
    "    \"feedback\": \"Incorrect.\"\n",
    "  },\n",
    "  {\n",
    "    \"answer\": \"By analyzing the organism's evolutionary adaptations\",\n",
    "    \"correct\": False,\n",
    "    \"feedback\": \"Incorrect.\"\n",
    "  }]\n",
    "},\n",
    "{\n",
    "  \"question\": \"What is stochasticity in the context of behaviour?\",\n",
    "  \"type\": \"multiple_choice\",\n",
    "  \"answers\": [\n",
    "    {\n",
    "      \"answer\": \"The specific niche an organism occupies within its environment\",\n",
    "      \"correct\": False,\n",
    "      \"feedback\": \"Incorrect.\"\n",
    "    },\n",
    "    {\n",
    "      \"answer\": \"The ability of an organism to adapt to changing environmental conditions\",\n",
    "      \"correct\": False,\n",
    "      \"feedback\": \"Incorrect.\"\n",
    "    },\n",
    "    {\n",
    "      \"answer\": \"The random elements present in both the environment and an organism's behavior\",\n",
    "      \"correct\": True,\n",
    "      \"feedback\": \"Correct.\"\n",
    "    },\n",
    "    {\n",
    "      \"answer\": \"The process of optimizing a policy to achieve better outcomes\",\n",
    "      \"correct\": False,\n",
    "      \"feedback\": \"Incorrect.\"\n",
    "    }]\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What is the main difference between random eating and controlled movement in the environment?\",\n",
    "    \"type\": \"multiple_choice\",\n",
    "    \"answers\": [\n",
    "    {\n",
    "      \"answer\": \"Random eating involves unpredictable movements, while controlled movement can be planned and strategic.\",\n",
    "      \"correct\": True,\n",
    "      \"feedback\": \"Correct.\"\n",
    "    },\n",
    "    {\n",
    "      \"answer\": \"Random eating leads to higher efficiency, while controlled movement leads to lower efficiency.\",\n",
    "      \"correct\": False,\n",
    "      \"feedback\": \"Incorrect.\"\n",
    "    },\n",
    "    {\n",
    "      \"answer\": \"Random eating relies on external cues, while controlled movement relies on internal motivations.\",\n",
    "      \"correct\": False,\n",
    "      \"feedback\": \"Incorrect.\"\n",
    "    },\n",
    "    {\n",
    "      \"answer\": \"Random eating results in adaptive behavior, while controlled movement leads to stagnation.\",\n",
    "      \"correct\": False,\n",
    "      \"feedback\": \"Incorrect.\"\n",
    "    }]\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What is the significance of GW7x7-10-30 in the context of optimized eating?\",\n",
    "    \"type\": \"multiple_choice\",\n",
    "    \"answers\": [\n",
    "    {\n",
    "      \"answer\": \"It represents a time-traveling superorganism with advanced cognitive abilities.\",\n",
    "      \"correct\": False,\n",
    "      \"feedback\": \"Incorrect.\"\n",
    "    },\n",
    "    {\n",
    "      \"answer\": \"It demonstrates the limitations of optimized behavior in a simple environment.\",\n",
    "      \"correct\": True,\n",
    "      \"feedback\": \"It could serve this purpose, though that wasn't the main reason we introduced it here.\"\n",
    "    },\n",
    "    {\n",
    "      \"answer\": \"It showcases the potential efficiency achievable through optimized behavior.\",\n",
    "      \"correct\": True,\n",
    "      \"feedback\": \"Correct.\"\n",
    "    },\n",
    "    {\n",
    "      \"answer\": \"It serves as a benchmark for comparing different organisms' performance.\",\n",
    "      \"correct\": True,\n",
    "      \"feedback\": \"It could serve this purpose, though that wasn't the main reason we introduced it here.\"\n",
    "    }]\n",
    "  }\n",
    "]\n",
    "\n",
    "\n",
    "display_quiz(comprehension_quiz)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "e97kdmn_my25"
   ],
   "gpuType": "T4",
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "P1C1_Sequence1",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
