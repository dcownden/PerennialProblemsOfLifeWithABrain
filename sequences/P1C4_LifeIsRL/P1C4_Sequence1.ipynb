{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dcownden/PerennialProblemsOfLifeWithABrain/blob/life-is-an-MDP/sequences/P1C4_LifeIsRL/P1C4_Sequence1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "ob9RxGkDZpjk"
      },
      "source": [
        "The following is part of a test for an upcoming text book on computational neuroscience from an optimization and learning perspective. The book will start with evolution because ultimately, all aspects of the brain are shaped by evolution and, as we will see, evolution can also be seen as an optimization algorithm. We are sharing it now to get feedback on what works and what does not and the developments we should do."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "TosOaQjqZpjm"
      },
      "source": [
        "___\n",
        "# **1.4.1: Is Life Just One Big Markov Decision Process? Yeah, kind of.**\n",
        "## Objective:\n",
        "In this sequence we explore and \"solve\" a simplified version of our Gridworld within the Markov Decision Process (MDP) framework. MDPs offer a robust and flexible method for rigorously defining and identifying optimal policies across various scenarios. Although the formalism of MDPs may seem complex, its components have straightforward and intuitive meanings. We are already acquainted with the key elements of an MDP:\n",
        "\n",
        "* Policy: The behavioural rule that maps stimuli to an organism's actions.\n",
        "* Organism (Agent): The entity that reacts to stimuli and performs actions.\n",
        "* Actions: The specific responses an organism makes at any moment, guided by its policy.\n",
        "* Environment: The context in which an organism operates, including the source of stimuli, the rules for state changes in response to actions, and the nature of rewards based on actions and state transitions. Other organisms' policies can influence environmental conditions.\n",
        "* Reward: An evaluation of the outcomes of an organism's actions, typically considered in evolutionary terms such as survival, reproduction, and offspring survival.\n",
        "* Markov Process: A framework for understanding stochastic dynamics by dividing the world into possible states and defining transition probabilities between these states. Crucially, these probabilities depend solely on the current state, embodying the Markov property and simplifying analysis. Historical relevance to state dynamics is integrated into the state definition, ensuring a comprehensive state concept.\n",
        "\n",
        "In the sequence we will introduce the crucial notion of **Value**, which integrates these elements and allows for rigorous optimization. Value reflects the expected total future reward from a specific state under a particular policy. Our focus will be on utilizing Value to determine the optimal policy within an MDP. We'll examine Dynamic Programming, specifically Backward Induction, as a method to determine optimal behavior using Value. Although theoretically ideal, Backward Induction (and Dynamic Programming generally) is often impractical for complex problems due to scalability and computational limits. Despite its practical limitations, Backward Induction provides a strong theoretical foundation for more scalable and hence practical solutions. These practical solutions can then be understood as approximations to the ideal but intractable solution method.\n",
        "\n",
        "Previously we have also touched upon Partial Observability, i.e. situations where the full state of the environment is not known to the organism. Most organisms are not omniscient, so in some sense partial observability is always the case. For now though we are going to leave Partial Observability aside and focus on the simple case where the state of the world is perfectly known to the organism, to streamline the presentation of Value and Backward Induction.\n",
        "\n",
        "This all seems a bit much, but as we walk through our simplifed Gridworld example, these concepts will become more accessible and less daunting than they might initially appear. We promise.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "TLEhDnkDZpjm"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "r95xBOAdZpjn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0dbce13-5492-4373-c141-7d74a1f2158e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random seed 2021 has been set.\n",
            "This notebook isn't using and doesn't need a GPU. Good.\n",
            "Running in colab\n"
          ]
        }
      ],
      "source": [
        "# @title Dependencies, Imports and Setup\n",
        "# @markdown You don't need to worry about how this code works â€“ but you do need to **run the cell**\n",
        "!apt install libgraphviz-dev > /dev/null 2> /dev/null #colab\n",
        "!pip install ipympl pygraphviz vibecheck datatops jupyterquiz > /dev/null 2> /dev/null #google.colab\n",
        "\n",
        "import requests\n",
        "from requests.exceptions import RequestException\n",
        "import numpy as np\n",
        "import itertools\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.patches as mpatches\n",
        "from matplotlib.animation import FuncAnimation\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "import pygraphviz as pgv\n",
        "import ipywidgets as widgets\n",
        "import time\n",
        "import logging\n",
        "import random\n",
        "import os\n",
        "import copy\n",
        "import torch\n",
        "import warnings\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from io import BytesIO\n",
        "from enum import Enum\n",
        "from scipy.spatial.distance import cdist\n",
        "from scipy.stats import norm\n",
        "from scipy.optimize import minimize\n",
        "from sklearn.linear_model import LinearRegression\n",
        "from tabulate import tabulate\n",
        "from IPython.display import display, clear_output, Markdown, HTML, Image, IFrame\n",
        "from jupyterquiz import display_quiz\n",
        "from vibecheck import DatatopsContentReviewContainer\n",
        "from pathlib import Path\n",
        "from typing import List, Dict\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
        "# random seed settings and\n",
        "# getting torch to use gpu if it's there\n",
        "\n",
        "\n",
        "def set_seed(seed=None, seed_torch=True):\n",
        "  \"\"\"\n",
        "  Function that controls randomness. NumPy and random modules must be imported.\n",
        "\n",
        "  Args:\n",
        "    seed : Integer\n",
        "      A non-negative integer that defines the random state. Default is `None`.\n",
        "    seed_torch : Boolean\n",
        "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
        "      must be imported. Default is `True`.\n",
        "\n",
        "  Returns:\n",
        "    Nothing.\n",
        "  \"\"\"\n",
        "  if seed is None:\n",
        "    seed = np.random.choice(2 ** 32)\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  if seed_torch:\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "    torch.backends.cudnn.deterministic = True\n",
        "\n",
        "  print(f'Random seed {seed} has been set.')\n",
        "\n",
        "\n",
        "def seed_worker(worker_id):\n",
        "  \"\"\"\n",
        "  DataLoader will reseed workers following randomness in\n",
        "  multi-process data loading algorithm.\n",
        "\n",
        "  Args:\n",
        "    worker_id: integer\n",
        "      ID of subprocess to seed. 0 means that\n",
        "      the data will be loaded in the main process\n",
        "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  worker_seed = torch.initial_seed() % 2**32\n",
        "  np.random.seed(worker_seed)\n",
        "  random.seed(worker_seed)\n",
        "\n",
        "\n",
        "def set_device():\n",
        "  \"\"\"\n",
        "  Set the device. CUDA if available, CPU otherwise\n",
        "\n",
        "  Args:\n",
        "    None\n",
        "\n",
        "  Returns:\n",
        "    Nothing\n",
        "  \"\"\"\n",
        "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "  if device != \"cuda\":\n",
        "    print(\"This notebook isn't using and doesn't need a GPU. Good.\")\n",
        "  else:\n",
        "    print(\"GPU is enabled in this notebook but not needed.\")\n",
        "    print(\"If possible, in the menu under `Runtime` -> \")\n",
        "    print(\"`Change runtime type.`  select `CPU`\")\n",
        "\n",
        "  return device\n",
        "\n",
        "\n",
        "SEED = 2021\n",
        "set_seed(seed=SEED)\n",
        "DEVICE = set_device()\n",
        "\n",
        "\n",
        "def printmd(string):\n",
        "  display(Markdown(string))\n",
        "\n",
        "\n",
        "# the different utility .py files used in this notebook\n",
        "filenames = ['gw_plotting.py', 'gw_board.py', 'gw_game.py',\n",
        "             'gw_widgets.py', 'gw_NN_RL.py']\n",
        "#filenames = []\n",
        "# just run the code straight out of the response, no local copies needed!\n",
        "for filename in filenames:\n",
        "  url = f'https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/utils/{filename}'\n",
        "  response = requests.get(url)\n",
        "  # Check that we got a valid response\n",
        "  if response.status_code == 200:\n",
        "    code = response.content.decode()\n",
        "    exec(code)\n",
        "  else:\n",
        "    print(f'Failed to download {url}')\n",
        "\n",
        "# environment contingent imports\n",
        "try:\n",
        "  print('Running in colab')\n",
        "  from google.colab import output\n",
        "  output.enable_custom_widget_manager()\n",
        "  from google.colab import data_table\n",
        "  data_table.disable_dataframe_formatter()\n",
        "  #from google.colab import output as colab_output\n",
        "  #colab_output.enable_custom_widget_manager()\n",
        "  IN_COLAB = True\n",
        "except:\n",
        "  IN_COLAB = False\n",
        "  print('Not running in colab')\n",
        "\n",
        "%matplotlib inline\n",
        "%config InlineBackend.figure_format = 'retina'\n",
        "%matplotlib widget\n",
        "plt.style.use(\"https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/pplb.mplstyle\")\n",
        "plt.ioff() #need to use plt.show() or display explicitly\n",
        "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)\n",
        "\n",
        "\n",
        "def content_review(notebook_section: str):\n",
        "  return DatatopsContentReviewContainer(\n",
        "    \"\",  # No text prompt\n",
        "    notebook_section,\n",
        "    {\n",
        "      \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
        "      \"name\": \"neuro_book\",\n",
        "      \"user_key\": \"xuk960xj\",\n",
        "    },\n",
        "  ).render()\n",
        "feedback_prefix = \"P1C2_S3\"\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "################################################################\n",
        "# Graph Viz Helper Functions\n",
        "################################################################\n",
        "# @title Graphvis Helper Functions\n",
        "\n",
        "\n",
        "def latex_to_png(latex_str, file_path, dpi, fontsize, figsize):\n",
        "  \"\"\"Convert a LaTeX string to a PNG image.\"\"\"\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  ax.text(0.5, 0.5, f\"${latex_str}$\", size=fontsize, ha='center', va='center')\n",
        "  ax.axis(\"off\")\n",
        "  #plt.tight_layout()\n",
        "  plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
        "  plt.savefig(file_path, dpi=dpi, bbox_inches='tight', transparent=True, pad_inches=0.02)\n",
        "  plt.close()\n",
        "\n",
        "def add_latex_edge_labels(graph, edge_labels, dpi=150, fontsize=16, figsize=(0.4,0.2)):\n",
        "  \"\"\"Add LaTeX-rendered images as edge labels using the dummy node approach.\"\"\"\n",
        "  for edge in edge_labels:\n",
        "    src, dest, latex_str = edge\n",
        "    if graph.has_edge(src, dest):\n",
        "      img_path = f\"{src}_to_{dest}_{latex_str}.png\"\n",
        "      latex_to_png(latex_str, img_path, dpi=dpi, fontsize=fontsize, figsize=figsize)\n",
        "      dummy_node_name = f\"dummy_{src}_{dest}_{latex_str}\"\n",
        "      graph.add_node(dummy_node_name, shape=\"box\", image=img_path, label=\"\")\n",
        "      graph.delete_edge(src, dest)\n",
        "      graph.add_edge(src, dummy_node_name, dir=\"none\", weight=10)\n",
        "      graph.add_edge(dummy_node_name, dest, dir=\"forward\", weight=10)\n",
        "  return graph\n",
        "\n",
        "def set_regular_node_sizes(graph, width=1.0, height=1.0):\n",
        "  \"\"\"Set the size of regular nodes (excluding dummy label nodes).\"\"\"\n",
        "  for node in graph.nodes():\n",
        "    if not node.startswith(\"dummy\"):\n",
        "      node.attr['width'] = width\n",
        "      node.attr['height'] = height\n",
        "  return graph\n",
        "\n",
        "\n",
        "def create_and_render_graph(nodes_list, edges_list, latex_edge_labels,\n",
        "                            action_nodes = [],\n",
        "                            node_colors = {},\n",
        "                            node_labels = {},\n",
        "                            output_path=\"graphviz_output.png\", dpi=300,\n",
        "                            figsize=(0.6, 0.3), fontsize=16):\n",
        "  \"\"\"\n",
        "  Create a graph with given nodes, edges, and LaTeX edge labels, then render and save it.\n",
        "\n",
        "  Parameters:\n",
        "    nodes_list (list): List of nodes in the graph.\n",
        "    edges_list (list): List of edges in the graph.\n",
        "    latex_edge_labels (list): List of tuples containing edge and its LaTeX label.\n",
        "    output_path (str): Path to save the rendered graph.\n",
        "    dpi (int): DPI for rendering the graph.\n",
        "    figsize (tuple): Figure size for the LaTeX labels.\n",
        "\n",
        "  Returns:\n",
        "    str: Path to the saved graph image.\n",
        "  \"\"\"\n",
        "  # Graph Creation and Configuration\n",
        "  G = pgv.AGraph(directed=True, strict=False, rankdir='LR', ranksep=0.5, nodesep=0.5)\n",
        "\n",
        "  # Add state and decision nodes\n",
        "  for node in nodes_list:\n",
        "    shape = \"box\" if node in action_nodes else \"ellipse\"  # Use 'box' for decision nodes\n",
        "    color = node_colors.get(node, \"black\")\n",
        "    label = node_labels.get(node, node)\n",
        "    G.add_node(node, color=color, label=label, shape=shape)\n",
        "\n",
        "  for edge in edges_list:\n",
        "    G.add_edge(edge[0], edge[1])\n",
        "\n",
        "  # Set size for regular nodes and add LaTeX-rendered image labels to the edges\n",
        "  G = set_regular_node_sizes(G, width=1, height=1)\n",
        "  G = add_latex_edge_labels(G, latex_edge_labels, dpi=dpi, figsize=figsize, fontsize=fontsize)\n",
        "\n",
        "  # Additional graph attributes\n",
        "  G.graph_attr['size'] = \"8,8\"\n",
        "  G.graph_attr['dpi'] = str(dpi)\n",
        "\n",
        "  # Render and save the graph\n",
        "  G.layout(prog='dot')\n",
        "  G.draw(output_path)\n",
        "\n",
        "  return output_path\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "# @title plotting functions\n",
        "#################################################\n",
        "# More plotting functions\n",
        "#################################################\n",
        "\n",
        "\n",
        "def plot_directions(fig, ax, loc_prob_dict, critter, deterministic=False,\n",
        "                    name=None):\n",
        "  \"\"\"\n",
        "  Plot vector field indicating critter direction probabilities.\n",
        "\n",
        "  Args:\n",
        "    fig, ax (matplotlib objects): Figure and axes objects for plotting.\n",
        "    loc_prob_dict (dict): Dictionary with keys as (row, col) location tuples\n",
        "      and values as lists of direction probabilities corresponding to the\n",
        "      directions ['right', 'down', 'left', 'up'].\n",
        "    critter (int): Identifier for which critter directions are associated with.\n",
        "    deterministic (bool, optional): If True, the probabilities array is\n",
        "      converted to 1-hot, and the arrows are plotted at the center of the cell\n",
        "      and are larger. Defaults to False.\n",
        "  \"\"\"\n",
        "\n",
        "  #looks like direction ignores inverted axis\n",
        "  direction_vectors = {'right': (1, 0), 'down': (0, -1),\n",
        "                       'left': (-1, 0), 'up': (0, 1)}\n",
        "  # but offsets need to be aware of inverted\n",
        "  direction_offsets = {'right': (0.1, 0), 'down': (0, 0.1),\n",
        "                       'left': (-0.1, 0), 'up': (0, -0.1)}\n",
        "  # Offsets for each critter type 1 and 2 to be used together, 0 by itself\n",
        "  critter_offsets = {0: (0, 0), 1: (-0.05, -0.05), 2: (0.05, 0.05)}\n",
        "  # same logic for colors\n",
        "  critter_colors = {0: 'black', 1: 'red', 2: 'blue'}\n",
        "  # Get the offset and color for this critter\n",
        "  critter_offset = critter_offsets[critter]\n",
        "  critter_color = critter_colors[critter]\n",
        "\n",
        "  # Add legend only if critter is not 0\n",
        "  custom_leg_handles = []\n",
        "  if critter != 0:\n",
        "    if name is None:\n",
        "      name = f'Critter {critter}'\n",
        "    legend_patch = mpatches.Patch(color=critter_color, label=name)\n",
        "    # Add the legend for this critter\n",
        "    custom_leg_handles.append(legend_patch)\n",
        "\n",
        "  C, R, U, V, A = [], [], [], [], []\n",
        "\n",
        "  for loc in loc_prob_dict.keys():\n",
        "    row, col = loc\n",
        "    probs = loc_prob_dict[loc]\n",
        "    for dir_key, prob in probs.items():\n",
        "      C.append(col + critter_offset[0] + direction_offsets[dir_key][0])\n",
        "      R.append(row + critter_offset[1] + direction_offsets[dir_key][1])\n",
        "      U.append(direction_vectors[dir_key][0])\n",
        "      V.append(direction_vectors[dir_key][1])\n",
        "\n",
        "      if deterministic:\n",
        "        A.append(1 if prob == max(probs.values()) else 0)\n",
        "      else:\n",
        "        A.append(prob)\n",
        "\n",
        "  linewidth = 1.5 if deterministic else 0.5\n",
        "  scale = 15 if deterministic else 30\n",
        "\n",
        "  ax.quiver(C, R, U, V, alpha=A, color=critter_color,\n",
        "            scale=scale, linewidth=linewidth)\n",
        "  return fig, ax, custom_leg_handles\n",
        "\n",
        "\n",
        "def make_grid(num_rows, num_cols, figsize=(7,6), title=None):\n",
        "  \"\"\"Plots an n_rows by n_cols grid with cells centered on integer indices and\n",
        "  returns fig and ax handles for further use\n",
        "  Args:\n",
        "    num_rows (int): number of rows in the grid (vertical dimension)\n",
        "    num_cols (int): number of cols in the grid (horizontal dimension)\n",
        "\n",
        "  Returns:\n",
        "    fig (matplotlib.figure.Figure): figure handle for the grid\n",
        "    ax: (matplotlib.axes._axes.Axes): axes handle for the grid\n",
        "  \"\"\"\n",
        "  # Create a new figure and axes with given figsize\n",
        "  fig, ax = plt.subplots(figsize=figsize, layout='constrained')\n",
        "  # Set width and height padding, remove horizontal and vertical spacing\n",
        "  fig.get_layout_engine().set(w_pad=4 / 72, h_pad=4 / 72, hspace=0, wspace=0)\n",
        "  # Show right and top borders (spines) of the plot\n",
        "  ax.spines[['right', 'top']].set_visible(True)\n",
        "  # Set major ticks (where grid lines will be) on x and y axes\n",
        "  ax.set_xticks(np.arange(0, num_cols, 1))\n",
        "  ax.set_yticks(np.arange(0, num_rows, 1))\n",
        "  # Set labels for major ticks with font size of 8\n",
        "  ax.set_xticklabels(np.arange(0, num_cols, 1),fontsize=8)\n",
        "  ax.set_yticklabels(np.arange(0, num_rows, 1),fontsize=8)\n",
        "  # Set minor ticks (no grid lines here) to be between major ticks\n",
        "  ax.set_xticks(np.arange(0.5, num_cols-0.5, 1), minor=True)\n",
        "  ax.set_yticks(np.arange(0.5, num_rows-0.5, 1), minor=True)\n",
        "  # Move x-axis ticks to the top of the plot\n",
        "  ax.xaxis.tick_top()\n",
        "  # Set grid lines based on minor ticks, make them grey, dashed, and half transparent\n",
        "  ax.grid(which='minor', color='grey', linestyle='-', linewidth=2, alpha=0.5)\n",
        "  # Remove minor ticks (not the grid lines)\n",
        "  ax.tick_params(which='minor', bottom=False, left=False)\n",
        "  # Set limits of x and y axes\n",
        "  ax.set_xlim(( -0.5, num_cols-0.5))\n",
        "  ax.set_ylim(( -0.5, num_rows-0.5))\n",
        "  # Invert y axis direction\n",
        "  ax.invert_yaxis()\n",
        "  # If title is provided, set it as the figure title\n",
        "  if title is not None:\n",
        "    fig.suptitle(title)\n",
        "  # Hide header and footer, disable toolbar and resizing of the figure\n",
        "  fig.canvas.header_visible = False\n",
        "  fig.canvas.toolbar_visible = False\n",
        "  fig.canvas.resizable = False\n",
        "  fig.canvas.footer_visible = False\n",
        "  # Redraw the figure with these settings\n",
        "  fig.canvas.draw()\n",
        "  # Return figure and axes handles for further customization\n",
        "  return fig, ax\n",
        "\n",
        "\n",
        "def plot_food(fig, ax, rc_food_loc, food=None, size=None,\n",
        "              show_food=True):\n",
        "  \"\"\"\n",
        "  Plots \"food\" on a grid implied by the given fig, ax arguments\n",
        "\n",
        "  Args:\n",
        "    fig, ax: matplotlib figure and axes objects\n",
        "    rc_food_loc: ndarry(int) of shape (N:num_food x 2:row,col)\n",
        "    food: a handle for the existing food matplotlib PatchCollection object\n",
        "    if one exists\n",
        "  Returns:\n",
        "    a handle for matplotlib PathCollection object of food scatter plot, either\n",
        "    new if no handle was passed or updated if it was\n",
        "  \"\"\"\n",
        "  # if no PathCollection handle passed in:\n",
        "  if size is None:\n",
        "    size=150\n",
        "  if food is None:\n",
        "    food = ax.scatter([], [], s=size, marker='o',\n",
        "                      color='red', label='Food')\n",
        "  if show_food:\n",
        "    rc_food_loc = np.array(rc_food_loc, dtype=int)\n",
        "    #matrix indexing convention is is [row-vertical, col-horizontal]\n",
        "    #plotting indexing convention is (x-horizontal,y-vertical), hence flip\n",
        "    food.set_offsets(np.fliplr(rc_food_loc))\n",
        "  return food\n",
        "\n",
        "\n",
        "def plot_critters(fig, ax, critter_specs: List[Dict[str, object]],\n",
        "                  size=None) -> List[Dict[str, object]]:\n",
        "  \"\"\"\n",
        "  Plots multiple types of \"critters\" on a grid implied by the given\n",
        "  fig, ax arguments.\n",
        "\n",
        "  Args:\n",
        "    fig, ax: matplotlib figure and axes objects.\n",
        "    critter_specs: List of dictionaries with keys 'location', 'name', 'color',\n",
        "    'marker', 'int_id', 'rc_critter_loc' and optionally 'handle' for each\n",
        "    critter.\n",
        "\n",
        "  Returns:\n",
        "    Updated critter_specs with handles.\n",
        "  \"\"\"\n",
        "  if size is None:\n",
        "    size=250\n",
        "  for spec in critter_specs:\n",
        "    # Ensure required keys are present\n",
        "    for key in ['marker', 'color', 'name', 'rc_loc']:\n",
        "      if key not in spec:\n",
        "        raise ValueError(f\"Key '{key}' missing in critter spec.\")\n",
        "    handle_ = spec.get('handle')\n",
        "    if handle_ is None:\n",
        "      handle_ = ax.scatter([], [], s=size, marker=spec['marker'],\n",
        "                           color=spec['color'], label=spec['name'],\n",
        "                           edgecolors='white', linewidths=1)\n",
        "    handle_.set_offsets(np.flip(spec['rc_loc']))\n",
        "    spec.update({'handle': handle_})\n",
        "  return critter_specs\n",
        "\n",
        "\n",
        "def plot_critter(fig, ax, rc_critter_loc,\n",
        "                 critter=None, critter_name='Critter'):\n",
        "  \"\"\"\n",
        "  Plots \"critter\" on a grid implied by the given fig, ax arguments\n",
        "\n",
        "  Args:\n",
        "    fig, ax: matplotlib figure and axes objects\n",
        "    rc_critter_loc: ndarry(int) of shape (N:num_critters x 2:row,col)\n",
        "    critter: a handle for the existing food matplotlib PatchCollection object\n",
        "    if one exists\n",
        "  Returns:\n",
        "    a handle for matplotlib PathCollection object of critter scatter plot,\n",
        "    either new if no handle was passed in or updated if it was.\n",
        "  \"\"\"\n",
        "  if critter is None:\n",
        "    critter = ax.scatter([], [], s=250, marker='h',\n",
        "                         color='blue', label=critter_name)\n",
        "  # matrix indexing convention is is [row-vertical, col-horizontal]\n",
        "  # plotting indexing convention is (x-horizontal,y-vertical), hence flip\n",
        "  critter.set_offsets(np.flip(rc_critter_loc))\n",
        "  return critter\n",
        "\n",
        "\n",
        "def plot_fov(fig, ax, rc_critter, n_rows, n_cols, radius, has_fov,\n",
        "             opaque=False, fov=None):\n",
        "  \"\"\"\n",
        "  Plots a mask on a grid implied by the given fig, ax arguments\n",
        "\n",
        "  Args:\n",
        "    fig, ax: matplotlib figure and axes objects\n",
        "    rc_critter: ndarry(int) (row,col) of the critter\n",
        "    mask: a handle for the existing mask matplotlib Image object if one exists\n",
        "  Returns:\n",
        "    a handle for matplotlib Image object of mask, either new if no handle\n",
        "    was passed in or updated if it was.\n",
        "  \"\"\"\n",
        "\n",
        "  # Initialize mask as a semi-transparent overlay for the entire grid\n",
        "  mask_array = np.ones((n_rows, n_cols, 4))\n",
        "  mask_array[:, :, :3] = 0.5  # light grey color\n",
        "  if has_fov == True:\n",
        "    if opaque:\n",
        "      mask_array[:, :, 3] = 1.0  # 50% opacity\n",
        "    else:\n",
        "      mask_array[:, :, 3] = 0.5  # 50% opacity\n",
        "    # Create arrays representing the row and column indices\n",
        "    rows = np.arange(n_rows)[:, np.newaxis]\n",
        "    cols = np.arange(n_cols)[np.newaxis, :]\n",
        "    # Iterate over each critter location\n",
        "    dist = np.abs(rows - rc_critter[0]) + np.abs(cols - rc_critter[1])\n",
        "    # Set the region within the specified radius around the critter to transparent\n",
        "    mask_array[dist <= radius, 3] = 0\n",
        "  else:\n",
        "    mask_array[:, :, 3] = 0\n",
        "\n",
        "  if fov is None:\n",
        "    fov = ax.imshow(mask_array, origin='lower', zorder=2)\n",
        "  else:\n",
        "    fov.set_data(mask_array)\n",
        "\n",
        "  return fov\n",
        "\n",
        "\n",
        "def remove_ip_clutter(fig):\n",
        "  fig.canvas.header_visible = False\n",
        "  fig.canvas.toolbar_visible = False\n",
        "  fig.canvas.resizable = False\n",
        "  fig.canvas.footer_visible = False\n",
        "  fig.canvas.draw()\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "execution": {},
        "id": "9ufNNgXqZpjs",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title Gridworld Board Class\n",
        "# Local definition to be put in utils later\n",
        "\n",
        "\n",
        "class GridworldBoard():\n",
        "  \"\"\"\n",
        "  A collection methods and parameters for our Gridworld game.\n",
        "\n",
        "  board state is represented by primarily by pieces, scores, rounds_left and is_over\n",
        "\n",
        "  pieces is a batch x n_rows x n_cols numpy array positive integers are critter\n",
        "  locations 0's are empty space and negative integers are food. Each critter is\n",
        "  unique and executing it's own policy so they are non-fungible, whereas food\n",
        "  (of the same type) is always the same, so there can and typically will be\n",
        "  duplicates of negative integers in the pieces array, but never of positive\n",
        "  integers\n",
        "\n",
        "  For pieces first dim is batch, second dim row , third is col,\n",
        "  so pieces[0][1][7] is the square in row 2, in column 8 of the first board in\n",
        "  the batch of boards.\n",
        "\n",
        "  scores is a batchsize x num_critters numpy array giving the scores for each\n",
        "  critter on each board in the batch (note off by one indexing)\n",
        "\n",
        "  rounds_left is how many rounds are left in the game. Each critter gets one\n",
        "  move per round so this will be the same for every critter in every batch.\n",
        "\n",
        "  is_over just tracks whether each game in each batch has concluded, this allows\n",
        "  for probabalistic end times, not just deterministic end times based on moves left\n",
        "\n",
        "  Note: In this version the game class handles the end conditions, without any\n",
        "      input from this board class. Even though they are not used, max_rounds_taken\n",
        "      and end_prob are passed in to the constructor for completeness.\n",
        "\n",
        "  Note:\n",
        "    In 2d np.array first dim is row (vertical), second dim is col (horizontal),\n",
        "    i.e. top left corner is (0,0), so take care when visualizing/plotting\n",
        "    as np.array visualization is aligned with typical tensor notation but at odds\n",
        "    with conventional plotting where (0,0) is bottom left, first dim, x, is\n",
        "    horizontal, second dim, y, is vertical, so we use invert y-axis when plotting\n",
        "    with matplotlib\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  class CritterFoodType(Enum):\n",
        "    FOOD = \"food\"\n",
        "    PREY = \"prey\"\n",
        "    PREDATOR = \"predator\"\n",
        "\n",
        "  ARRAY_PAD_VALUE = -200\n",
        "\n",
        "\n",
        "  def __init__(self, batch_size=2,\n",
        "               n_rows=7, n_cols=7,\n",
        "               num_foragers=1,\n",
        "               num_predators=0,\n",
        "               max_rounds_taken=30,\n",
        "               end_prob=0.00,\n",
        "               food_num_deterministic = True,\n",
        "               food_patch_prob=10.0/49.0,\n",
        "               food_forager_regen = True,\n",
        "               rng=None,\n",
        "               state_elements = ['pieces', 'scores', 'is_over', 'rounds_left'],\n",
        "               init_board_state = None\n",
        "               ):\n",
        "\n",
        "    \"\"\"Set the parameters of the game.\"\"\"\n",
        "    # size of the board/world\n",
        "    self.n_rows = n_rows\n",
        "    self.n_cols = n_cols\n",
        "    self.batch_size = batch_size\n",
        "\n",
        "    #number and type of critters on the board\n",
        "    self.num_foragers = num_foragers\n",
        "    self.num_predators = num_predators\n",
        "    # foragers will be indicated by lower valued positive integers, predators\n",
        "    # by higher valued intagers\n",
        "    self.forager_predator_threshold = self.num_foragers\n",
        "    self.num_critters = num_foragers + num_predators\n",
        "\n",
        "    # end conditions can be deterministic or stochastic\n",
        "    # one of moving, or eating or both might take time, e.g. eating might be\n",
        "    # automatic and free after moving, conversely, moving might be free, but\n",
        "    # eating count towards the session/episode ending, or both might\n",
        "    self.max_rounds_taken = max_rounds_taken\n",
        "    self.end_prob = end_prob\n",
        "\n",
        "    # what proportion of the (non-critter occupied) patches contain food.\n",
        "    self.food_patch_prob = food_patch_prob\n",
        "    self.food_num_deterministic = food_num_deterministic\n",
        "    if self.food_num_deterministic:\n",
        "      self.num_food = int((self.n_rows * self.n_cols - self.num_critters)\n",
        "                          * self.food_patch_prob)\n",
        "    self.food_forager_regen = food_forager_regen\n",
        "\n",
        "    # reproducible stochasticity\n",
        "    if rng is None:\n",
        "      self.rng = np.random.default_rng(seed=SEED)\n",
        "    else:\n",
        "      self.rng = rng\n",
        "\n",
        "    self.state_elements = state_elements\n",
        "\n",
        "    # initialize the board\n",
        "    if init_board_state is None:\n",
        "      init_board_state = self.get_init_board_state()\n",
        "\n",
        "    self.set_state(init_board_state)\n",
        "\n",
        "\n",
        "  def init_loc(self, n_rows, n_cols, num, rng=None):\n",
        "    \"\"\"\n",
        "    Samples random 2d grid locations without replacement, useful for placing\n",
        "    critters and food on the board.\n",
        "\n",
        "    Args:\n",
        "      n_rows: int, number of rows in the grid\n",
        "      n_cols: int, number of columns in the grid\n",
        "      num:    int, number of samples to generate. Should throw an error if num > n_rows x n_cols\n",
        "      rng:    instance of numpy.random's default rng. Used for reproducibility.\n",
        "\n",
        "    Returns:\n",
        "      int_loc: ndarray(int) of shape (num,), flat indices for a 2D grid flattened into 1D\n",
        "      rc_index: tuple(ndarray(int), ndarray(int)), a pair of arrays with the first giving\n",
        "        the row indices and the second giving the col indices. Useful for indexing into\n",
        "        an n_rows by n_cols numpy array.\n",
        "      rc_plotting: ndarray(int) of shape (num, 2), 2D coordinates suitable for matplotlib plotting\n",
        "    \"\"\"\n",
        "\n",
        "    # Set up default random generator, use the boards default if none explicitly given\n",
        "    if rng is None:\n",
        "      rng = self.rng\n",
        "    # Choose 'num' unique random indices from a flat 1D array of size n_rows*n_cols\n",
        "    int_loc = rng.choice(n_rows * n_cols, num, replace=False)\n",
        "    # Convert the flat indices to 2D indices based on the original shape (n_rows, n_cols)\n",
        "    rc_index = np.unravel_index(int_loc, (n_rows, n_cols))\n",
        "    # Transpose indices to get num x 2 array for easy plotting with matplotlib\n",
        "    rc_plotting = np.array(rc_index).T\n",
        "    # Return 1D flat indices, 2D indices for numpy array indexing and 2D indices for plotting\n",
        "    return int_loc, rc_index, rc_plotting\n",
        "\n",
        "\n",
        "  def get_init_board_state(self):\n",
        "    \"\"\"\n",
        "    Set up starting board using game parameters\n",
        "    \"\"\"\n",
        "    state = {}\n",
        "    state['rounds_left'] = (np.ones(self.batch_size) *\n",
        "                           self.max_rounds_taken)\n",
        "    state['is_over'] = np.zeros(self.batch_size, dtype=bool)\n",
        "    state['scores'] = np.zeros((self.batch_size, self.num_critters))\n",
        "\n",
        "    # create an empty board array.\n",
        "    pieces = np.zeros((self.batch_size, self.n_rows, self.n_cols),\n",
        "                       dtype=int)\n",
        "    # Place critter and initial food items on the board randomly\n",
        "    if self.food_num_deterministic:\n",
        "      init_food_nums = [self.num_food] * self.batch_size\n",
        "    else:\n",
        "      init_food_nums = self.rng.binomial(self.n_rows * self.n_cols - self.num_critters,\n",
        "                                         self.food_patch_prob, size=self.batch_size)\n",
        "    # place food and critters randomly\n",
        "    for ii in np.arange(self.batch_size):\n",
        "      # num_food+num_critter because we want critter and food locations\n",
        "      int_loc, rc_idx, rc_plot = self.init_loc(\n",
        "        self.n_rows, self.n_cols, init_food_nums[ii]+self.num_critters)\n",
        "      # critter random start locations\n",
        "      for c_ in np.arange(self.num_critters):\n",
        "        pieces[(ii, rc_idx[0][c_], rc_idx[1][c_])] = c_ + 1\n",
        "      # food random start locations\n",
        "      for f_ in np.arange(init_food_nums[ii]):\n",
        "        pieces[(ii, rc_idx[0][self.num_critters + f_],\n",
        "                    rc_idx[1][self.num_critters + f_])] = -f_ - 1\n",
        "    state['pieces'] = pieces\n",
        "    return state\n",
        "\n",
        "\n",
        "  def set_state(self, board, check=False):\n",
        "    \"\"\" board is dictionary giving game state \"\"\"\n",
        "    if check:\n",
        "      if board['pieces'].shape != (self.batch_size, self.n_rows, self.n_cols):\n",
        "        raise ValueError(\"Invalid shape for 'pieces'\")\n",
        "      if board['scores'].shape != (self.batch_size, self.num_crititters):\n",
        "        raise ValueError(\"Invalid shape for 'scores'\")\n",
        "      if board['rounds_left'].shape != (self.batch_size,):\n",
        "        raise ValueError(\"Invalid shape for 'rounds_left'\")\n",
        "      if board['is_over'].shape != (self.batch_size,):\n",
        "        raise ValueError(\"Invalid shape for 'is_over'\")\n",
        "    for key in self.state_elements:\n",
        "      if key in board:\n",
        "        setattr(self, key, board[key].copy())\n",
        "      else:\n",
        "        raise ValueError(f\"Key '{key}' not found in the provided board state.\")\n",
        "\n",
        "\n",
        "  def get_state(self):\n",
        "    \"\"\" returns a board state dictionary\"\"\"\n",
        "    state = {key: getattr(self, key).copy() for key in self.state_elements}\n",
        "    return state\n",
        "\n",
        "\n",
        "  def __getitem__(self, index):\n",
        "    return self.pieces[index]\n",
        "\n",
        "\n",
        "  def get_critter_food_type(self, critter_food):\n",
        "    if critter_food <= -1:\n",
        "        critter_food_type = self.CritterFoodType.FOOD\n",
        "    elif critter_food > self.forager_predator_threshold:\n",
        "        critter_food_type = self.CritterFoodType.PREDATOR\n",
        "    else:\n",
        "        critter_food_type = self.CritterFoodType.PREY\n",
        "    return critter_food_type\n",
        "\n",
        "\n",
        "  def get_type_masks(self):\n",
        "    \"\"\"\n",
        "    Returns masks indicating the position types on the board.\n",
        "    Returns:\n",
        "        tuple: Tuple containing masks for empty spaces, food, prey, and predator.\n",
        "    \"\"\"\n",
        "    empt_mask = self.pieces == 0\n",
        "    food_mask = self.pieces <= -1\n",
        "    prey_mask = (1 <= self.pieces) & (self.pieces <= self.forager_predator_threshold)\n",
        "    pred_mask = self.forager_predator_threshold < self.pieces\n",
        "    return empt_mask, food_mask, prey_mask, pred_mask\n",
        "\n",
        "\n",
        "  def get_collisions(self, moves, critter_food, critter_food_type):\n",
        "    \"\"\"\n",
        "    Determine the collision results and update scores accordingly.\n",
        "    Args:\n",
        "        moves (tuple): Tuple of arrays indicating the moves.\n",
        "        critter_food (int): Index to identify the critter or food.\n",
        "        critter_food_type (enum): Type of the critter or food\n",
        "    Returns:\n",
        "        tuple: Tuple containing move collision messages and separates out the\n",
        "        moves by where they land i.e., empty spaces, food, prey, and predator.\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = self.pieces.shape\n",
        "    move_mask = np.zeros(self.pieces.shape, dtype=bool)\n",
        "    move_mask[moves] = True\n",
        "    (empt_mask, food_mask,\n",
        "     prey_mask, pred_mask) = self.get_type_masks()\n",
        "\n",
        "    move_coll_msg = np.zeros(batch_size)\n",
        "    empt_moves = np.where(empt_mask & move_mask)\n",
        "    food_moves = np.where(food_mask & move_mask)\n",
        "    prey_moves = np.where(prey_mask & move_mask)\n",
        "    pred_moves = np.where(pred_mask & move_mask)\n",
        "    move_coll_msg[empt_moves[0]] = 1\n",
        "\n",
        "    if critter_food_type == self.CritterFoodType.PREY:\n",
        "      move_coll_msg[food_moves[0]] = 2\n",
        "    elif critter_food_type == self.CritterFoodType.PREDATOR:\n",
        "      move_coll_msg[food_moves[0]] = 3\n",
        "      move_coll_msg[prey_moves[0]] = 4\n",
        "    # all collision types are blocking for food types\n",
        "\n",
        "    return (move_coll_msg, empt_moves, food_moves, prey_moves, pred_moves)\n",
        "\n",
        "\n",
        "  def update_scores(self, move_coll_msg, critter_food,\n",
        "                    critter_food_type, prey_moves):\n",
        "    if critter_food_type == self.CritterFoodType.PREY:\n",
        "      self.scores[:, critter_food-1] += (move_coll_msg == 2)\n",
        "    elif critter_food_type == self.CritterFoodType.PREDATOR:\n",
        "      # predators that eat get a point\n",
        "      self.scores[:, critter_food-1] += (move_coll_msg == 4)\n",
        "      # prey that are eaten lose 10 points\n",
        "      who_eaten = self.pieces[prey_moves]\n",
        "      self.scores[prey_moves[0], who_eaten-1] -= 10\n",
        "    # food types don't get a score, it's a neuro book\n",
        "\n",
        "\n",
        "  def move_pieces(self, critter_food, move_coll_msg, moves):\n",
        "    \"\"\"\n",
        "    Move the pieces on the board based on the collision messages.\n",
        "\n",
        "    Args:\n",
        "        critter_food (int): Index to identify the critter or food.\n",
        "        move_coll_msg (np.array): Array of collision messages.\n",
        "        moves (tuple): Tuple of arrays indicating the moves.\n",
        "    \"\"\"\n",
        "    old_locs = np.where(self.pieces == critter_food)\n",
        "    vacated_old_locs = np.column_stack(old_locs)[np.where(move_coll_msg > 0)]\n",
        "    vacated_old_locs_idx = (vacated_old_locs[:,0],\n",
        "                            vacated_old_locs[:,1],\n",
        "                            vacated_old_locs[:,2])\n",
        "    self.pieces[vacated_old_locs_idx] = 0\n",
        "    new_locs = np.column_stack(moves)[np.where(move_coll_msg > 0)]\n",
        "    new_locs_idx = (new_locs[:,0], new_locs[:,1], new_locs[:,2])\n",
        "    self.pieces[new_locs_idx] = critter_food\n",
        "\n",
        "\n",
        "  def replace_destroyed(self, destroying_moves, old_pieces):\n",
        "    \"\"\"\n",
        "    Replace the destroyed pieces on the board.\n",
        "\n",
        "    Args:\n",
        "        destroying_moves (tuple): Tuple of arrays indicating the moves that\n",
        "        resulted in destruction.\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = old_pieces.shape\n",
        "    g_gone = np.zeros(batch_size)\n",
        "    g_gone[destroying_moves[0]] = 1\n",
        "    which_gone = old_pieces[destroying_moves]\n",
        "    if np.sum(g_gone) > 0:\n",
        "      num_empty_after = (n_rows*n_cols - self.num_food - self.num_critters + 1)\n",
        "      p_new_locs = np.where(np.logical_and(\n",
        "        self.pieces == 0, g_gone.reshape(batch_size, 1, 1)))\n",
        "      food_sample_ = self.rng.choice(num_empty_after, size=int(np.sum(g_gone)))\n",
        "      food_sample = food_sample_ + np.arange(int(np.sum(g_gone)))*num_empty_after\n",
        "      new_loc_vals = self.pieces[(p_new_locs[0][food_sample],\n",
        "                   p_new_locs[1][food_sample],\n",
        "                   p_new_locs[2][food_sample])]\n",
        "      # this requires that p_new_locs and destroying moves are both\n",
        "      # lexographically sorted... but they are not always\n",
        "      self.pieces[(p_new_locs[0][food_sample],\n",
        "                   p_new_locs[1][food_sample],\n",
        "                   p_new_locs[2][food_sample])] = which_gone\n",
        "\n",
        "\n",
        "  def execute_moves(self, moves, critter_food):\n",
        "    \"\"\"\n",
        "    Execute the moves on the board, handle collisions, update scores,\n",
        "    and replace destroyed/eaten pieces.\n",
        "\n",
        "    Args:\n",
        "      moves (tuple): Tuple of arrays indicating the moves.\n",
        "      critter_food (int): Index to identify the critter or food.\n",
        "    \"\"\"\n",
        "    # what type of critter is moving\n",
        "    critter_food_type = self.get_critter_food_type(critter_food)\n",
        "    # what do they land on when they move\n",
        "    (move_coll_msg, empt_moves, food_moves,\n",
        "     prey_moves, pred_moves) = self.get_collisions(\n",
        "        moves, critter_food, critter_food_type)\n",
        "    # based on what they move onto increment/decrement scores\n",
        "    self.update_scores(move_coll_msg, critter_food,\n",
        "                       critter_food_type, prey_moves)\n",
        "    # move the pieces\n",
        "    old_pieces = self.pieces.copy()\n",
        "    self.move_pieces(critter_food, move_coll_msg, moves)\n",
        "    # eaten/destroyed food and prey respawn in some variants\n",
        "    if critter_food_type == self.CritterFoodType.PREY:\n",
        "      if self.food_forager_regen:\n",
        "        self.replace_destroyed(food_moves, old_pieces)\n",
        "    elif critter_food_type == self.CritterFoodType.PREDATOR:\n",
        "      if self.food_forager_regen:\n",
        "        self.replace_destroyed(food_moves, old_pieces)\n",
        "        self.replace_destroyed(prey_moves, old_pieces)\n",
        "\n",
        "    if self.food_forager_regen:\n",
        "      check_sum = np.sum(np.arange(start=-self.num_food,\n",
        "                                   stop=self.num_critters+1))\n",
        "      if np.any(np.sum(self.pieces, axis=(1,2)) != check_sum):\n",
        "        print('something went terribly wrong')\n",
        "        print(old_pieces)\n",
        "        print(critter_food)\n",
        "        print(moves)\n",
        "        print(self.pieces)\n",
        "\n",
        "\n",
        "  def get_neighbor_grc_indices(self, critter_food, radius, pad=False):\n",
        "    \"\"\"\n",
        "    Returns all grid positions within a certain cityblock distance radius from\n",
        "    the place corresponding to critter_food.\n",
        "\n",
        "    Args:\n",
        "        critter_food (int): The idex of the focal critter_food.\n",
        "        radius (int): The cityblock distance.\n",
        "        pad (bool): whether or not to pad the array, if padded all row, col\n",
        "          indexes are valid for the padded array, useful for getting percept\n",
        "          if not all indexes are correct for the original array, useful for\n",
        "          figuring out legal moves.\n",
        "\n",
        "    Returns:\n",
        "        an array of indices, each row is a g, r, c index for the neighborhoods\n",
        "        around the critters, can use the g value to know which board you are in.\n",
        "        if pad=True also returns the padded array (the indices in that case) are\n",
        "        for the padded array, so won't work on self.pieces, whereas if pad is\n",
        "        False the indices will be for the offsets in reference to the original\n",
        "        self.pieces, but note that some of these will be invalid, and will\n",
        "        need to be filtered out (as we do in get_legal)\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = self.pieces.shape\n",
        "    # Create meshgrid for offsets\n",
        "    if pad is True:\n",
        "      padded_arr = np.pad(self.pieces, ((0, 0), (radius, radius),\n",
        "        (radius, radius)), constant_values=self.ARRAY_PAD_VALUE)\n",
        "      batch, rows, cols = np.where(padded_arr == critter_food)\n",
        "    else:\n",
        "      batch, rows, cols = np.where(self.pieces == critter_food)\n",
        "    row_offsets, col_offsets = np.meshgrid(\n",
        "        np.arange(-radius, radius + 1),\n",
        "        np.arange(-radius, radius + 1),\n",
        "        indexing='ij')\n",
        "\n",
        "    # Filter for valid cityblock distances\n",
        "    mask = np.abs(row_offsets) + np.abs(col_offsets) <= radius\n",
        "    valid_row_offsets = row_offsets[mask]\n",
        "    valid_col_offsets = col_offsets[mask]\n",
        "    # Extend rows and cols dimensions for broadcasting\n",
        "    extended_rows = rows[:, np.newaxis]\n",
        "    extended_cols = cols[:, np.newaxis]\n",
        "    # Compute all neighbors for each position in the batch\n",
        "    neighbors_rows = extended_rows + valid_row_offsets\n",
        "    neighbors_cols = extended_cols + valid_col_offsets\n",
        "\n",
        "    indices = np.column_stack((np.repeat(np.arange(batch_size),\n",
        "                                         neighbors_rows.shape[1]),\n",
        "                               neighbors_rows.ravel(),\n",
        "                               neighbors_cols.ravel()))\n",
        "    if pad is False:\n",
        "      return indices\n",
        "    elif pad is True:\n",
        "      return indices, padded_arr\n",
        "\n",
        "\n",
        "  def get_legal_moves(self, critter_food, radius=1):\n",
        "    \"\"\"\n",
        "    Identifies all legal moves for the critter, taking into acount which moves\n",
        "    are blocking based on type.\n",
        "\n",
        "    Returns:\n",
        "      A numpy int array of size batch x 3(g,x,y) x 4(possible moves)\n",
        "\n",
        "    Note:\n",
        "      moves[0,1,3] is the x coordinate of the move corresponding to the\n",
        "      fourth offset on the first board.\n",
        "      moves[1,:,1] will give the g,x,y triple corresponding to the\n",
        "      move on the second board and the second offset, actions are integers\n",
        "    \"\"\"\n",
        "\n",
        "    critter_locs = np.array(np.where(self.pieces == critter_food))\n",
        "    # turn those row, col offsets into a set of legal offsets\n",
        "    legal_offsets = self.get_neighbor_grc_indices(critter_food, radius)\n",
        "    legal_offsets = {tuple(m_) for m_ in legal_offsets}\n",
        "\n",
        "    # Apply logic of where a successful move can be made, by which\n",
        "    # type of critter, be they food, prey, predator or something else\n",
        "    empt_mask, food_mask, prey_mask, pred_mask = self.get_type_masks()\n",
        "    critter_food_type = self.get_critter_food_type(critter_food)\n",
        "    #print(critter_food_type)\n",
        "    if critter_food_type == self.CritterFoodType.FOOD:\n",
        "      #food only drifts into empty places\n",
        "      legal_destinations = np.where(empt_mask)\n",
        "    elif critter_food_type == self.CritterFoodType.PREY:\n",
        "      legal_destinations = np.where(empt_mask | food_mask)\n",
        "    elif critter_food_type == self.CritterFoodType.PREDATOR:\n",
        "      legal_destinations = np.where(empt_mask | food_mask | prey_mask)\n",
        "    else:\n",
        "      raise ValueError(\"Unexpected value for critter_food_type.\")\n",
        "    legal_destinations = {tuple(coords) for coords in zip(*legal_destinations)}\n",
        "    # Add the current locations of the critters to legal_destinations\n",
        "    current_locations = {tuple(loc) for loc in critter_locs.T}\n",
        "    legal_destinations = legal_destinations.union(current_locations)\n",
        "\n",
        "    # legal moves are both legal offsets and legal destinations\n",
        "    legal_moves = legal_offsets.intersection(legal_destinations)\n",
        "    return legal_moves\n",
        "\n",
        "\n",
        "  def get_legal_offsets(self, critter_food, radius):\n",
        "    \"\"\"\n",
        "    Identifies all legal offsets for a critter or food, so filter out moves\n",
        "    that are off the board, but does not filter out collisions that would be\n",
        "    blocking. For a random valid player likely better to use get_legal_moves,\n",
        "    but this is much quicker, because it doesn't check collision types, for\n",
        "    use by RL agents in training loops\n",
        "\n",
        "    Returns:\n",
        "      A numpy int array of size batch x 3(g,x,y) x 4(possible moves)\n",
        "\n",
        "    Note:\n",
        "      moves[0,1,3] is the x coordinate of the move corresponding to the\n",
        "      fourth offset on the first board.\n",
        "      moves[1,:,1] will give the g,x,y triple corresponding to the\n",
        "      move on the second board and the second offset, actions are integers\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = self.pieces.shape\n",
        "    batch, rows, cols = np.where(self.pieces == critter_food)\n",
        "    row_offsets, col_offsets = np.meshgrid(\n",
        "        np.arange(-radius, radius + 1),\n",
        "        np.arange(-radius, radius + 1),\n",
        "        indexing='ij')\n",
        "    # Filter for valid cityblock distances\n",
        "    mask = np.abs(row_offsets) + np.abs(col_offsets) <= radius\n",
        "    valid_row_offsets = row_offsets[mask]\n",
        "    valid_col_offsets = col_offsets[mask]\n",
        "    # Extend rows and cols dimensions for broadcasting\n",
        "    extended_rows = rows[:, np.newaxis]\n",
        "    extended_cols = cols[:, np.newaxis]\n",
        "    # Compute all neighbors for each position in the batch\n",
        "    potential_moves_rows = extended_rows + valid_row_offsets\n",
        "    potential_moves_cols = extended_cols + valid_col_offsets\n",
        "\n",
        "    # Filter offsets that would take the critter outside the board\n",
        "    c1 = potential_moves_rows >= 0\n",
        "    c2 = potential_moves_rows <= n_rows-1\n",
        "    c3 = potential_moves_cols >= 0\n",
        "    c4 = potential_moves_cols <= n_cols-1\n",
        "    valid_move_mask = np.logical_and.reduce([c1, c2, c3, c4])\n",
        "\n",
        "    legal_offsets_rows = potential_moves_rows[valid_move_mask]\n",
        "    legal_offsets_cols = potential_moves_cols[valid_move_mask]\n",
        "    batch_indexes = np.repeat(batch, valid_row_offsets.shape[0])\n",
        "    legal_offsets = np.column_stack((batch_indexes[valid_move_mask.ravel()],\n",
        "                                     legal_offsets_rows.ravel(),\n",
        "                                     legal_offsets_cols.ravel()))\n",
        "    return legal_offsets, valid_move_mask\n",
        "\n",
        "\n",
        "  def get_perceptions(self, critter_food, radius):\n",
        "    idx, pad_pieces = self.get_neighbor_grc_indices(critter_food,\n",
        "                                                    radius, pad=True)\n",
        "    #percept_mask = np.zeros(pad_pieces.shape, dtype=bool)\n",
        "    #percept_mask[idx[:,0], idx[:,1]], idx[:,2]] = True\n",
        "    percept = pad_pieces[idx[:,0], idx[:,1], idx[:,2]]\n",
        "    return(percept.reshape(self.batch_size, -1))\n",
        "\n",
        "\n",
        "  def execute_drift(self, offset_probs, wrapping=False):\n",
        "    \"\"\"\n",
        "    Drift the food on the board based on the given offsets probabilities.\n",
        "    Collisions handled by checking possible new locations in a random order and\n",
        "    cancelling moves that result in a collision.\n",
        "\n",
        "    Parameters:\n",
        "    - offset_probs: Probabilities corresponding to each offset, note implicit\n",
        "    order dependence here\n",
        "\n",
        "\n",
        "    Returns:\n",
        "    - nothing, just updates self.pieces\n",
        "    \"\"\"\n",
        "    # Check the length of offset_probs\n",
        "    #if len(offset_probs) != 5:\n",
        "    #    raise ValueError(\"offset_probs should be of length 5.\")\n",
        "    # Check if values are non-negative\n",
        "    #if any(p < 0 for p in offset_probs):\n",
        "    #    raise ValueError(\"All probabilities in offset_probs should be non-negative.\")\n",
        "    # Normalize the probabilities\n",
        "    #offset_probs = np.array(offset_probs) / np.sum(offset_probs)\n",
        "    # Convert offsets to a 2D numpy array\n",
        "    possible_offsets = np.array([[ 0, -1,  0], # up\n",
        "                                 [ 0,  1,  0], # down\n",
        "                                 [ 0,  0, -1], # left\n",
        "                                 [ 0,  0,  1], # right\n",
        "                                 [ 0,  0,  0]]) # still\n",
        "    batch_size, n_rows, n_cols = self.pieces.shape\n",
        "    # original food locations\n",
        "    food_locations = np.argwhere(self.pieces == -1)\n",
        "    # Sample offsets for each food location\n",
        "    num_food = food_locations.shape[0]\n",
        "    sampled_offsets = possible_offsets[self.rng.choice(\n",
        "        np.arange(possible_offsets.shape[0]),\n",
        "        size=num_food, replace=True, p=offset_probs)]\n",
        "    # Possible new food locations\n",
        "    possible_new_locations = food_locations + sampled_offsets\n",
        "    possible_wrap_row_indexes = self.rng.choice(np.arange(n_rows),\n",
        "                                                size=num_food)\n",
        "    possible_wrap_col_indexes = self.rng.choice(np.arange(n_cols),\n",
        "                                                size=num_food)\n",
        "\n",
        "    # Randomly iterate through the possible new locations\n",
        "    random_order = np.random.permutation(num_food)\n",
        "    for idx in random_order:\n",
        "      g, r, c = possible_new_locations[idx]\n",
        "      # Check if the new location is inside the boundaries of the board\n",
        "      if 0 <= r < self.pieces.shape[1] and 0 <= c < self.pieces.shape[2]:\n",
        "        # Check if the new location is empty or contains a critter\n",
        "        if self.pieces[g, r, c] == 0:\n",
        "          # Update the board\n",
        "          old_g, old_r, old_c = food_locations[idx]\n",
        "          self.pieces[g, r, c] = -1\n",
        "          self.pieces[old_g, old_r, old_c] = 0\n",
        "      elif wrapping == True:\n",
        "        # If wrapping is on then food can drift off the edge of the board and\n",
        "        # 'new' food will appear in a random loc on the opposite side\n",
        "        # Determine the opposite edge\n",
        "        if r < 0:  # Top edge\n",
        "          opposite_r = n_rows - 1\n",
        "          opposite_c = possible_wrap_col_indexes[idx]\n",
        "        elif r >= n_rows:  # Bottom edge\n",
        "          opposite_r = 0\n",
        "          opposite_c = possible_wrap_col_indexes[idx]\n",
        "        elif c < 0:  # Left edge\n",
        "          opposite_c = n_cols - 1\n",
        "          opposite_r = possible_wrap_row_indexes[idx]\n",
        "        elif c >= n_cols:  # Right edge\n",
        "          opposite_c = 0\n",
        "          opposite_r = possible_wrap_row_indexes[idx]\n",
        "\n",
        "        # Check if the opposite location is unoccupied\n",
        "        if self.pieces[g, opposite_r, opposite_c] == 0:\n",
        "          old_g, old_r, old_c = food_locations[idx]\n",
        "          self.pieces[g, opposite_r, opposite_c] = -1\n",
        "          self.pieces[old_g, old_r, old_c] = 0\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title GridworldGame class\n",
        "#######################################################################\n",
        "# extend GridworldGame class locally before integrating in shared utils\n",
        "#######################################################################\n",
        "\n",
        "\n",
        "\n",
        "class GridworldGame():\n",
        "  \"\"\"\n",
        "  A collection methods and parameters of a gridworld game that allow\n",
        "  for interaction with and display of GridwordlBoard objects.\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, batch_size=2,\n",
        "               n_rows=7, n_cols=7,\n",
        "               num_foragers=1,\n",
        "               num_predators=0,\n",
        "               max_rounds_taken=30,\n",
        "               end_prob=0.00,\n",
        "               food_num_deterministic = True,\n",
        "               food_patch_prob=10.0/48.0,\n",
        "               food_forager_regen = True,\n",
        "               rng=None,\n",
        "               state_elements = ['pieces', 'scores', 'is_over', 'rounds_left'],\n",
        "               init_board_state = None,\n",
        "               drift_player = None):\n",
        "\n",
        "    \"\"\"\n",
        "    Initializes an instance of the class with the specified parameters.\n",
        "    Args:\n",
        "      batch_size (int, optional): Number of instances in a batch. Default is 1.\n",
        "      n_rows (int, optional): Number of rows in the grid. Default is 7.\n",
        "      n_cols (int, optional): Number of columns in the grid. Default is 7.\n",
        "      num_foragers (int, optional): Number of different agents running around\n",
        "        on each board in the batch eating food. Default is 1.\n",
        "      num_predators (int, optional): Number of different agents running around\n",
        "        on each board in the batch eating foragers. Default is 0.\n",
        "      max_rounds_taken (int, optional): Time before critter's foraging session\n",
        "        ends, in terms of moves taken. Default is 30.\n",
        "      end_prob (float, optional): Probability of ending the game before max\n",
        "        moves are taken, on a given round. Default is 0.00.\n",
        "      food_num_deterministic (bool, optional): Whether or not the number of food\n",
        "        items on each board is deterministic. Default is True.\n",
        "      food_patch_prob (float, optional): Probability of food appearing on each\n",
        "        non-critter-occupied grid cell. Default is 10.0/49.\n",
        "        If food_num_determinisitc is true we use the expected value for each\n",
        "        game in the batch\n",
        "      food_forager_regen (bool, optional): Whether or not foragers and food\n",
        "        respawn/regenerate after they are eaten/destroyed. Default is True.\n",
        "      rng (numpy random number generator, optional): Random number generator\n",
        "        for reproducibility. If None, uses default RNG with a preset seed.\n",
        "      state_elements (list of strings, optional): Elements of the state\n",
        "        passed to players to determine moves. Default is ['pieces', 'scores',\n",
        "        'is_over', 'rounds_left'].\n",
        "      init_board_state (dict, optional): Allows for manual game state\n",
        "        initilization. Default is None, resulting in a random initialization.\n",
        "      drift_player (player object, optional): a 'player' who moves the food\n",
        "        pieces around (drifting) if none, skip food movement\n",
        "\n",
        "    Note: In this version game class handles the end conditions, without any\n",
        "      input from the board class.\n",
        "    \"\"\"\n",
        "\n",
        "    # Check for positive integer inputs\n",
        "    assert all(isinstance(i, int) and i >= 0\n",
        "               for i in [batch_size, n_rows, n_cols, num_foragers,\n",
        "                         num_predators, max_rounds_taken]), \"These inputs must be non-negative integers.\"\n",
        "\n",
        "    if rng is None:\n",
        "      self.rng = np.random.default_rng(seed=SEED)\n",
        "    else:\n",
        "      self.rng = rng\n",
        "\n",
        "    self.batch_size = batch_size\n",
        "    self.n_rows = n_rows\n",
        "    self.n_cols = n_cols\n",
        "    self.num_foragers = num_foragers\n",
        "    self.num_predators = num_predators\n",
        "    self.num_critters = num_predators + num_foragers\n",
        "    self.pred_prey_threshold = self.num_foragers\n",
        "    self.max_rounds_taken = max_rounds_taken\n",
        "    self.end_prob = end_prob\n",
        "    self.food_num_deterministic = food_num_deterministic\n",
        "    self.food_patch_prob = food_patch_prob\n",
        "    self.food_forager_regen = food_forager_regen\n",
        "    self.drift_player = drift_player\n",
        "    self.init_board_state = init_board_state\n",
        "    self.state_elements = state_elements\n",
        "\n",
        "    # convience wrapper for passing parameters to board class constructor\n",
        "    self.board_params = {\n",
        "      'batch_size': self.batch_size,\n",
        "      'n_rows': self.n_rows,\n",
        "      'n_cols': self.n_cols,\n",
        "      'num_foragers': self.num_foragers,\n",
        "      'num_predators': self.num_predators,\n",
        "      'max_rounds_taken': self.max_rounds_taken,\n",
        "      'end_prob': self.end_prob,\n",
        "      'food_num_deterministic': self.food_num_deterministic,\n",
        "      'food_patch_prob': self.food_patch_prob,\n",
        "      'food_forager_regen': self.food_forager_regen,\n",
        "      'rng': self.rng,\n",
        "      'state_elements': self.state_elements\n",
        "    }\n",
        "\n",
        "  def get_init_board(self):\n",
        "    \"\"\"\n",
        "    Generates a starting board given the parameters of the game.\n",
        "    Returns a tuple giving current state of the game\n",
        "    \"\"\"\n",
        "    # current score, and rounds left in the episode\n",
        "    b = GridworldBoard(**self.board_params,\n",
        "                       init_board_state=self.init_board_state)\n",
        "    return b.get_state()\n",
        "\n",
        "\n",
        "  def get_board_shape(self):\n",
        "    \"\"\"Shape of a single board, doesn't give batch size\"\"\"\n",
        "    return (self.n_rows, self.n_cols)\n",
        "\n",
        "\n",
        "  def get_action_size(self):\n",
        "    \"\"\"\n",
        "    Returns the number of all possible actions, even though only  2-4 of\n",
        "    these will ever be valid on a given turn.\n",
        "    Actions correspond to integer indexes of board locations,\n",
        "    moves to g,r,c coordinate indexes of board locations\n",
        "    \"\"\"\n",
        "    return self.n_rows * self.n_cols\n",
        "\n",
        "\n",
        "  def get_batch_size(self):\n",
        "    \"\"\"\n",
        "    Returns the number of actions, only 0-4 of these will ever be valid.\n",
        "    Actions correspond to integer indexes of board locations,\n",
        "    moves to r,c indexes of board locations\n",
        "    \"\"\"\n",
        "    return self.batch_size\n",
        "\n",
        "\n",
        "  def string_rep(self, board, g=0):\n",
        "    \"\"\" A bytestring representation board g's state in the batch of boards\"\"\"\n",
        "    return (board['pieces'][g].tobytes() + board['scores'][g].tobytes() +\n",
        "            board['rounds_left'][g].tobytes())\n",
        "\n",
        "\n",
        "  def get_square_symbol(self, piece):\n",
        "    \"\"\" Translate integer piece value to symbol for display\"\"\"\n",
        "    if piece <= -1:\n",
        "      return \"X\"\n",
        "    elif piece == 0:\n",
        "      return \"-\"\n",
        "    elif piece >= 1:\n",
        "      return \"0\"\n",
        "    else:\n",
        "      return \"???????????????????????????\"\n",
        "\n",
        "\n",
        "  def string_rep_readable(self, board, g=0):\n",
        "    \"\"\" A human readable representation of g-th board's state in the batch\"\"\"\n",
        "    board_s = \"\".join([self.get_square_symbol(square)\n",
        "                        for row in board['pieces'][g]\n",
        "                          for square in row])\n",
        "    board_s = board_s + '_' + str(board['scores'][g])\n",
        "    board_s = board_s + '_' + str(board['rounds_left'][g])\n",
        "    return board_s\n",
        "\n",
        "\n",
        "  def get_scores(self, board):\n",
        "    return board['scores'].copy()\n",
        "\n",
        "\n",
        "  def get_rounds_left(self, board):\n",
        "    return board['rounds_left'].copy()\n",
        "\n",
        "\n",
        "  def display(self, board, g=0):\n",
        "    \"\"\"Displays the g-th games in the batch of boards\"\"\"\n",
        "    print(\"   \", end=\"\")\n",
        "    for c_ in range(self.n_cols):\n",
        "      print(c_, end=\" \")\n",
        "    print(\"\")\n",
        "    print(\"-----------------------\")\n",
        "    for r_ in range(self.n_rows):\n",
        "      print(r_, \"|\", end=\"\")    # Print the row\n",
        "      for c_ in range(self.n_cols):\n",
        "        piece = board['pieces'][g,r_,c_]    # Get the piece to print\n",
        "        #print(piece)\n",
        "        print(self.get_square_symbol(piece), end=\" \")\n",
        "      print(\"|\")\n",
        "    print(\"-----------------------\")\n",
        "    print(\"Rounds Left: \" + str(board['rounds_left'][g]))\n",
        "    print(\"Score: \" + str(board['scores'][g]))\n",
        "\n",
        "\n",
        "  def get_critter_rc(self, board, g, critter_index):\n",
        "    return np.squeeze(np.array(np.where(board['pieces'][g]==critter_index)))\n",
        "\n",
        "\n",
        "  def plot_moves(self, board, player0, g=0, player1=None,\n",
        "                 fig=None, ax=None, p0_name='Player 0', p1_name='Player 1',\n",
        "                 figsize=(6,5), critter_name='Critter', title=None,\n",
        "                 deterministic=False):\n",
        "    \"\"\"\n",
        "    Uses plotting functions to make picture of the current board state, and what\n",
        "    a critter would do at each non-food location in the current board state\n",
        "    \"\"\"\n",
        "    def make_prob_dict(critter_locs, play):\n",
        "      offset_dict = {(0, 1): 'right',\n",
        "                     (0,-1): 'left',\n",
        "                     ( 1, 0): 'down',\n",
        "                     (-1, 0): 'up'}\n",
        "      index_probs = play[2].copy()\n",
        "      loc_prob_dict = {}\n",
        "      # for each non food locations\n",
        "      for g, loc_ in enumerate(critter_locs):\n",
        "        # this is the location as an r, c tuple\n",
        "        rc_tup = tuple((loc_[1], loc_[2]))\n",
        "        # the relevant probabilities\n",
        "        raw_probs = index_probs[g]\n",
        "        probs = raw_probs[raw_probs > 0]\n",
        "        indexes = np.argwhere(raw_probs > 0)\n",
        "        # turn the probability indexes into r, c coords\n",
        "        rows = np.floor_divide(indexes, gwg.n_cols)\n",
        "        cols = np.remainder(indexes, gwg.n_cols)\n",
        "        moves = np.squeeze(np.array([z for z in zip(rows, cols)]), axis=2)\n",
        "        #compute the offsets and turn them to strings\n",
        "        offsets = moves - loc_[1:]\n",
        "        str_offsets = np.array(list(map(offset_dict.get, map(tuple, offsets))))\n",
        "        # update the loc_prob_dict for plotting\n",
        "        prob_dict = dict(zip(str_offsets, probs))\n",
        "        loc_prob_dict.update({rc_tup: prob_dict})\n",
        "      return loc_prob_dict\n",
        "\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    plt.ioff()\n",
        "    if fig is None and ax is None:\n",
        "      fig, ax = make_grid(n_rows, n_cols, figsize=figsize, title=title)\n",
        "\n",
        "    rc_food_index = np.array(np.where(board['pieces'][g] <= -1))\n",
        "    rc_food_plotting = np.array(rc_food_index).T\n",
        "    food = plot_food(fig, ax, rc_food_plotting)\n",
        "\n",
        "    expanded_board = self.critter_everywhere_state_expansion(\n",
        "      board, player0.critter_index, to_expand=g)\n",
        "    critter_locs = np.argwhere(expanded_board['pieces']==player0.critter_index)\n",
        "    #play the expanded state\n",
        "    p0_play = player0.play(expanded_board)\n",
        "    #get the prob dict\n",
        "    p0_loc_prob_dict = make_prob_dict(critter_locs, p0_play)\n",
        "    # same for player1 if there is one\n",
        "    if player1 is not None:\n",
        "      p1_play = player1.play(expanded_board)\n",
        "      p1_loc_prob_dict = make_prob_dict(critter_locs, p1_play)\n",
        "\n",
        "    existing_handels, _ = ax.get_legend_handles_labels()\n",
        "    if player1 is None:\n",
        "      fig, ax, leg_handles_0 = plot_directions(fig, ax, p0_loc_prob_dict,\n",
        "        critter=0, deterministic=deterministic)\n",
        "      leg_handles = existing_handels\n",
        "    else:\n",
        "      fig, ax, leg_handles_0 = plot_directions(fig, ax, p0_loc_prob_dict,\n",
        "        critter=1, deterministic=deterministic, name=p0_name)\n",
        "      fig, ax, leg_handles_1 = plot_directions(fig, ax, p1_loc_prob_dict,\n",
        "        critter=2, deterministic=deterministic, name=p1_name)\n",
        "      leg_handles = existing_handels + leg_handles_0 + leg_handles_1\n",
        "\n",
        "    fig.legend(handles=leg_handles, loc=\"outside right upper\")\n",
        "    fig.canvas.draw()\n",
        "    return fig, ax\n",
        "\n",
        "\n",
        "  def plot_board(self, board, g=0,\n",
        "                 fig=None, ax=None, critter_specs=None, food=None, fov=None,\n",
        "                 legend_type='included',\n",
        "                 has_fov=False, #fog_of_war feild_of_view\n",
        "                 fov_opaque=False, #let human see trhough fog of war or not\n",
        "                 radius=2, figsize=(6,5), title=None,\n",
        "                 name='Critter',\n",
        "                 focal_critter_index = 0):\n",
        "    \"\"\"Uses plotting functions to make picture of the current board state\"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    plt.ioff()\n",
        "    if fig is None and ax is None:\n",
        "      fig, ax = make_grid(n_rows, n_cols, figsize=figsize, title=title)\n",
        "\n",
        "    # generate critter plotting specs if we don't already have them\n",
        "    if critter_specs is None:\n",
        "      critter_specs = []\n",
        "      markers = ['h', 'd']  # hexagon and diamond\n",
        "      colors = sns.color_palette(\"colorblind\")\n",
        "      for i in range(self.num_critters):\n",
        "        critter_name = name if self.num_critters == 1 else f'{name} {i+1}'\n",
        "        spec = {'marker': markers[i % len(markers)],\n",
        "                'color': colors[i // len(markers) % len(colors)],\n",
        "                'name': critter_name,\n",
        "                'int_id': i+1}\n",
        "        critter_specs.append(spec)\n",
        "    # get critter locs and plot them\n",
        "    assert len(critter_specs) == self.num_critters, \"More/fewer specs than critters\"\n",
        "    for spec in critter_specs:\n",
        "      rc_loc = np.array(np.where(board['pieces'][g] == spec['int_id'])).T\n",
        "      spec.update({'rc_loc': rc_loc})\n",
        "    critter_specs = plot_critters(fig, ax, critter_specs)\n",
        "\n",
        "    # get food locs and plot them\n",
        "    rc_food_index = np.array(np.where(board['pieces'][g] <= -1))\n",
        "    rc_food_plotting = np.array(rc_food_index).T\n",
        "    if food is None:\n",
        "      food = plot_food(fig, ax, rc_food_plotting)\n",
        "    else:\n",
        "      food = plot_food(fig, ax, rc_food_plotting, food)\n",
        "\n",
        "    #plot field of view if doing that\n",
        "    if has_fov:\n",
        "      # plot field of view around the 'active player'\n",
        "      if fov is None:\n",
        "        fov = plot_fov(fig, ax, critter_specs[focal_critter_index]['rc_loc'][0],\n",
        "                       n_rows, n_cols, radius, has_fov, opaque=fov_opaque)\n",
        "      else:\n",
        "        fov = plot_fov(fig, ax, critter_specs[focal_critter_index]['rc_loc'][0],\n",
        "                       n_rows, n_cols, radius, has_fov, opaque=fov_opaque, fov=fov)\n",
        "    # make legend and draw and return figure\n",
        "    if legend_type == 'included':\n",
        "      fig.legend(loc = \"outside right upper\", markerscale=0.8)\n",
        "      fig.canvas.draw()\n",
        "      return fig, ax, critter_specs, food, fov\n",
        "    elif legend_type == 'separate':\n",
        "      fig_legend, ax_legend = plt.subplots(figsize=(1.5,1.5), layout='constrained')\n",
        "      fig_legend.get_layout_engine().set(w_pad=0, h_pad=0, hspace=0, wspace=0)\n",
        "      handles, labels = ax.get_legend_handles_labels()\n",
        "      ax_legend.legend(handles, labels, loc='center', markerscale=0.8)\n",
        "      ax_legend.axis('off')\n",
        "      fig_legend.canvas.header_visible = False\n",
        "      fig_legend.canvas.toolbar_visible = False\n",
        "      fig_legend.canvas.resizable = False\n",
        "      fig_legend.canvas.footer_visible = False\n",
        "      fig_legend.canvas.draw()\n",
        "      return fig, ax, critter_specs, food, fov, fig_legend, ax_legend\n",
        "    else: #no legend\n",
        "      fig.canvas.draw()\n",
        "      return fig, ax, critter_specs, food, fov\n",
        "\n",
        "\n",
        "  def get_legal_moves(self, board, critter=1, radius=1):\n",
        "    \"\"\"\n",
        "    A Helper function to get the legal moves, as set of batch, row, col triples\n",
        "    giving for the given board. Does return moves that are technically legal\n",
        "    but that will result in a blocking move, this is good for a random valid\n",
        "    player, so that the don't have a high probability of staying still if\n",
        "    there are lots of blocking moves.\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "      critter (int): value of critter we are getting the valid actions for\n",
        "      radius (int): how far, in city block distance the critter can move\n",
        "\n",
        "    Returns:\n",
        "      moves: set or tuples (g, r, c)\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    adapted_board_params = self.board_params.copy()\n",
        "    adapted_board_params.update({'batch_size': batch_size,\n",
        "                                'init_board_state': board})\n",
        "    b = GridworldBoard(**adapted_board_params)\n",
        "    legal_moves =  b.get_legal_moves(critter, radius)\n",
        "    return legal_moves\n",
        "\n",
        "\n",
        "  def get_legal_offsets(self, board, critter=1, radius=1):\n",
        "    \"\"\"\n",
        "    A Helper function to the legal moves, as an array where each row is\n",
        "    a batch, row, col index giving legal moves on a given board. Includes\n",
        "    blocking moves, but excludes offsets that will take the critter off the\n",
        "    board\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "      critter (int): value of critter we are getting the valid actions for\n",
        "      radius (int): how far, in city block distance the critter can move\n",
        "\n",
        "    Returns:\n",
        "      moves: set or tuples (g, r, c)\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    adapted_board_params = self.board_params.copy()\n",
        "    adapted_board_params.update({'batch_size': batch_size,\n",
        "                                'init_board_state': board})\n",
        "    b = GridworldBoard(**adapted_board_params)\n",
        "    legal_offsets, valid_moves_mask =  b.get_legal_offsets(critter, radius)\n",
        "    return legal_offsets, valid_moves_mask\n",
        "\n",
        "\n",
        "  def get_valid_actions(self, board, critter=1, radius=1):\n",
        "    \"\"\"\n",
        "    A Helper function to translate the g,x,y, tuples provided the\n",
        "    GridworldBoard.get_legal_moves method into valid actions, represented\n",
        "    as binary vectors of len num_actions.\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "      critter (int): value of critter we are getting the valid actions for\n",
        "      radius (int): how far, in city block distance the critter can move\n",
        "\n",
        "    Returns:\n",
        "      valids: np.ndarray(binary) batch_size x num_actions, 1's represent\n",
        "              valid moves\n",
        "    \"\"\"\n",
        "    legal_moves =  self.get_legal_moves(board, critter, radius)\n",
        "    g, r, c = zip(*legal_moves)\n",
        "    valids = np.zeros((self.batch_size, self.n_rows * self.n_cols))\n",
        "    valids[g, np.array(r) * self.n_cols + np.array(c)] = 1\n",
        "    return valids\n",
        "\n",
        "\n",
        "  def display_moves(self, board, critter=1, g=0):\n",
        "    \"\"\"Displays possible moves for the g-th games in the batch of boards\"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    A=np.reshape(self.get_valid_actions(board, critter)[g],\n",
        "                 (n_rows, n_cols))\n",
        "    print(\"  \")\n",
        "    print(\"possible moves\")\n",
        "    print(\"   \", end=\"\")\n",
        "    for col in range(self.n_cols):\n",
        "      print(col, end=\" \")\n",
        "    print(\"\")\n",
        "    print(\"-----------------------\")\n",
        "    for col in range(self.n_cols):\n",
        "      print(col, \"|\", end=\"\")    # Print the row\n",
        "      for row in range(self.n_rows):\n",
        "        piece = A[col][row]    # Get the piece to print\n",
        "        print(self.get_square_symbol(piece), end=\" \")\n",
        "      print(\"|\")\n",
        "    print(\"-----------------------\")\n",
        "\n",
        "\n",
        "  def get_perceptions(self, board, radius, critter):\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    adapted_board_params = self.board_params.copy()\n",
        "    adapted_board_params.update({'batch_size': batch_size,\n",
        "                                'init_board_state': board})\n",
        "    b = GridworldBoard(**adapted_board_params)\n",
        "    perceptions = b.get_perceptions(radius, critter)\n",
        "    return perceptions\n",
        "\n",
        "\n",
        "  def get_next_state(self, board, critter, actions, a_indx=None):\n",
        "    \"\"\"\n",
        "    Helper function using GridworldBoard.execute_moves to update board state\n",
        "    given actions on a batch of boards, for a given critter\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "      critter: integer index of the critter type\n",
        "      actions: list of flat integer indexes of critter's new board positions\n",
        "      a_indx: list of integer indexes indicating which actions are being taken\n",
        "        on which boards in the batch\n",
        "\n",
        "    Returns:\n",
        "      a board triple signifying next state\n",
        "\n",
        "    Note:\n",
        "      if len(actions) > batch_size of board the returned board state will have\n",
        "      an expanded batch size, allowing multiple paths in the game tree to be\n",
        "      explored in parallel\n",
        "\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    if board['rounds_left'][0] <= 0:\n",
        "      # assumes all boards in the batch have the same rounds left\n",
        "      # no rounds left return the board unchanged\n",
        "      return board\n",
        "    else:\n",
        "      adapted_board_params = self.board_params.copy()\n",
        "      adapted_board_params.update({'batch_size': len(actions)})\n",
        "      if a_indx is None:\n",
        "        # just one move on each board in the batch\n",
        "        assert batch_size == len(actions)\n",
        "        adapted_board_params.update({'init_board_state': board})\n",
        "        b = GridworldBoard(**adapted_board_params)\n",
        "      else:\n",
        "        # potentially multiple moves on each board, expand the batch\n",
        "        assert len(actions) == len(a_indx)\n",
        "        new_pieces = np.array([board['pieces'][ai].copy() for ai in a_indx])\n",
        "        new_scores = np.array([board['scores'][ai].copy() for ai in a_indx])\n",
        "        new_rounds_left = np.array([board['rounds_left'][ai].copy() for ai in a_indx])\n",
        "        new_active_player = copy(board['active_player'])\n",
        "        new_state = {'pieces': new_pieces,\n",
        "                     'scores': new_scores,\n",
        "                     'rounds_left': new_rounds_left,\n",
        "                     'active_player': new_active_player}\n",
        "        adapted_board_params.update({'init_board_state': new_state})\n",
        "        b = GridworldBoard(**adapted_board_params)\n",
        "      moves = self.actions_to_moves(actions)\n",
        "      b.execute_moves(moves, critter)\n",
        "      return b.get_state()\n",
        "\n",
        "\n",
        "  def actions_to_moves(self, actions):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      actions: a batch length list of integer indexes for the flattened boards,\n",
        "      i.e. in the range(n_cols * n_rows) actions are often much easier to use\n",
        "      as training targets for NN based RL agents.\n",
        "    Returns\n",
        "      moves: a 3-tuple of 1-d arrays each of length batch_size,\n",
        "        the first array gives the specific board within the batch,\n",
        "        the second array in the tuple gives the new row coord for each critter\n",
        "        on each board and the third gives the new col coord. Note this is\n",
        "        exactly the format expected by GridworldBoard.execute_moves, and\n",
        "        is a canonical way of indexing arrays for quick numpy operations.\n",
        "    \"\"\"\n",
        "    moves = (np.arange(len(actions)),\n",
        "             np.floor_divide(actions, self.n_cols),\n",
        "             np.remainder(actions, self.n_cols))\n",
        "    return moves\n",
        "\n",
        "\n",
        "  def moves_to_actions(self, moves):\n",
        "    \"\"\"\n",
        "    Args:\n",
        "      moves: a 3-tuple of 1-d arrays each of length batch_size,\n",
        "        the first array gives the specific board within the batch,\n",
        "        the second array in the tuple gives the new row coord for each critter\n",
        "        on each board and the third gives the new col coord. Note this is\n",
        "        exactly the format expected by GridworldBoard.execute_moves, and\n",
        "        is a canonical way of indexing arrays for quick numpy operations.\n",
        "    Returns:\n",
        "      actions: a batch length list of integer indexes for the flattened boards,\n",
        "      i.e. in the range(n_cols * n_rows) actions are often much easier to use\n",
        "      as training targets for NN based RL agents.\n",
        "    \"\"\"\n",
        "    _, rows, cols = moves\n",
        "    actions = rows * self.n_cols + cols\n",
        "    return actions\n",
        "\n",
        "\n",
        "  def critter_oriented_get_next_state(self, board, critter, offsets):\n",
        "    \"\"\"\n",
        "    Translates directions in reference to the critter's location into\n",
        "    moves on the board in absolute terms, while checking for\n",
        "    bouncing/reflecting then get's the next state.\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "      offsets: batch length list of strings one 'up', 'down', 'left', 'right'\n",
        "\n",
        "    Returns:\n",
        "      a board triple signifying next state\n",
        "\n",
        "    Note:\n",
        "      Unlike get_next_state, this method does not allow for expansion\n",
        "      of the game tree, i.e. len(offsets)==batch_size required\n",
        "    \"\"\"\n",
        "    assert len(offsets) == board['pieces'].shape[0]\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    adapted_board_params = self.board_params.copy()\n",
        "    adapted_board_params.update({'batch_size': batch_size,\n",
        "                                'init_board_state': board})\n",
        "    b = GridworldBoard(**adapted_board_params)\n",
        "    moves = self.critter_direction_to_move(board, offsets, critter)\n",
        "    b.execute_moves(moves, critter)\n",
        "    return(b.get_state())\n",
        "\n",
        "\n",
        "  def critter_direction_to_move(self, board, offsets, critter):\n",
        "    \"\"\"\n",
        "    Translates directions in reference to the critter's location into\n",
        "    moves on the board in absolute terms, while checking for\n",
        "    bouncing/reflecting then returns moves. Doesn't check for collisions with\n",
        "    other critters though. In general player's move methods should be checking\n",
        "    valid moves and only making legal ones.\n",
        "\n",
        "    Args:\n",
        "      board: dict of np arrays representing board state\n",
        "        'pieces':       batch_size x n_rows x n_cols\n",
        "        'scores':       batch_size\n",
        "        'rounds_left':  batch_size\n",
        "      offsets: batch length list of strings,\n",
        "        one of 'up', 'down', 'left', 'right'\n",
        "      critter: integer index for the critter we want moves for\n",
        "\n",
        "    Returns:\n",
        "      moves: a 3-tuple of 1-d arrays each of length batch_size,\n",
        "        the first array gives the specific board within the batch,\n",
        "        the second array in the tuple gives the new row coord for each critter\n",
        "        on each board and the third gives the new col coord. Note this is\n",
        "        exactly the format expected by GridworldBoard.execute_moves, and\n",
        "        is a canonical way of indexing arrays for numpy.\n",
        "\n",
        "    Note:\n",
        "      Unlike get_next_state, this method does not allow for expansion\n",
        "      of the game tree, i.e. len(offsets)==batch_size required\n",
        "    \"\"\"\n",
        "    assert len(offsets) == board['pieces'].shape[0]\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    offset_dict = {'up': (0, -1, 0),\n",
        "                   'down': (0, 1, 0),\n",
        "                   'left': (0, 0, -1),\n",
        "                   'right': (0, 0, 1),\n",
        "                   'still': (0, 0, 0)}\n",
        "    this_critter_locs = np.where(board['pieces'] == critter)\n",
        "    all_critter_locs = np.where(board['pieces'] >= 1)\n",
        "    offsets_array = np.hstack([np.array(offset_dict[ost_]).reshape((3,1))\n",
        "                           for ost_ in offsets])\n",
        "    new_locs = np.array(this_critter_locs) + offsets_array\n",
        "    #check bounces at boundaries\n",
        "    new_locs[1,:] = np.where(new_locs[1] >=\n",
        "                               n_rows, n_rows-2, new_locs[1])\n",
        "    new_locs[2,:] = np.where(new_locs[2,:] >=\n",
        "                               n_cols, n_cols-2, new_locs[2,:])\n",
        "    new_locs[1,:] = np.where(new_locs[1,:] < 0, 1, new_locs[1,:])\n",
        "    new_locs[2,:] = np.where(new_locs[2,:] < 0, 1, new_locs[2,:])\n",
        "    moves = tuple(new_locs)\n",
        "    return moves\n",
        "\n",
        "\n",
        "  def direction_probs_to_flat_probs(self, board, direction_probs, critter):\n",
        "    \"\"\"\n",
        "    Converts direction probabilities in reference to the critter's location into\n",
        "    probability arrays on the flattened board.\n",
        "\n",
        "    Args:\n",
        "      board: dict of np arrays representing board state\n",
        "        'pieces':       batch_size x n_rows x n_cols\n",
        "        'scores':       batch_size\n",
        "        'rounds_left':  batch_size\n",
        "      direction_probs: batch length list of dictionaries with keys\n",
        "        ['up', 'down', 'left', 'right'] and corresponding probabilities.\n",
        "\n",
        "    Returns:\n",
        "      probs_arrays: list of arrays, where each array is of length n_rows*n_cols\n",
        "                    and represents the flattened probability distribution for\n",
        "                    board in the batch.\n",
        "    \"\"\"\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    offset_dict = {\n",
        "        'up': np.array((0, -1, 0)),\n",
        "        'down': np.array((0, 1, 0)),\n",
        "        'left': np.array((0, 0, -1)),\n",
        "        'right': np.array((0, 0, 1))}\n",
        "    critter_locs = np.where(board['pieces'] == critter)\n",
        "    probs_arrays = np.zeros((batch_size, n_rows * n_cols))\n",
        "    for batch_index in range(batch_size):\n",
        "      prob_array = np.zeros(n_rows * n_cols)\n",
        "      for direction, prob in direction_probs[batch_index].items():\n",
        "          offset = offset_dict[direction]\n",
        "          new_loc = np.array(critter_locs)[:, batch_index] + offset\n",
        "          # Check bounces at boundaries\n",
        "          new_loc[1] = np.where(new_loc[1] >= n_rows, n_rows-2, new_loc[1])\n",
        "          new_loc[2] = np.where(new_loc[2] >= n_cols, n_cols-2, new_loc[2])\n",
        "          new_loc[1] = np.where(new_loc[1] < 0, 1, new_loc[1])\n",
        "          new_loc[2] = np.where(new_loc[2] < 0, 1, new_loc[2])\n",
        "          # Convert 2D location to flattened index\n",
        "          flattened_index = new_loc[1] * n_cols + new_loc[2]\n",
        "          prob_array[flattened_index] += prob\n",
        "      probs_arrays[batch_index, :] = prob_array\n",
        "    return list(probs_arrays)\n",
        "\n",
        "\n",
        "  def action_to_critter_direction(self, board, critter, actions):\n",
        "    \"\"\"\n",
        "    Translates an integer index action into up/down/left/right\n",
        "\n",
        "    Args:\n",
        "      board: a triple of np arrays representing board state\n",
        "        pieces,       - batch_size x n_rows x n_cols\n",
        "        scores,       - batch_size\n",
        "        rounds_left   - batch_size\n",
        "      actions: a batch size ndarry of integer indexes for actions on each board\n",
        "\n",
        "    Returns:\n",
        "      offsets: a batch length list of strings 'up', 'down', 'left', 'right', 'still'\n",
        "    \"\"\"\n",
        "    offset_dict = {(0, 0, 0): 'still',\n",
        "                   (0, 0, 1): 'right',\n",
        "                   (0, 0,-1): 'left',\n",
        "                   (0, 1, 0): 'down',\n",
        "                   (0,-1, 0): 'up'}\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    critter_locs = np.where(board['pieces'] == critter)\n",
        "    moves = (np.arange(len(actions)),\n",
        "               np.floor_divide(actions, n_cols),\n",
        "               np.remainder(actions, n_cols))\n",
        "    # need to reverse this from above, moves is equiv to new_locs\n",
        "    # new_locs = np.array(critter_locs) + offsets_array\n",
        "    offsets_array = np.array(moves) - np.array(critter_locs)\n",
        "    offsets = [offset_dict[tuple(o_)] for o_ in offsets_array.T]\n",
        "    return offsets\n",
        "\n",
        "\n",
        "  def get_valid_directions(self, board, critter):\n",
        "    \"\"\"\n",
        "    Transforms output of get_valid_actions to a list of the valid directions\n",
        "    for each board in the batch for a given critter.\n",
        "    \"\"\"\n",
        "    offset_dict = {( 0, 1): 'right',\n",
        "                   ( 0,-1): 'left',\n",
        "                   ( 1, 0): 'down',\n",
        "                   (-1, 0): 'up',\n",
        "                   ( 0, 0): 'still'}\n",
        "    batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "    valid_actions = self.get_valid_actions(board, critter)\n",
        "    if batch_size != len(valid_actions):\n",
        "      raise ValueError(\"Need Exactly one set of valid actions per board in batch\")\n",
        "    critter_locs = np.column_stack(np.where(board['pieces'] == critter))\n",
        "    valid_directions = []\n",
        "    for g, batch_valid in enumerate(valid_actions):\n",
        "      valid_int_indices = np.where(batch_valid==1)[0]\n",
        "      critter_loc = critter_locs[critter_locs[:, 0] == g, 1:]\n",
        "      # critter_loc shape is (1, 2)\n",
        "      critter_loc = np.squeeze(critter_loc)\n",
        "      moves = np.column_stack([valid_int_indices // n_cols, valid_int_indices % n_cols])\n",
        "      offsets = moves - critter_loc\n",
        "      batch_valid_directions = [offset_dict[tuple(offset)] for offset in offsets]\n",
        "      valid_directions.append(batch_valid_directions)\n",
        "    return valid_directions\n",
        "\n",
        "\n",
        "  def get_game_ended(self, board):\n",
        "    \"\"\"\n",
        "    Helper function to signify if game has ended\n",
        "    Returns a batch size np.array of -1 if not ended, and scores for each game\n",
        "    in the batch if it is ended, note only returns scores if all games in the\n",
        "    batch have ended\n",
        "    \"\"\"\n",
        "    rounds_left = board['rounds_left']\n",
        "    scores = board['scores']\n",
        "    if np.any(rounds_left >= 1):\n",
        "      return np.ones(self.batch_size) * -1.0\n",
        "    else:\n",
        "      return scores\n",
        "\n",
        "\n",
        "  def critter_everywhere_state_expansion(self, board_state,\n",
        "                                         critter=1, to_expand=0):\n",
        "    \"\"\"\n",
        "    Expand a given board state by placing a critter at each non-food location.\n",
        "\n",
        "    The function takes a game state and returns an expanded version of it. For\n",
        "    each board in the state, it creates a new version of the board for every\n",
        "    non-food location, placing a critter at that location. The scores and\n",
        "    remaining rounds are copied for each new board. The result is a new game state\n",
        "    with a larger number of boards, each representing a possible configuration\n",
        "    with a critter at a different location.\n",
        "\n",
        "    Args:\n",
        "      board_state (dict): A dictionary containing the current game state.\n",
        "      It should have the following keys:\n",
        "        - 'pieces': a 3D numpy array (batch x n_col x n_row) representing the game\n",
        "          board. -1 -> food, 0 -> empty cell, and 1 -> critter.\n",
        "        - 'scores': 1D numpy array of the score for each board in the batch.\n",
        "        - 'rounds_left': a 1D numpy array of the rounds left for\n",
        "          each board in the batch.\n",
        "      critter: integer index to place on the expanded board state\n",
        "      to_expand (list (int)): list of batch indices to have state expanded\n",
        "\n",
        "    Returns:\n",
        "      dict: A dictionary containing the expanded game state with the same keys\n",
        "        as the input. The number of boards will be larger than the input state.\n",
        "    \"\"\"\n",
        "    pieces = board_state['pieces'].copy()\n",
        "    scores = board_state['scores'].copy()\n",
        "    rounds_left = board_state['rounds_left'].copy()\n",
        "    active_player = copy(board_state['active_player'])\n",
        "    # Determine non-food locations\n",
        "    non_food_locs = np.argwhere(pieces[to_expand] != -1)\n",
        "    #scrub all existing critter locations,\n",
        "    # maybe later only scrub specific critter type\n",
        "    pieces[pieces >= 1] = 0\n",
        "    # lists to store expanded states\n",
        "    expanded_pieces = []\n",
        "    expanded_scores = []\n",
        "    expanded_rounds_left = []\n",
        "    # Iterate over each non-food location\n",
        "    for i in range(non_food_locs.shape[0]):\n",
        "      # Create a copy of the board\n",
        "      expanded_board = np.copy(pieces[to_expand])\n",
        "      # Place the critter at the non-food location\n",
        "      # later consider only placing at non-food,\n",
        "      # non-other critter locs\n",
        "      expanded_board[tuple(non_food_locs[i])] = critter\n",
        "      # Add the expanded board to the list along score and rounds_left\n",
        "      expanded_pieces.append(expanded_board)\n",
        "      expanded_scores.append(scores[to_expand])\n",
        "      expanded_rounds_left.append(rounds_left[to_expand])\n",
        "    # Convert to arrays and create expanded board state\n",
        "    expanded_state = {'pieces': np.stack(expanded_pieces),\n",
        "                      'scores': np.array(expanded_scores),\n",
        "                      'rounds_left': np.array(expanded_rounds_left),\n",
        "                      'active_player': active_player}\n",
        "    return expanded_state\n",
        "\n",
        "\n",
        "  def play_game(self, players=[], collect_fov_data=False, fov_radius=2,\n",
        "                visualize = False):\n",
        "    \"\"\"This method takes a list of players the same length as num_critters,\n",
        "        and then plays a batch of games with them and returns the final board\n",
        "        state\"\"\"\n",
        "    if len(players) != self.num_critters:\n",
        "      raise ValueError(\"number of players different than expected\")\n",
        "\n",
        "    board = self.get_init_board()\n",
        "    if visualize == True:\n",
        "      self.display(board, 0)\n",
        "\n",
        "    if collect_fov_data is True:\n",
        "      batch_size, n_rows, n_cols = board['pieces'].shape\n",
        "      adapted_board_params = self.board_params.copy()\n",
        "      adapted_board_params.update({'batch_size': batch_size,\n",
        "                                'init_board_state': board})\n",
        "      b = GridworldBoard(**adapted_board_params)\n",
        "    for p_idx, player_ in enumerate(players):\n",
        "      if player_.critter_index != p_idx+1:\n",
        "        print(player_.critter_index)\n",
        "        print(p_idx + 1)\n",
        "        raise ValueError(\"player order does not match assigned critter index\")\n",
        "\n",
        "    for ii in range(self.max_rounds_taken):\n",
        "      for player_ in players:\n",
        "        old_scores = board['scores']\n",
        "        if collect_fov_data is True:\n",
        "          b.set_state(board)\n",
        "          percepts = b.get_perceptions(fov_radius)\n",
        "\n",
        "        a_player, _, _ = player_.play(board)\n",
        "        board = self.get_next_state(board, player_.critter_index, a_player)\n",
        "        if visualize == True:\n",
        "          self.display(board, 0)\n",
        "    return board\n"
      ],
      "metadata": {
        "cellView": "form",
        "id": "PoB0wa_hsWcl"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Interactive Gridworld Widget\n",
        "\n",
        "########################################\n",
        "# widgets refactor for multi-critter\n",
        "#########################################\n",
        "# Interactive Gridworld Game Widgets\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class RandomValidPlayer():\n",
        "  \"\"\"\n",
        "  Instantiate random player for GridWorld, could be prey or pred... or even food\n",
        "  It leans hard on the game's get valid method and then just samples from there\n",
        "  \"\"\"\n",
        "\n",
        "\n",
        "  def __init__(self, game, critter_index=1, speed=1):\n",
        "    self.game = game\n",
        "    self.critter_index = critter_index\n",
        "    self.speed = speed\n",
        "    assert (isinstance(critter_index, int) and\n",
        "        0 < critter_index <= game.num_critters), \"Value is not a positive integer or exceeds the upper limit.\"\n",
        "\n",
        "\n",
        "  def play(self, board):\n",
        "    \"\"\"\n",
        "    Simulates a batch of random game plays based on the given board state.\n",
        "\n",
        "    This function computes the probability of each valid move being played\n",
        "    (uniform for valid moves, 0 for others), then selects a move randomly for\n",
        "    each game in the batch based on these probabilities.\n",
        "\n",
        "    Args:\n",
        "      board (dict): A dictionary representing the state of the game. It\n",
        "          contains:\n",
        "          - 'pieces': A (batch_size, x_size, y_size) numpy array indicating\n",
        "                      the pieces on the board.\n",
        "          - 'scores' (not used directly in this function, but expected in dict)\n",
        "          - 'rounds_left' (not used directly in this function, but expected in dict)\n",
        "\n",
        "    Returns:\n",
        "      tuple:\n",
        "      - a (numpy array): An array of shape (batch_size,) containing randomly\n",
        "                         chosen actions for each game in the batch.\n",
        "      - a_1hots (numpy array): An array of shape (batch_size, action_size)\n",
        "                               with one-hot encoded actions.\n",
        "      - probs (numpy array): An array of the same shape as 'valids' containing\n",
        "                             the probability of each move being played.\n",
        "    \"\"\"\n",
        "    batch_size, x_size, y_size = board['pieces'].shape\n",
        "    valids = self.game.get_valid_actions(board, self.critter_index, self.speed)\n",
        "    action_size = self.game.get_action_size()\n",
        "\n",
        "    probs = valids / np.sum(valids, axis=1).reshape(batch_size,1)\n",
        "\n",
        "    a = [self.game.rng.choice(action_size, p=probs[ii])\n",
        "                                for ii in range(batch_size)]\n",
        "    a_1hots = np.zeros((batch_size, action_size))\n",
        "    a_1hots[(range(batch_size), a)] = 1.0\n",
        "    return np.array(a), a_1hots, probs\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "class InteractiveGridworld():\n",
        "  \"\"\"\n",
        "  A widget based object for interacting with a gridworld game\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, gridworld_game, init_board=None, has_fov=False,\n",
        "               radius=2, fov_opaque=False, collect_fov_data=False,\n",
        "               figsize=(6,5), critter_names=['Critter'], players=['human']):\n",
        "    \"\"\"\n",
        "    Initializes a widget based object for interacting with a gridworld game\n",
        "\n",
        "    Args:\n",
        "      gridworld_game: an instance of GridworldGame object\n",
        "        InteractiveGridworld expects the GridworldGame to have batchsize 1\n",
        "      has_fov: bool, whether or not to display fog of war around the critter\n",
        "      radius: int, number of squares the critter can \"see\" around it\n",
        "      figsize: tuple (int, int), size of the figure\n",
        "      critter_names: a list of strings that determines what the critter is called\n",
        "        in the plot legend, order should align with players\n",
        "      player: a list of either 'human', None, or a player object with a play\n",
        "        method and a critter_index attribute. If 'human' use buttons,  if None\n",
        "        default to making a RandomValidPlayer object, otherwise use the\n",
        "        player class provided to make the player objects and use a start button.\n",
        "        The list needs to be as long as the gridworld_game.num_critters\n",
        "        attribute. Order should align with critter_name.\n",
        "\n",
        "      Note: fov is going to look pretty janky with more than one player, maybe\n",
        "      we get fov to only turn on for the 'active' player?\n",
        "      Note: Specific initialization state is handled by the GridworldGame object\n",
        "    \"\"\"\n",
        "\n",
        "    # Set GridworldGame object and initialize the board state\n",
        "    self.gwg = gridworld_game\n",
        "    self.has_fov = has_fov\n",
        "    self.radius = radius\n",
        "    self.fov_opaque = fov_opaque\n",
        "    self.percept_len = 2*self.radius*(self.radius+1)\n",
        "    self.collect_fov_data = collect_fov_data\n",
        "    self.figsize = figsize\n",
        "    # initialize players and plotting specs together to ensure alignment\n",
        "    self.players = []\n",
        "    self.any_human_players = False\n",
        "    self.active_player_index = 0\n",
        "    self.crit_specs = []\n",
        "    markers = ['h', 'd']  # hexagon and diamond\n",
        "    colors = sns.color_palette(\"colorblind\")\n",
        "    for i in range(self.gwg.num_critters):\n",
        "      spec = {'marker': markers[i % len(markers)],\n",
        "              'color': colors[i // len(markers) % len(colors)],\n",
        "              'name': critter_names[i],\n",
        "              'int_id': i+1}\n",
        "      self.crit_specs.append(spec)\n",
        "      player = players[i] #implict check that players is at least long enough\n",
        "      if player is None:\n",
        "        self.players.append(RandomValidPlayer(self.gwg, critter_index=i+1))\n",
        "      elif player == 'human':\n",
        "        self.players.append('human')\n",
        "        # right now only ever have on human player with index 1\n",
        "        self.any_human_players = True\n",
        "      else:\n",
        "        # player objects expected to have a critter_index attribute\n",
        "        # we set it appropriately here so it aligns with the players list\n",
        "        # used to create the widget\n",
        "        player.critter_index = i+1\n",
        "        self.players.append(player)\n",
        "    self.final_scores = []\n",
        "    self.board_state = self.gwg.get_init_board()\n",
        "    if self.collect_fov_data is True:\n",
        "      # keep raw records of percept and eating for manipulation later\n",
        "      self.percept_eat_records = []\n",
        "      # keep data in contingency table of how many food items were in\n",
        "      # the percept, and whether or not food was eaten\n",
        "      self.fov_eat_table_data = np.zeros((2, self.percept_len+1))\n",
        "    # Initialize widgets and buttons\n",
        "    self.output = widgets.Output(layout=widgets.Layout(\n",
        "      width = '20.0em', min_width='20.0em', max_width='21.0em',\n",
        "      min_height='10.0em', overflow='auto'))\n",
        "    self.scoreboard = widgets.Output(layout=widgets.Layout(\n",
        "      min_width='12.5em', max_width='18.8em',\n",
        "      min_height='6.3em', overflow='auto'))\n",
        "    self.fov_eat_table_display = widgets.Output(layout=widgets.Layout(\n",
        "      min_width='25.0em', min_height='18.8em', overflow='auto'))\n",
        "    self.up_button = widgets.Button(description=\"Up\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.down_button = widgets.Button(description=\"Down\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.left_button = widgets.Button(description=\"Left\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.right_button = widgets.Button(description=\"Right\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "    self.start_button = widgets.Button(description=\"Start\",\n",
        "      layout=widgets.Layout(width='6.3em'))\n",
        "\n",
        "    # get plot canvas widgets and other plotting objects\n",
        "    plt.ioff()\n",
        "    if self.collect_fov_data and self.any_human_players:\n",
        "      self.legend_type = None # don't keep regenerating the legend\n",
        "      # do legend separately if showing observations and no human player\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov,\n",
        "       self.b_fig_legend, self.b_ax_legend) = self.gwg.plot_board(\n",
        "          self.board_state, g=0, critter_specs=self.crit_specs,\n",
        "          legend_type='separate', figsize=self.figsize, has_fov=self.has_fov,\n",
        "          radius=self.radius, fov_opaque=self.fov_opaque)\n",
        "    elif len(self.players) > 1:\n",
        "      self.legend_type=None # don't keep regenerating the legend\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov,\n",
        "       self.b_fig_legend, self.b_ax_legend) = self.gwg.plot_board(\n",
        "          self.board_state, g=0, critter_specs=self.crit_specs,\n",
        "          has_fov=self.has_fov, legend_type='separate',\n",
        "          radius=self.radius, fov_opaque=self.fov_opaque, figsize=self.figsize)\n",
        "    else:\n",
        "      self.legend_type = 'included'\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov\n",
        "        ) = self.gwg.plot_board(self.board_state, g=0,\n",
        "                                critter_specs=self.crit_specs,\n",
        "                                has_fov=self.has_fov,\n",
        "                                fov_opaque=self.fov_opaque,\n",
        "                                radius=self.radius, figsize=self.figsize)\n",
        "    # lump buttons together\n",
        "    self.buttons = widgets.HBox([self.left_button,\n",
        "                               widgets.VBox([self.up_button, self.down_button]),\n",
        "                               self.right_button])\n",
        "    # automatically pick different layouts for different situations\n",
        "    if self.any_human_players:\n",
        "      self.board_and_buttons = widgets.VBox([self.b_fig.canvas,\n",
        "                                             self.buttons])\n",
        "      if len(self.players) == 1:\n",
        "        #one human player\n",
        "        self.output_and_score = widgets.HBox([self.scoreboard, self.output])\n",
        "        self.no_table_final_display = widgets.VBox([self.board_and_buttons,\n",
        "                                                  self.output_and_score])\n",
        "        if self.collect_fov_data == True:\n",
        "          # a single human player collecting data\n",
        "          self.final_display = widgets.HBox([self.no_table_final_display,\n",
        "                                           self.fov_eat_table_display])\n",
        "        else: # self.collect_fov_data == False:\n",
        "          # a single human player not collecting data\n",
        "          self.final_display = self.no_table_final_display\n",
        "      else:\n",
        "        # more than one player, one of them human\n",
        "        self.V_board_outbput = widgets.VBox([self.board_and_buttons,\n",
        "                                             self.output])\n",
        "        self.V_scoreboard_start_legend = widgets.VBox([\n",
        "        self.scoreboard, self.start_button, self.b_fig_legend.canvas])\n",
        "        self.final_display = widgets.HBox([self.V_board_outbput,\n",
        "                                             self.V_scoreboard_start_legend])\n",
        "    else: # player is some kind of ai\n",
        "      if self.collect_fov_data == True:\n",
        "        # an ai player with recording\n",
        "        # in this case legend is separate\n",
        "        self.V_score_start_output_legend = widgets.VBox([self.scoreboard,\n",
        "          self.start_button,  self.output, self.b_fig_legend.canvas])\n",
        "        self.V_board_table = widgets.VBox([self.b_fig.canvas,\n",
        "                                           self.fov_eat_table_display])\n",
        "        self.final_display = widgets.HBox([self.V_board_table,\n",
        "                                           self.V_score_start_output_legend])\n",
        "      else:\n",
        "        if len(self.players) == 1:\n",
        "          # an ai player without recording\n",
        "          self.H_score_output_start = widgets.HBox([\n",
        "            self.scoreboard, self.output, self.start_button])\n",
        "          self.final_display = widgets.VBox([\n",
        "            self.b_fig.canvas, self.H_score_output_start])\n",
        "        else:\n",
        "          # more than one ai player\n",
        "          self.V_board_outbput = widgets.VBox([self.b_fig.canvas, self.output])\n",
        "          self.V_scoreboard_start_legend = widgets.VBox([\n",
        "              self.scoreboard, self.start_button, self.b_fig_legend.canvas])\n",
        "          self.final_display = widgets.HBox([self.V_board_outbput,\n",
        "                                             self.V_scoreboard_start_legend])\n",
        "\n",
        "    # initialize text outputs\n",
        "    with self.scoreboard:\n",
        "      table = [['High Score:'] + ['--'] * self.gwg.num_critters,\n",
        "               ['Last Score:'] + ['--'] * self.gwg.num_critters,\n",
        "               ['Average Score:'] + ['--'] * self.gwg.num_critters,]\n",
        "      if len(self.players) > 1:\n",
        "        headers = [''] + [f'P{i+1}' for i in range(self.gwg.num_critters)]\n",
        "        print(tabulate(table, headers=headers))\n",
        "      else: # len(self.players) == 1\n",
        "        print(tabulate(table))\n",
        "    with self.output:\n",
        "      if self.any_human_players:\n",
        "        print('Click a button to start playing')\n",
        "        print('There are {} rounds in this game'.format(self.board_state['rounds_left'][0]))\n",
        "      else:\n",
        "        print('Click the start button to run the simulation')\n",
        "    with self.fov_eat_table_display:\n",
        "      printmd(\"**Observations**\")\n",
        "      table_data = [[str(ii),\n",
        "                     str(self.fov_eat_table_data[0,ii]),\n",
        "                     str(self.fov_eat_table_data[1,ii])] for ii in range(11)]\n",
        "      table = ([['Food in Percept', 'Food Not Eaten', 'Food Eaten']] +\n",
        "               table_data)\n",
        "      print(tabulate(table))\n",
        "\n",
        "    # fussy off-by-one adjustement\n",
        "    self.board_state['rounds_left'] -= 1\n",
        "\n",
        "    # Connect the buttons to functions that do something\n",
        "    self.up_button.on_click(self.on_up_button_clicked)\n",
        "    self.down_button.on_click(self.on_down_button_clicked)\n",
        "    self.left_button.on_click(self.on_left_button_clicked)\n",
        "    self.right_button.on_click(self.on_right_button_clicked)\n",
        "    self.start_button.on_click(self.on_start_button_clicked)\n",
        "\n",
        "\n",
        "  def button_output_update(self, which_button):\n",
        "    old_board = self.board_state.copy()\n",
        "    # index of players is 0 through num_critter-1,\n",
        "    # same player represented by value of index + 1 in\n",
        "    old_scores = old_board['scores'][0]\n",
        "    if self.collect_fov_data is True:\n",
        "      batch_size, n_rows, n_cols = old_board['pieces'].shape\n",
        "      adapted_board_params = self.gwg.board_params.copy()\n",
        "      adapted_board_params['init_state'] = old_board\n",
        "      b = GridworldBoard(**adapted_board_params)\n",
        "      percept = b.get_perceptions(self.radius)[0]\n",
        "\n",
        "    if (isinstance(self.players[self.active_player_index], str) and\n",
        "        'human' in self.players[self.active_player_index]):\n",
        "      direction = which_button\n",
        "    else:\n",
        "      a_player, _, _ = self.players[self.active_player_index].play(old_board)\n",
        "      # print(a_player)\n",
        "      a_player = self.gwg.action_to_critter_direction(old_board,\n",
        "                                                      self.active_player_index+1,\n",
        "                                                      a_player)\n",
        "      # but we only want to apply their move to the appropriate board\n",
        "      direction = a_player[0]\n",
        "\n",
        "    self.board_state = self.gwg.critter_oriented_get_next_state(\n",
        "          self.board_state, self.active_player_index+1, [direction])\n",
        "    new_scores = self.board_state['scores'][0] #first batch first critter type\n",
        "    rounds_left = self.board_state['rounds_left'][0]\n",
        "    num_moves = np.floor(self.gwg.max_rounds_taken -\n",
        "                         rounds_left / self.gwg.num_critters)\n",
        "    if new_scores[self.active_player_index] > old_scores[self.active_player_index]:\n",
        "      #eating happened\n",
        "      eating_string = \"They ate the food/prey there!\"\n",
        "      did_eat = 1\n",
        "    else: #eating didn't happen\n",
        "      eating_string = \"There's no food/prey there.\"\n",
        "      did_eat = 0\n",
        "    row, col = self.gwg.get_critter_rc(self.board_state, 0,\n",
        "                                       self.active_player_index+1)\n",
        "    (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov\n",
        "     ) = self.gwg.plot_board(self.board_state, g=0,\n",
        "                             fig=self.b_fig, ax=self.b_ax,\n",
        "                             critter_specs=self.b_crit_specs, food=self.b_food,\n",
        "                             fov=self.b_fov, has_fov=self.has_fov,\n",
        "                             fov_opaque=self.fov_opaque,\n",
        "                             radius=self.radius, legend_type=self.legend_type)\n",
        "    if self.collect_fov_data is True:\n",
        "      p_e_data = {'perception': percept.copy(),\n",
        "                  'state': old_board,\n",
        "                  'did_eat': bool(did_eat)}\n",
        "      self.percept_eat_records.append(p_e_data)\n",
        "      percept_int = np.sum(percept==-1) # number of food items in FoV\n",
        "      self.fov_eat_table_data[did_eat, percept_int] += 1\n",
        "\n",
        "    with self.output:\n",
        "      clear_output()\n",
        "      if len(self.players) == 1:\n",
        "        print(\"The critter (tried) to move \" + direction +\n",
        "              \" and is now at ({}, {}).\".format(row,col))\n",
        "        print(eating_string)\n",
        "        print(\"Rounds Left: {}\\nFood Eaten: {}\\nFood Per Move: {:.2f}\".format(\n",
        "            rounds_left, new_scores[self.active_player_index],\n",
        "            new_scores[self.active_player_index] / num_moves))\n",
        "      else: # more than one players\n",
        "        print(\"Critter {} (tried) to move \".format(self.active_player_index+1) +\n",
        "              direction +\n",
        "              \" and is now at ({}, {}).\".format(row, col))\n",
        "        print(eating_string)\n",
        "        print(\"Rounds Left: {}\\nFood Eaten: {}\".format(\n",
        "            rounds_left, new_scores))\n",
        "    if rounds_left == 0:\n",
        "      self.final_scores.append(new_scores)\n",
        "      with self.output:\n",
        "        clear_output\n",
        "        if len(new_scores) == 1:\n",
        "          print('Game Over. Final Score {}'.format(new_scores[0]))\n",
        "        else:\n",
        "          print('Game Over. Final Score {}'.format(new_scores))\n",
        "        print('Resetting the board for another game')\n",
        "        self.board_state = self.gwg.get_init_board()\n",
        "      (self.b_fig, self.b_ax, self.b_crit_specs, self.b_food, self.b_fov\n",
        "       ) = self.gwg.plot_board(self.board_state, 0, self.b_fig, self.b_ax,\n",
        "                               self.b_crit_specs, self.b_food, self.b_fov,\n",
        "                               has_fov=self.has_fov, radius=self.radius,\n",
        "                               fov_opaque=self.fov_opaque,\n",
        "                               legend_type=self.legend_type)\n",
        "    with self.scoreboard:\n",
        "        clear_output()\n",
        "        print('Games Played: ' + str(len(self.final_scores)))\n",
        "        if len(self.players) == 1:\n",
        "          if len(self.final_scores) > 0:\n",
        "            table = [\n",
        "              ['High Score:', str(np.max(np.array(self.final_scores)))],\n",
        "              ['Last Score:', str(self.final_scores[-1][0])],\n",
        "              ['Average Score',\n",
        "              '{:.2f}'.format(np.mean(np.array(self.final_scores)))]]\n",
        "          else:\n",
        "            table = [['High Score:', '--'],\n",
        "                     ['Last Score:', '--'],\n",
        "                     ['Average Score:', '--']]\n",
        "          print(tabulate(table))\n",
        "        else: # len(self.players) > 1\n",
        "          headers = [''] + [f'P{i+1}' for i in range(self.gwg.num_critters)]\n",
        "          if len(self.final_scores) > 0:\n",
        "            table = []\n",
        "            # Assuming the batch size is 1 for now\n",
        "            current_scores = self.final_scores[-1]\n",
        "            max_scores = np.max(np.array(self.final_scores), axis=0)\n",
        "            average_scores = np.mean(np.array(self.final_scores), axis=0)\n",
        "            table.append(['High Scores:'] +\n",
        "              [str(score) for score in max_scores])\n",
        "            table.append(['Last Scores:'] +\n",
        "              [str(score) for score in current_scores])\n",
        "            table.append(['Average Scores:'] +\n",
        "              ['{:.2f}'.format(score) for score in average_scores])\n",
        "          else:\n",
        "            table = [\n",
        "              ['High Score:'] + ['--'] * self.gwg.num_critters,\n",
        "              ['Last Score:'] + ['--'] * self.gwg.num_critters,\n",
        "              ['Average Score:'] + ['--'] * self.gwg.num_critters,]\n",
        "          print(tabulate(table, headers=headers))\n",
        "\n",
        "    with self.fov_eat_table_display:\n",
        "      clear_output()\n",
        "      printmd(\"**Observations**\")\n",
        "      table_data = [[str(ii),\n",
        "                     str(self.fov_eat_table_data[0,ii]),\n",
        "                     str(self.fov_eat_table_data[1,ii])] for ii in range(11)]\n",
        "      table = ([['Food in Percept', 'Food Not Eaten', 'Food Eaten']] +\n",
        "               table_data)\n",
        "      print(tabulate(table))\n",
        "\n",
        "  def disable_direction_buttons(self):\n",
        "    self.up_button.disabled = True\n",
        "    self.down_button.disabled = True\n",
        "    self.left_button.disabled = True\n",
        "    self.right_button.disabled = True\n",
        "\n",
        "  def enable_direction_buttons(self):\n",
        "    self.up_button.disabled = False\n",
        "    self.down_button.disabled = False\n",
        "    self.left_button.disabled = False\n",
        "    self.right_button.disabled = False\n",
        "\n",
        "  def human_ai_player_loop(self, direction):\n",
        "    self.disable_direction_buttons()  # Disable buttons, no double clicks\n",
        "    # Execute the move of the human who clicked the button\n",
        "    self.button_output_update(direction)\n",
        "    # Move to the next player\n",
        "    def update_player_and_rounds():\n",
        "      \"\"\"Update the player index and decrement rounds if a full loop is completed.\"\"\"\n",
        "      self.active_player_index = (self.active_player_index + 1) % len(self.players)\n",
        "      if self.active_player_index == 0:\n",
        "        self.board_state['rounds_left'] -= 1\n",
        "    update_player_and_rounds()\n",
        "    # Do AI moves if there are any\n",
        "    while self.players[self.active_player_index] != 'human':\n",
        "      self.button_output_update('tbd')\n",
        "      # Move to the next player\n",
        "      update_player_and_rounds()\n",
        "    # Next player is human turn buttons on for them\n",
        "    self.enable_direction_buttons()\n",
        "\n",
        "  def on_up_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('up')\n",
        "\n",
        "  def on_down_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('down')\n",
        "\n",
        "  def on_left_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('left')\n",
        "\n",
        "  def on_right_button_clicked(self, *args):\n",
        "    self.human_ai_player_loop('right')\n",
        "\n",
        "  def on_start_button_clicked(self, *args):\n",
        "    self.start_button.disabled = True\n",
        "    for ii in range(self.gwg.max_rounds_taken*self.gwg.num_critters):\n",
        "      self.button_output_update('tbd')\n",
        "      time.sleep(0.2)\n",
        "    self.start_button.disabled = False"
      ],
      "metadata": {
        "cellView": "form",
        "id": "LprlzYln4Elf"
      },
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1.4.1.1 Being the very best in a simple Gridworld\n",
        "\n",
        "The Gridworld problem we initially explored earlier in this book had some complexity, making the absolutely optimal policy difficult to determine. Here we will look at a simplified version of the problem that is readily tractable. Run the code cell below to try out this highly simplified version."
      ],
      "metadata": {
        "id": "DWC3jNWPm84k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Gridworld, but shorter, smaller, and food doesn't regenerate\n",
        "# @markdown Run this cell to try and eat as much food as possible in relatively few moves\n",
        "init_state = {\n",
        "  'pieces': np.array([[[ 0, 0, 0, -1,],\n",
        "                       [-2, 1, 0, -3,]]], dtype=int),\n",
        "  'scores': np.array([[0]]),\n",
        "  'rounds_left': np.array([3]),\n",
        "  'is_over': np.array([0])\n",
        "}\n",
        "gwg = GridworldGame(batch_size=1,\n",
        "                    n_rows=2, n_cols=4,\n",
        "                    num_foragers=1,\n",
        "                    num_predators=0,\n",
        "                    max_rounds_taken=5,\n",
        "                    end_prob=0.0,\n",
        "                    food_num_deterministic=True,\n",
        "                    food_patch_prob=3/7,\n",
        "                    food_forager_regen=False,\n",
        "                    init_board_state=init_state)\n",
        "\n",
        "igwg = InteractiveGridworld(\n",
        "    gwg, players=['human'], critter_names=['Critter (You)'],\n",
        "    figsize=(5,4), has_fov=False)\n",
        "display(igwg.b_fig.canvas)\n",
        "clear_output()\n",
        "display(igwg.final_display)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629,
          "referenced_widgets": [
            "522e30f93a43461db93301b808acddfa",
            "47bdb74a7b9743a0bb5f60ca680fbd6f",
            "c9b1efbfa8cd40719f3954b6e669c627",
            "b1fd31d1c9a0426e990e1e9df72865ea",
            "896c1982f874408d8851e34d48e96bfa",
            "c2cb9c383f234594a47f95ec4735f460",
            "84b700b21a8b44448403f011b184397f",
            "6e859f92e02f4700b543ded7f0ee5b9f",
            "e11ca1b7dc42494f9f3b2b3611836169",
            "c008c977121443fb92bdff8b2f07fbbb",
            "f6f29f0a34ce49d092e66b9eeb06de85",
            "1598945670b848f583cec1b35b1bb468",
            "d1e4f28761134ee792167907372f381a",
            "cd131653ed164b58b38316750e1f4a25",
            "4d86805f8600486c81b0d20cb266f89f",
            "266df4330d044f1cad2935628f4da6f0",
            "d64fa95a529f497c8a9f898fb6924c78",
            "ce891d77e3204d8ba53025d39848e415",
            "f747f187268e45b1a8716ed25649b798",
            "c1dba2ccfa004f39a72a8d2a52f9305b",
            "3e6f83dc772e4c89aa720c9355c7ba95",
            "2f8ff6d585ee49c9a4b49cf0262a5247",
            "9be374d9066f47149605ab86d2d4fa7c",
            "f819246ede554dd493f26e90c691b831",
            "1ea4ed0a65494188a9bb172fd0a9d7d7",
            "f101ba2a0d4145449911a9863bb35332",
            "61a8b2dfa3b5401a883c9c1c02b2c3ab",
            "3b42aedbd614434ca5d5f79f3f3adab3",
            "73dd3e88a456493baee99ea0ec3a8989",
            "9c8f5665070746f1823ad70af408abbe"
          ]
        },
        "id": "sc-MT6VtF5-O",
        "outputId": "773a25ae-bcba-4560-a3aa-5a62948a8520"
      },
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "VBox(children=(VBox(children=(Canvas(footer_visible=False, header_visible=False, resizable=False, toolbar=Toolâ€¦"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "522e30f93a43461db93301b808acddfa"
            }
          },
          "metadata": {
            "application/vnd.jupyter.widget-view+json": {
              "colab": {
                "custom_widget_manager": {
                  "url": "https://ssl.gstatic.com/colaboratory-static/widgets/colab-cdn-widget-manager/2b70e893a8ba7c0f/manager.min.js"
                }
              }
            }
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hopefully you were able to score 2 points in this variant of the game.\n",
        "Thinking Exercises:\n",
        "\n",
        "Is this the best that can be done?(Answer: Yes)\n",
        "\n",
        "How do you know? (Answer: With only three moves and three pieces of food the highest possible score is at most 3. However, the three pieces of food aren't contiguous, so the highest possible score is at most 2. We were able to achieve a score of 2, so the highest possible score is 2. Other lines of reasoning also work.)\n",
        "\n",
        "How did you figure out what the best policy was, do you just try different things, or plan out your three moves and see which sequence of moves gave the best result, or some combination of these two approaches?\n",
        "\n",
        "This simplified version of the Gridworld problem is only slightly different from the original problem we investigated, but these slight differences make it relatively easy to figure out the best policy. Some obvious dif"
      ],
      "metadata": {
        "id": "to1ilTUhnk3q"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPynoewPlnqz"
      },
      "source": [
        "# 1.4.1.1 Foraging in a patchy environment, two flavours.\n",
        "\n",
        "In Seqeunce 1.2.3 on Normative thinking we introduced a patchy foraging game. The game from that sequence (vanilla here) is playable below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "MCCqjDSOZpjv"
      },
      "outputs": [],
      "source": [
        "# @title Omniscient Patchy Foraging - Vanilla\n",
        "# @markdown **Run this cell** to play the patchy foraging game.\n",
        "rng = np.random.default_rng(1)\n",
        "pfg = PatchyForagingGame(max_rounds_taken=20, food_patch_prob=0.3,\n",
        "                         forage_success_prob=0.6, food_extinct_prob=0.2,\n",
        "                         moves_cost=False, end_prob=0, rng=rng)\n",
        "omni_ipfg = InteractivePatchyForage(pfg, show_food=True, show_misses=True,\n",
        "                                    figsize=(4,5))\n",
        "display(omni_ipfg.b_fig.canvas)\n",
        "clear_output()\n",
        "display(omni_ipfg.final_display)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "zLfvxRqHZpjv"
      },
      "outputs": [],
      "source": [
        "# @title Omniscient Patchy Foraging - Chocolate\n",
        "# @markdown **Run this cell** to play the a slight variation on the previous patchy foraging game.\n",
        "rng = np.random.default_rng(1)\n",
        "pfg = PatchyForagingGame(max_rounds_taken=20, food_patch_prob=0.3,\n",
        "                         forage_success_prob=0.6, food_extinct_prob=0.2,\n",
        "                         moves_cost=True, end_prob=0, rng=rng)\n",
        "omni_ipfg = InteractivePatchyForage(pfg, show_food=True, show_misses=True,\n",
        "                                    figsize=(4,5))\n",
        "display(omni_ipfg.b_fig.canvas)\n",
        "clear_output()\n",
        "display(omni_ipfg.final_display)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "9wQn5SipZpjw"
      },
      "source": [
        "Can you spot the difference between the two variants? Hint: Look at what happens to the number of rounds left when you make a move (up, down, left, right) in each variant.\n",
        "\n",
        "When we can see the food patches and tell when they have been exhausted, the optimal policy is similar in both scenarios. Move to a patch with food forager there until food is exhausted, then move on to the next patch with food. In the variant where moves are costly, some care needs to be taken so that patches with food are navagated to efficiently, much like in our earliest Gridworld foraging problems. But other than this requirement on efficient movement between patches, the decision about when to move on is identical when the state of food patches is known. However, in sequence 1.2.3 we focused on a more complex situation, where the presence or absence of food at a location was not immediately detectable, but rather could only be inferred from the recent history of foraging successes and failures at a given patch.\n",
        "\n",
        "You can try out that variant of the game below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "8O7ypmOiZpjw"
      },
      "outputs": [],
      "source": [
        "# @title Cryptic Patchy Foraging - Moves Cost\n",
        "# @markdown **Run this cell** to play the patchy foraging game with cryptic patches and movement has an opportunity cost.\n",
        "rng = np.random.default_rng(3)\n",
        "pfg = PatchyForagingGame(max_rounds_taken=20, food_patch_prob=0.3,\n",
        "                         forage_success_prob=0.6, food_extinct_prob=0.2,\n",
        "                         end_prob=0, moves_cost=True, rng=rng)\n",
        "cryptic_ipfg = InteractivePatchyForage(pfg, show_food=False,\n",
        "                                       show_misses=True,\n",
        "                                       figsize=(4,5))\n",
        "display(cryptic_ipfg.b_fig.canvas)\n",
        "clear_output()\n",
        "display(cryptic_ipfg.final_display)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "3-fDTlkdZpjw"
      },
      "source": [
        "While the variant where moves are free and the variant where moves have an opportunity cost are very similar in many ways, this slight difference, means that the approach we used to determine an optimal policy (behaviour rule) for one variant will not work for the other.\n",
        "\n",
        "Consider, when movement between patches has no opportunity cost, all an optimal organism needs to worry about is foraging at a patch that has the highest possible probability of having food present. If that happens to be the patch the organism currently occupies, great, forage there, but if not, no problem, movement is free in some sense, so just move on to a fresh patch if the foraging odds are better there. In contrast, more nuance is required when time spent moving between patches uses up time that could have been spent foraging, i.e. when movement has an opportunity cost. To see this think about what happens when there is a single round left in the foraging episode. When movement is costly is there any situation where movement is preferable to foraging at the current patch on this last round? No, there is always some chance of success (from the forager's perspective) at the current patch, but there is zero chance of foraging success when moving, so an optimal forager would never move on the last round.\n",
        "\n",
        "Things are certainly more complicated things, but the kind of thinking we applied in sequence 1.2.3 can be extended to find an optimal policy for this new, trickier problem."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "V7anPtSuZpjw"
      },
      "source": [
        "# 1.4.1.2 Reasoning About The Problem"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "-I5zBeafZpjx"
      },
      "source": [
        "## **Defining the Problem**\n",
        "First we need define our model problem precisely.\n",
        "\n",
        "* **Patchy Environment**: The foraging environment consists of discrete patches (represented as grid cells). At the start of the simulation each patch has a probability $p_e \\in (0,1)$ of containing food. The forager starts at a fresh patch.\n",
        "\n",
        "* **Possible Actions**: In each turn, the organism has two options:\n",
        "  - Try to forage at its current patch.\n",
        "  - Move to a new patch.\n",
        "\n",
        "* **Foraging Success**: When a patch contains food, foraging is often successful but not always guaranteed. In this model, foraging at a patch with food is successful with probability $p_s \\in (0,1)$. Conversely, foraging on a food-less patch is certain to be unsuccessful.\n",
        "\n",
        "* **Patch Exhaustion**: After each foraging success, there is a probability $p_x \\in (0,1)$ that the patch becomes exhausted. In such cases, the patch won't provide any more food.\n",
        "\n",
        "* **Session Limit**: The foragers can take a fixed number of actions, $T$, before the session end. Both move actions and foraging attemp actions count towards this limit.\n",
        "\n",
        "* **Rewards**: Every successful foraging attempt gives the organism a reward of 1 point. If the foraging attempt is unsuccessful, no points are awarded for that round. Similarly, if the organism moves, no points are awarded. We denote the reward received on round $t$ as $R_t$.\n",
        "\n",
        "* **Goal**: The overarching objective for the organism is to maximize its *expected cumulative reward* over the entire session. Formally, the forager aims to maximize:\n",
        "$$\n",
        "\\mathbb{E}\\left[ \\sum_{t=1}^{T} R_t \\right] = \\sum_{t=1}^{T} \\mathbb{E}\\left[ R_t \\right]\n",
        "$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "HILMu54_Zpjx"
      },
      "source": [
        "Previously we kind of glossed over where exactly the actions of the forager were applied in the decision making process. We made simplifying assumptions (implicitly! Yikes!) that of course the forager would forage at a newly arrived patch (why else would it have moved these), but for a moment we're going to leave that aside and be as totally verbose and explicit as possible about all the different things that can happen. Just as a result of the foragers very first action."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "3W9us168Zpjx"
      },
      "outputs": [],
      "source": [
        "def latex_to_png(latex_str, file_path, dpi, fontsize, figsize):\n",
        "  \"\"\"Convert a LaTeX string to a PNG image.\"\"\"\n",
        "  fig, ax = plt.subplots(figsize=figsize)\n",
        "  ax.text(0.5, 0.5, f\"${latex_str}$\", size=fontsize, ha='center', va='center')\n",
        "  ax.axis(\"off\")\n",
        "  #plt.tight_layout()\n",
        "  plt.subplots_adjust(left=0, right=1, top=1, bottom=0)\n",
        "  plt.savefig(file_path, dpi=dpi, bbox_inches='tight', transparent=True, pad_inches=0.02)\n",
        "  plt.close()\n",
        "\n",
        "def add_latex_edge_labels(graph, edge_labels, dpi=150, fontsize=16, figsize=(0.4,0.2)):\n",
        "  \"\"\"Add LaTeX-rendered images as edge labels using the dummy node approach.\"\"\"\n",
        "  for edge in edge_labels:\n",
        "    src, dest, latex_str = edge\n",
        "    if graph.has_edge(src, dest):\n",
        "      img_path = f\"{src}_to_{dest}_{latex_str}.png\"\n",
        "      latex_to_png(latex_str, img_path, dpi=dpi, fontsize=fontsize, figsize=figsize)\n",
        "      dummy_node_name = f\"dummy_{src}_{dest}_{latex_str}\"\n",
        "      graph.add_node(dummy_node_name, shape=\"box\", image=img_path, label=\"\", color=\"green\")\n",
        "      graph.delete_edge(src, dest)\n",
        "      graph.add_edge(src, dummy_node_name, dir=\"none\", weight=10)\n",
        "      graph.add_edge(dummy_node_name, dest, dir=\"forward\", weight=10)\n",
        "  return graph\n",
        "\n",
        "def set_regular_node_sizes(graph, width=1.0, height=1.0):\n",
        "  \"\"\"Set the size of regular nodes (excluding dummy label nodes).\"\"\"\n",
        "  for node in graph.nodes():\n",
        "    if not node.startswith(\"dummy\"):\n",
        "      node.attr['width'] = width\n",
        "      node.attr['height'] = height\n",
        "  return graph\n",
        "\n",
        "\n",
        "def create_and_render_graph(nodes_list, edges_list, latex_edge_labels,\n",
        "                            action_nodes = [],\n",
        "                            node_colors = {},\n",
        "                            node_labels = {},\n",
        "                            output_path=\"graphviz_output.png\", dpi=300,\n",
        "                            figsize=(0.6, 0.3), fontsize=16):\n",
        "  \"\"\"\n",
        "  Create a graph with given nodes, edges, and LaTeX edge labels, then render and save it.\n",
        "\n",
        "  Parameters:\n",
        "    nodes_list (list): List of nodes in the graph.\n",
        "    edges_list (list): List of edges in the graph.\n",
        "    latex_edge_labels (list): List of tuples containing edge and its LaTeX label.\n",
        "    output_path (str): Path to save the rendered graph.\n",
        "    dpi (int): DPI for rendering the graph.\n",
        "    figsize (tuple): Figure size for the LaTeX labels.\n",
        "\n",
        "  Returns:\n",
        "    str: Path to the saved graph image.\n",
        "  \"\"\"\n",
        "  # Graph Creation and Configuration\n",
        "  G = pgv.AGraph(directed=True, strict=False, rankdir='LR', ranksep=0.5, nodesep=0.5)\n",
        "\n",
        "  # Add state and decision nodes\n",
        "  for node in nodes_list:\n",
        "    shape = \"box\" if node in action_nodes else \"ellipse\"  # Use 'box' for decision nodes\n",
        "    if node in action_nodes:\n",
        "      # action nodes are square and default to blue colour\n",
        "      color = node_colors.get(node, \"blue\")\n",
        "      shape = \"box\"\n",
        "    else:\n",
        "      # state nodes are round and default to black colour\n",
        "      shape = \"ellipse\"\n",
        "      color = node_colors.get(node, \"black\")\n",
        "    label = node_labels.get(node, node)\n",
        "    G.add_node(node, color=color, label=label, shape=shape)\n",
        "\n",
        "  for edge in edges_list:\n",
        "    G.add_edge(edge[0], edge[1])\n",
        "\n",
        "  # Set size for regular nodes and add LaTeX-rendered image labels to the edges\n",
        "  G = set_regular_node_sizes(G, width=1, height=1)\n",
        "  G = add_latex_edge_labels(G, latex_edge_labels, dpi=dpi, figsize=figsize, fontsize=fontsize)\n",
        "\n",
        "  # Additional graph attributes\n",
        "  G.graph_attr['size'] = \"8,8\"\n",
        "  G.graph_attr['dpi'] = str(dpi)\n",
        "\n",
        "  # Render and save the graph\n",
        "  G.layout(prog='dot')\n",
        "  G.draw(output_path)\n",
        "\n",
        "  return output_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "ABVVO6olZpjx"
      },
      "outputs": [],
      "source": [
        "# @markdown **Run This Cell** to visualize the decision tree\n",
        "\n",
        "\n",
        "nodes_list = [\n",
        "    \"New Patch\", \"Has Food0\", \"No Food0\", \"Didn't Find Food0\", \"Found the Food0\",\n",
        "    \"No Food to Find0\", \"Found Impossible Food0\",\n",
        "    \"Search (has food)0\", \"Leave (has food)0\",\n",
        "    \"Search (no food)0\", \"Leave (no food)0\",\n",
        "    \"Has Food1\", \"No Food1\", \"Has Food2\", \"No Food2\"\n",
        "]\n",
        "\n",
        "edges_list = [\n",
        "    (\"New Patch\", \"Has Food0\"), (\"New Patch\", \"No Food0\"),\n",
        "    (\"Has Food0\", \"Search (has food)0\"), (\"Has Food0\", \"Leave (has food)0\"),\n",
        "    (\"No Food0\", \"Search (no food)0\"), (\"No Food0\", \"Leave (no food)0\"),\n",
        "    (\"Search (has food)0\", \"Found the Food0\"), (\"Search (has food)0\", \"Didn't Find Food0\"),\n",
        "    (\"Search (no food)0\", \"Found Impossible Food0\"), (\"Search (no food)0\", \"No Food to Find0\"),\n",
        "    (\"Leave (has food)0\", \"Has Food1\"), (\"Leave (has food)0\", \"No Food1\"),\n",
        "    (\"Leave (no food)0\", \"Has Food2\"), (\"Leave (no food)0\", \"No Food2\"),\n",
        "]\n",
        "\n",
        "latex_edge_labels = [\n",
        "    (\"New Patch\", \"Has Food0\", \"p_e\"),\n",
        "    (\"New Patch\", \"No Food0\", \"1-p_e\"),\n",
        "    (\"Search (has food)0\", \"Didn't Find Food0\", \"1-p_s\"),\n",
        "    (\"Search (has food)0\", \"Found the Food0\", \"p_s\"),\n",
        "    (\"Search (no food)0\", \"No Food to Find0\", \"1\"),\n",
        "    (\"Search (no food)0\", \"Found Impossible Food0\", \"0\"),\n",
        "    (\"Leave (has food)0\", \"No Food1\", \"p_e\"),\n",
        "    (\"Leave (has food)0\", \"Has Food1\", \"1-p_e\"),\n",
        "    (\"Leave (no food)0\", \"No Food2\", \"p_e\"),\n",
        "    (\"Leave (no food)0\", \"Has Food2\", \"1-p_e\")\n",
        "]\n",
        "\n",
        "action_nodes = [\n",
        "    \"Search (has food)0\", \"Search (no food)0\", \"Leave (has food)0\", \"Leave (no food)0\"\n",
        "]\n",
        "\n",
        "node_colors = {\n",
        "    \"New Patch\": \"red\",\n",
        "    \"Has Food0\": \"red\",\n",
        "    \"No Food0\": \"red\",\n",
        "}\n",
        "\n",
        "node_labels = {\n",
        "    \"Has Food0\": \"New Patch\\nHas Food\",\n",
        "    \"No Food0\": \"New Patch Has\\nNo Food\",\n",
        "    \"Has Food1\": \"New Patch\\nHas Food\",\n",
        "    \"No Food1\": \"New Patch Has\\nNo Food\",\n",
        "    \"Has Food2\": \"New Patch\\nHas Food\",\n",
        "    \"No Food2\": \"New Patch Has\\nNo Food\",\n",
        "    \"Search (has food)0\": \"Search\",\n",
        "    \"Leave (has food)0\": \"Leave\",\n",
        "    \"Search (no food)0\": \"Search\",\n",
        "    \"Leave (no food)0\": \"Leave\",\n",
        "    \"Didn't Find Food0\": \"No Food Found\",\n",
        "    \"No Food to Find0\": \"No Food Found\",\n",
        "    \"Found the Food0\": \"Food Found\\n+1 Reward Point\",\n",
        "    \"Found Impossible Food0\": \"Food Found\\n+1 Reward Point\"\n",
        "}\n",
        "\n",
        "\n",
        "output_path = create_and_render_graph(nodes_list, edges_list, latex_edge_labels,\n",
        "                                      action_nodes=action_nodes,\n",
        "                                      node_colors=node_colors,\n",
        "                                      node_labels=node_labels)\n",
        "Image(output_path, height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "SQEC9fPRZpjx"
      },
      "source": [
        "In this diagram rounded nodes represent states of this process, i.e. the situation the organism is in with respect to the environment. Blue squares represent actions taken by the organism, and yellow squares give the probability of transitioning from the previous state, to the next state, given the action the organism took. These transitions can also be thought of as actions taken by the environment. This the full expansion, but looking at this we can see that if the organism leaves a patch, it doesn't matter whether or not there was food there, the state of the new patch is unaffected by this so we can already simplify this slightly."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "fHzapqleZpjx"
      },
      "outputs": [],
      "source": [
        "# @markdown **Run This Cell** to visualize the decision tree\n",
        "\n",
        "\n",
        "nodes_list = [\n",
        "  \"New Patch\", \"Has Food0\", \"No Food0\", \"Didn't Find Food0\", \"Found the Food0\",\n",
        "  \"No Food to Find0\", \"Found Impossible Food0\",\n",
        "  \"Search (has food)0\", \"Leave0\",\n",
        "  \"Search (no food)0\",\n",
        "  \"Has Food1\", \"No Food1\"\n",
        "]\n",
        "\n",
        "edges_list = [\n",
        "  (\"New Patch\", \"Has Food0\"), (\"New Patch\", \"No Food0\"),\n",
        "  (\"Has Food0\", \"Search (has food)0\"), (\"Has Food0\", \"Leave0\"),\n",
        "  (\"No Food0\", \"Search (no food)0\"), (\"No Food0\", \"Leave0\"),\n",
        "  (\"Search (has food)0\", \"Found the Food0\"), (\"Search (has food)0\", \"Didn't Find Food0\"),\n",
        "  (\"Search (no food)0\", \"Found Impossible Food0\"), (\"Search (no food)0\", \"No Food to Find0\"),\n",
        "  (\"Leave0\", \"Has Food1\"), (\"Leave0\", \"No Food1\"),\n",
        "]\n",
        "\n",
        "latex_edge_labels = [\n",
        "  (\"New Patch\", \"Has Food0\", \"p_e\"),\n",
        "  (\"New Patch\", \"No Food0\", \"1-p_e\"),\n",
        "  (\"Search (has food)0\", \"Didn't Find Food0\", \"1-p_s\"),\n",
        "  (\"Search (has food)0\", \"Found the Food0\", \"p_s\"),\n",
        "  (\"Search (no food)0\", \"No Food to Find0\", \"1\"),\n",
        "  (\"Search (no food)0\", \"Found Impossible Food0\", \"0\"),\n",
        "  (\"Leave0\", \"No Food1\", \"p_e\"),\n",
        "  (\"Leave0\", \"Has Food1\", \"1-p_e\"),\n",
        "]\n",
        "\n",
        "action_nodes = [\n",
        "  \"Search (has food)0\", \"Search (no food)0\", \"Leave0\"\n",
        "]\n",
        "\n",
        "node_colors = {\n",
        "    \"New Patch\": \"red\",\n",
        "    \"Has Food0\": \"red\",\n",
        "    \"No Food0\": \"red\",\n",
        "}\n",
        "\n",
        "node_labels = {\n",
        "    \"Has Food0\": \"New Patch\\nHas Food\",\n",
        "    \"No Food0\": \"New Patch Has\\nNo Food\",\n",
        "    \"Has Food1\": \"New Patch\\nHas Food\",\n",
        "    \"No Food1\": \"New Patch Has\\nNo Food\",\n",
        "    \"Search (has food)0\": \"Search\",\n",
        "    \"Leave0\": \"Leave\",\n",
        "    \"Search (no food)0\": \"Search\",\n",
        "    \"Didn't Find Food0\": \"No Food Found\",\n",
        "    \"No Food to Find0\": \"No Food Found\",\n",
        "    \"Found the Food0\": \"Food Found\\n+1 Reward Point\",\n",
        "    \"Found Impossible Food0\": \"Food Found\\n+1 Reward Point\"\n",
        "}\n",
        "\n",
        "\n",
        "output_path = create_and_render_graph(nodes_list, edges_list, latex_edge_labels,\n",
        "                                      action_nodes=action_nodes,\n",
        "                                      node_colors=node_colors,\n",
        "                                      node_labels=node_labels)\n",
        "Image(output_path, height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "LgCbXrC9Zpjy"
      },
      "source": [
        "Similarly we can remove the zero probability event\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "execution": {},
        "id": "y9nFQk2SZpjy"
      },
      "outputs": [],
      "source": [
        "nodes_list = [\n",
        "  \"New Patch\", \"Has Food0\", \"No Food0\", \"Didn't Find Food0\", \"Found the Food0\",\n",
        "  \"No Food to Find0\",\n",
        "  \"Search (has food)0\",\n",
        "  \"Search (has food)1\"\n",
        "  \"Leave0\",\n",
        "  \"Leave1\"\n",
        "  \"Search (no food)0\",\n",
        "  \"Search (no food)1\",\n",
        "  \"Has Food1\", \"No Food1\",\n",
        "  \"Search (didn't find food)0\",\n",
        "  \"Search (found the food)0\",\n",
        "  \"Search (no food to find)0\",\n",
        "  \"Leave (didn't find food)0\",\n",
        "  \"Leave (found the food)0\",\n",
        "  \"Leave (no food to find)0\",\n",
        "]\n",
        "\n",
        "edges_list = [\n",
        "  (\"New Patch\", \"Has Food0\"), (\"New Patch\", \"No Food0\"),\n",
        "  (\"Has Food0\", \"Search (has food)0\"), (\"Has Food0\", \"Leave0\"),\n",
        "  (\"No Food0\", \"Search (no food)0\"), (\"No Food0\", \"Leave0\"),\n",
        "  (\"Search (has food)0\", \"Found the Food0\"), (\"Search (has food)0\", \"Didn't Find Food0\"),\n",
        "  (\"Search (no food)0\", \"No Food to Find0\"),\n",
        "  (\"Leave0\", \"Has Food1\"), (\"Leave0\", \"No Food1\"),\n",
        "]\n",
        "\n",
        "latex_edge_labels = [\n",
        "  (\"New Patch\", \"Has Food0\", \"p_e\"),\n",
        "  (\"New Patch\", \"No Food0\", \"1-p_e\"),\n",
        "  (\"Search (has food)0\", \"Didn't Find Food0\", \"1-p_s\"),\n",
        "  (\"Search (has food)0\", \"Found the Food0\", \"p_s\"),\n",
        "  (\"Search (no food)0\", \"No Food to Find0\", \"1\"),\n",
        "  (\"Leave0\", \"No Food1\", \"p_e\"),\n",
        "  (\"Leave0\", \"Has Food1\", \"1-p_e\"),\n",
        "]\n",
        "\n",
        "action_nodes = [\n",
        "  \"Search (has food)0\", \"Search (no food)0\", \"Leave0\"\n",
        "]\n",
        "\n",
        "node_colors = {}\n",
        "\n",
        "node_labels = {\n",
        "    \"Has Food0\": \"New Patch\\nHas Food\",\n",
        "    \"No Food0\": \"New Patch Has\\nNo Food\",\n",
        "    \"Has Food1\": \"New Patch\\nHas Food\",\n",
        "    \"No Food1\": \"New Patch Has\\nNo Food\",\n",
        "    \"Search (has food)0\": \"Search\",\n",
        "    \"Leave0\": \"Leave\",\n",
        "    \"Search (no food)0\": \"Search\",\n",
        "    \"Didn't Find Food0\": \"No Food Found\",\n",
        "    \"No Food to Find0\": \"No Food Found\",\n",
        "    \"Found the Food0\": \"Food Found\\n+1 Reward Point\",\n",
        "}\n",
        "\n",
        "\n",
        "output_path = create_and_render_graph(nodes_list, edges_list, latex_edge_labels,\n",
        "                                      action_nodes=action_nodes,\n",
        "                                      node_colors=node_colors,\n",
        "                                      node_labels=node_labels)\n",
        "Image(output_path, height=600)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "kOH6cO5-Zpjy"
      },
      "source": [
        "# MDP Notation\n",
        "To get precise about what we are trying to optimize we first need to introduce some important notation, and formalize many of the general concepts introduced earlier in the book through our Gridworld example. If you are already farmiliar with these ideas feel free to skip this bit. Similarly if you find mathematical notation a bit overwhelming, you can also skim this section, (don't worry about understanding it all right away) and then use this as glossary as needed. A shortened version of these definitions also appear in the glossary/notation reference section found at the end of each notebook.\n",
        "\n",
        "* $\\pi_{\\theta}(a|s)$: **Policy Function** - A policy is the behavioural blueprint for the organism. It's a function that takes (some representation or filtered down aspect of) the environmental state $s$ as input, and guided by its parameters $\\theta$, gives the probability of taking action $a$, where $a$ is in the set $\\mathcal{A}(s)$ of possible actions given state $s$. The organism can then sample an actio from this set according to these probabilities. Sometimes the explicit reference to $\\theta$ is dropped when it is clear from context or does not need to be emphasized as in $\\pi(a|s)$, other times the the reference to the parameters is made more explicit by writing $\\pi(a | s, \\theta)$. In our Gridworld example each of the organisms we defined, 'Random Valid', 'Parameterized Weights', 'Eat When Near' all had a policy function at their core.\n",
        "\n",
        "* $s$: **A State** - The state represents a complete snapshot of what the environment looks like at a given moment. In our Gridworld example this is primarily the positions of food pieces and the organism, but also the number of rounds left in the simulation. The set of all possible states is denoted $\\mathcal{S}$.\n",
        "\n",
        "* $a$: **An Action** - The action an organism takes. Depending on how things are set up in our Gridworld example this might be represented as a direction or as a (row, columns) coordinate of the organism's new position, or as a flattened boolean index of the organism's new position. The set of all possible actions is denoted $\\mathcal{A}$, and the set of possible actions in a given state as $\\mathcal{A}(s)$.\n",
        "\n",
        "* $r$ : **A Reward** - The immediate reward (feedback, score, points etc.) an organism recieves after taking an action $a$ in state $s$ and transitioning to new state $s'$. In our Gridworld example $r = 1$ if the organism eats a food piece as a result of its move and $r = 0$ otherwise.\n",
        "\n",
        "* $\\theta$: **Parameters** - The aspects of an organism's policy function that can be represented by numbers. Note that these do not describe the overall structure of the policy function, but rather determine a particular instance of the policy functions possible *given* the structure (archietecture) of a policy function. In our 'Parameterized Weights' policy from our Gridworld example, the connective weight strengths $W$ are the paramweters, i.e. $\\theta = W$ in for this particular policy. For a more complicated policy with many layers of connective weights we might write $\\theta = \\{W_1, W_2,\\dots, W_N \\}$. We use $\\theta$ as a generic term so that we can make general statements about parameterized policies without having to worry about the particular archiectecure or functional form of the policy.   \n",
        "\n",
        "Given the stochastic nature of the environment (and often the policy as well), at any given time $t$ over the course of a simulation run, each of states, actions and rewards can be thought of as random variables specifically:\n",
        "\n",
        "* $S_t$: **State at Time $t$** - A random variable that denotes the state of the environment at a specific time $t$. For example, $S_t = s$ means that at time $t$, in a particular simulation run, the environment was in state $s$, or in other words that $s$ is the realization of the random variable $S_t$.\n",
        "\n",
        "* $A_t$: **Action at Time $t$** - A random variable denoting the action taken by the organism at time $t$. $A_t = a$ indicates that the action $a$ is taken at time $t$, or that $a$ is the realization of the random variable $A_t$ in a particular simulation run.\n",
        "\n",
        "* $R_t$: **Reward at Time $t$** - A random variable indicating the immediate reward received by the organism at time $t$. $R_t = r$ indicates that the reward $r$ is obtained at time $t$, or in that $r$ is the realization of the random variable $R_t$ in a particular simulation run.\n",
        "\n",
        "* $T$: **Total Simulation Time** - The total number of time steps in a given simulation. There are cases where having an infinite time horizon, $T=\\infty$, is a mathematical convenience, but since our focus is on evolved, living and learning systems, and few things live forever, we will typically work with a finite time horizons.\n",
        "\n",
        "* $t$: **Time-Step Index** - We typically subscript with $t$ to denote the value of a state, reward, action, etc. at a given specific time $t$.\n",
        "\n",
        "We can then think of simulation run as sequence of random variables:\n",
        "$$S_0, A_0, R_1, S_1, A_1, R_2, S_2, A_2, R_3, \\dots, S_{T-1}, A_{T-1}, R_{T}, {S_T}$$\n",
        "\n",
        "The dynamics, or equations of motion, that generate this sequence of random variables are primarily encapsulated in a *transition function*, together with an *initial state distribution*, both defined as follows.\n",
        "\n",
        "* $p(s', r | s, a)$: **Transition Function** - Sometimes called the *State Transition Function*, or the *Transition Kernel* (kernel is more common when dealing with continuous state spaces) this function give the probability of transitioning from state $s$ to $s'$ and recieving reward $r$ from time-step $t$ to $t+1$, given that action $a$ is taken at time $t$. In terms of our previous notation this is defined as:\n",
        "$$ p(s', r | s, a) := \\Pr \\{S_{t+1} = s' , R_{t+1} = r | S_t = s, A_t = a \\}$$  \n",
        "\n",
        "* $p_0(s)$: **Initial State Distribution** - This is the probability distribution (density function) over the set of possible states, \\mathcal{S}, so $p_0(s) := \\Pr \\{S_0 = s\\}$. Sometimes we write $S_0 \\sim p_0$, which is read as 'The random variable $S_0$ is distributed according to the probability density function $p_0$'.\n",
        "\n",
        "This random variable notation also allows us to make uur definition of a policy function more precise: $$\\pi_{\\theta}(a | s) := \\Pr \\{A_{t} = a | S_t = s\\}.$$\n",
        "\n",
        "Then, if a policy is fixed it can simply be folded into the dynamics of the environment, creating what is refered to as the *policy-induced dynamics*.\n",
        "\n",
        "* $p_\\pi(s', r | s)$: **Policy-Induced Dynamics** - This is also called the 'dynamics under policy $\\pi$' and is defined as:\n",
        "$$p_\\pi(s', r | s):= \\Pr \\{S_{t+1} = s' , R_{t+1} = r | S_t = s, \\pi \\} = \\sum_{a\\in\\mathcal{A}(s)} \\pi_\\theta (a | s) \\ p(s', r | s, a).$$\n",
        "Sometimes the depedence on a specific policy, $\\pi$, is taken as implicit and we simply write $p(s', r | s)$.\n",
        "\n",
        "The takeaway here is that for a fixed $\\pi$ and a given transition function $p$ (and initial state distribution $p_0$) the stochastic dynamics of the system are completely determined.\n",
        "\n",
        "With all that defined we can start to formally describe how rewards should be added up over time to define our goals. We just need to introduce the idea of a *Return* and a *Value* function.\n",
        "\n",
        "* $G_t$: **Return following time $t$** - Sometimes called the reward to go, or simply the return, this a random variable that indicates the total reward yet to be realized after time $t$, i.e. $G_t := \\sum_{k=t+1}^T R_k$.\n",
        "\n",
        "* $v_{\\pi}(s,t)$: **Value Function** - A function giving the *expected* return conditional on being in state $s$ at time $t$ and following a given policy $\\pi$, specifically:\n",
        "$$v_{\\pi}(s,t) := \\mathbb{E}_\\pi \\left[G_t | S_t = s \\right].$$\n",
        "In a slight stretch of notation $t$ can be treated as part of $s$ and we can write $v_{\\pi}(s)$. The dependence on a specific policy is sometimes treated as implicit and we write $v(s)$ or $v(s,t)$.\n",
        "\n",
        "In this context then our goal is to maximize the *Expectation* of a simulation run, or equivalently the average value from playing through many simulations (in the limit as many --> $\\infty$). We call this formalization of our goal objective function and define our particular objective function in this context as\n",
        "\n",
        "* $J(\\theta)$: **Objective Function** - The function that we are trying to maximize, emphasizing the dependence on the parameters, $\\theta$.\n",
        "\n",
        "The objective function is in some ways the most subjective thing in this whole set up. It's what defines the \"problem to be solved\". In our particular case we we are going to use the following as our objective.\n",
        "\n",
        "$$J(\\theta):= \\mathbb{E}\\left[ v_{\\pi_\\theta}(S_0) \\right] = \\sum_{s \\in \\mathcal{S}} p_0(s) \\cdot v_{\\pi_{\\theta}}(s)$$\n",
        "\n",
        "Then the formalization of our problem is choosing parameters $\\theta$ such that $J(\\theta)$ is as high as possible. In general this goal is written as:\n",
        "$$ \\max_{\\theta} J(\\theta),$$\n",
        "\n",
        "and in our particular case of maximizing the expected value, given a finite and discrete state space, our goal is written as:\n",
        "\n",
        "$$ \\max_\\theta\\sum_{s \\in \\mathcal{S}} p_0(s) \\cdot v_{\\pi_{\\theta}}(s)$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "sDhxEIc3Zpjz"
      },
      "outputs": [],
      "source": [
        "# @markdown Submit your feedback\n",
        "content_review(f\"{feedback_prefix}_M3\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "1cwpPN34Zpjz"
      },
      "source": [
        "# Quiz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "vv_eGTSUZpjz"
      },
      "outputs": [],
      "source": [
        "# @markdown **Run this cell** to take the quiz\n",
        "# @markdown **Run this cell** to take the quiz\n",
        "comprehension_quiz = [\n",
        "  {\n",
        "    \"question\": \"What is the impact of mutation on the evolutionary process?\",\n",
        "    \"type\": \"multiple_choice\",\n",
        "    \"answers\": [\n",
        "      {\n",
        "        \"answer\": \"It always increases the fitness of individuals in a population.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"Mutation does not always increase fitness; it typically introduces neutral or deleterious variations. Beneficial mutations are rare.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"It introduces necessary variation to explore new genotypes.\",\n",
        "        \"correct\": True,\n",
        "        \"feedback\": \"Correct! Mutation is essential for introducing genetic variation, which allows populations to explore new genotypes and adapt over time.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"It decreases genetic diversity within a population.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"Mutation actually increases genetic diversity by introducing new genetic variations.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"It reduces the population size over time.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"Mutation itself does not necessarily reduce population size; it's the selection process that might influence population numbers based on the fitness effects of mutations.\"\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"question\": \"How does evolution compare to a typical optimization algorithm?\",\n",
        "    \"type\": \"multiple_choice\",\n",
        "    \"answers\": [\n",
        "      {\n",
        "        \"answer\": \"Evolution has a clear termination condition when a global maximum is reached.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"Evolution lacks a termination condition and does not stop even when high-fitness solutions are found.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"Evolution is a process that continually explores and exploits, without awareness of the global fitness landscape.\",\n",
        "        \"correct\": True,\n",
        "        \"feedback\": \"Exactly! Evolution continuously explores new genotypes and exploits current adaptations without a concept of the overall fitness landscape. In this way it is like a 'black-box' optimization algorithm\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"Evolutionary processes always find the globally optimal solution.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"Evolution does not necessarily find global optima; it often settles on local maxima due to its hill-climbing nature.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"Evolution stops mutations once a sufficiently good solution is found.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"Evolution does not stop mutating genotypes even after finding high-fitness solutions, which can lead to further, fitness reducing variation.\"\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"question\": \"In the context of evolutionary simulations, what does a low mutation rate typically lead to?\",\n",
        "    \"type\": \"multiple_choice\",\n",
        "    \"answers\": [\n",
        "      {\n",
        "        \"answer\": \"A diverse population with many different genotypes coexisting.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"A low mutation rate usually results in less genetic diversity, not more.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"Rapid convergence to the global fitness peak.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"Low mutation rates can lead to rapid convergence, but not necessarily to global peaksâ€”often to local ones.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"The population is generally dominated by a single variant.\",\n",
        "        \"correct\": True,\n",
        "        \"feedback\": \"Correct! Low mutation rates can lead to populations being dominated by a single, high-fitness variant.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"An increase in the number of harmful mutations.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"A low mutation rate means fewer mutations overall, not an increase in harmful ones specifically.\"\n",
        "      }\n",
        "    ]\n",
        "  },\n",
        "  {\n",
        "    \"question\": \"What role do 'sticky attractors' play in evolutionary processes?\",\n",
        "    \"type\": \"multiple_choice\",\n",
        "    \"answers\": [\n",
        "      {\n",
        "        \"answer\": \"They prevent the population from reaching any kind of fitness peak.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"Sticky attractors do not prevent the attainment of fitness peaks; they are the peaks where populations tend to stabilize.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"They represent states of low fitness that populations tend to avoid.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"Sticky attractors are not low-fitness states; they are high-fitness states that populations are drawn to.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"They are high-fitness states in the genotype space that populations are likely to remain in for long periods.\",\n",
        "        \"correct\": True,\n",
        "        \"feedback\": \"Exactly! Sticky attractors are robust high-fitness states where populations tend to remain stable over time.\"\n",
        "      },\n",
        "      {\n",
        "        \"answer\": \"They are synonymous with global maxima in the fitness function.\",\n",
        "        \"correct\": False,\n",
        "        \"feedback\": \"Sticky attractors correspond to local maxima, not necessarily global maxima, in the fitness landscape.\"\n",
        "      }\n",
        "    ]\n",
        "  }\n",
        "]\n",
        "\n",
        "display_quiz(comprehension_quiz)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "name": "P1C4_Sequence1",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "522e30f93a43461db93301b808acddfa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_47bdb74a7b9743a0bb5f60ca680fbd6f",
              "IPY_MODEL_c9b1efbfa8cd40719f3954b6e669c627"
            ],
            "layout": "IPY_MODEL_b1fd31d1c9a0426e990e1e9df72865ea"
          }
        },
        "47bdb74a7b9743a0bb5f60ca680fbd6f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_896c1982f874408d8851e34d48e96bfa",
              "IPY_MODEL_c2cb9c383f234594a47f95ec4735f460"
            ],
            "layout": "IPY_MODEL_84b700b21a8b44448403f011b184397f"
          }
        },
        "c9b1efbfa8cd40719f3954b6e669c627": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_6e859f92e02f4700b543ded7f0ee5b9f",
              "IPY_MODEL_e11ca1b7dc42494f9f3b2b3611836169"
            ],
            "layout": "IPY_MODEL_c008c977121443fb92bdff8b2f07fbbb"
          }
        },
        "b1fd31d1c9a0426e990e1e9df72865ea": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "896c1982f874408d8851e34d48e96bfa": {
          "model_module": "jupyter-matplotlib",
          "model_name": "MPLCanvasModel",
          "model_module_version": "^0.11",
          "state": {
            "_cursor": "default",
            "_data_url": "data:image/png;base64,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",
            "_dom_classes": [],
            "_figure_label": "Figure 18",
            "_image_mode": "full",
            "_message": "x= y=",
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "MPLCanvasModel",
            "_rubberband_height": 0,
            "_rubberband_width": 0,
            "_rubberband_x": 0,
            "_rubberband_y": 0,
            "_size": [
              500,
              400
            ],
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "MPLCanvasView",
            "capture_scroll": false,
            "footer_visible": false,
            "header_visible": false,
            "layout": "IPY_MODEL_d64fa95a529f497c8a9f898fb6924c78",
            "pan_zoom_throttle": 33,
            "resizable": false,
            "toolbar": "IPY_MODEL_ce891d77e3204d8ba53025d39848e415",
            "toolbar_position": "left",
            "toolbar_visible": false
          }
        },
        "c2cb9c383f234594a47f95ec4735f460": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f6f29f0a34ce49d092e66b9eeb06de85",
              "IPY_MODEL_1598945670b848f583cec1b35b1bb468",
              "IPY_MODEL_d1e4f28761134ee792167907372f381a"
            ],
            "layout": "IPY_MODEL_cd131653ed164b58b38316750e1f4a25"
          }
        },
        "84b700b21a8b44448403f011b184397f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6e859f92e02f4700b543ded7f0ee5b9f": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_4d86805f8600486c81b0d20cb266f89f",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "--------------  --\n",
                  "High Score:     --\n",
                  "Last Score:     --\n",
                  "Average Score:  --\n",
                  "--------------  --\n"
                ]
              }
            ]
          }
        },
        "e11ca1b7dc42494f9f3b2b3611836169": {
          "model_module": "@jupyter-widgets/output",
          "model_name": "OutputModel",
          "model_module_version": "1.0.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/output",
            "_model_module_version": "1.0.0",
            "_model_name": "OutputModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/output",
            "_view_module_version": "1.0.0",
            "_view_name": "OutputView",
            "layout": "IPY_MODEL_266df4330d044f1cad2935628f4da6f0",
            "msg_id": "",
            "outputs": [
              {
                "output_type": "stream",
                "name": "stdout",
                "text": [
                  "Click a button to start playing\n",
                  "There are 3 rounds in this game\n"
                ]
              }
            ]
          }
        },
        "c008c977121443fb92bdff8b2f07fbbb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f6f29f0a34ce49d092e66b9eeb06de85": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Left",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f747f187268e45b1a8716ed25649b798",
            "style": "IPY_MODEL_c1dba2ccfa004f39a72a8d2a52f9305b",
            "tooltip": ""
          }
        },
        "1598945670b848f583cec1b35b1bb468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "VBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "VBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_3e6f83dc772e4c89aa720c9355c7ba95",
              "IPY_MODEL_2f8ff6d585ee49c9a4b49cf0262a5247"
            ],
            "layout": "IPY_MODEL_9be374d9066f47149605ab86d2d4fa7c"
          }
        },
        "d1e4f28761134ee792167907372f381a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Right",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_f819246ede554dd493f26e90c691b831",
            "style": "IPY_MODEL_1ea4ed0a65494188a9bb172fd0a9d7d7",
            "tooltip": ""
          }
        },
        "cd131653ed164b58b38316750e1f4a25": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "4d86805f8600486c81b0d20cb266f89f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": "18.8em",
            "min_height": "6.3em",
            "min_width": "12.5em",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": "auto",
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "266df4330d044f1cad2935628f4da6f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": "21.0em",
            "min_height": "10.0em",
            "min_width": "20.0em",
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": "auto",
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "20.0em"
          }
        },
        "d64fa95a529f497c8a9f898fb6924c78": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "ce891d77e3204d8ba53025d39848e415": {
          "model_module": "jupyter-matplotlib",
          "model_name": "ToolbarModel",
          "model_module_version": "^0.11",
          "state": {
            "_current_action": "",
            "_dom_classes": [],
            "_model_module": "jupyter-matplotlib",
            "_model_module_version": "^0.11",
            "_model_name": "ToolbarModel",
            "_view_count": null,
            "_view_module": "jupyter-matplotlib",
            "_view_module_version": "^0.11",
            "_view_name": "ToolbarView",
            "button_style": "",
            "collapsed": true,
            "layout": "IPY_MODEL_f101ba2a0d4145449911a9863bb35332",
            "orientation": "vertical",
            "toolitems": [
              [
                "Home",
                "Reset original view",
                "home",
                "home"
              ],
              [
                "Back",
                "Back to previous view",
                "arrow-left",
                "back"
              ],
              [
                "Forward",
                "Forward to next view",
                "arrow-right",
                "forward"
              ],
              [
                "Pan",
                "Left button pans, Right button zooms\nx/y fixes axis, CTRL fixes aspect",
                "arrows",
                "pan"
              ],
              [
                "Zoom",
                "Zoom to rectangle\nx/y fixes axis",
                "square-o",
                "zoom"
              ],
              [
                "Download",
                "Download plot",
                "floppy-o",
                "save_figure"
              ]
            ]
          }
        },
        "f747f187268e45b1a8716ed25649b798": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "6.3em"
          }
        },
        "c1dba2ccfa004f39a72a8d2a52f9305b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "3e6f83dc772e4c89aa720c9355c7ba95": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Up",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_61a8b2dfa3b5401a883c9c1c02b2c3ab",
            "style": "IPY_MODEL_3b42aedbd614434ca5d5f79f3f3adab3",
            "tooltip": ""
          }
        },
        "2f8ff6d585ee49c9a4b49cf0262a5247": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ButtonView",
            "button_style": "",
            "description": "Down",
            "disabled": false,
            "icon": "",
            "layout": "IPY_MODEL_73dd3e88a456493baee99ea0ec3a8989",
            "style": "IPY_MODEL_9c8f5665070746f1823ad70af408abbe",
            "tooltip": ""
          }
        },
        "9be374d9066f47149605ab86d2d4fa7c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f819246ede554dd493f26e90c691b831": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "6.3em"
          }
        },
        "1ea4ed0a65494188a9bb172fd0a9d7d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "f101ba2a0d4145449911a9863bb35332": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "61a8b2dfa3b5401a883c9c1c02b2c3ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "6.3em"
          }
        },
        "3b42aedbd614434ca5d5f79f3f3adab3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        },
        "73dd3e88a456493baee99ea0ec3a8989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": "6.3em"
          }
        },
        "9c8f5665070746f1823ad70af408abbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ButtonStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ButtonStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "button_color": null,
            "font_weight": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}