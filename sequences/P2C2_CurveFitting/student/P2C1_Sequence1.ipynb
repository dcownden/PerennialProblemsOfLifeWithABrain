{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {},
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/dcownden/PerennialProblemsOfLifeWithABrain/blob/main/sequences/P2C1_CurveFitting/student/P2C1_Sequence1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a> &nbsp; <a href=\"https://kaggle.com/kernels/welcome?src=https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/sequences/P2C1_CurveFitting/student/P2C1_Sequence1.ipynb\" target=\"_parent\"><img src=\"https://kaggle.com/static/images/open-in-kaggle.svg\" alt=\"Open in Kaggle\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "The following is part of a test for an upcoming text book on computational neuroscience from an optimization and learning perspective. The book will start with evolution because ultimately, all aspects of the brain are shaped by evolution and, as we will see, evolution can also be seen as an optimization algorithm. We are sharing it now to get feedback on what works and what does not and the developments we should do."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "___\n",
    "# **2.1.1: Curve Fitting Through Perturbation**\n",
    "In the first part of the book we gained insight into what the brain is for: rapid acquisition of adaptive behaviours. Now that we know what a brain is for, we are going to start thinking about how it does what it needs to do. Instead of taking a bottom up approach grounded in observed physiological mechanisms, we are going to use a problem oriented, top down approach. That is, we will think about what problems the brain is solving and then survey the various physiological mechanisms that could feasibly implement algorithms that solve those problems. We will start with problems that are simple to understand from a statistical and mathematical perspective; a broad sub-field of machine learning known as supervised learning. Supervised learning problems take as given many affordances and abilities without obvious physiological implementations in the brain. Nevertheless, for simplicity and to build foundational understanding, we start with this class of problems and associated algorithms, drawing connections to physiological mechanisms where we can. As more elaborate learning algorithms (un/semi-supervised learning, complex reinforcement learning) and their applications become clear, we promise that an outline of the physiology of a unified neural system which feasibly solves the myriad statistical decision problems faced by living animals will emerge.\n",
    "\n",
    "### Objective: Solve a simple problem using perturbation methods, and connect these methods with physiological neural plasticity mechanisms.\n",
    "\n",
    "In this sequence we will:\n",
    "\n",
    "* Introduce two visual (binary) discrimination tasks, one simple, the other more complex.\n",
    "\n",
    "* Build and train a simple 'neural circuit' model which 'learns' to solve these binary discrimination problems based on scalar reward feedback.\n",
    "\n",
    "* Relate the different aspects of our simple 'neural circuit' model to various neural plasticity mechanisms.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Setup\n",
    "\n",
    "Run the following cell to setup and install the various dependencies and helper functions for this ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Dependencies, Imports and Setup\n",
    "# @markdown You don't need to worry about how this code works â€“ but you do need to **run the cell**\n",
    "!apt install libgraphviz-dev > /dev/null 2> /dev/null #colab\n",
    "!pip install ipympl pygraphviz vibecheck datatops jupyterquiz ucimlrepo > /dev/null 2> /dev/null #google.colab\n",
    "\n",
    "import requests\n",
    "from requests.exceptions import RequestException\n",
    "import numpy as np\n",
    "import itertools\n",
    "import collections\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "from matplotlib.animation import FuncAnimation\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import pygraphviz as pgv\n",
    "import ipywidgets as widgets\n",
    "import time\n",
    "import logging\n",
    "import random\n",
    "import os\n",
    "import copy\n",
    "import torch\n",
    "import warnings\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from io import BytesIO\n",
    "from enum import Enum\n",
    "from scipy.spatial.distance import cdist\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from tabulate import tabulate\n",
    "from IPython.display import display, clear_output, Markdown, HTML, Image\n",
    "from jupyterquiz import display_quiz\n",
    "from vibecheck import DatatopsContentReviewContainer\n",
    "from pathlib import Path\n",
    "from typing import List, Dict\n",
    "from tqdm.notebook import tqdm\n",
    "from ucimlrepo import fetch_ucirepo\n",
    "\n",
    "data_set = fetch_ucirepo(id=80)\n",
    "X = data_set.data.features.values\n",
    "# Translate the data to have a minimum of 0\n",
    "X_translated = X - X.min()\n",
    "# Scale the data to have a range from 0 to 12 (which is 6 - (-6))\n",
    "scaling_factor = 12 / (X.max() - X.min())\n",
    "X_scaled = X_translated * scaling_factor\n",
    "# Finally, shift the data to be centered between -6 and 6\n",
    "X_final = X_scaled - 6\n",
    "\n",
    "y = data_set.data.targets.values\n",
    "rng = np.random.default_rng(seed=2021)\n",
    "scramble_permutation = rng.permutation(X.shape[1])\n",
    "Xs = X_final[:, scramble_permutation]\n",
    "y1 = y % 2\n",
    "y2 = np.array(y >= 5, dtype=y.dtype)\n",
    "simple_index = ((y.flatten()==1) | (y.flatten()==0))\n",
    "X_simple = Xs[simple_index]\n",
    "y1_simple = y1[simple_index]\n",
    "# if you only had one feature which would likely be best for discrimination\n",
    "epsilon = 10\n",
    "class_a_sep = np.mean(X_simple[y1_simple.flatten() == 1, :], axis=0) / (np.std(X_simple[y1_simple.flatten() == 1, :], axis=0) + epsilon)\n",
    "class_b_sep = np.mean(X_simple[y1_simple.flatten() == 0, :], axis=0) / (np.std(X_simple[y1_simple.flatten() == 0, :], axis=0) + epsilon)\n",
    "best_feature = np.argmax(class_a_sep - class_b_sep)\n",
    "print(f'Best feature is {best_feature}')\n",
    "X_simple_1_feature = X_simple[:, [best_feature]]\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning, module=\"matplotlib\")\n",
    "# random seed settings and\n",
    "# getting torch to use gpu if it's there\n",
    "\n",
    "\n",
    "def set_seed(seed=None, seed_torch=True):\n",
    "  \"\"\"\n",
    "  Function that controls randomness. NumPy and random modules must be imported.\n",
    "\n",
    "  Args:\n",
    "    seed : Integer\n",
    "      A non-negative integer that defines the random state. Default is `None`.\n",
    "    seed_torch : Boolean\n",
    "      If `True` sets the random seed for pytorch tensors, so pytorch module\n",
    "      must be imported. Default is `True`.\n",
    "\n",
    "  Returns:\n",
    "    Nothing.\n",
    "  \"\"\"\n",
    "  if seed is None:\n",
    "    seed = np.random.choice(2 ** 32)\n",
    "  random.seed(seed)\n",
    "  np.random.seed(seed)\n",
    "  if seed_torch:\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "\n",
    "  print(f'Random seed {seed} has been set.')\n",
    "\n",
    "\n",
    "def seed_worker(worker_id):\n",
    "  \"\"\"\n",
    "  DataLoader will reseed workers following randomness in\n",
    "  multi-process data loading algorithm.\n",
    "\n",
    "  Args:\n",
    "    worker_id: integer\n",
    "      ID of subprocess to seed. 0 means that\n",
    "      the data will be loaded in the main process\n",
    "      Refer: https://pytorch.org/docs/stable/data.html#data-loading-randomness for more details\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  worker_seed = torch.initial_seed() % 2**32\n",
    "  np.random.seed(worker_seed)\n",
    "  random.seed(worker_seed)\n",
    "\n",
    "\n",
    "def set_device():\n",
    "  \"\"\"\n",
    "  Set the device. CUDA if available, CPU otherwise\n",
    "\n",
    "  Args:\n",
    "    None\n",
    "\n",
    "  Returns:\n",
    "    Nothing\n",
    "  \"\"\"\n",
    "  device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "  if device != \"cuda\":\n",
    "    print(\"This notebook isn't using and doesn't need a GPU. Good.\")\n",
    "  else:\n",
    "    print(\"GPU is enabled in this notebook but not needed.\")\n",
    "    print(\"If possible, in the menu under `Runtime` -> \")\n",
    "    print(\"`Change runtime type.`  select `CPU`\")\n",
    "\n",
    "  return device\n",
    "\n",
    "\n",
    "SEED = 2021\n",
    "set_seed(seed=SEED)\n",
    "DEVICE = set_device()\n",
    "\n",
    "\n",
    "def printmd(string):\n",
    "  display(Markdown(string))\n",
    "\n",
    "\n",
    "# the different utility .py files used in this notebook\n",
    "filenames = []\n",
    "# just run the code straight out of the response, no local copies needed!\n",
    "for filename in filenames:\n",
    "  url = f'https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/utils/{filename}'\n",
    "  response = requests.get(url)\n",
    "  # Check that we got a valid response\n",
    "  if response.status_code == 200:\n",
    "    code = response.content.decode()\n",
    "    exec(code)\n",
    "  else:\n",
    "    print(f'Failed to download {url}')\n",
    "\n",
    "# environment contingent imports\n",
    "try:\n",
    "  print('Running in colab')\n",
    "  from google.colab import output\n",
    "  output.enable_custom_widget_manager()\n",
    "  from google.colab import data_table\n",
    "  data_table.disable_dataframe_formatter()\n",
    "  #from google.colab import output as colab_output\n",
    "  #colab_output.enable_custom_widget_manager()\n",
    "  IN_COLAB = True\n",
    "except:\n",
    "  IN_COLAB = False\n",
    "  print('Not running in colab')\n",
    "\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%matplotlib widget\n",
    "plt.style.use(\"https://raw.githubusercontent.com/dcownden/PerennialProblemsOfLifeWithABrain/main/pplb.mplstyle\")\n",
    "plt.ioff() #need to use plt.show() or display explicitly\n",
    "logging.getLogger('matplotlib.font_manager').setLevel(logging.ERROR)\n",
    "\n",
    "\n",
    "def remove_ip_clutter(fig):\n",
    "  fig.canvas.header_visible = False\n",
    "  fig.canvas.toolbar_visible = False\n",
    "  fig.canvas.resizable = False\n",
    "  fig.canvas.footer_visible = False\n",
    "  fig.canvas.draw()\n",
    "\n",
    "\n",
    "def content_review(notebook_section: str):\n",
    "  return DatatopsContentReviewContainer(\n",
    "    \"\",  # No text prompt\n",
    "    notebook_section,\n",
    "    {\n",
    "      \"url\": \"https://pmyvdlilci.execute-api.us-east-1.amazonaws.com/klab\",\n",
    "      \"name\": \"neuro_book\",\n",
    "      \"user_key\": \"xuk960xj\",\n",
    "    },\n",
    "  ).render()\n",
    "feedback_prefix = \"P2C1_S1\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# 2.1.1.1: Learning to Do the Right Thing\n",
    "\n",
    "In our last chapter on evolution, we motivated much of our modeling using a binary classification problem in which a lurking predator must choose between striking and not striking based on sensory input. Initially, we viewed the behavioral map from sensory input to action as genetically determined. However, we concluded the last chapter by highlighting the evolutionary advantage of at least partially learning these sensory-behaviour maps within an organism's lifetime. These advantages emerge in part due to variable environments and complex behaviors with non-linear fitness impacts. Here we shift our focus and work with the case where the behavioural map from sensory input to action is to be entirely 'learned' by the organism, using feedback signals from the environment. Before we build a highly abstracted model of a neural circuit to solve this problem, let's see if your neural network is up to the task. Given a sensory input pattern, determine whether to strike or not. Try to maximize your average score and see how well you can perform. We will start with a very simple 'sensory' pattern."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown **Run this cell** to try out the 'strike-no-strike' discrimination task.\n",
    "\n",
    "class InteractiveMNISTPredator():\n",
    "  def __init__(self,\n",
    "               features=Xs,\n",
    "               labels=y,\n",
    "               feedback_type='on_strike_only', seed=123):\n",
    "    # Initialize dataset, settings for image scrambling and feedback\n",
    "    self.features = features\n",
    "    self.labels = labels\n",
    "    # features is num_data_points x 64 (reshape to 8x8 for display, each cell 0-16)\n",
    "    # labels is num_data_points x 1 (values 0-9 or 0/1 depending)\n",
    "    self.feedback_type = feedback_type\n",
    "    self.rng = np.random.default_rng(seed)\n",
    "    sample_order = self.rng.permutation(self.features.shape[0])\n",
    "    self.features = self.features[sample_order]\n",
    "    self.labels = self.labels[sample_order]\n",
    "    # initialize game state\n",
    "    self.current_index = 0\n",
    "    self.score = 0\n",
    "    self.best_possible_score = 0\n",
    "    self.successful_strikes = 0\n",
    "    self.failed_strikes = 0\n",
    "    self.non_strikes = 0\n",
    "    # Initialize widgets\n",
    "    self.strike_button = widgets.Button(description='Strike')\n",
    "    self.no_strike_button = widgets.Button(description='No Strike')\n",
    "    self.score_display = widgets.Output()\n",
    "    self.feedback_display = widgets.Output()\n",
    "\n",
    "    # Initialize the figure for image display\n",
    "    self.fig, self.ax = plt.subplots(figsize=(4, 4))\n",
    "    remove_ip_clutter(self.fig)\n",
    "    self.show_next_image()\n",
    "    # Bind event handlers\n",
    "    self.strike_button.on_click(self.on_strike_clicked)\n",
    "    self.no_strike_button.on_click(self.on_no_strike_clicked)\n",
    "\n",
    "    # Arrange widgets in a layout\n",
    "    buttons_layout = widgets.HBox([self.strike_button, self.no_strike_button])\n",
    "    board_buttons = widgets.VBox([self.fig.canvas, buttons_layout])\n",
    "    self.ui = widgets.HBox([board_buttons, widgets.VBox([self.score_display,\n",
    "                                                         self.feedback_display])])\n",
    "\n",
    "  def show_next_image(self):\n",
    "    # Display the next image\n",
    "    image = self.features[self.current_index]\n",
    "    if len(image) == 64:\n",
    "        image = image.reshape(8, 8)\n",
    "    elif len(image) == 1:\n",
    "      scalar_value = image.flatten()[0]\n",
    "      # Initialize the 8x8 array with -6 (black)\n",
    "      image = np.full((8, 8), -6.0)\n",
    "      # Set the second ring to 6 (white)\n",
    "      image[1:-1, 1:-1] = 6\n",
    "      # Set the third (inner ring) back to -6 (black)\n",
    "      image[2:-2, 2:-2] = -6\n",
    "      # Assuming scalar_value is already in the range -6 to 6\n",
    "      #print(scalar_value)\n",
    "      image[3:-3, 3:-3] = scalar_value\n",
    "    else:\n",
    "      raise ValueError(f'Unexpected image shape: {image.shape}')\n",
    "    # Display the image\n",
    "    #print(image)\n",
    "    self.fig.clf()\n",
    "    self.ax = self.fig.add_subplot(111)\n",
    "    self.ax.set_xlim(-.5, 7.5)\n",
    "    self.ax.set_ylim(-0.5, 7.5)\n",
    "    self.ax.set_aspect('equal')\n",
    "    self.ax.axis('off')\n",
    "    self.ax.imshow(image, cmap='gray', vmin=-6, vmax=6)\n",
    "    self.fig.canvas.draw_idle()  # Force redraw\n",
    "\n",
    "  def on_strike_clicked(self, button):\n",
    "    self.process_decision('Strike')\n",
    "\n",
    "  def on_no_strike_clicked(self, button):\n",
    "    self.process_decision('No Strike')\n",
    "\n",
    "  def process_decision(self, decision):\n",
    "    # freeze buttons while we process\n",
    "    self.strike_button.disabled = True\n",
    "    self.no_strike_button.disabled = True\n",
    "\n",
    "    # Process the user's decision, update score, and provide feedback\n",
    "    correct_action = 'Strike' if self.labels[self.current_index] == 1 else 'No Strike'\n",
    "    if decision == 'Strike':\n",
    "      if decision == correct_action:\n",
    "        self.score += 1\n",
    "        self.successful_strikes += 1\n",
    "      else:\n",
    "        self.score -= 1\n",
    "        self.failed_strikes += 1\n",
    "    elif decision == 'No Strike':\n",
    "      self.non_strikes += 1\n",
    "      # no strike means no gain or loss\n",
    "    else:\n",
    "      raise ValueError(f'Unknown decision: {decision}')\n",
    "\n",
    "    # Show feedback and score\n",
    "    if (self.feedback_type == 'both' or\n",
    "      (self.feedback_type == 'on_strike_only' and decision == 'Strike')):\n",
    "      # Show informative feedback\n",
    "      feedback = f'Your last choice: {decision}\\nCorrect last choice: {correct_action}'\n",
    "    else:\n",
    "      # Show uninformative feedback\n",
    "      feedback = 'Feedback only available after striking.'\n",
    "    with self.feedback_display:\n",
    "      clear_output(wait=True)\n",
    "      print(feedback)\n",
    "\n",
    "    # Show score\n",
    "    with self.score_display:\n",
    "      clear_output(wait=True)\n",
    "      average_score = self.score / (self.current_index+1)\n",
    "      print(f'Total Score: {self.score}')\n",
    "      print(f'Number of Trials: {self.current_index + 1}')\n",
    "      print(f'Successful Strikes: {self.successful_strikes}')\n",
    "      print(f'Failed Strikes: {self.failed_strikes}')\n",
    "      print(f'Non-Strikes: {self.non_strikes}')\n",
    "      print(f'Average Score Per Trial: {average_score:.2f}')\n",
    "\n",
    "    # Prepare the next image\n",
    "    self.current_index += 1\n",
    "    #print(self.current_index)\n",
    "    self.show_next_image()\n",
    "    # Re-enable buttons\n",
    "    self.strike_button.disabled = False\n",
    "    self.no_strike_button.disabled = False\n",
    "\n",
    "\n",
    "scramble_01_imp = InteractiveMNISTPredator(features=X_simple_1_feature,\n",
    "                                           labels=y1_simple, feedback_type='both')\n",
    "display(scramble_01_imp.fig.canvas)\n",
    "clear_output()\n",
    "display(scramble_01_imp.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "For us at least, this task wasn't too hard. The simple association - strike when the center pixel is relatively light, don't strike when the center pixel is dark - works well. We can learn this association with our eyes and brains. Now, let's see if we can come up with a way to program an algorithm that will also learn this association. The dataset that underlies this strike-no-strike decision problem is sourced from the UCI Machine Learning Repository, (Alpaydin,E. and Kaynak,C. 1998. https://doi.org/10.24432/C50P49). Let's take a quick look at the data before we start coming up with a simple machine learning algorithm to correctly distinguish between the strike and no-strike cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# What is the shape and type of the data we have to work with\n",
    "print(f'features data type: {X_simple_1_feature.dtype}')\n",
    "print(f'features shape: {X_simple_1_feature.shape}')\n",
    "print(f'labels data type: {y1_simple.dtype}')\n",
    "print(f'labels shape: {y1_simple.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# what do the labels look like, what is their range\n",
    "print(y1_simple[:10])\n",
    "print(f'max label: {np.max(y1_simple)}')\n",
    "print(f'min label: {np.min(y1_simple)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "***Note on Terminology:*** In a Supervised Learning context what we have been thinking of as the inputs to a sensory-behaviour circuit are called **features**. In a statistical/regression/experimental context these features or inputs are thought of as the independent variables or regressors. The 'correct' behavioural output is called the **label** or **target** in a supervised learning ML context, or the dependent variable in a statistical/regression/experimental context. Supervised Learning revolves around the concept of feature-label or $(\\mathbf{x},\\mathbf{y})$ pairs. The basic goal of Supervised Learning is to discover the rule or process that generates these pairs, or a good approximation of it, solely by examining examples. The set of examples that we have to learn the rule from is called the **training set**. We will use the terms features and label when we want to emphasize the abstract algorithm and learning problem, and the terms sensory-input and target behaviour when we want to emphasize the embodied neural context of the problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In the game we setup above we used the label '1' to correspond to situations when 'strike' is the correct action and the label '0' to correspond to situations where 'no-strike' is the correct action."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# what do the features look like, what is there range\n",
    "print(X_simple_1_feature[:10])\n",
    "print(f'max features: {np.max(X_simple_1_feature)}')\n",
    "print(f'min features: {np.min(X_simple_1_feature)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In the visualization above a high 'feature value' corresponded to lighter colors in the center pixels and a lower feature value corresponded to darker feature values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# and for scalar data always good to look at a histogram\n",
    "fig, (ax1, ax2) = plt.subplots(2, 1)\n",
    "ax1.hist(X_simple_1_feature[y1_simple.flatten() == 1])\n",
    "ax1.set_title('Feature Distribution When Strike is Correct')\n",
    "ax2.hist(X_simple_1_feature[y1_simple.flatten() == 0])\n",
    "ax2.set_title('Feature Distribution When No-Strike is Correct')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Looking at the distribution of the feature across these two classes (strike vs. no-strike situations), we see that we should be able to correctly discriminate between these two cases most of the time using just this one feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Now, if we were acting as scientists (which we sometimes do!), we'd think hard and carefully about the specific physical processes behind these features (the ML term for model/sensory inputs) and labels (the ML term for 'correct answer'), and this would guide the types of analyses to perform on the data and the kinds of inferences and conclusions we could draw.\n",
    "But in this moment, we're not acting as scientists in pursuit of deep understanding; we're acting as algorithm designers focused on figuring out how to do the right thing. We want to come up with a process for 'learning a function' that takes this feature as an input and generates the correct behaviour (as defined by the labels) as output. A zero label means no strike is the right thing to do (no prey present) and a one label means striking is the right thing to do (prey are present).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As inspiration for our learning algorithm we imagine a very simple organism. One that has a single sensory input neuron, in turn connected to a single output neuron by single synaptic weight. If the output neuron fires (spikes) the predator strikes, and if it does not fire the predator does not strike.\n",
    "\n",
    "We model this creature's sensory-behaviour system as follows. Let $x$ be the raw sensory input (scalar) in a given episode. We imagine that $x$ corresponds to the activation level and firing rate of a single photosensitive neuron. This input neuron is then connected by a synapse to a single output neuron. The activation level of this output neuron is computed as\n",
    "$$y = wx + b$$\n",
    "Here, $b$ is the (scalar) bias, or baseline activation level of the output neuron and $w$ is the strength of the synaptic weight between the input neuron and the output neuron. Is this case there is only one output and one input so $w$ is a scalar. In cases with multiple inputs and outputs we would use $\\mathbf{W}$ to denote the matrix of such synaptic weights and $\\mathbf{x}$ to denote the vector of sensory inputs. (A quick notation reminder: bold lowercase letters typically represent column vectors, bold uppercase letters typically denote matrices or higher-order tensors.) We imagine that the probabilistic spiking of this output neuron determines the strike-no-strike behaviour of the organism, specifically:\n",
    "$$ \\Pr \\{\\text{strike}\\} = \\sigma(y) $$\n",
    "$$ \\Pr \\{\\text{no strike}\\} = 1 - \\sigma(y)$$\n",
    "\n",
    "Here $\\sigma(y): \\frac{1}{1+e^{-y}} = \\frac{e^y}{1+e^y}$ is the standard logistic (sigmoid) function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "--Picture of this very simple neural circuit here--"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "**Quick Math Exercise: The Connection Between Softmax Normalization and the Standard Logistic Sigmoid.**\n",
    "\n",
    "Consider a random variable with two possible outcomes, $A$ and $B$. The probability of each outcome is determined by applying the softmax function to their respective scores, $a$ and $b$. Specifically, the probability of outcome $A$ occurring is given by the softmax formula:\n",
    "$$ \\Pr \\{A\\} = \\frac{e^a}{e^a + e^b}$$\n",
    "Interestingly, $\\Pr\\{A\\}$ can be expressed in terms of the logistic (sigmoid) function, $\\sigma(x)$, where $x$ is a function of the scores $a$ and $b$. Your task is to determine this function, denoted as $f(a, b)$, so that $\\Pr{A} = \\sigma(f(a, b))$.\n",
    "\n",
    "(Answer: $$\\frac{e^a}{e^a + e^b} = \\frac{1}{1 + e^{b-a}} = \\sigma(a-b)$$\n",
    "The sigmoid of the difference in the scores gives the probability.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Having established how behaviour is determined by sensory input, $x$, and parameters $w$, $b$, i.e. our policy, we now need to develop a rule for modifying this policy based on environmental feedback.\n",
    "\n",
    "Our goal is to come up with a rule that prescribes changes to the synaptic weight $w$ and bias $b$ in such a way that the reward obtained over time increases (and ideally approaches the theoretical maximum over many learning trials).\n",
    "\n",
    "Our previous 'guess and check' learning method from sequence 1.3.4, while not the most efficient, proved effective, as were the 'propose and reject' style algorithms that we explored earlier and that are akin to what evolution by natural selection implements. Building on this idea of 'propose and reject' we will perturb the existing parameters by a small amount and evaluate the behaviour function using the perturbed parameters. However, instead of just simply accepting or rejecting the proposed parameters (kind of like natural selection does) we will instead ***measure the relationship between the change in the performance of the organism (in terms of reward obtained) and the changes in the parameters.*** An update will then be applied to the weights that is ***proportional*** to the ***measured performance changes*** over the ***measured parameter changes***, i.e. an estimate of the rate of change in performance for changes in the parameters. As a word equation\n",
    "\n",
    "$$ \\text{Parameter Update} = \\alpha \\cdot \\frac{\\text{Measured Perturbation in Performance}}{\\text{Measured Perturbation in Parameters}}$$\n",
    "\n",
    "where $\\alpha$ is some constant of proportionality, in this case usually called the learning rate or step-size meta-parameter of the learning algorithm.\n",
    "\n",
    "On the one hand we might expect a 'measure and update' method to be more efficient than a 'propose and reject' method, because with a 'propose and reject' algorithm we don't make any parameter updates unless 'better' parameters are proposed. This means that most of the information from evaluation is thrown away every time parameters are rejected. In contrast, a 'measure and update' method will always updated the parameters using the information gleaned from the tested parameters. However, unlike the 'propose and reject' algorithm it's possible that the updates made by a 'measure and update' approach do not actually improve performance.\n",
    "\n",
    "Let's try it and see."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO for students: Complete the lines with ... to implement a parameter\n",
    "# evaluation function\n",
    "raise NotImplementedError(\"Exercise: parameter evaluation\")\n",
    "################################################################################\n",
    "\n",
    "\n",
    "def np_sigmoid(x):\n",
    "  return 1 / (1 + np.exp(-x))\n",
    "\n",
    "\n",
    "def eval_params_slow(w, b, x, y):\n",
    "  \"\"\"\n",
    "  evaluates parameters of simple behaviour circuit given inputs and target\n",
    "  outputs, use for loops to think carefully about what we're doing\n",
    "  Args:\n",
    "    w: (scalar) weight between sensory and output neuron\n",
    "    b: (scalar) bias of behavioural output neuron\n",
    "    x: (1 np.array x batch) sensory input\n",
    "       (can be single input, mini-batch of inputs or the whole batch of inputs)\n",
    "    y: (1 np.array x batch) target behavioural output (can be a single target,\n",
    "       mini-batch of targets, or whole batch), needs to correspond to input\n",
    "\n",
    "  Returns:\n",
    "    R_bar: the average/expected reward obtained given the parameters, over the\n",
    "           (mini-)batch of inputs and targets. (mini-batch could be size 1)\n",
    "  \"\"\"\n",
    "  batch_len = x.shape[1]\n",
    "  h = np.zeros((1, batch_len))\n",
    "  y_hat = np.zeros((1, batch_len))\n",
    "  R_total = 0\n",
    "  for ii in range(batch_len):\n",
    "    h[0,ii] = ...\n",
    "    y_hat[0,ii] = np_sigmoid(...)\n",
    "    # y_hat is our probability of striking\n",
    "    # compute the expected score\n",
    "    if y[0,ii] == 1:\n",
    "      # supposed to strike\n",
    "      # with probability y_hat creature strikes and gets a point\n",
    "      R_total += y_hat[0,ii] * 1.0\n",
    "      # with probability 1-y_hat creature doesn't strike and gets zero points\n",
    "      R_total += (1-y_hat[0,ii]) * 0.0\n",
    "    elif y[0,ii] == 0:\n",
    "      # not supposed to strike\n",
    "      # with probability y_hat creature strikes and loses a point\n",
    "      R_total += y_hat[0,ii] * -1.0\n",
    "      # with probability 1-y_hat creature doesn't strike and gets zero points\n",
    "      R_total += (1-y_hat[0,ii]) * 0.0\n",
    "    else:\n",
    "      raise ValueError(f'Unexpected target: {y[ii,0]}')\n",
    "  R_avg = R_total / batch_len\n",
    "  return R_avg\n",
    "\n",
    "\n",
    "def eval_params(w, b, x, y):\n",
    "  \"\"\"\n",
    "  evaluates parameters of simple behaviour circuit given inputs and target\n",
    "  outputs, use numpy broadcasting to be fast and concise\n",
    "  Args:\n",
    "    w: (scalar) weight between sensory and output neuron\n",
    "    b: (scalar) bias of behavioural output neuron\n",
    "    x: (batch x 1 np.array) sensory input\n",
    "       (can be single input, mini-batch of inputs or the whole batch of inputs)\n",
    "    y: (batch x 1 np.array) target behavioural output (can be a single target,\n",
    "       mini-batch of targets, or whole batch), needs to correspond to input\n",
    "\n",
    "  Returns:\n",
    "    R_bar: the average/expected reward obtained given the parameters, over the\n",
    "           (mini-)batch of inputs and targets. (mini-batch could be size 1)\n",
    "  \"\"\"\n",
    "  h = w * x + b\n",
    "  y_hat = np_sigmoid(h)\n",
    "  y_score = np.copy(y)\n",
    "  y_score[y_score == 0] = -1\n",
    "  batch_expected_reward = y_score * y_hat\n",
    "  R_avg = np.mean(batch_expected_reward)\n",
    "  return R_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/dcownden/PerennialProblemsOfLifeWithABrain/tree/main//sequences/P2C1_CurveFitting/solutions/P2C1_Sequence1_Solution_d8158759.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In this exercise, we actually implemented the same function twice, once using a for loop to iterate over the (mini-)batch of inputs and targets, and once using NumPy broadcasting to compute the batch reward (roughly) in parallel. Run the following code cells to see what kind of computational efficiency this buys us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "X_simple_1_feature.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "eval_params_slow(1, 0, X_simple_1_feature.T, y1_simple.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "eval_params(1, 0, X_simple_1_feature.T, y1_simple.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "%timeit eval_params_slow(1, 0, X_simple_1_feature.T, y1_simple.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "%timeit eval_params(1, 0, X_simple_1_feature.T, y1_simple.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "In our specific example (on the specific COLAB instance we're writing this on in 2024), the broadcasting approach in Python, using NumPy, is approximately 50 times faster than using for-loops. This is because for-loops in interpreted languages like Python incur significant overhead at each iteration, but also because potential dependencies between loop iterations limit parallelization. In contrast, broadcasting allows for vectorized operations, enabling parallel execution that can harness more of the underlying hardware's computational power. NumPy enhances this efficiency further by utilizing highly optimized, pre-compiled linear algebra libraries (primarily hardware-specific implementations of BLAS and LAPACK). The same principles apply (though are sometimes less critical) in compiled languages or with Just-In-Time (JIT) compilation frameworks like JAX. Broadcasting or tensor notation not only improves performance but also maintains code brevity and alignment with mathematical notation. As scientists and programmers, we do not need to understand every detail of how the magic of computational parallelism allows for fast linear algebra, but it is crucial to appreciate the potential impacts on computational efficiency."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Okay, so we have the ability to evaluate the parameters in terms of the average score they yield when applied across the whole dataset of example pairs of sensory inputs and correct actions. In each iteration of our learning (training) loop, we will perturb our parameters using Gaussian noise and ***measure the relationship*** between the parameter changes and the average expected reward as determined by our evaluation function. After measuring this relationship, we will update each parameter in proportion to the rate of improvement of the score with respect to the change in the underlying parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Measure and Update Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# TODO for students: Complete the lines with ... to implement a parameter\n",
    "# evalution function\n",
    "raise NotImplementedError(\"Exercise: Measure and Update Training Loop\")\n",
    "################################################################################\n",
    "\n",
    "\n",
    "learn_rng = np.random.default_rng(0)\n",
    "num_learning_episodes = 100000\n",
    "alpha = 100 #learning rate / step size\n",
    "perturbation_scale = 0.01 # std of Gaussian parameter perturbations\n",
    "w_init = 1\n",
    "b_init = 0\n",
    "w = w_init\n",
    "b = b_init\n",
    "start_time = time.time()\n",
    "for ii in range(num_learning_episodes+1):\n",
    "  R_bar_old = eval_params(w, b, X_simple_1_feature.T, y1_simple.T)\n",
    "  # perturb w and evaluate\n",
    "  w_perturbation = learn_rng.normal(0, perturbation_scale)\n",
    "  w_perturbed = w + ...\n",
    "  R_bar_perturbed_w = eval_params(..., b, X_simple_1_feature.T, y1_simple.T)\n",
    "  # perturb b and evaluate\n",
    "  b_perturbation = learn_rng.normal(0, perturbation_scale)\n",
    "  b_perturbed = b + ...\n",
    "  R_bar_perturbed_b = eval_params(..., b_perturbed, X_simple_1_feature, y1_simple)\n",
    "  # estimate rate of change of reward for each parameter\n",
    "  finite_difference_w = ...\n",
    "  finite_difference_b = ...\n",
    "  # update parameters based on finte difference estimate rate of change\n",
    "  # of reward with respect to parameters\n",
    "  delta_w = alpha * finite_difference_w\n",
    "  delta_b = alpha * finite_difference_b\n",
    "  w += delta_w\n",
    "  b += delta_b\n",
    "\n",
    "  if ii == 0 or ii % 5000 == 0:\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'{\"Iteration\":>12}: {ii:<6} | {\"w\":>1}={w:<8.4f} | {\"b\":>1}={b:<8.4f} | {\"R_bar\":>5}={R_bar_old:<8.6f} | {\"Time\":>4}={elapsed_time:<5.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "execution": {}
   },
   "source": [
    "[*Click for solution*](https://github.com/dcownden/PerennialProblemsOfLifeWithABrain/tree/main//sequences/P2C1_CurveFitting/solutions/P2C1_Sequence1_Solution_23a7271d.py)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Is an R_bar of 0.4951... good or bad? Let's look at the data. How many striking opportunities are there, versus situation where no-strike is best?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# number of striking opportunities\n",
    "np.sum(y1_simple == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "#number of non-strike situations\n",
    "np.sum(y1_simple == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# proportion of situations where a point can be earned\n",
    "571 / (571 + 554)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "So, back to our question: Is an average score of 0.4951... per round good? Well, yes. A perfect score is ~0.5075. Given that we have only a single feature - that can't perfectly separate the two cases as the feature distributions for each case overlap - we are bound to have a few false positives and false negatives. These will lower the score a bit, but for the most part, this is roughly as good as can be expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "**Algorithmic Thinking Exercise:**\n",
    "\n",
    "In the 'measure and update' learning loop implemented above, we perturb each parameter, measure the effect of perturbations, and then update the parameters. Alternatively we could have perturbed the $w$ parameter, evaluated and then updated the $w$ parameter, and then perturbed the $b$ parameter, evaluated, and then updated the $b$ parameter.\n",
    "1. In the implementation above how many times is the `eval_params` function called per iteration?\n",
    "\n",
    "  (Answer: 3)\n",
    "2. If we used the alternative method where each parameter is updated and evaluated separately, how many times would eval_params need to be called per iteration?\n",
    "\n",
    "  (Answer: 4, After updating $w$ we can't simply use `R_bar_old` to measure the change in performance from changing $b$ since `R_bar_perturbed_b` will be computed using the updated $w$. An `R_bar_new_w_old_b` will need to be computed and used to inform the changes to $b$.)\n",
    "3. If we had $n$ parameters instead of 2, how many times would the `eval_params` function be called per iteration in the implementation above?\n",
    "\n",
    "  (Answer: $n+1$)\n",
    "4. If we had $n$ parameters instead of 2, how many times would the `eval_params` function be called per iteration in the alternate implementation?\n",
    "\n",
    "  (Answer: $2n$)\n",
    "\n",
    "Little details like this in implementation can make big differences to algorithm speed. Note though that this slower alternative isn't quite a dead loss. Technically the parameter updates made by the alternative algorithm, will be 'better' (precisely what we mean by better we leave aside for the moment), however, in this particular case the 'betterness' of the parameter updates is not enough to make up for the added computational cost of calling `eval_params` and extra $n-1$ times."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Okay, now just as a sanity and intuition check, two questions:\n",
    "1. Do we get the same answer when we use a propose and reject method?  \n",
    "2. Is the propose and reject method quicker or slower at finding the solution?\n",
    "Let's quickly adapt the adapt 'measure and update' learning loop to do 'propose and reject' instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Propose And Reject Training Loop\n",
    "learn_rng = np.random.default_rng(0)\n",
    "num_learning_episodes = 50000\n",
    "perturbation_scale = 0.1 # std of Gaussian parameter perturbations\n",
    "w_init = 1\n",
    "b_init = 0\n",
    "w = w_init\n",
    "b = b_init\n",
    "start_time = time.time()  # Record the start time\n",
    "R_bar_best = eval_params(w, b, X_simple_1_feature.T, y1_simple.T)\n",
    "for ii in range(num_learning_episodes+1):\n",
    "  # perturb w and evaluate\n",
    "  w_perturbation = learn_rng.normal(0, perturbation_scale)\n",
    "  w_proposed = w + w_perturbation\n",
    "  R_bar_proposed = eval_params(w_proposed, b, X_simple_1_feature, y1_simple)\n",
    "  if R_bar_best < R_bar_proposed:\n",
    "    w = w_proposed\n",
    "    R_bar_best = R_bar_proposed\n",
    "  # perturb b and evaluate\n",
    "  b_perturbation = learn_rng.normal(0, perturbation_scale)\n",
    "  b_proposed = b + b_perturbation\n",
    "  R_bar_proposed = eval_params(w, b_proposed, X_simple_1_feature, y1_simple)\n",
    "  if R_bar_best < R_bar_proposed:\n",
    "    b = b_proposed\n",
    "    R_bar_best = R_bar_proposed\n",
    "\n",
    "  if ii == 0 or ii % 5000 == 0:\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'{\"Iteration\":>12}: {ii:<6} | {\"w\":>1}={w:<8.4f} | {\"b\":>1}={b:<8.4f} | {\"R_bar\":>5}={R_bar_best:<8.6f} | {\"Time\":>4}={elapsed_time:<5.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Both 'Propose and Reject' and 'Measure and Update' get to similar answers, but 'Propose and Reject' gets there much more quickly. In part, this is because there are fewer calls to `eval_params` per iteration (2 instead of 3). Additionally, this is because the step size in parameter space remains relatively constant throughout the 'Propose and Reject' process, while in the 'Measure and Update' method, the step size in parameter space diminishes as the relative improvements in performance decrease. For these reasons, our initial hope that 'Measure and Update' might be more efficient that 'Propose and Reject' is not born out in this simple problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "-- animation of propose and reject versus measure and update in this simple 2 parameter problem --"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "A couple things to think about here:\n",
    "1. In our 'Measure and Update' implementation above we make one perturbation and one measurement of change in reward for each parameter. What would happen if we perturbed every parameter at once and then made a single measurement of change in reward? There would only be two calls to `eval_params` per iteration, regardless of the number of parameters. Together these two `eval_params` would measure the combined effect of all the parameter changes on reward. As a result the estimated effect of any one parameter on the reward would be polluted by the effects of all the other parameter perturbations. Whether this improves or breaks the algorithm will depend on whether the efficiency from fewer `eval_params` calls compensate for the noise introduced, or if the noise make these faster parameter updates fundamentally unhelpful? In other words is it better to take more/quicker noisy steps in parameters space or fewer/slower steps in better directions?\n",
    "2. In the learning loops above the impact on reward for a perturbation is measured using the entirety of the data set available to us. In this example the data set is only ~1000 examples, but what if it consisted of trillions of examples, would it still make sense to use the entire data set to evaluate each perturbation or would it be better to evaluate parameter changes using a smaller sample from this data set? Using a smaller sample will often make evaluations faster at the price of introducing noise to the estimate of rate of reward change (on the full data set) with respect to parameter changes. Again, this is question of more/quicker noisy steps or fewer/slower careful steps in parameters space.\n",
    "3. In the learning loops above we measure the relationship between parameter changes and reward changes using a single perturbation, but could we make better parameter updates if we measured using many perturbations before updating the parameters? This would require making more evaluations per update. Whether is this is a good or bad idea again comes down to a question of more/quicker noisy parameter updates versus fewer/slower careful parameter updates. What is the right balance?\n",
    "\n",
    "For this very straightforward problem these questions may seem kind of beside the point. We have a good answer, and it didn't take too long to get, why worry about these details now? We don't really need to now, but as we'll soon see, these details become increasingly relevant as we work to extend this 'measure and update' approach to a more complex problem. Indeed, the trade-off between more/quick noisy steps and few/slow careful steps is one of the fundamental questions at the dark heart of Machine Learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_M1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# 2.1.1.2: Learning to Do the Right Thing - Harder\n",
    "In the previous section, we worked on a pretty simple discrimination problem, there was a single feature that, for the most part, correlated with correct times to strike and not-strike. Now we're going to look at a slightly harder problem, where the answer is less obvious (to us at least). As before, given a sensory input pattern, the problem is to determine whether or not to strike. Again, try to maximize your average score for this new problem where the 'sensory' input is more complex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "scramble_bin_hard = InteractiveMNISTPredator(features=Xs,\n",
    "                                             labels=y1,\n",
    "                                             feedback_type='both')\n",
    "display(scramble_bin_hard.fig.canvas)\n",
    "clear_output()\n",
    "display(scramble_bin_hard.ui)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "So now instead of a single feature to base our strike/no-strike discrimination on, we have 64 (8x8) features to potentially inform our decision. Will our simple setup from before readily generalize to this situation with richer sensory input? Let's find out."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We model this creature's sensory-behaviour system much as before. Now, $\\mathbf{x}$ is the raw sensory input (vector) in a given episode. Each element $x_i$ of $\\mathbf{x}$ corresponds to the activation level and firing rate of a single photosensitive neuron."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# the data set we're working with has 5620 example sensory inputs,\n",
    "# each consisting of 64 (8x8) values\n",
    "print(Xs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# this is the first example\n",
    "print(Xs[0].reshape(8,8,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# visualizing the example we see that lower values correspond to darker pixels\n",
    "# and higher values correspond to lighter values\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "remove_ip_clutter(fig)\n",
    "ax.imshow(Xs[0].reshape(8,8), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "These input neurons are then connected by synapses to a single output neuron. The activation level of this output neuron is computed as\n",
    "$$y = \\mathbf{Wx} + b$$\n",
    "Here, $b$ is the (scalar) bias, or baseline activation level of the output neuron, and $\\mathbf{W}$ is a matrix of synaptic weights between the input neurons and the single output neuron. (In this case where there is only one output neuron so $\\mathbf{W}$ has shape 1x64 so could also be thought of as a row vector.)  As before, the probabilistic spiking of this output neuron determines the strike-no-strike behaviour of the organism, specifically:\n",
    "$$ \\Pr \\{\\text{strike}\\} = \\sigma(y) $$\n",
    "$$ \\Pr \\{\\text{no strike}\\} = 1 - \\sigma(y)$$\n",
    "\n",
    "Recall that $\\sigma(y): \\frac{1}{1+e^{-y}} = \\frac{e^y}{1+e^y}$ is the standard logistic (sigmoid) function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# the eval_params function needs to be adapted\n",
    "# to work with this richer sensory input\n",
    "def eval_params_rich(W, b, x, y):\n",
    "  \"\"\"\n",
    "  evaluates parameters of simple behaviour circuit given inputs and target\n",
    "  outputs, use numpy broadcasting to be fast and concise\n",
    "  Args:\n",
    "    W: (outputs(1) x inputs(64) np.array)\n",
    "       weights between sensory neurons and output neuron\n",
    "    b: (scalar) bias of behavioural output neuron\n",
    "    x: (input(64) x batch np.array) sensory input\n",
    "       (can be single input, mini-batch of inputs or the whole batch of inputs)\n",
    "    y: (outputs(1) x batch np.array) target behavioural output\n",
    "       (can be a single target, mini-batch of targets, or whole batch),\n",
    "       needs to correspond to input\n",
    "\n",
    "  Returns:\n",
    "    R_bar: the average/expected reward obtained given the parameters, over the\n",
    "           (mini-)batch of inputs and targets. (mini-batch could be size 1)\n",
    "  \"\"\"\n",
    "  h = np.dot(W,x) + b # 1 x batch\n",
    "  y_hat = np_sigmoid(h) # 1 x batch\n",
    "  y_score = np.copy(y)\n",
    "  y_score[y_score == 0] = -1\n",
    "  batch_expected_reward = y_score * y_hat\n",
    "  R_bar = np.mean(batch_expected_reward)\n",
    "  return R_bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "eval_params_rich(np.ones((1,64)), 0, Xs.T, y1.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "%timeit eval_params_rich(np.ones((1,64)), 0, Xs.T, y1.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "That's working and relatively quick now let's adapt our learning loop for this new setup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Measure and Update Training Loop\n",
    "\n",
    "learn_rng = np.random.default_rng(0)\n",
    "num_learning_episodes = 2000\n",
    "alpha = 0.5 #learning rate or step size\n",
    "perturbation_scale = 0.001 # std of gaussian perturbations\n",
    "W_init = np.zeros((1,64))\n",
    "b_init = 0\n",
    "W = W_init\n",
    "b = b_init\n",
    "start_time = time.time()\n",
    "for ii in range(num_learning_episodes+1):\n",
    "  R_bar_old = eval_params_rich(W, b, Xs.T, y1.T)\n",
    "  # get perturbations for W all at once\n",
    "  W_perturbations = learn_rng.normal(0, perturbation_scale, size=(1,64))\n",
    "  #perturb and evaluate each W_j separately\n",
    "  finite_differences_W = np.zeros(W.shape)\n",
    "  for j in range(W_perturbations.shape[1]):\n",
    "    W_perturbed = np.copy(W)\n",
    "    W_perturbed[0,j] += W_perturbations[0,j]\n",
    "    R_bar_perturbed_Wj = eval_params_rich(W_perturbed, b, Xs.T, y1.T)\n",
    "    finite_difference_Wj = (R_bar_perturbed_Wj - R_bar_old) / W_perturbations[0,j]\n",
    "    finite_differences_W[0,j] = finite_difference_Wj\n",
    "  # perturb b and evaluate\n",
    "  b_perturbation = learn_rng.normal(0, perturbation_scale)\n",
    "  b_perturbed = b + b_perturbation\n",
    "  R_bar_perturbed_b = eval_params_rich(W, b_perturbed, Xs.T, y1.T)\n",
    "  # estimate rate of change of reward for each parameter\n",
    "  finite_difference_b = (R_bar_perturbed_b - R_bar_old) / b_perturbation\n",
    "  # update parameters based on finte difference estimate rate of change\n",
    "  # of reward with respect to parameters\n",
    "  delta_W = alpha * finite_differences_W\n",
    "  delta_b = alpha * finite_difference_b\n",
    "  W += delta_W\n",
    "  b += delta_b\n",
    "\n",
    "  if ii == 0 or ii % 100 == 0:\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'{\"Iteration\":>12}: {ii:<6} | {\"W_0\":>1}={W[0,0]:<8.4f} | {\"b\":>1}={b:<8.4f} | {\"R_bar\":>5}={R_bar_old:<8.6f} | {\"Time\":>4}={elapsed_time:<5.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "So it looks like this is learning to do an okay job. A quick inspection of the data tells us that doing perfect discrimination would give an average score of 0.503... per round.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# There are this many cases where striking is the right thing to do\n",
    "np.sum(y1 == 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# And this many cases where striking is the wrong thing to do\n",
    "np.sum(y1 == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# So this the average score per round with perfect discrimination\n",
    "np.sum(y1 == 1) / (len(y1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Without benchmarks, it's hard to know what level is possible given this particular dataset and discrimination task using this particular sensory-behaviour circuit. Not only are we unsure if this is a good result in a general sense, but we also don't know whether our less-than-perfect performance is due to limitations of the circuit architecture (the model in ML terms) or our learning algorithm's inability to find optimal parameters for the given architecture. We could always let the above learning process run for a really long time and see where it stops, but who wants to wait around for results, not us. Let's see if we can come up with some faster learning processes for this sensory-behaviour circuit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_M2\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# 2.1.1.3: Learning to Do the Right Thing - Faster\n",
    "\n",
    "In our simple problem 'propose and reject' was quite effective, let's see how it fares in this more complex problem. First, though, to make our programming and notation a little cleaner we are going 'hide' our bias term. We to do this by augmenting the features to include a feature that always has the value '1'. Then, the 'weight' associated with this feature, which always has a value of '1', will effectively serve as the bias term."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# Before augmentation this is the shape of the feature set\n",
    "Xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# After augmentation there is one extra column of features\n",
    "Xs_aug = np.hstack([Xs, np.ones((Xs.shape[0],1))])\n",
    "print(Xs_aug.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# We need to tweak our eval_params function to work with this augmented\n",
    "# feature set\n",
    "\n",
    "def eval_params_aug(W, x, y):\n",
    "  \"\"\"\n",
    "  evaluates parameters of simple behaviour circuit given inputs and target\n",
    "  outputs, use numpy broadcasting to be fast and concise\n",
    "  Args:\n",
    "    W: (outputs(1) x inputs(64) np.array)\n",
    "       weights between sensory neurons and output neuron\n",
    "    x: (input(64) x batch np.array) sensory input\n",
    "       (can be single input, mini-batch of inputs or the whole batch of inputs)\n",
    "    y: (outputs(1) x batch np.array) target behavioural output\n",
    "       (can be a single target, mini-batch of targets, or whole batch),\n",
    "       needs to correspond to input\n",
    "\n",
    "  Returns:\n",
    "    R_bar: the average/expected reward obtained given the parameters, over the\n",
    "           (mini-)batch of inputs and targets. (mini-batch could be size 1)\n",
    "  \"\"\"\n",
    "  h = np.dot(W,x) # 1 x batch\n",
    "  y_hat = np_sigmoid(h) # 1 x batch\n",
    "  y_score = np.copy(y)\n",
    "  y_score[y_score == 0] = -1\n",
    "  batch_expected_reward = y_score * y_hat\n",
    "  R_bar = np.mean(batch_expected_reward)\n",
    "  return R_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This is what 'propose and reject' looks like for this harder problem:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Propose and Reject Training Loop\n",
    "learn_rng = np.random.default_rng(0)\n",
    "num_learning_episodes = 2000\n",
    "perturbation_scale = 0.1 # std of gaussian perturbations\n",
    "W_init = np.zeros((1,65))\n",
    "W = W_init\n",
    "start_time = time.time()\n",
    "R_bar_best = eval_params_aug(W, Xs_aug.T, y1.T)\n",
    "for ii in range(num_learning_episodes+1):\n",
    "  W_perturbations = learn_rng.normal(0, perturbation_scale, size=(1,65))\n",
    "  #perturb and evaluate each W_j separately\n",
    "  finite_differences_W = np.zeros(W.shape)\n",
    "  for j in range(W_perturbations.shape[1]):\n",
    "    #perturb W\n",
    "    W[0,j] += W_perturbations[0,j]\n",
    "    R_bar_perturbed = eval_params_aug(W, Xs_aug.T, y1.T)\n",
    "    if R_bar_perturbed > R_bar_best:\n",
    "      # leave the perturbation in place and update the best\n",
    "      R_bar_best = R_bar_perturbed\n",
    "    else:\n",
    "      #undo the perturbation\n",
    "      W[0,j] -= W_perturbations[0,j]\n",
    "  if ii == 0 or ii % 100 == 0:\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'{\"Iteration\":>12}: {ii:<6} | {\"W_0\":>1}={W[0,0]:<8.4f} | {\"b\":>1}={W[0,-1]:<8.4f} | {\"R_bar\":>5}={R_bar_best:<8.6f} | {\"Time\":>4}={elapsed_time:<5.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This 'propose and reject' method was faster, in that, although it took as long per iteration, the iterations got to a higher `R_bar` more quickly. Again we could run this for a long time and see where improvement really caps out, but we wont' just now.\n",
    "\n",
    "An important idea for speeding up learning is the idea of a 'mini-batch'. Currently in our learning the impact on reward for a perturbation is measured using the entirety of the dataset available to us. If we were to use a smaller (but representative) sample of this data set for our evaluations of parameter perturbations, we could potentially speed things up significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "Xs_aug.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Our dataset consists of 5620 examples to learn from. This size means the dataset can be nicely broken down into 10 mini-batches of 562. Let's find out how much faster our evaluation function is when using a mini-batch that is ten times smaller."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "W = np.zeros((1,65))\n",
    "%timeit eval_params_aug(W, Xs_aug[:562,:].T, y1[:562].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "%timeit eval_params_aug(W, Xs_aug.T, y1.T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We observe a 2-3x speed up in this case. One thing to notice is that this was not a 10x speedup. This is due to the 'algorithmic efficiencies of scale' inherent in our heavily optimized evaluation function, which utilizes numpy broadcasting. These efficiencies of scale are tied to underlying hardware implementations of the operations. Thus in practical ML contexts choosing a 'good' mini-batch size requires consideration of hardware specific efficiencies of scale, to answer the question how much worse are my parameter updates versus how much faster are they for a given mini-batch size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title Mini-Batched Measure and Update Training Loop\n",
    "learn_rng = np.random.default_rng(0)\n",
    "num_epochs = 800\n",
    "alpha = 0.5 #learning rate or step size\n",
    "perturbation_scale = 0.001 # std of gaussian perturbations\n",
    "num_batches = 10  # Number of mini-batches\n",
    "batch_size = 562  # Size of each mini-batch\n",
    "W_init = np.zeros((1,65))\n",
    "W = W_init\n",
    "start_time = time.time()\n",
    "indices = np.arange(Xs_aug.shape[0])\n",
    "for epoch in range(num_epochs):\n",
    "  learn_rng.shuffle(indices)  # Shuffle the indices for each epoch\n",
    "  for batch in range(num_batches):\n",
    "    # Select a mini-batch for this iteration\n",
    "    batch_indices = indices[batch * batch_size : (batch + 1) * batch_size]\n",
    "    Xs_batch = Xs_aug[batch_indices, :].T\n",
    "    y1_batch = y1[batch_indices].T\n",
    "    R_bar_old = eval_params_aug(W, Xs_batch, y1_batch)\n",
    "    W_perturbations = learn_rng.normal(0, perturbation_scale, size=(1,65))\n",
    "    #perturb and evaluate each W_j separately\n",
    "    finite_differences_W = np.zeros(W.shape)\n",
    "    for jj in range(W_perturbations.shape[1]):\n",
    "      original_value = W[0,jj]\n",
    "      W[0, jj] += W_perturbations[0, jj]\n",
    "      R_bar_perturbed_Wj = eval_params_aug(W, Xs_batch, y1_batch)\n",
    "      finite_differences_W[0,jj] = (R_bar_perturbed_Wj - R_bar_old) / W_perturbations[0,jj]\n",
    "      W[0,jj] = original_value  # Revert the perturbation\n",
    "\n",
    "    delta_W = alpha * finite_differences_W\n",
    "    W += delta_W\n",
    "\n",
    "  if epoch == 0 or (epoch + 1) % 50 == 0:\n",
    "    R_bar_full_batch = eval_params_aug(W, Xs_aug.T, y1.T)\n",
    "    elapsed_time = time.time() - start_time\n",
    "    print(f'Epoch {epoch + 1}/{num_epochs} completed | Full Batch R_bar: {R_bar_full_batch:.6f} | Time elapsed: {elapsed_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Applying the mini-batch idea to the 'measure and update' process made it quicker, and perhaps it even performed a bit better than 'propose and reject'. However, it's important to note that comparisons between algorithms is challenging, as algorithm performance often depends heavily on the choice of meta-parameters, such as learning rate, perturbation scale, mini-batch size, etc., relative to the dataset and underlying model being optimized."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_M3\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# 2.1.1.4 Learning to Do the Right Thing - Better - Stronger\n",
    "One thing that could be holding back performance on this discrimination problem is that our algorithms are not capable of finding the optimal parameters for the given model, but... we don't really think that is the case here. Another possibility is that our simple sensory-behaviour circuit is not flexible or complex enough to fully discriminate between the two types of input. There is good reason to think that this might be the case. Our current sensory-behavioural circuit is effectively equivalent to logistic regression, i.e. each feature can either inhibit or potentiate striking behaviour to varying degrees, but there is no possibility for conditional interaction between features. By 'conditional interaction,' we mean a scenario where, for instance, feature 1 typically inhibits the behavior, except when feature 2 is positive, under which condition feature 1 becomes potentiating. These kinds of feature interactions are impossible in the current model. One way to allow for such interactions is to augment the base set of features with composite features, e.g. incorporate all the pairwise products of the existing feature set, so that instead of 65 features (bias included) we have $(65^2 - 1) = 4224$ features to work with. This could work, but what if we want something that depends on the interaction of more than 2 features, adding higher order polynomial terms will quickly make the problem intractable (Reference appendix section on why hidden layers not polynomials if we do that). If we had some mechanistically grounded understanding or hypothesis about the relationship between the features and label could might be able to cherry pick some small subset of higher order interaction terms, but the ML/supervised learning framework is in large part about automating the feature selection processes based on the data alone. In turns out that instead of resorting the regression on polynomial terms to capture feature interactions, there is a much more compact and expressive way of allowing for feature interactions. The idea is to allow for feature interactions to emerge as needed in a 'hidden' computational layer of our highly abstracted neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "As before $\\mathbf{x}$ is the raw sensory input (vector) in a given episode and each element of $\\mathbf{x}$ corresponds to the activation level and firing rate of a single photosensitive neuron.\n",
    "These input neurons are then connected by synapses to a 'hidden layer' of intermediate computational neurons, say 10 of them. The activation level of these hidden layer neurons is computed as\n",
    "$$\\mathbf{h} = \\sigma(\\mathbf{W}_{in} \\cdot \\mathbf{x})$$\n",
    "Now $\\mathbf{W}_{in}$ is a matrix of synaptic weights between the input neurons and the hidden layer neurons, and $\\cdot$ denotes standard matrix vector multiplication. (In this case $\\mathbf{W}$ has shape $10 \\times 64$. Each the values in the $i^{th}$ row of $\\mathbf{W}_{in}$ given the sign and strength of the connections coming into the $i^{th}$ element of $h$ and similarly each value in the $j^{th}$ column of $\\mathbf{W}_{in}$ corresponds to connection strengths coming out of the $j^{th}$ sensory input neuron.)  We still us $\\sigma$ to represent the standard logistic sigmoid function, but in these case applied elementwise the vector output of the product $\\mathbf{W}_{in} \\cdot \\mathbf{x}$. Then much as before our striking probability is computed as\n",
    "$$y = \\mathbf{W}_{out} \\cdot \\mathbf{h}$$\n",
    "and\n",
    "$$ \\Pr \\{\\text{strike}\\} = \\sigma(y) $$\n",
    "$$ \\Pr \\{\\text{no strike}\\} = 1 - \\sigma(y)$$\n",
    "Here $\\mathbf{W}_{out}$ has shape $1  \\times 10$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We will need to write a new eval params function for this new model, let's do it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "def eval_params_hidden(W_in, W_out, x, y):\n",
    "  \"\"\"\n",
    "  evaluates parameters of simple behaviour circuit given inputs and target\n",
    "  outputs, use numpy broadcasting to be fast and concise\n",
    "  Args:\n",
    "    W_in: (hidden-neurons(20) x inputs(65) np.array)\n",
    "           weights between sensory neurons and hidden layer neurons\n",
    "    W_out: (output(1) x hidden-neurons(20) np.array)\n",
    "           weights between hidden layer neurons and output\n",
    "    x: (input(64) x batch np.array) sensory input\n",
    "       (can be single input, mini-batch of inputs or the whole batch of inputs)\n",
    "    y: (outputs(1) x batch np.array) target behavioural output\n",
    "       (can be a single target, mini-batch of targets, or whole batch),\n",
    "       needs to correspond to input\n",
    "\n",
    "  Returns:\n",
    "    R_bar: the average/expected reward obtained given the parameters, over the\n",
    "           (mini-)batch of inputs and targets. (mini-batch could be size 1)\n",
    "  \"\"\"\n",
    "  h = np_sigmoid(np.dot(W_in,x)) # hidden x batch\n",
    "  y_hat = np_sigmoid(np.dot(W_out,h)) # 1 x batch\n",
    "  y_score = np.copy(y)\n",
    "  y_score[y_score == 0] = -1\n",
    "  batch_expected_reward = y_score * y_hat\n",
    "  R_bar = np.mean(batch_expected_reward)\n",
    "  return R_bar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We've got a more complicated circuit with more parameters, how much longer does it take us to evaluate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "W = np.zeros((1,65))\n",
    "%timeit eval_params_aug(W, Xs_aug[:562,:].T, y1[:562].T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "W_in = np.zeros((10,65))\n",
    "W_out = np.zeros((1,10))\n",
    "%timeit eval_params_hidden(W_in, W_out, Xs_aug[:562,:].T, y1[:562].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "We're added a lot more operations here, and now our sensory to behaviour function takes about 4x times longer to evaluate. What if we made our minibatch really small, like 20, so that we had 261 mini-batches each of size 20, how much of a speed up does that give us?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {}
   },
   "outputs": [],
   "source": [
    "%timeit eval_params_hidden(W_in, W_out, Xs_aug[:10,:].T, y1[:10].T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Okay that's starting to be pretty quick again, but we have a lot more parameters to evaluate, $11 \\times 65 = 715$, as contrasted with $65$ from our more simple circuit? Can the mini-batched measure and update training loop, find good parameters is reasonable amount of time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title 10 Hidden Units - Measure and Update Training Loop\n",
    "learn_rng = np.random.default_rng(0)\n",
    "num_epochs = 20\n",
    "alpha = 0.5 #learning rate or step size\n",
    "perturbation_scale = 0.001 # std of gaussian perturbations\n",
    "num_batches = 261  # Number of mini-batches\n",
    "batch_size = 20  # Size of each mini-batch\n",
    "num_hidden_units = 10\n",
    "# initializing both layers as zero leads to some issues, so we\n",
    "# use a Xavier/Glorot random initialization scheme\n",
    "in_init = np.sqrt(6 / (65 + num_hidden_units))\n",
    "W_in_init = learn_rng.uniform(-in_init, in_init, size=(num_hidden_units, 65))\n",
    "out_init = np.sqrt(6 / (10 + 1))\n",
    "W_out_init = learn_rng.uniform(-out_init, out_init, size=(1, num_hidden_units))\n",
    "W_in = W_in_init\n",
    "W_out = W_out_init\n",
    "start_time = time.time()\n",
    "indices = np.arange(Xs_aug.shape[0])\n",
    "for epoch in range(num_epochs):\n",
    "  learn_rng.shuffle(indices)  # Shuffle the indices for each epoch\n",
    "  for batch in range(num_batches):\n",
    "    # Select a mini-batch for this iteration\n",
    "    batch_indices = indices[batch * batch_size : (batch + 1) * batch_size]\n",
    "    Xs_batch = Xs_aug[batch_indices, :].T\n",
    "    y1_batch = y1[batch_indices].T\n",
    "    R_bar_old = eval_params_hidden(W_in, W_out, Xs_batch, y1_batch)\n",
    "    W_in_perturbations = learn_rng.normal(0, perturbation_scale, size=W_in.shape)\n",
    "    W_out_perturbations = learn_rng.normal(0, perturbation_scale, size=W_out.shape)\n",
    "    #perturb and evaluate each parameter separately\n",
    "    finite_differences_W_in = np.zeros(W_in.shape)\n",
    "    for ii in range(W_in_perturbations.shape[0]):\n",
    "      for jj in range(W_in_perturbations.shape[1]):\n",
    "        original_value = W_in[ii,jj]\n",
    "        W_in[ii,jj] += W_in_perturbations[ii,jj] # perturb\n",
    "        R_bar_perturbed = eval_params_hidden(W_in, W_out, Xs_batch, y1_batch) #evaluate\n",
    "        finite_differences_W_in[ii,jj] = (R_bar_perturbed - R_bar_old) / W_in_perturbations[ii,jj]\n",
    "        W_in[ii,jj] = original_value  # Revert the perturbation\n",
    "    finite_differences_W_out = np.zeros(W_out.shape)\n",
    "    for ii in range(W_out_perturbations.shape[0]):\n",
    "      for jj in range(W_out_perturbations.shape[1]):\n",
    "        original_value = W_out[ii,jj]\n",
    "        W_out[ii,jj] += W_out_perturbations[ii,jj] # perturb\n",
    "        R_bar_perturbed = eval_params_hidden(W_in, W_out, Xs_batch, y1_batch) #evaluate\n",
    "        finite_differences_W_out[ii,jj] = (R_bar_perturbed - R_bar_old) / W_out_perturbations[ii,jj]\n",
    "        W_out[ii,jj] = original_value  # Revert the perturbation\n",
    "\n",
    "    delta_W_in = alpha * finite_differences_W_in\n",
    "    W_in += delta_W_in\n",
    "    delta_W_out = alpha * finite_differences_W_out\n",
    "    W_out += delta_W_out\n",
    "\n",
    "  R_bar_full_batch = eval_params_hidden(W_in, W_out, Xs_aug.T, y1.T)\n",
    "  elapsed_time = time.time() - start_time\n",
    "  print(f'Epoch {epoch + 1}/{num_epochs} completed | Full Batch R_bar: {R_bar_full_batch:.6f} | Time elapsed: {elapsed_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "So this new, more complex circuit is great. We're much closer to the theoretical maximum performance of 0.5033807829181495, maybe with a few more hidden units, and a little longer training time we could have perfect discrimination. Let's see what happens when we go up to 20 hidden units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @title 20 Hidden Units - Measure and Update Training Loop\n",
    "learn_rng = np.random.default_rng(0)\n",
    "num_epochs = 20\n",
    "alpha = 0.5 #learning rate or step size\n",
    "perturbation_scale = 0.001 # std of gaussian perturbations\n",
    "num_batches = 261  # Number of mini-batches\n",
    "batch_size = 20  # Size of each mini-batch\n",
    "num_hidden_units = 20\n",
    "# initializing both layers as zero leads to some issues, so we\n",
    "# use a Xavier/Glorot random initialization scheme\n",
    "in_init = np.sqrt(6 / (65 + num_hidden_units))\n",
    "W_in_init = learn_rng.uniform(-in_init, in_init, size=(num_hidden_units, 65))\n",
    "out_init = np.sqrt(6 / (10 + 1))\n",
    "W_out_init = learn_rng.uniform(-out_init, out_init, size=(1, num_hidden_units))\n",
    "W_in = W_in_init\n",
    "W_out = W_out_init\n",
    "start_time = time.time()\n",
    "indices = np.arange(Xs_aug.shape[0])\n",
    "for epoch in range(num_epochs):\n",
    "  learn_rng.shuffle(indices)  # Shuffle the indices for each epoch\n",
    "  for batch in range(num_batches):\n",
    "    # Select a mini-batch for this iteration\n",
    "    batch_indices = indices[batch * batch_size : (batch + 1) * batch_size]\n",
    "    Xs_batch = Xs_aug[batch_indices, :].T\n",
    "    y1_batch = y1[batch_indices].T\n",
    "    R_bar_old = eval_params_hidden(W_in, W_out, Xs_batch, y1_batch)\n",
    "    W_in_perturbations = learn_rng.normal(0, perturbation_scale, size=W_in.shape)\n",
    "    W_out_perturbations = learn_rng.normal(0, perturbation_scale, size=W_out.shape)\n",
    "    #perturb and evaluate each parameter separately\n",
    "    finite_differences_W_in = np.zeros(W_in.shape)\n",
    "    for ii in range(W_in_perturbations.shape[0]):\n",
    "      for jj in range(W_in_perturbations.shape[1]):\n",
    "        original_value = W_in[ii,jj]\n",
    "        W_in[ii,jj] += W_in_perturbations[ii,jj] # perturb\n",
    "        R_bar_perturbed = eval_params_hidden(W_in, W_out, Xs_batch, y1_batch) #evaluate\n",
    "        finite_differences_W_in[ii,jj] = (R_bar_perturbed - R_bar_old) / W_in_perturbations[ii,jj]\n",
    "        W_in[ii,jj] = original_value  # Revert the perturbation\n",
    "    finite_differences_W_out = np.zeros(W_out.shape)\n",
    "    for ii in range(W_out_perturbations.shape[0]):\n",
    "      for jj in range(W_out_perturbations.shape[1]):\n",
    "        original_value = W_out[ii,jj]\n",
    "        W_out[ii,jj] += W_out_perturbations[ii,jj] # perturb\n",
    "        R_bar_perturbed = eval_params_hidden(W_in, W_out, Xs_batch, y1_batch) #evaluate\n",
    "        finite_differences_W_out[ii,jj] = (R_bar_perturbed - R_bar_old) / W_out_perturbations[ii,jj]\n",
    "        W_out[ii,jj] = original_value  # Revert the perturbation\n",
    "\n",
    "    delta_W_in = alpha * finite_differences_W_in\n",
    "    W_in += delta_W_in\n",
    "    delta_W_out = alpha * finite_differences_W_out\n",
    "    W_out += delta_W_out\n",
    "\n",
    "  R_bar_full_batch = eval_params_hidden(W_in, W_out, Xs_aug.T, y1.T)\n",
    "  elapsed_time = time.time() - start_time\n",
    "  print(f'Epoch {epoch + 1}/{num_epochs} completed | Full Batch R_bar: {R_bar_full_batch:.6f} | Time elapsed: {elapsed_time:.2f} seconds')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This more complex circuit get's us even closer to the theoretical maximum performance of 0.5033..., but it's taking longer to get there. This is because there are more parameters to figure out good values for. Consequently, function evaluations take a bit longer, and more significantly, we need many more function evaluations â€” an additional one for each parameter â€” in each iteration. With more hidden units and more time we can likely learn perfect discrimination, but it will take even longer (more than 5 minutes!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "Although the toy neural circuit models in this sequence are a far cry from actual neural circuits, they still provide insight into potential learning processes in the brain. We can imagine a scenario where synaptic strengths between neurons in a circuit undergo small, transient perturbations. The brain might integrate and compare the performance of these perturbations over a learning episode (for example, a day) to previous performance levels. (Though, we leave aside the specifics of how this integration and comparison occur.)\n",
    "\n",
    "If performance improves with a perturbation, synaptic changes could be consolidated in the direction of the perturbation, proportionate to the degree of improvement. Conversely, if performance worsens, changes might be consolidated in the opposite direction, also proportional to the performance decrease. This concept, while still vague, suggests a mechanism of synaptic adjustment based on performance feedback.\n",
    "\n",
    "One critical point to consider is the scalability of such a learning process. The number of learning episodes required for effective optimization grows with the number of parameters in a neural circuit. This implies that 'measure and update' perturbation-based learning cannot be the primary mechanism driving neural plasticity in large, complex neural circuits. This limitation is critical, as life simply isn't long enough to accommodate the learning episodes needed for such extensive optimization.\n",
    "\n",
    "However, as demonstrated in our example, a more complex circuit achieved significantly better performance in the discrimination task, so large complex circuits can be useful. This suggests that even if empirical evidence of perturbation-based learning in the brain exists and its physiological implementation is understood, such processes are unlikely to be the primary drivers of neural plasticity for complex and challenging behaviors.\n",
    "\n",
    "(One counterargument in favor of simple learning rules is that extensive learning might not be necessary if genetic predisposition starts the circuit off close to an optimal parameter configuration. Then subsequently, relatively slow learning processes could 'fine-tune' the neural circuit's configuration. However, as noted in our earlier discussions on evolution, changing environments necessitate that a significant portion of behavior must emerge from learning, thereby limiting the extent to which genetic predispositions can facilitate efficient and adaptive learning.)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "This concludes our sequence on fitting data through perturbations. In the sequence to come, we will see how different tricks and insights can make our learning algorithms faster and more efficient. We close with a thought on how all of this learning is based simply on changes in average reward. These learning algorithms make no use of information about what the right output should have been (compared to what it was) in any specific situation. Could we make more effective parameter updates if we incorporated information about which situations our circuit already yields 'correct' behavior and which ones it does not?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown Submit your feedback\n",
    "content_review(f\"{feedback_prefix}_M4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "execution": {}
   },
   "source": [
    "# Quiz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "execution": {}
   },
   "outputs": [],
   "source": [
    "# @markdown **Run this cell** to take the quiz\n",
    "comprehension_quiz = [\n",
    "  {\n",
    "    \"question\": \"How does the complexity of a neural circuit (number of parameters) impact the number of learning iterations and hence time to learn using a 'measure and update' learning process?\",\n",
    "    \"type\": \"multiple_choice\",\n",
    "    \"answers\": [\n",
    "      {\n",
    "        \"answer\": \"It does not affect the number of iterations required; the process scales well regardless of circuit complexity.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Actually, the the number of iterations required grows with the complexity of the circuit due to more parameters requiring optimization.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"The process requires few learning iterations, by leveraging algorithmic economies of scale\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Contrary to this, an increase in parameters leads the more learning iterations being required.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"The process becomes requires more learning episodes for larger, more complex circuits.\",\n",
    "        \"correct\": True,\n",
    "        \"feedback\": \"Correct! More parameters mean more complexity and thus more learning episodes are needed.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"The number of learning iterations needed is solely dependent on the type of learning task, not the circuit complexity.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Circuit complexity, particularly the number of parameters, plays a significant role in the number of learning iterations needed.\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"Why was the introduction of a 'hidden layer' beneficial in our complex discrimination tasks?\",\n",
    "    \"type\": \"multiple_choice\",\n",
    "    \"answers\": [\n",
    "      {\n",
    "        \"answer\": \"It allowed the model to perform tasks more quickly but with reduced accuracy.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"The hidden layer's primary benefit is not speed at the cost of accuracy, but rather an enhancement in handling complex patterns.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It introduces feature interactions and non-linearities, enabling the model to capture complex patterns.\",\n",
    "        \"correct\": True,\n",
    "        \"feedback\": \"Exactly! Hidden layers allow for complex interactions and non-linear processing of features, which can be crucial for generating behaviour contingent on rich sensory input.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It reduces the number of parameters needed, simplifying the model.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Adding a hidden layer typically increases the number of parameters, adding complexity to the model.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It primarily improves the model's visualization, making it easier to interpret.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"While interpretability is important, this is not an advantage of adding a hidden layer.\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"In the context of machine learning, what is the impact of using a 'mini-batch' approach?\",\n",
    "    \"type\": \"multiple_choice\",\n",
    "    \"answers\": [\n",
    "      {\n",
    "        \"answer\": \"It guarantees a 10x speedup in learning algorithms.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"While mini-batches can speed up learning, the magnitude of this speed-up will depend on choice of mini-batch size and the interaction of this size with underlying algorithmic efficiencies of scale at the hardware implementation level.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It reduces the time for evaluations by using a smaller, representative data sample.\",\n",
    "        \"correct\": True,\n",
    "        \"feedback\": \"Correct! A mini-batch approach uses a smaller subset of data for quicker evaluations, though it introduces some noise to the estimates.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It decreases the accuracy of parameter evaluation\",\n",
    "        \"correct\": True,\n",
    "        \"feedback\": \"Correct! Mini-batches do introduce some noise to parameter evaluation, but is used thoughtfully this usually isn't an issue.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"It eliminates the need for parameter updates in the learning process.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Mini-batches still require parameter updates; they just alter the way data is processed during learning.\"\n",
    "      }\n",
    "    ]\n",
    "  },\n",
    "  {\n",
    "    \"question\": \"What challenge arises when comparing different machine learning algorithms?\",\n",
    "    \"type\": \"multiple_choice\",\n",
    "    \"answers\": [\n",
    "      {\n",
    "        \"answer\": \"Algorithms cannot be compared due to their differing objectives.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"While objectives can vary, this doesn't make comparison impossible; it's more about how different parameters and conditions affect performance.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"All algorithms perform similarly when given the same data and task.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Performance can vary significantly between algorithms depending on their design and the specificities of the task and data.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"Performance is highly dependent on meta-parameter choices, making direct comparisons challenging.\",\n",
    "        \"correct\": True,\n",
    "        \"feedback\": \"Variations in learning rate, perturbation scale, mini-batch size, and other meta-parameters can significantly impact algorithm performance, complicating direct comparisons.\"\n",
    "      },\n",
    "      {\n",
    "        \"answer\": \"Algorithms' performance cannot be measured or quantified.\",\n",
    "        \"correct\": False,\n",
    "        \"feedback\": \"Performance can indeed be measured and quantified, but the challenge lies in accounting for differences in meta-parameters and conditions.\"\n",
    "      }\n",
    "    ]\n",
    "  }\n",
    "]\n",
    "\n",
    "display_quiz(comprehension_quiz)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "include_colab_link": true,
   "machine_shape": "hm",
   "name": "P2C1_Sequence1",
   "provenance": [],
   "toc_visible": true
  },
  "kernel": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
